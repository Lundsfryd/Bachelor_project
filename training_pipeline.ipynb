{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64371899",
   "metadata": {},
   "source": [
    "To do:\n",
    "- Have a look at learning rate and gradient norm clipping which I need to read up on.\n",
    "    - Setting learning rate to 1e-4 from the \"Embedding sweep\" section of the mmBERT paper\n",
    "    - Keeping gradient norm clipping to the default which caps it at 1.0\n",
    "\n",
    "- Hyperparameter tuning (Alpha, learning rate, batch size so on - not sure how to figure this out)\n",
    "    - There is precedence for no hyperparameter tuning from the author of the OG NLI model that DEBATE is based on = Due to computational restrains and the points from this paper, no hyperparameter tuning was performed in this case. The model tuning in itself is also not the primary focus in this paper, but simply serves as a tool for the actual inquiry into blame in the Danish Parliament\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d09f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r \"requirements_bert.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fb794a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/RuneEgeskovTrust#9638/miniconda3/envs/blame/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-10-28 11:50:49.876407: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-28 11:50:49.928281: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-28 11:50:50.915157: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import bitsandbytes\n",
    "import accelerate\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import json\n",
    "from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer, BitsAndBytesConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from keras.losses import binary_crossentropy\n",
    "from sklearn.metrics import accuracy_score, f1_score, average_precision_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdbb29e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at jhu-clsp/mmBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"jhu-clsp/mmBERT-base\"\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "                                        load_in_4bit=True,\n",
    "                                         bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                                         bnb_4bit_quant_type=\"nf4\",\n",
    "                                         bnb_4bit_use_double_quant=True,\n",
    "                                         )\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=quantization_config,\n",
    "    dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2dc543b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,416,096 || all params: 310,947,874 || trainable%: 1.0986\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=16,  # Low-rank dimension\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=\"all-linear\",  # Fine-tuning all linear (classification, attention... layers)\n",
    ")\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2659a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    report_to='wandb',\n",
    "    output_dir='./test_tune_results',\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    learning_rate=1e-4, # Learning rate copied from mmBERT paper on embedding sweep of LR (1e-4) as they found this to perform best\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=128, # Batching at 256 to balance generalization and efficient training\n",
    "    gradient_accumulation_steps=1,  # Gradient of 1 as full batch fits in memory, accumulation then only slows\n",
    "    logging_steps=1,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    bf16=True,  # Enable mixed precision\n",
    "    fp16=False,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=8,\n",
    "    remove_unused_columns=True, # Avoiding manual handling of residual text columns\n",
    "    max_grad_norm=1.0,\n",
    "    disable_tqdm=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e6b6e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], \n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=512, # Padding to 512 to massively cut down on computation compared to base 8,192 tokens. \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2af8187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_bincrossentropy(true, pred, weight_zero = 99.0, weight_one = 1):\n",
    "    \"\"\"\n",
    "    Calculates weighted binary cross entropy. The weights are fixed to represent class imbalance in the dataset.\n",
    "        \n",
    "    For example if there are 10x as many positive classes as negative classes,\n",
    "        if you adjust weight_zero = 1.0, weight_one = 0.1, then false positives \n",
    "        will be penalized 10 times as much as false negatives.\n",
    "\n",
    "    \"\"\"\n",
    "  \n",
    "    # calculate the binary cross entropy\n",
    "    bin_crossentropy = binary_crossentropy(true, pred)\n",
    "    \n",
    "    # apply the weights\n",
    "    weights = true * weight_one + (1. - true) * weight_zero\n",
    "    #weights /= (weight_one + weight_zero) # Normalizing to be more consistent with regular BCE for comparison \n",
    "    weighted_bin_crossentropy = weights * bin_crossentropy \n",
    "\n",
    "    return np.mean(weighted_bin_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94619e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    #From logits to probabilities\n",
    "    probs_2d = np.exp(predictions) / np.exp(predictions).sum(axis=1, keepdims=True)\n",
    "    probs = probs_2d[:, 1]  # positive class extraction\n",
    "    \n",
    "    weigthted_bce = weighted_bincrossentropy(labels, probs)\n",
    "    keras_bce = binary_crossentropy(labels, probs)\n",
    "    keras_bce = float(np.mean(keras_bce.numpy()))  # Converting from keras eagertensor to float value\n",
    "    \n",
    "    # Wrapping all metrics to floats for json serialization during model eval\n",
    "    return {\n",
    "        'keras_BCE': keras_bce,\n",
    "        'weighted BCE': weigthted_bce,\n",
    "        'recall': float(recall_score(labels, probs.round())),\n",
    "        'precision': float(average_precision_score(labels, probs)),\n",
    "        'accuracy': float(accuracy_score(labels, probs.round())), # Need rounding for these two computations (integer required)\n",
    "        'f1': float(f1_score(labels, probs.round(), average='macro')) # macro f1 is better for imbalanced dataset\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1035b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # Sigmoid for binary classification (BCE setup)\n",
    "    if predictions.shape[1] == 1:\n",
    "        probs = 1 / (1 + np.exp(-predictions)).flatten()\n",
    "        print(\"This is the if statement\")\n",
    "    else:\n",
    "        probs = np.exp(predictions[:, 1]) / np.exp(predictions).sum(axis=1)\n",
    "        print(\"This is the else statement\")\n",
    "    \n",
    "    weighted_bce = weighted_bincrossentropy(labels, probs)\n",
    "    keras_bce = binary_crossentropy(labels, probs)\n",
    "    keras_bce = float(np.mean(keras_bce.numpy()))\n",
    "    \n",
    "    preds = probs.round()\n",
    "    return {\n",
    "        'keras_BCE': keras_bce,\n",
    "        'weighted_BCE': weighted_bce,\n",
    "        'recall': float(recall_score(labels, preds)),\n",
    "        'precision': float(precision_score(labels, preds)),\n",
    "        'accuracy': float(accuracy_score(labels, preds)),\n",
    "        'f1': float(f1_score(labels, preds, average='macro'))\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "240cae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # For CrossEntropyLoss with 2 classes, apply softmax\n",
    "    probs = np.exp(predictions) / np.exp(predictions).sum(axis=-1, keepdims=True)\n",
    "    # Get probability of positive class\n",
    "    positive_probs = probs[:, 1]\n",
    "    \n",
    "    # Use threshold for binary predictions\n",
    "    preds = (positive_probs > 0.5).astype(int)\n",
    "    \n",
    "    return {\n",
    "        'recall': float(recall_score(labels, preds)),\n",
    "        'precision': float(precision_score(labels, preds)),\n",
    "        'accuracy': float(accuracy_score(labels, preds)),\n",
    "        'f1': float(f1_score(labels, preds)),\n",
    "        'f1_weighted': float(f1_score(labels, preds, average='weighted'))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0af2ddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claudes shot at trainer\n",
    "train_labels = test_dataframe['label'].tolist()\n",
    "class_counts = Counter(train_labels)\n",
    "total = sum(class_counts.values())\n",
    "weights = [total/(class_counts[0]*2), total/(class_counts[1]*2)]  # Normalized properly\n",
    "class_weights = torch.tensor(weights, dtype=torch.float32)\n",
    "\n",
    "#define custom trainer that uses weigted loss\n",
    "import torch.nn as nn\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        \n",
    "        # Define weighted loss\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=class_weights.to(model.device))\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "726840cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claudes training args\n",
    "training_args = TrainingArguments(\n",
    "    report_to='wandb',\n",
    "    output_dir='./test_tune_results',\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    learning_rate=3e-5,  # Lower for LoRA\n",
    "    num_train_epochs=5,  # More epochs with early stopping\n",
    "    per_device_train_batch_size=32,  # Smaller batches\n",
    "    gradient_accumulation_steps=4,  # Effective batch of 128\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,  # Evaluate more frequently\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    load_best_model_at_end=True,  # CRITICAL: Load best checkpoint\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    bf16=True,  # Enable mixed precision\n",
    "    fp16=False,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=8,\n",
    "    remove_unused_columns=True, # Avoiding manual handling of residual text columns\n",
    "    max_grad_norm=1.0,\n",
    "    disable_tqdm=False,\n",
    ")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71500ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom trainer class (weigthed)\n",
    "from collections import Counter\n",
    "\n",
    "labels = test_dataframe['label'].tolist()\n",
    "class_counts = Counter(labels)\n",
    "total = sum(class_counts.values())\n",
    "\n",
    "# Higher weight = more emphasis\n",
    "weights = [total/class_counts[0], total/class_counts[1]]\n",
    "class_weights = torch.tensor(weights, dtype=torch.float)\n",
    "\n",
    "#define custom trainer that uses weigted loss\n",
    "import torch.nn as nn\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        \n",
    "        # Define weighted loss\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=class_weights.to(model.device))\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c6f08eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=16): 100%|██████████| 258/258 [00:00<00:00, 496.55 examples/s]\n"
     ]
    }
   ],
   "source": [
    "val_dataframe = pd.read_json(\"/work/RuneEgeskovTrust#9638/Bachelor/Bachelor_project/Model_data/validation_set.json\")\n",
    "\n",
    "val_dataframe = val_dataframe[['text', 'label']]\n",
    "\n",
    "val_dataset = Dataset.from_pandas(val_dataframe)\n",
    "\n",
    "tokenized_val = val_dataset.map(tokenize_function, batched=True, num_proc=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00acf585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=16): 100%|██████████| 5000/5000 [00:00<00:00, 8518.89 examples/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataframe = pd.read_json(\"/work/RuneEgeskovTrust#9638/Bachelor/training_data/cleaned_training_data.json\")\n",
    "\n",
    "test_dataframe = test_dataframe[['text', 'label']]\n",
    "\n",
    "test_dataframe = test_dataframe[0:5000]\n",
    "\n",
    "test_dataframe['labels'] = test_dataframe['label']\n",
    "\n",
    "test_dataframe = test_dataframe.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "test_dataset = Dataset.from_pandas(test_dataframe)\n",
    "\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True, num_proc=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4402b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_json(\"/work/RuneEgeskovTrust#9638/Bachelor/training_data/preproc_data_for_tuning_final.json\")\n",
    "\n",
    "dataframe = dataframe[['text', 'label']]\n",
    "\n",
    "dataset = Dataset.from_pandas(dataframe)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True, num_proc=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a36abd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/RuneEgeskovTrust#9638/miniconda3/envs/blame/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 06:37, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.473964</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.847344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.572771</td>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.705357</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.840795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.615699</td>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.724771</td>\n",
       "      <td>0.848837</td>\n",
       "      <td>0.802030</td>\n",
       "      <td>0.851919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.613369</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.712963</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.840428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/RuneEgeskovTrust#9638/miniconda3/envs/blame/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/work/RuneEgeskovTrust#9638/miniconda3/envs/blame/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/work/RuneEgeskovTrust#9638/miniconda3/envs/blame/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=0.3469268417358398, metrics={'train_runtime': 399.474, 'train_samples_per_second': 62.582, 'train_steps_per_second': 0.501, 'total_flos': 8781302323200000.0, 'train_loss': 0.3469268417358398, 'epoch': 5.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Look into learning rates, model is currently overfitting quite drastically (\"small\" test-set)\n",
    "Normalizing weigthed BCE or no?\n",
    "Look into regularization, dropout and early stopping to avoid overfitting\n",
    "'''\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_test,#dataset,\n",
    "    eval_dataset=tokenized_val,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db5fc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the specific checkpoint\n",
    "best_model = AutoModelForSequenceClassification.from_pretrained(\"./full_tune_results/checkpoint-3032\")\n",
    "\n",
    "\n",
    "\n",
    "# Save permanently to a new folder\n",
    "best_model.save_pretrained(\"/work/RuneEgeskovTrust#9638/Bachelor/best_model_epoch2\")\n",
    "tokenizer.save_pretrained(\"/work/RuneEgeskovTrust#9638/Bachelor/best_model_epoch2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdafdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# 1️⃣ Load the base model\n",
    "base_model_name = \"jhu-clsp/mmBERT-base\"  # or whatever your base model is\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(base_model_name)\n",
    "\n",
    "# 2️⃣ Load the LoRA adapter from the 2nd-epoch checkpoint\n",
    "adapter_checkpoint = \"./full_tune_results/checkpoint-3032\"\n",
    "lora_model = PeftModel.from_pretrained(base_model, adapter_checkpoint)\n",
    "\n",
    "# 3️⃣ Merge LoRA weights into the base model\n",
    "merged_model = lora_model.merge_and_unload()\n",
    "\n",
    "# 4️⃣ Save the merged model as a standalone Hugging Face model\n",
    "save_dir = \"/work/RuneEgeskovTrust#9638/Bachelor/merged_model_epoch2\"\n",
    "merged_model.save_pretrained(save_dir)\n",
    "\n",
    "'''\n",
    "# 5️⃣ Save tokenizer too\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb88c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_params = [p for p in merged_model.parameters() if p.requires_grad]\n",
    "print(f\"Trainable parameters after merge: {len(trainable_params)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14401d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeaf63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINE_TUNED_MODEL_NAME = \"mmBlameBERT-pol-DA\"\n",
    "\n",
    "#merged_model = model.merge_and_unload()    # PEFT: incorporates LoRA into base weights\n",
    "merged_dir = f\"/work/RuneEgeskovTrust#9638/Bachelor/{FINE_TUNED_MODEL_NAME}-final-tune\"\n",
    "merged_model.save_pretrained(merged_dir)\n",
    "#tokenizer.save_pretrained(merged_dir)\n",
    "print(\"✓ Merged model saved to:\", merged_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b80786",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"/work/RuneEgeskovTrust#9638/Bachelor/LORA-adapters-for-final-tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadde19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9680560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"/work/RuneEgeskovTrust#9638/Bachelor/Bachelor_project/Final_tune_eval_result.txt\", \"w\") as f:\n",
    "    f.write(str(eval_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d675da03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_json(input_path, output_path=None):\n",
    "    \"\"\"\n",
    "    Preprocesses a JSON file by filtering out entries based on the 'text' key.\n",
    "    \n",
    "    Criteria for deletion:\n",
    "      - 'text' is missing or empty\n",
    "      - 'text' length is <= 3\n",
    "      - 'text' contains '(' or ')'\n",
    "    \n",
    "    Parameters:\n",
    "        input_path (str): Path to the input JSON file.\n",
    "        output_path (str, optional): If provided, saves the filtered JSON here.\n",
    "    \n",
    "    Returns:\n",
    "        list: The filtered list of JSON entries.\n",
    "    \"\"\"\n",
    "    # Load JSON file\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Filter entries\n",
    "    filtered_data = [\n",
    "        entry for entry in data\n",
    "        if 'text' in entry\n",
    "        and entry['text']\n",
    "        and len(entry['text']) > 3\n",
    "        and '(' not in entry['text']\n",
    "        and ')' not in entry['text']\n",
    "    ]\n",
    "\n",
    "    # Optionally save to a new file\n",
    "    if output_path:\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(filtered_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd33ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d743b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_json(\"/work/RuneEgeskovTrust#9638/Bachelor/training_data/cleaned_training_data_3_4_5_temps.json\",\n",
    "\"/work/RuneEgeskovTrust#9638/Bachelor/training_data/preproc_data_for_tuning_final.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
