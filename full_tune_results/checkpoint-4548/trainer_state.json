{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 4548,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0006596306068601583,
      "grad_norm": 4.531986236572266,
      "learning_rate": 0.0001,
      "loss": 1.0457,
      "step": 1
    },
    {
      "epoch": 0.0013192612137203166,
      "grad_norm": 5.067681789398193,
      "learning_rate": 9.997801231310466e-05,
      "loss": 0.9627,
      "step": 2
    },
    {
      "epoch": 0.001978891820580475,
      "grad_norm": 5.772594451904297,
      "learning_rate": 9.995602462620933e-05,
      "loss": 0.7771,
      "step": 3
    },
    {
      "epoch": 0.002638522427440633,
      "grad_norm": 6.303614616394043,
      "learning_rate": 9.993403693931399e-05,
      "loss": 0.8937,
      "step": 4
    },
    {
      "epoch": 0.0032981530343007917,
      "grad_norm": 2.969001531600952,
      "learning_rate": 9.991204925241865e-05,
      "loss": 0.6488,
      "step": 5
    },
    {
      "epoch": 0.00395778364116095,
      "grad_norm": 9.095396041870117,
      "learning_rate": 9.98900615655233e-05,
      "loss": 0.6489,
      "step": 6
    },
    {
      "epoch": 0.004617414248021108,
      "grad_norm": 16.392295837402344,
      "learning_rate": 9.986807387862797e-05,
      "loss": 0.8172,
      "step": 7
    },
    {
      "epoch": 0.005277044854881266,
      "grad_norm": 4.317264556884766,
      "learning_rate": 9.984608619173263e-05,
      "loss": 0.6442,
      "step": 8
    },
    {
      "epoch": 0.005936675461741424,
      "grad_norm": 5.794140815734863,
      "learning_rate": 9.982409850483729e-05,
      "loss": 0.8768,
      "step": 9
    },
    {
      "epoch": 0.006596306068601583,
      "grad_norm": 5.2939019203186035,
      "learning_rate": 9.980211081794196e-05,
      "loss": 0.7239,
      "step": 10
    },
    {
      "epoch": 0.007255936675461741,
      "grad_norm": 6.291360855102539,
      "learning_rate": 9.978012313104662e-05,
      "loss": 0.7026,
      "step": 11
    },
    {
      "epoch": 0.0079155672823219,
      "grad_norm": 4.184798240661621,
      "learning_rate": 9.975813544415129e-05,
      "loss": 0.7767,
      "step": 12
    },
    {
      "epoch": 0.008575197889182058,
      "grad_norm": 3.3040435314178467,
      "learning_rate": 9.973614775725594e-05,
      "loss": 0.6402,
      "step": 13
    },
    {
      "epoch": 0.009234828496042216,
      "grad_norm": 2.6878457069396973,
      "learning_rate": 9.971416007036061e-05,
      "loss": 0.8372,
      "step": 14
    },
    {
      "epoch": 0.009894459102902375,
      "grad_norm": 16.032752990722656,
      "learning_rate": 9.969217238346527e-05,
      "loss": 1.0326,
      "step": 15
    },
    {
      "epoch": 0.010554089709762533,
      "grad_norm": 5.763377666473389,
      "learning_rate": 9.967018469656993e-05,
      "loss": 0.717,
      "step": 16
    },
    {
      "epoch": 0.011213720316622692,
      "grad_norm": 4.459600448608398,
      "learning_rate": 9.964819700967458e-05,
      "loss": 1.0234,
      "step": 17
    },
    {
      "epoch": 0.011873350923482849,
      "grad_norm": 4.630609035491943,
      "learning_rate": 9.962620932277925e-05,
      "loss": 0.78,
      "step": 18
    },
    {
      "epoch": 0.012532981530343008,
      "grad_norm": 3.39028263092041,
      "learning_rate": 9.960422163588391e-05,
      "loss": 0.7027,
      "step": 19
    },
    {
      "epoch": 0.013192612137203167,
      "grad_norm": 5.187651634216309,
      "learning_rate": 9.958223394898857e-05,
      "loss": 0.9289,
      "step": 20
    },
    {
      "epoch": 0.013852242744063324,
      "grad_norm": 12.003926277160645,
      "learning_rate": 9.956024626209324e-05,
      "loss": 0.7179,
      "step": 21
    },
    {
      "epoch": 0.014511873350923483,
      "grad_norm": 5.073107719421387,
      "learning_rate": 9.95382585751979e-05,
      "loss": 0.8415,
      "step": 22
    },
    {
      "epoch": 0.015171503957783642,
      "grad_norm": 7.556689262390137,
      "learning_rate": 9.951627088830255e-05,
      "loss": 0.873,
      "step": 23
    },
    {
      "epoch": 0.0158311345646438,
      "grad_norm": 6.803813457489014,
      "learning_rate": 9.949428320140721e-05,
      "loss": 0.7995,
      "step": 24
    },
    {
      "epoch": 0.016490765171503958,
      "grad_norm": 8.11173152923584,
      "learning_rate": 9.947229551451188e-05,
      "loss": 0.9972,
      "step": 25
    },
    {
      "epoch": 0.017150395778364115,
      "grad_norm": 10.537644386291504,
      "learning_rate": 9.945030782761654e-05,
      "loss": 0.6363,
      "step": 26
    },
    {
      "epoch": 0.017810026385224276,
      "grad_norm": 3.1294376850128174,
      "learning_rate": 9.94283201407212e-05,
      "loss": 0.7346,
      "step": 27
    },
    {
      "epoch": 0.018469656992084433,
      "grad_norm": 2.057481527328491,
      "learning_rate": 9.940633245382587e-05,
      "loss": 0.6061,
      "step": 28
    },
    {
      "epoch": 0.01912928759894459,
      "grad_norm": 1.193145990371704,
      "learning_rate": 9.938434476693052e-05,
      "loss": 0.5502,
      "step": 29
    },
    {
      "epoch": 0.01978891820580475,
      "grad_norm": 2.5944647789001465,
      "learning_rate": 9.936235708003518e-05,
      "loss": 0.6297,
      "step": 30
    },
    {
      "epoch": 0.020448548812664908,
      "grad_norm": 3.0091919898986816,
      "learning_rate": 9.934036939313984e-05,
      "loss": 0.6462,
      "step": 31
    },
    {
      "epoch": 0.021108179419525065,
      "grad_norm": 3.257093667984009,
      "learning_rate": 9.93183817062445e-05,
      "loss": 0.7555,
      "step": 32
    },
    {
      "epoch": 0.021767810026385226,
      "grad_norm": 3.5682806968688965,
      "learning_rate": 9.929639401934916e-05,
      "loss": 0.7987,
      "step": 33
    },
    {
      "epoch": 0.022427440633245383,
      "grad_norm": 1.2468340396881104,
      "learning_rate": 9.927440633245383e-05,
      "loss": 0.5583,
      "step": 34
    },
    {
      "epoch": 0.02308707124010554,
      "grad_norm": 2.471144676208496,
      "learning_rate": 9.925241864555849e-05,
      "loss": 0.6557,
      "step": 35
    },
    {
      "epoch": 0.023746701846965697,
      "grad_norm": 2.374011993408203,
      "learning_rate": 9.923043095866316e-05,
      "loss": 0.5802,
      "step": 36
    },
    {
      "epoch": 0.024406332453825858,
      "grad_norm": 2.9550600051879883,
      "learning_rate": 9.920844327176782e-05,
      "loss": 0.644,
      "step": 37
    },
    {
      "epoch": 0.025065963060686015,
      "grad_norm": 2.389709234237671,
      "learning_rate": 9.918645558487248e-05,
      "loss": 0.6308,
      "step": 38
    },
    {
      "epoch": 0.025725593667546173,
      "grad_norm": 3.5071465969085693,
      "learning_rate": 9.916446789797715e-05,
      "loss": 0.7297,
      "step": 39
    },
    {
      "epoch": 0.026385224274406333,
      "grad_norm": 8.733741760253906,
      "learning_rate": 9.91424802110818e-05,
      "loss": 0.7281,
      "step": 40
    },
    {
      "epoch": 0.02704485488126649,
      "grad_norm": 2.8885374069213867,
      "learning_rate": 9.912049252418646e-05,
      "loss": 0.6053,
      "step": 41
    },
    {
      "epoch": 0.027704485488126648,
      "grad_norm": 3.98757266998291,
      "learning_rate": 9.909850483729112e-05,
      "loss": 0.5921,
      "step": 42
    },
    {
      "epoch": 0.02836411609498681,
      "grad_norm": 2.6323204040527344,
      "learning_rate": 9.907651715039579e-05,
      "loss": 0.5386,
      "step": 43
    },
    {
      "epoch": 0.029023746701846966,
      "grad_norm": 2.8174002170562744,
      "learning_rate": 9.905452946350044e-05,
      "loss": 0.565,
      "step": 44
    },
    {
      "epoch": 0.029683377308707123,
      "grad_norm": 6.7299065589904785,
      "learning_rate": 9.90325417766051e-05,
      "loss": 0.6746,
      "step": 45
    },
    {
      "epoch": 0.030343007915567283,
      "grad_norm": 2.758044481277466,
      "learning_rate": 9.901055408970977e-05,
      "loss": 0.4941,
      "step": 46
    },
    {
      "epoch": 0.03100263852242744,
      "grad_norm": 1.7152965068817139,
      "learning_rate": 9.898856640281443e-05,
      "loss": 0.5033,
      "step": 47
    },
    {
      "epoch": 0.0316622691292876,
      "grad_norm": 1.4907680749893188,
      "learning_rate": 9.896657871591909e-05,
      "loss": 0.5776,
      "step": 48
    },
    {
      "epoch": 0.032321899736147755,
      "grad_norm": 1.680080533027649,
      "learning_rate": 9.894459102902374e-05,
      "loss": 0.5173,
      "step": 49
    },
    {
      "epoch": 0.032981530343007916,
      "grad_norm": 1.9971681833267212,
      "learning_rate": 9.892260334212841e-05,
      "loss": 0.6037,
      "step": 50
    },
    {
      "epoch": 0.033641160949868076,
      "grad_norm": 9.688085556030273,
      "learning_rate": 9.890061565523307e-05,
      "loss": 0.5462,
      "step": 51
    },
    {
      "epoch": 0.03430079155672823,
      "grad_norm": 3.970235824584961,
      "learning_rate": 9.887862796833773e-05,
      "loss": 0.6729,
      "step": 52
    },
    {
      "epoch": 0.03496042216358839,
      "grad_norm": 2.120004653930664,
      "learning_rate": 9.88566402814424e-05,
      "loss": 0.5057,
      "step": 53
    },
    {
      "epoch": 0.03562005277044855,
      "grad_norm": 10.357929229736328,
      "learning_rate": 9.883465259454706e-05,
      "loss": 0.5715,
      "step": 54
    },
    {
      "epoch": 0.036279683377308705,
      "grad_norm": 9.115762710571289,
      "learning_rate": 9.881266490765173e-05,
      "loss": 0.4746,
      "step": 55
    },
    {
      "epoch": 0.036939313984168866,
      "grad_norm": 5.591172218322754,
      "learning_rate": 9.879067722075638e-05,
      "loss": 0.6536,
      "step": 56
    },
    {
      "epoch": 0.037598944591029027,
      "grad_norm": 2.4644813537597656,
      "learning_rate": 9.876868953386105e-05,
      "loss": 0.5088,
      "step": 57
    },
    {
      "epoch": 0.03825857519788918,
      "grad_norm": 6.665093421936035,
      "learning_rate": 9.874670184696571e-05,
      "loss": 0.8179,
      "step": 58
    },
    {
      "epoch": 0.03891820580474934,
      "grad_norm": 5.4693498611450195,
      "learning_rate": 9.872471416007037e-05,
      "loss": 0.5125,
      "step": 59
    },
    {
      "epoch": 0.0395778364116095,
      "grad_norm": 2.9178969860076904,
      "learning_rate": 9.870272647317502e-05,
      "loss": 0.5517,
      "step": 60
    },
    {
      "epoch": 0.040237467018469655,
      "grad_norm": 2.3586549758911133,
      "learning_rate": 9.86807387862797e-05,
      "loss": 0.4732,
      "step": 61
    },
    {
      "epoch": 0.040897097625329816,
      "grad_norm": 2.713927745819092,
      "learning_rate": 9.865875109938435e-05,
      "loss": 0.4758,
      "step": 62
    },
    {
      "epoch": 0.04155672823218998,
      "grad_norm": 1.9510691165924072,
      "learning_rate": 9.863676341248901e-05,
      "loss": 0.3906,
      "step": 63
    },
    {
      "epoch": 0.04221635883905013,
      "grad_norm": 3.3277153968811035,
      "learning_rate": 9.861477572559368e-05,
      "loss": 0.4649,
      "step": 64
    },
    {
      "epoch": 0.04287598944591029,
      "grad_norm": 4.11034631729126,
      "learning_rate": 9.859278803869834e-05,
      "loss": 0.546,
      "step": 65
    },
    {
      "epoch": 0.04353562005277045,
      "grad_norm": 5.576740741729736,
      "learning_rate": 9.857080035180299e-05,
      "loss": 0.5581,
      "step": 66
    },
    {
      "epoch": 0.044195250659630606,
      "grad_norm": 4.263465404510498,
      "learning_rate": 9.854881266490765e-05,
      "loss": 0.574,
      "step": 67
    },
    {
      "epoch": 0.044854881266490766,
      "grad_norm": 3.7017147541046143,
      "learning_rate": 9.852682497801232e-05,
      "loss": 0.3851,
      "step": 68
    },
    {
      "epoch": 0.04551451187335093,
      "grad_norm": 3.178976058959961,
      "learning_rate": 9.850483729111698e-05,
      "loss": 0.3864,
      "step": 69
    },
    {
      "epoch": 0.04617414248021108,
      "grad_norm": 8.117331504821777,
      "learning_rate": 9.848284960422163e-05,
      "loss": 0.5726,
      "step": 70
    },
    {
      "epoch": 0.04683377308707124,
      "grad_norm": 3.4088168144226074,
      "learning_rate": 9.846086191732629e-05,
      "loss": 0.4248,
      "step": 71
    },
    {
      "epoch": 0.047493403693931395,
      "grad_norm": 2.6418685913085938,
      "learning_rate": 9.843887423043096e-05,
      "loss": 0.3513,
      "step": 72
    },
    {
      "epoch": 0.048153034300791556,
      "grad_norm": 1.60867178440094,
      "learning_rate": 9.841688654353562e-05,
      "loss": 0.3322,
      "step": 73
    },
    {
      "epoch": 0.048812664907651716,
      "grad_norm": 3.885395050048828,
      "learning_rate": 9.839489885664029e-05,
      "loss": 0.3567,
      "step": 74
    },
    {
      "epoch": 0.04947229551451187,
      "grad_norm": 2.9260194301605225,
      "learning_rate": 9.837291116974495e-05,
      "loss": 0.3209,
      "step": 75
    },
    {
      "epoch": 0.05013192612137203,
      "grad_norm": 6.384348392486572,
      "learning_rate": 9.835092348284962e-05,
      "loss": 0.3784,
      "step": 76
    },
    {
      "epoch": 0.05079155672823219,
      "grad_norm": 2.570908784866333,
      "learning_rate": 9.832893579595427e-05,
      "loss": 0.2482,
      "step": 77
    },
    {
      "epoch": 0.051451187335092345,
      "grad_norm": 16.984237670898438,
      "learning_rate": 9.830694810905893e-05,
      "loss": 1.384,
      "step": 78
    },
    {
      "epoch": 0.052110817941952506,
      "grad_norm": 3.1267828941345215,
      "learning_rate": 9.82849604221636e-05,
      "loss": 0.3955,
      "step": 79
    },
    {
      "epoch": 0.052770448548812667,
      "grad_norm": 61.00532150268555,
      "learning_rate": 9.826297273526826e-05,
      "loss": 1.3551,
      "step": 80
    },
    {
      "epoch": 0.05343007915567282,
      "grad_norm": 3.1040701866149902,
      "learning_rate": 9.824098504837292e-05,
      "loss": 0.3821,
      "step": 81
    },
    {
      "epoch": 0.05408970976253298,
      "grad_norm": 4.638526439666748,
      "learning_rate": 9.821899736147759e-05,
      "loss": 0.5077,
      "step": 82
    },
    {
      "epoch": 0.05474934036939314,
      "grad_norm": 6.687178611755371,
      "learning_rate": 9.819700967458224e-05,
      "loss": 0.3525,
      "step": 83
    },
    {
      "epoch": 0.055408970976253295,
      "grad_norm": 13.174142837524414,
      "learning_rate": 9.81750219876869e-05,
      "loss": 0.5467,
      "step": 84
    },
    {
      "epoch": 0.056068601583113456,
      "grad_norm": 1.9921770095825195,
      "learning_rate": 9.815303430079156e-05,
      "loss": 0.2906,
      "step": 85
    },
    {
      "epoch": 0.05672823218997362,
      "grad_norm": 3.9600632190704346,
      "learning_rate": 9.813104661389623e-05,
      "loss": 0.2594,
      "step": 86
    },
    {
      "epoch": 0.05738786279683377,
      "grad_norm": 3.9642388820648193,
      "learning_rate": 9.810905892700088e-05,
      "loss": 0.3104,
      "step": 87
    },
    {
      "epoch": 0.05804749340369393,
      "grad_norm": 1.7085200548171997,
      "learning_rate": 9.808707124010554e-05,
      "loss": 0.1688,
      "step": 88
    },
    {
      "epoch": 0.05870712401055409,
      "grad_norm": 4.156135559082031,
      "learning_rate": 9.80650835532102e-05,
      "loss": 0.2328,
      "step": 89
    },
    {
      "epoch": 0.059366754617414245,
      "grad_norm": 5.6058878898620605,
      "learning_rate": 9.804309586631487e-05,
      "loss": 0.3186,
      "step": 90
    },
    {
      "epoch": 0.060026385224274406,
      "grad_norm": 6.102548599243164,
      "learning_rate": 9.802110817941953e-05,
      "loss": 0.2986,
      "step": 91
    },
    {
      "epoch": 0.06068601583113457,
      "grad_norm": 16.016244888305664,
      "learning_rate": 9.799912049252418e-05,
      "loss": 0.399,
      "step": 92
    },
    {
      "epoch": 0.06134564643799472,
      "grad_norm": 8.95863151550293,
      "learning_rate": 9.797713280562885e-05,
      "loss": 0.4655,
      "step": 93
    },
    {
      "epoch": 0.06200527704485488,
      "grad_norm": 3.887929916381836,
      "learning_rate": 9.795514511873351e-05,
      "loss": 0.2281,
      "step": 94
    },
    {
      "epoch": 0.06266490765171503,
      "grad_norm": 4.085494518280029,
      "learning_rate": 9.793315743183817e-05,
      "loss": 0.2395,
      "step": 95
    },
    {
      "epoch": 0.0633245382585752,
      "grad_norm": 17.440839767456055,
      "learning_rate": 9.791116974494284e-05,
      "loss": 1.9235,
      "step": 96
    },
    {
      "epoch": 0.06398416886543536,
      "grad_norm": 8.297568321228027,
      "learning_rate": 9.78891820580475e-05,
      "loss": 0.6553,
      "step": 97
    },
    {
      "epoch": 0.06464379947229551,
      "grad_norm": 3.6152451038360596,
      "learning_rate": 9.786719437115217e-05,
      "loss": 0.284,
      "step": 98
    },
    {
      "epoch": 0.06530343007915568,
      "grad_norm": 12.869908332824707,
      "learning_rate": 9.784520668425682e-05,
      "loss": 0.3809,
      "step": 99
    },
    {
      "epoch": 0.06596306068601583,
      "grad_norm": 8.249813079833984,
      "learning_rate": 9.782321899736149e-05,
      "loss": 0.3895,
      "step": 100
    },
    {
      "epoch": 0.06662269129287599,
      "grad_norm": 7.127250671386719,
      "learning_rate": 9.780123131046615e-05,
      "loss": 0.3677,
      "step": 101
    },
    {
      "epoch": 0.06728232189973615,
      "grad_norm": 11.182333946228027,
      "learning_rate": 9.777924362357081e-05,
      "loss": 0.7908,
      "step": 102
    },
    {
      "epoch": 0.0679419525065963,
      "grad_norm": 22.779510498046875,
      "learning_rate": 9.775725593667546e-05,
      "loss": 0.8439,
      "step": 103
    },
    {
      "epoch": 0.06860158311345646,
      "grad_norm": 3.75848650932312,
      "learning_rate": 9.773526824978013e-05,
      "loss": 0.21,
      "step": 104
    },
    {
      "epoch": 0.06926121372031663,
      "grad_norm": 11.627514839172363,
      "learning_rate": 9.771328056288479e-05,
      "loss": 0.4251,
      "step": 105
    },
    {
      "epoch": 0.06992084432717678,
      "grad_norm": 17.779827117919922,
      "learning_rate": 9.769129287598945e-05,
      "loss": 0.9118,
      "step": 106
    },
    {
      "epoch": 0.07058047493403694,
      "grad_norm": 6.356856822967529,
      "learning_rate": 9.76693051890941e-05,
      "loss": 0.3861,
      "step": 107
    },
    {
      "epoch": 0.0712401055408971,
      "grad_norm": 5.841317176818848,
      "learning_rate": 9.764731750219878e-05,
      "loss": 0.4019,
      "step": 108
    },
    {
      "epoch": 0.07189973614775726,
      "grad_norm": 4.2984514236450195,
      "learning_rate": 9.762532981530343e-05,
      "loss": 0.2313,
      "step": 109
    },
    {
      "epoch": 0.07255936675461741,
      "grad_norm": 1.7280741930007935,
      "learning_rate": 9.760334212840809e-05,
      "loss": 0.2054,
      "step": 110
    },
    {
      "epoch": 0.07321899736147758,
      "grad_norm": 8.101102828979492,
      "learning_rate": 9.758135444151276e-05,
      "loss": 0.2712,
      "step": 111
    },
    {
      "epoch": 0.07387862796833773,
      "grad_norm": 8.789128303527832,
      "learning_rate": 9.755936675461742e-05,
      "loss": 0.5046,
      "step": 112
    },
    {
      "epoch": 0.07453825857519789,
      "grad_norm": 6.344821929931641,
      "learning_rate": 9.753737906772207e-05,
      "loss": 0.2059,
      "step": 113
    },
    {
      "epoch": 0.07519788918205805,
      "grad_norm": 20.985668182373047,
      "learning_rate": 9.751539138082673e-05,
      "loss": 1.1103,
      "step": 114
    },
    {
      "epoch": 0.0758575197889182,
      "grad_norm": 10.115891456604004,
      "learning_rate": 9.74934036939314e-05,
      "loss": 0.2982,
      "step": 115
    },
    {
      "epoch": 0.07651715039577836,
      "grad_norm": 11.470943450927734,
      "learning_rate": 9.747141600703606e-05,
      "loss": 0.6502,
      "step": 116
    },
    {
      "epoch": 0.07717678100263853,
      "grad_norm": 3.588383436203003,
      "learning_rate": 9.744942832014073e-05,
      "loss": 0.225,
      "step": 117
    },
    {
      "epoch": 0.07783641160949868,
      "grad_norm": 3.0699503421783447,
      "learning_rate": 9.742744063324539e-05,
      "loss": 0.2426,
      "step": 118
    },
    {
      "epoch": 0.07849604221635884,
      "grad_norm": 4.775482654571533,
      "learning_rate": 9.740545294635006e-05,
      "loss": 0.2953,
      "step": 119
    },
    {
      "epoch": 0.079155672823219,
      "grad_norm": 4.584918975830078,
      "learning_rate": 9.738346525945471e-05,
      "loss": 0.3863,
      "step": 120
    },
    {
      "epoch": 0.07981530343007916,
      "grad_norm": 5.9860758781433105,
      "learning_rate": 9.736147757255937e-05,
      "loss": 0.2795,
      "step": 121
    },
    {
      "epoch": 0.08047493403693931,
      "grad_norm": 4.324174880981445,
      "learning_rate": 9.733948988566404e-05,
      "loss": 0.4418,
      "step": 122
    },
    {
      "epoch": 0.08113456464379948,
      "grad_norm": 9.555084228515625,
      "learning_rate": 9.73175021987687e-05,
      "loss": 0.6746,
      "step": 123
    },
    {
      "epoch": 0.08179419525065963,
      "grad_norm": 13.854504585266113,
      "learning_rate": 9.729551451187336e-05,
      "loss": 0.6313,
      "step": 124
    },
    {
      "epoch": 0.08245382585751979,
      "grad_norm": 8.088510513305664,
      "learning_rate": 9.727352682497801e-05,
      "loss": 0.3207,
      "step": 125
    },
    {
      "epoch": 0.08311345646437995,
      "grad_norm": 6.426117420196533,
      "learning_rate": 9.725153913808268e-05,
      "loss": 0.2712,
      "step": 126
    },
    {
      "epoch": 0.08377308707124011,
      "grad_norm": 4.953434467315674,
      "learning_rate": 9.722955145118734e-05,
      "loss": 0.3994,
      "step": 127
    },
    {
      "epoch": 0.08443271767810026,
      "grad_norm": 4.749808311462402,
      "learning_rate": 9.7207563764292e-05,
      "loss": 0.2691,
      "step": 128
    },
    {
      "epoch": 0.08509234828496043,
      "grad_norm": 6.768006801605225,
      "learning_rate": 9.718557607739667e-05,
      "loss": 0.2721,
      "step": 129
    },
    {
      "epoch": 0.08575197889182058,
      "grad_norm": 3.2697718143463135,
      "learning_rate": 9.716358839050132e-05,
      "loss": 0.1877,
      "step": 130
    },
    {
      "epoch": 0.08641160949868074,
      "grad_norm": 10.125407218933105,
      "learning_rate": 9.714160070360598e-05,
      "loss": 0.8895,
      "step": 131
    },
    {
      "epoch": 0.0870712401055409,
      "grad_norm": 5.645936489105225,
      "learning_rate": 9.711961301671064e-05,
      "loss": 0.26,
      "step": 132
    },
    {
      "epoch": 0.08773087071240106,
      "grad_norm": 5.156286239624023,
      "learning_rate": 9.709762532981531e-05,
      "loss": 0.3277,
      "step": 133
    },
    {
      "epoch": 0.08839050131926121,
      "grad_norm": 4.345258712768555,
      "learning_rate": 9.707563764291997e-05,
      "loss": 0.3462,
      "step": 134
    },
    {
      "epoch": 0.08905013192612138,
      "grad_norm": 2.528203248977661,
      "learning_rate": 9.705364995602462e-05,
      "loss": 0.2541,
      "step": 135
    },
    {
      "epoch": 0.08970976253298153,
      "grad_norm": 3.7870678901672363,
      "learning_rate": 9.70316622691293e-05,
      "loss": 0.2907,
      "step": 136
    },
    {
      "epoch": 0.09036939313984169,
      "grad_norm": 2.0809385776519775,
      "learning_rate": 9.700967458223395e-05,
      "loss": 0.1854,
      "step": 137
    },
    {
      "epoch": 0.09102902374670185,
      "grad_norm": 10.749056816101074,
      "learning_rate": 9.698768689533861e-05,
      "loss": 0.417,
      "step": 138
    },
    {
      "epoch": 0.09168865435356201,
      "grad_norm": 4.189787864685059,
      "learning_rate": 9.696569920844328e-05,
      "loss": 0.2488,
      "step": 139
    },
    {
      "epoch": 0.09234828496042216,
      "grad_norm": 7.159988880157471,
      "learning_rate": 9.694371152154795e-05,
      "loss": 0.2837,
      "step": 140
    },
    {
      "epoch": 0.09300791556728233,
      "grad_norm": 3.8593969345092773,
      "learning_rate": 9.69217238346526e-05,
      "loss": 0.2673,
      "step": 141
    },
    {
      "epoch": 0.09366754617414248,
      "grad_norm": 58.34790802001953,
      "learning_rate": 9.689973614775726e-05,
      "loss": 0.2787,
      "step": 142
    },
    {
      "epoch": 0.09432717678100264,
      "grad_norm": 16.038251876831055,
      "learning_rate": 9.687774846086192e-05,
      "loss": 0.8106,
      "step": 143
    },
    {
      "epoch": 0.09498680738786279,
      "grad_norm": 14.047736167907715,
      "learning_rate": 9.685576077396659e-05,
      "loss": 0.6585,
      "step": 144
    },
    {
      "epoch": 0.09564643799472296,
      "grad_norm": 22.948694229125977,
      "learning_rate": 9.683377308707125e-05,
      "loss": 0.8468,
      "step": 145
    },
    {
      "epoch": 0.09630606860158311,
      "grad_norm": 1.706349492073059,
      "learning_rate": 9.68117854001759e-05,
      "loss": 0.1385,
      "step": 146
    },
    {
      "epoch": 0.09696569920844327,
      "grad_norm": 4.248431205749512,
      "learning_rate": 9.678979771328057e-05,
      "loss": 0.1875,
      "step": 147
    },
    {
      "epoch": 0.09762532981530343,
      "grad_norm": 5.504576206207275,
      "learning_rate": 9.676781002638523e-05,
      "loss": 0.1686,
      "step": 148
    },
    {
      "epoch": 0.09828496042216359,
      "grad_norm": 10.182625770568848,
      "learning_rate": 9.674582233948989e-05,
      "loss": 0.7761,
      "step": 149
    },
    {
      "epoch": 0.09894459102902374,
      "grad_norm": 5.391607761383057,
      "learning_rate": 9.672383465259455e-05,
      "loss": 0.1835,
      "step": 150
    },
    {
      "epoch": 0.09960422163588391,
      "grad_norm": 9.352992057800293,
      "learning_rate": 9.670184696569922e-05,
      "loss": 0.5852,
      "step": 151
    },
    {
      "epoch": 0.10026385224274406,
      "grad_norm": 6.914687156677246,
      "learning_rate": 9.667985927880387e-05,
      "loss": 0.4032,
      "step": 152
    },
    {
      "epoch": 0.10092348284960422,
      "grad_norm": 14.83975887298584,
      "learning_rate": 9.665787159190853e-05,
      "loss": 0.9284,
      "step": 153
    },
    {
      "epoch": 0.10158311345646438,
      "grad_norm": 6.7429728507995605,
      "learning_rate": 9.66358839050132e-05,
      "loss": 0.2489,
      "step": 154
    },
    {
      "epoch": 0.10224274406332454,
      "grad_norm": 3.148801803588867,
      "learning_rate": 9.661389621811786e-05,
      "loss": 0.306,
      "step": 155
    },
    {
      "epoch": 0.10290237467018469,
      "grad_norm": 3.0552284717559814,
      "learning_rate": 9.659190853122251e-05,
      "loss": 0.3134,
      "step": 156
    },
    {
      "epoch": 0.10356200527704486,
      "grad_norm": 9.207420349121094,
      "learning_rate": 9.656992084432717e-05,
      "loss": 0.8167,
      "step": 157
    },
    {
      "epoch": 0.10422163588390501,
      "grad_norm": 6.983640193939209,
      "learning_rate": 9.654793315743184e-05,
      "loss": 0.2557,
      "step": 158
    },
    {
      "epoch": 0.10488126649076517,
      "grad_norm": 3.1181278228759766,
      "learning_rate": 9.65259454705365e-05,
      "loss": 0.1565,
      "step": 159
    },
    {
      "epoch": 0.10554089709762533,
      "grad_norm": 8.010306358337402,
      "learning_rate": 9.650395778364117e-05,
      "loss": 0.3395,
      "step": 160
    },
    {
      "epoch": 0.10620052770448549,
      "grad_norm": 2.4721341133117676,
      "learning_rate": 9.648197009674583e-05,
      "loss": 0.125,
      "step": 161
    },
    {
      "epoch": 0.10686015831134564,
      "grad_norm": 1.9041739702224731,
      "learning_rate": 9.64599824098505e-05,
      "loss": 0.2007,
      "step": 162
    },
    {
      "epoch": 0.10751978891820581,
      "grad_norm": 3.5505146980285645,
      "learning_rate": 9.643799472295515e-05,
      "loss": 0.2043,
      "step": 163
    },
    {
      "epoch": 0.10817941952506596,
      "grad_norm": 13.114124298095703,
      "learning_rate": 9.641600703605981e-05,
      "loss": 0.8276,
      "step": 164
    },
    {
      "epoch": 0.10883905013192612,
      "grad_norm": 2.7680492401123047,
      "learning_rate": 9.639401934916448e-05,
      "loss": 0.1985,
      "step": 165
    },
    {
      "epoch": 0.10949868073878628,
      "grad_norm": 2.6186463832855225,
      "learning_rate": 9.637203166226914e-05,
      "loss": 0.1169,
      "step": 166
    },
    {
      "epoch": 0.11015831134564644,
      "grad_norm": 3.694247007369995,
      "learning_rate": 9.63500439753738e-05,
      "loss": 0.2272,
      "step": 167
    },
    {
      "epoch": 0.11081794195250659,
      "grad_norm": 5.367670059204102,
      "learning_rate": 9.632805628847845e-05,
      "loss": 0.2045,
      "step": 168
    },
    {
      "epoch": 0.11147757255936676,
      "grad_norm": 6.287727355957031,
      "learning_rate": 9.630606860158312e-05,
      "loss": 0.2035,
      "step": 169
    },
    {
      "epoch": 0.11213720316622691,
      "grad_norm": 15.984766006469727,
      "learning_rate": 9.628408091468778e-05,
      "loss": 1.1333,
      "step": 170
    },
    {
      "epoch": 0.11279683377308707,
      "grad_norm": 19.921527862548828,
      "learning_rate": 9.626209322779244e-05,
      "loss": 0.6229,
      "step": 171
    },
    {
      "epoch": 0.11345646437994723,
      "grad_norm": 1.4522851705551147,
      "learning_rate": 9.624010554089711e-05,
      "loss": 0.0885,
      "step": 172
    },
    {
      "epoch": 0.11411609498680739,
      "grad_norm": 1.608290195465088,
      "learning_rate": 9.621811785400176e-05,
      "loss": 0.0936,
      "step": 173
    },
    {
      "epoch": 0.11477572559366754,
      "grad_norm": 22.7802791595459,
      "learning_rate": 9.619613016710642e-05,
      "loss": 1.5382,
      "step": 174
    },
    {
      "epoch": 0.11543535620052771,
      "grad_norm": 20.197134017944336,
      "learning_rate": 9.617414248021108e-05,
      "loss": 0.6578,
      "step": 175
    },
    {
      "epoch": 0.11609498680738786,
      "grad_norm": 31.607677459716797,
      "learning_rate": 9.615215479331575e-05,
      "loss": 1.0615,
      "step": 176
    },
    {
      "epoch": 0.11675461741424802,
      "grad_norm": 15.968056678771973,
      "learning_rate": 9.61301671064204e-05,
      "loss": 0.5403,
      "step": 177
    },
    {
      "epoch": 0.11741424802110818,
      "grad_norm": 0.9046594500541687,
      "learning_rate": 9.610817941952506e-05,
      "loss": 0.0837,
      "step": 178
    },
    {
      "epoch": 0.11807387862796834,
      "grad_norm": 12.26724624633789,
      "learning_rate": 9.608619173262972e-05,
      "loss": 0.7243,
      "step": 179
    },
    {
      "epoch": 0.11873350923482849,
      "grad_norm": 3.6950275897979736,
      "learning_rate": 9.606420404573439e-05,
      "loss": 0.2389,
      "step": 180
    },
    {
      "epoch": 0.11939313984168866,
      "grad_norm": 9.74068546295166,
      "learning_rate": 9.604221635883906e-05,
      "loss": 0.4203,
      "step": 181
    },
    {
      "epoch": 0.12005277044854881,
      "grad_norm": 4.175169944763184,
      "learning_rate": 9.602022867194372e-05,
      "loss": 0.269,
      "step": 182
    },
    {
      "epoch": 0.12071240105540897,
      "grad_norm": 3.911198377609253,
      "learning_rate": 9.599824098504839e-05,
      "loss": 0.378,
      "step": 183
    },
    {
      "epoch": 0.12137203166226913,
      "grad_norm": 7.8163533210754395,
      "learning_rate": 9.597625329815305e-05,
      "loss": 0.4011,
      "step": 184
    },
    {
      "epoch": 0.12203166226912929,
      "grad_norm": 11.546730995178223,
      "learning_rate": 9.59542656112577e-05,
      "loss": 0.5726,
      "step": 185
    },
    {
      "epoch": 0.12269129287598944,
      "grad_norm": 7.248900413513184,
      "learning_rate": 9.593227792436236e-05,
      "loss": 0.5427,
      "step": 186
    },
    {
      "epoch": 0.12335092348284961,
      "grad_norm": 6.656569957733154,
      "learning_rate": 9.591029023746703e-05,
      "loss": 0.327,
      "step": 187
    },
    {
      "epoch": 0.12401055408970976,
      "grad_norm": 8.585644721984863,
      "learning_rate": 9.588830255057169e-05,
      "loss": 0.7683,
      "step": 188
    },
    {
      "epoch": 0.12467018469656992,
      "grad_norm": 2.7941060066223145,
      "learning_rate": 9.586631486367634e-05,
      "loss": 0.1743,
      "step": 189
    },
    {
      "epoch": 0.12532981530343007,
      "grad_norm": 3.8324575424194336,
      "learning_rate": 9.584432717678101e-05,
      "loss": 0.2373,
      "step": 190
    },
    {
      "epoch": 0.12598944591029024,
      "grad_norm": 5.790744781494141,
      "learning_rate": 9.582233948988567e-05,
      "loss": 0.2279,
      "step": 191
    },
    {
      "epoch": 0.1266490765171504,
      "grad_norm": 2.7161808013916016,
      "learning_rate": 9.580035180299033e-05,
      "loss": 0.1262,
      "step": 192
    },
    {
      "epoch": 0.12730870712401055,
      "grad_norm": 16.125776290893555,
      "learning_rate": 9.577836411609499e-05,
      "loss": 0.6914,
      "step": 193
    },
    {
      "epoch": 0.1279683377308707,
      "grad_norm": 14.788344383239746,
      "learning_rate": 9.575637642919966e-05,
      "loss": 0.4566,
      "step": 194
    },
    {
      "epoch": 0.12862796833773088,
      "grad_norm": 19.527645111083984,
      "learning_rate": 9.573438874230431e-05,
      "loss": 0.9014,
      "step": 195
    },
    {
      "epoch": 0.12928759894459102,
      "grad_norm": 11.289031982421875,
      "learning_rate": 9.571240105540897e-05,
      "loss": 0.9914,
      "step": 196
    },
    {
      "epoch": 0.1299472295514512,
      "grad_norm": 4.1000871658325195,
      "learning_rate": 9.569041336851363e-05,
      "loss": 0.1791,
      "step": 197
    },
    {
      "epoch": 0.13060686015831136,
      "grad_norm": 6.532097339630127,
      "learning_rate": 9.56684256816183e-05,
      "loss": 0.2298,
      "step": 198
    },
    {
      "epoch": 0.1312664907651715,
      "grad_norm": 5.43147611618042,
      "learning_rate": 9.564643799472295e-05,
      "loss": 0.2111,
      "step": 199
    },
    {
      "epoch": 0.13192612137203166,
      "grad_norm": 7.010229110717773,
      "learning_rate": 9.562445030782761e-05,
      "loss": 0.602,
      "step": 200
    },
    {
      "epoch": 0.13258575197889183,
      "grad_norm": 14.178595542907715,
      "learning_rate": 9.560246262093228e-05,
      "loss": 0.808,
      "step": 201
    },
    {
      "epoch": 0.13324538258575197,
      "grad_norm": 7.512713432312012,
      "learning_rate": 9.558047493403694e-05,
      "loss": 0.6022,
      "step": 202
    },
    {
      "epoch": 0.13390501319261214,
      "grad_norm": 6.7358927726745605,
      "learning_rate": 9.555848724714161e-05,
      "loss": 0.3095,
      "step": 203
    },
    {
      "epoch": 0.1345646437994723,
      "grad_norm": 3.4137418270111084,
      "learning_rate": 9.553649956024627e-05,
      "loss": 0.2505,
      "step": 204
    },
    {
      "epoch": 0.13522427440633245,
      "grad_norm": 5.655755043029785,
      "learning_rate": 9.551451187335094e-05,
      "loss": 0.6017,
      "step": 205
    },
    {
      "epoch": 0.1358839050131926,
      "grad_norm": 8.7196626663208,
      "learning_rate": 9.54925241864556e-05,
      "loss": 0.378,
      "step": 206
    },
    {
      "epoch": 0.13654353562005278,
      "grad_norm": 4.970999717712402,
      "learning_rate": 9.547053649956025e-05,
      "loss": 0.3696,
      "step": 207
    },
    {
      "epoch": 0.13720316622691292,
      "grad_norm": 2.659224271774292,
      "learning_rate": 9.544854881266492e-05,
      "loss": 0.2462,
      "step": 208
    },
    {
      "epoch": 0.1378627968337731,
      "grad_norm": 2.564129114151001,
      "learning_rate": 9.542656112576958e-05,
      "loss": 0.2685,
      "step": 209
    },
    {
      "epoch": 0.13852242744063326,
      "grad_norm": 10.508207321166992,
      "learning_rate": 9.540457343887424e-05,
      "loss": 0.5707,
      "step": 210
    },
    {
      "epoch": 0.1391820580474934,
      "grad_norm": 8.377464294433594,
      "learning_rate": 9.538258575197889e-05,
      "loss": 0.3179,
      "step": 211
    },
    {
      "epoch": 0.13984168865435356,
      "grad_norm": 3.788947343826294,
      "learning_rate": 9.536059806508356e-05,
      "loss": 0.2135,
      "step": 212
    },
    {
      "epoch": 0.14050131926121373,
      "grad_norm": 6.8638691902160645,
      "learning_rate": 9.533861037818822e-05,
      "loss": 0.3873,
      "step": 213
    },
    {
      "epoch": 0.14116094986807387,
      "grad_norm": 3.6801187992095947,
      "learning_rate": 9.531662269129288e-05,
      "loss": 0.2075,
      "step": 214
    },
    {
      "epoch": 0.14182058047493404,
      "grad_norm": 7.366370677947998,
      "learning_rate": 9.529463500439753e-05,
      "loss": 0.2979,
      "step": 215
    },
    {
      "epoch": 0.1424802110817942,
      "grad_norm": 1.507960557937622,
      "learning_rate": 9.52726473175022e-05,
      "loss": 0.1739,
      "step": 216
    },
    {
      "epoch": 0.14313984168865435,
      "grad_norm": 3.6374645233154297,
      "learning_rate": 9.525065963060686e-05,
      "loss": 0.2495,
      "step": 217
    },
    {
      "epoch": 0.1437994722955145,
      "grad_norm": 5.5132269859313965,
      "learning_rate": 9.522867194371152e-05,
      "loss": 0.2764,
      "step": 218
    },
    {
      "epoch": 0.14445910290237468,
      "grad_norm": 3.053514242172241,
      "learning_rate": 9.520668425681619e-05,
      "loss": 0.217,
      "step": 219
    },
    {
      "epoch": 0.14511873350923482,
      "grad_norm": 3.836074113845825,
      "learning_rate": 9.518469656992085e-05,
      "loss": 0.1745,
      "step": 220
    },
    {
      "epoch": 0.145778364116095,
      "grad_norm": 4.121550559997559,
      "learning_rate": 9.51627088830255e-05,
      "loss": 0.2166,
      "step": 221
    },
    {
      "epoch": 0.14643799472295516,
      "grad_norm": 15.297948837280273,
      "learning_rate": 9.514072119613017e-05,
      "loss": 1.0627,
      "step": 222
    },
    {
      "epoch": 0.1470976253298153,
      "grad_norm": 13.965232849121094,
      "learning_rate": 9.511873350923483e-05,
      "loss": 1.1596,
      "step": 223
    },
    {
      "epoch": 0.14775725593667546,
      "grad_norm": 12.847553253173828,
      "learning_rate": 9.50967458223395e-05,
      "loss": 0.5558,
      "step": 224
    },
    {
      "epoch": 0.14841688654353563,
      "grad_norm": 22.347904205322266,
      "learning_rate": 9.507475813544416e-05,
      "loss": 0.9866,
      "step": 225
    },
    {
      "epoch": 0.14907651715039577,
      "grad_norm": 4.095053672790527,
      "learning_rate": 9.505277044854883e-05,
      "loss": 0.151,
      "step": 226
    },
    {
      "epoch": 0.14973614775725594,
      "grad_norm": 14.058609962463379,
      "learning_rate": 9.503078276165349e-05,
      "loss": 0.9183,
      "step": 227
    },
    {
      "epoch": 0.1503957783641161,
      "grad_norm": 11.485191345214844,
      "learning_rate": 9.500879507475814e-05,
      "loss": 0.4986,
      "step": 228
    },
    {
      "epoch": 0.15105540897097625,
      "grad_norm": 8.885944366455078,
      "learning_rate": 9.49868073878628e-05,
      "loss": 0.3998,
      "step": 229
    },
    {
      "epoch": 0.1517150395778364,
      "grad_norm": 3.3462908267974854,
      "learning_rate": 9.496481970096747e-05,
      "loss": 0.1675,
      "step": 230
    },
    {
      "epoch": 0.15237467018469658,
      "grad_norm": 4.375722408294678,
      "learning_rate": 9.494283201407213e-05,
      "loss": 0.3403,
      "step": 231
    },
    {
      "epoch": 0.15303430079155672,
      "grad_norm": 6.561213970184326,
      "learning_rate": 9.492084432717678e-05,
      "loss": 0.3421,
      "step": 232
    },
    {
      "epoch": 0.1536939313984169,
      "grad_norm": 4.641203880310059,
      "learning_rate": 9.489885664028144e-05,
      "loss": 0.2862,
      "step": 233
    },
    {
      "epoch": 0.15435356200527706,
      "grad_norm": 3.8651139736175537,
      "learning_rate": 9.487686895338611e-05,
      "loss": 0.1935,
      "step": 234
    },
    {
      "epoch": 0.1550131926121372,
      "grad_norm": 1.7850981950759888,
      "learning_rate": 9.485488126649077e-05,
      "loss": 0.2116,
      "step": 235
    },
    {
      "epoch": 0.15567282321899736,
      "grad_norm": 6.068543434143066,
      "learning_rate": 9.483289357959543e-05,
      "loss": 0.2744,
      "step": 236
    },
    {
      "epoch": 0.15633245382585753,
      "grad_norm": 2.1093294620513916,
      "learning_rate": 9.48109058927001e-05,
      "loss": 0.1222,
      "step": 237
    },
    {
      "epoch": 0.15699208443271767,
      "grad_norm": 3.2206156253814697,
      "learning_rate": 9.478891820580475e-05,
      "loss": 0.2057,
      "step": 238
    },
    {
      "epoch": 0.15765171503957784,
      "grad_norm": 5.696338653564453,
      "learning_rate": 9.476693051890941e-05,
      "loss": 0.2303,
      "step": 239
    },
    {
      "epoch": 0.158311345646438,
      "grad_norm": 7.671870708465576,
      "learning_rate": 9.474494283201407e-05,
      "loss": 0.321,
      "step": 240
    },
    {
      "epoch": 0.15897097625329815,
      "grad_norm": 3.0645029544830322,
      "learning_rate": 9.472295514511874e-05,
      "loss": 0.1358,
      "step": 241
    },
    {
      "epoch": 0.15963060686015831,
      "grad_norm": 8.630577087402344,
      "learning_rate": 9.47009674582234e-05,
      "loss": 0.4683,
      "step": 242
    },
    {
      "epoch": 0.16029023746701848,
      "grad_norm": 9.467769622802734,
      "learning_rate": 9.467897977132805e-05,
      "loss": 0.3776,
      "step": 243
    },
    {
      "epoch": 0.16094986807387862,
      "grad_norm": 3.119511127471924,
      "learning_rate": 9.465699208443272e-05,
      "loss": 0.1365,
      "step": 244
    },
    {
      "epoch": 0.1616094986807388,
      "grad_norm": 4.410305976867676,
      "learning_rate": 9.463500439753739e-05,
      "loss": 0.1863,
      "step": 245
    },
    {
      "epoch": 0.16226912928759896,
      "grad_norm": 11.90566349029541,
      "learning_rate": 9.461301671064205e-05,
      "loss": 0.7895,
      "step": 246
    },
    {
      "epoch": 0.1629287598944591,
      "grad_norm": 15.504525184631348,
      "learning_rate": 9.45910290237467e-05,
      "loss": 1.0234,
      "step": 247
    },
    {
      "epoch": 0.16358839050131926,
      "grad_norm": 1.4994410276412964,
      "learning_rate": 9.456904133685138e-05,
      "loss": 0.1622,
      "step": 248
    },
    {
      "epoch": 0.16424802110817943,
      "grad_norm": 3.1784205436706543,
      "learning_rate": 9.454705364995603e-05,
      "loss": 0.3086,
      "step": 249
    },
    {
      "epoch": 0.16490765171503957,
      "grad_norm": 2.8643293380737305,
      "learning_rate": 9.452506596306069e-05,
      "loss": 0.2153,
      "step": 250
    },
    {
      "epoch": 0.16556728232189974,
      "grad_norm": 4.11081600189209,
      "learning_rate": 9.450307827616535e-05,
      "loss": 0.3581,
      "step": 251
    },
    {
      "epoch": 0.1662269129287599,
      "grad_norm": 4.917235374450684,
      "learning_rate": 9.448109058927002e-05,
      "loss": 0.2695,
      "step": 252
    },
    {
      "epoch": 0.16688654353562005,
      "grad_norm": 2.669201135635376,
      "learning_rate": 9.445910290237468e-05,
      "loss": 0.2481,
      "step": 253
    },
    {
      "epoch": 0.16754617414248021,
      "grad_norm": 7.605030536651611,
      "learning_rate": 9.443711521547933e-05,
      "loss": 0.3376,
      "step": 254
    },
    {
      "epoch": 0.16820580474934038,
      "grad_norm": 5.632042407989502,
      "learning_rate": 9.4415127528584e-05,
      "loss": 0.2278,
      "step": 255
    },
    {
      "epoch": 0.16886543535620052,
      "grad_norm": 12.501486778259277,
      "learning_rate": 9.439313984168866e-05,
      "loss": 0.8338,
      "step": 256
    },
    {
      "epoch": 0.1695250659630607,
      "grad_norm": 9.749971389770508,
      "learning_rate": 9.437115215479332e-05,
      "loss": 0.5013,
      "step": 257
    },
    {
      "epoch": 0.17018469656992086,
      "grad_norm": 17.205278396606445,
      "learning_rate": 9.434916446789797e-05,
      "loss": 1.3322,
      "step": 258
    },
    {
      "epoch": 0.170844327176781,
      "grad_norm": 15.249499320983887,
      "learning_rate": 9.432717678100264e-05,
      "loss": 0.9385,
      "step": 259
    },
    {
      "epoch": 0.17150395778364116,
      "grad_norm": 10.776744842529297,
      "learning_rate": 9.43051890941073e-05,
      "loss": 0.46,
      "step": 260
    },
    {
      "epoch": 0.17216358839050133,
      "grad_norm": 12.72671890258789,
      "learning_rate": 9.428320140721196e-05,
      "loss": 0.7001,
      "step": 261
    },
    {
      "epoch": 0.17282321899736147,
      "grad_norm": 6.652371406555176,
      "learning_rate": 9.426121372031663e-05,
      "loss": 0.2714,
      "step": 262
    },
    {
      "epoch": 0.17348284960422164,
      "grad_norm": 6.954916000366211,
      "learning_rate": 9.423922603342129e-05,
      "loss": 0.2861,
      "step": 263
    },
    {
      "epoch": 0.1741424802110818,
      "grad_norm": 7.584397792816162,
      "learning_rate": 9.421723834652594e-05,
      "loss": 0.3263,
      "step": 264
    },
    {
      "epoch": 0.17480211081794195,
      "grad_norm": 3.30351185798645,
      "learning_rate": 9.419525065963061e-05,
      "loss": 0.3144,
      "step": 265
    },
    {
      "epoch": 0.17546174142480211,
      "grad_norm": 8.403555870056152,
      "learning_rate": 9.417326297273527e-05,
      "loss": 0.4162,
      "step": 266
    },
    {
      "epoch": 0.17612137203166228,
      "grad_norm": 5.725770950317383,
      "learning_rate": 9.415127528583994e-05,
      "loss": 0.322,
      "step": 267
    },
    {
      "epoch": 0.17678100263852242,
      "grad_norm": 9.461005210876465,
      "learning_rate": 9.41292875989446e-05,
      "loss": 0.5001,
      "step": 268
    },
    {
      "epoch": 0.1774406332453826,
      "grad_norm": 3.0130867958068848,
      "learning_rate": 9.410729991204925e-05,
      "loss": 0.4525,
      "step": 269
    },
    {
      "epoch": 0.17810026385224276,
      "grad_norm": 7.698887348175049,
      "learning_rate": 9.408531222515393e-05,
      "loss": 0.4358,
      "step": 270
    },
    {
      "epoch": 0.1787598944591029,
      "grad_norm": 2.1622262001037598,
      "learning_rate": 9.406332453825858e-05,
      "loss": 0.1798,
      "step": 271
    },
    {
      "epoch": 0.17941952506596306,
      "grad_norm": 2.9267311096191406,
      "learning_rate": 9.404133685136324e-05,
      "loss": 0.1884,
      "step": 272
    },
    {
      "epoch": 0.18007915567282323,
      "grad_norm": 3.0657594203948975,
      "learning_rate": 9.401934916446791e-05,
      "loss": 0.3082,
      "step": 273
    },
    {
      "epoch": 0.18073878627968337,
      "grad_norm": 7.003755569458008,
      "learning_rate": 9.399736147757257e-05,
      "loss": 0.7174,
      "step": 274
    },
    {
      "epoch": 0.18139841688654354,
      "grad_norm": 4.500641822814941,
      "learning_rate": 9.397537379067722e-05,
      "loss": 0.1894,
      "step": 275
    },
    {
      "epoch": 0.1820580474934037,
      "grad_norm": 2.134341239929199,
      "learning_rate": 9.395338610378188e-05,
      "loss": 0.1062,
      "step": 276
    },
    {
      "epoch": 0.18271767810026385,
      "grad_norm": 2.0787932872772217,
      "learning_rate": 9.393139841688655e-05,
      "loss": 0.1192,
      "step": 277
    },
    {
      "epoch": 0.18337730870712401,
      "grad_norm": 6.1616387367248535,
      "learning_rate": 9.390941072999121e-05,
      "loss": 0.3163,
      "step": 278
    },
    {
      "epoch": 0.18403693931398418,
      "grad_norm": 13.011774063110352,
      "learning_rate": 9.388742304309587e-05,
      "loss": 1.3315,
      "step": 279
    },
    {
      "epoch": 0.18469656992084432,
      "grad_norm": 10.852892875671387,
      "learning_rate": 9.386543535620054e-05,
      "loss": 0.5583,
      "step": 280
    },
    {
      "epoch": 0.1853562005277045,
      "grad_norm": 17.953712463378906,
      "learning_rate": 9.384344766930519e-05,
      "loss": 1.3629,
      "step": 281
    },
    {
      "epoch": 0.18601583113456466,
      "grad_norm": 11.034554481506348,
      "learning_rate": 9.382145998240985e-05,
      "loss": 0.7461,
      "step": 282
    },
    {
      "epoch": 0.1866754617414248,
      "grad_norm": 5.567540645599365,
      "learning_rate": 9.379947229551451e-05,
      "loss": 0.2415,
      "step": 283
    },
    {
      "epoch": 0.18733509234828497,
      "grad_norm": 7.338798522949219,
      "learning_rate": 9.377748460861918e-05,
      "loss": 0.3696,
      "step": 284
    },
    {
      "epoch": 0.1879947229551451,
      "grad_norm": 13.176653861999512,
      "learning_rate": 9.375549692172383e-05,
      "loss": 0.9469,
      "step": 285
    },
    {
      "epoch": 0.18865435356200527,
      "grad_norm": 1.9688154458999634,
      "learning_rate": 9.37335092348285e-05,
      "loss": 0.1837,
      "step": 286
    },
    {
      "epoch": 0.18931398416886544,
      "grad_norm": 5.629026412963867,
      "learning_rate": 9.371152154793316e-05,
      "loss": 0.4105,
      "step": 287
    },
    {
      "epoch": 0.18997361477572558,
      "grad_norm": 6.030405044555664,
      "learning_rate": 9.368953386103783e-05,
      "loss": 0.6806,
      "step": 288
    },
    {
      "epoch": 0.19063324538258575,
      "grad_norm": 9.411407470703125,
      "learning_rate": 9.366754617414249e-05,
      "loss": 0.5073,
      "step": 289
    },
    {
      "epoch": 0.19129287598944592,
      "grad_norm": 3.406062126159668,
      "learning_rate": 9.364555848724715e-05,
      "loss": 0.2882,
      "step": 290
    },
    {
      "epoch": 0.19195250659630606,
      "grad_norm": 7.303451061248779,
      "learning_rate": 9.362357080035182e-05,
      "loss": 0.4168,
      "step": 291
    },
    {
      "epoch": 0.19261213720316622,
      "grad_norm": 8.242011070251465,
      "learning_rate": 9.360158311345647e-05,
      "loss": 0.5135,
      "step": 292
    },
    {
      "epoch": 0.1932717678100264,
      "grad_norm": 3.9878385066986084,
      "learning_rate": 9.357959542656113e-05,
      "loss": 0.2935,
      "step": 293
    },
    {
      "epoch": 0.19393139841688653,
      "grad_norm": 2.068594217300415,
      "learning_rate": 9.355760773966579e-05,
      "loss": 0.4069,
      "step": 294
    },
    {
      "epoch": 0.1945910290237467,
      "grad_norm": 2.4738967418670654,
      "learning_rate": 9.353562005277046e-05,
      "loss": 0.2338,
      "step": 295
    },
    {
      "epoch": 0.19525065963060687,
      "grad_norm": 8.180070877075195,
      "learning_rate": 9.351363236587512e-05,
      "loss": 0.6877,
      "step": 296
    },
    {
      "epoch": 0.195910290237467,
      "grad_norm": 2.0007987022399902,
      "learning_rate": 9.349164467897977e-05,
      "loss": 0.1935,
      "step": 297
    },
    {
      "epoch": 0.19656992084432717,
      "grad_norm": 3.8324484825134277,
      "learning_rate": 9.346965699208444e-05,
      "loss": 0.1823,
      "step": 298
    },
    {
      "epoch": 0.19722955145118734,
      "grad_norm": 10.783690452575684,
      "learning_rate": 9.34476693051891e-05,
      "loss": 0.7957,
      "step": 299
    },
    {
      "epoch": 0.19788918205804748,
      "grad_norm": 3.433708667755127,
      "learning_rate": 9.342568161829376e-05,
      "loss": 0.2222,
      "step": 300
    },
    {
      "epoch": 0.19854881266490765,
      "grad_norm": 0.9049488306045532,
      "learning_rate": 9.340369393139841e-05,
      "loss": 0.0715,
      "step": 301
    },
    {
      "epoch": 0.19920844327176782,
      "grad_norm": 8.10256290435791,
      "learning_rate": 9.338170624450308e-05,
      "loss": 0.5624,
      "step": 302
    },
    {
      "epoch": 0.19986807387862796,
      "grad_norm": 1.9499095678329468,
      "learning_rate": 9.335971855760774e-05,
      "loss": 0.0875,
      "step": 303
    },
    {
      "epoch": 0.20052770448548812,
      "grad_norm": 4.462866306304932,
      "learning_rate": 9.33377308707124e-05,
      "loss": 0.2162,
      "step": 304
    },
    {
      "epoch": 0.2011873350923483,
      "grad_norm": 4.302006244659424,
      "learning_rate": 9.331574318381706e-05,
      "loss": 0.1939,
      "step": 305
    },
    {
      "epoch": 0.20184696569920843,
      "grad_norm": 2.0927228927612305,
      "learning_rate": 9.329375549692173e-05,
      "loss": 0.1185,
      "step": 306
    },
    {
      "epoch": 0.2025065963060686,
      "grad_norm": 2.592996597290039,
      "learning_rate": 9.327176781002638e-05,
      "loss": 0.1053,
      "step": 307
    },
    {
      "epoch": 0.20316622691292877,
      "grad_norm": 7.068577289581299,
      "learning_rate": 9.324978012313105e-05,
      "loss": 0.2732,
      "step": 308
    },
    {
      "epoch": 0.2038258575197889,
      "grad_norm": 1.071905493736267,
      "learning_rate": 9.322779243623571e-05,
      "loss": 0.0875,
      "step": 309
    },
    {
      "epoch": 0.20448548812664907,
      "grad_norm": 8.733232498168945,
      "learning_rate": 9.320580474934038e-05,
      "loss": 0.5305,
      "step": 310
    },
    {
      "epoch": 0.20514511873350924,
      "grad_norm": 12.489777565002441,
      "learning_rate": 9.318381706244504e-05,
      "loss": 1.2819,
      "step": 311
    },
    {
      "epoch": 0.20580474934036938,
      "grad_norm": 4.520515441894531,
      "learning_rate": 9.31618293755497e-05,
      "loss": 0.1965,
      "step": 312
    },
    {
      "epoch": 0.20646437994722955,
      "grad_norm": 5.594666481018066,
      "learning_rate": 9.313984168865437e-05,
      "loss": 0.3413,
      "step": 313
    },
    {
      "epoch": 0.20712401055408972,
      "grad_norm": 1.7970514297485352,
      "learning_rate": 9.311785400175902e-05,
      "loss": 0.1111,
      "step": 314
    },
    {
      "epoch": 0.20778364116094986,
      "grad_norm": 1.7292300462722778,
      "learning_rate": 9.309586631486368e-05,
      "loss": 0.1642,
      "step": 315
    },
    {
      "epoch": 0.20844327176781002,
      "grad_norm": 3.2029671669006348,
      "learning_rate": 9.307387862796835e-05,
      "loss": 0.2253,
      "step": 316
    },
    {
      "epoch": 0.2091029023746702,
      "grad_norm": 1.8017809391021729,
      "learning_rate": 9.305189094107301e-05,
      "loss": 0.1845,
      "step": 317
    },
    {
      "epoch": 0.20976253298153033,
      "grad_norm": 1.6349616050720215,
      "learning_rate": 9.302990325417766e-05,
      "loss": 0.1695,
      "step": 318
    },
    {
      "epoch": 0.2104221635883905,
      "grad_norm": 6.758336544036865,
      "learning_rate": 9.300791556728232e-05,
      "loss": 0.3865,
      "step": 319
    },
    {
      "epoch": 0.21108179419525067,
      "grad_norm": 4.430947303771973,
      "learning_rate": 9.298592788038699e-05,
      "loss": 0.2053,
      "step": 320
    },
    {
      "epoch": 0.2117414248021108,
      "grad_norm": 5.5015339851379395,
      "learning_rate": 9.296394019349165e-05,
      "loss": 0.1682,
      "step": 321
    },
    {
      "epoch": 0.21240105540897097,
      "grad_norm": 2.217189073562622,
      "learning_rate": 9.29419525065963e-05,
      "loss": 0.1016,
      "step": 322
    },
    {
      "epoch": 0.21306068601583114,
      "grad_norm": 12.043814659118652,
      "learning_rate": 9.291996481970096e-05,
      "loss": 1.1503,
      "step": 323
    },
    {
      "epoch": 0.21372031662269128,
      "grad_norm": 6.839044570922852,
      "learning_rate": 9.289797713280563e-05,
      "loss": 0.1388,
      "step": 324
    },
    {
      "epoch": 0.21437994722955145,
      "grad_norm": 16.582380294799805,
      "learning_rate": 9.287598944591029e-05,
      "loss": 1.7686,
      "step": 325
    },
    {
      "epoch": 0.21503957783641162,
      "grad_norm": 1.3707796335220337,
      "learning_rate": 9.285400175901495e-05,
      "loss": 0.0611,
      "step": 326
    },
    {
      "epoch": 0.21569920844327176,
      "grad_norm": 2.1243717670440674,
      "learning_rate": 9.283201407211962e-05,
      "loss": 0.0823,
      "step": 327
    },
    {
      "epoch": 0.21635883905013192,
      "grad_norm": 10.42601490020752,
      "learning_rate": 9.281002638522427e-05,
      "loss": 0.5142,
      "step": 328
    },
    {
      "epoch": 0.2170184696569921,
      "grad_norm": 4.671543598175049,
      "learning_rate": 9.278803869832894e-05,
      "loss": 0.1488,
      "step": 329
    },
    {
      "epoch": 0.21767810026385223,
      "grad_norm": 24.10990333557129,
      "learning_rate": 9.27660510114336e-05,
      "loss": 1.3161,
      "step": 330
    },
    {
      "epoch": 0.2183377308707124,
      "grad_norm": 1.9906197786331177,
      "learning_rate": 9.274406332453827e-05,
      "loss": 0.0859,
      "step": 331
    },
    {
      "epoch": 0.21899736147757257,
      "grad_norm": 0.7828160524368286,
      "learning_rate": 9.272207563764293e-05,
      "loss": 0.0303,
      "step": 332
    },
    {
      "epoch": 0.2196569920844327,
      "grad_norm": 1.4524950981140137,
      "learning_rate": 9.270008795074759e-05,
      "loss": 0.0591,
      "step": 333
    },
    {
      "epoch": 0.22031662269129287,
      "grad_norm": 0.5822636485099792,
      "learning_rate": 9.267810026385226e-05,
      "loss": 0.0153,
      "step": 334
    },
    {
      "epoch": 0.22097625329815304,
      "grad_norm": 18.789011001586914,
      "learning_rate": 9.265611257695691e-05,
      "loss": 1.8068,
      "step": 335
    },
    {
      "epoch": 0.22163588390501318,
      "grad_norm": 28.460872650146484,
      "learning_rate": 9.263412489006157e-05,
      "loss": 1.4046,
      "step": 336
    },
    {
      "epoch": 0.22229551451187335,
      "grad_norm": 15.232007026672363,
      "learning_rate": 9.261213720316623e-05,
      "loss": 1.105,
      "step": 337
    },
    {
      "epoch": 0.22295514511873352,
      "grad_norm": 13.255441665649414,
      "learning_rate": 9.25901495162709e-05,
      "loss": 1.8761,
      "step": 338
    },
    {
      "epoch": 0.22361477572559366,
      "grad_norm": 25.39190673828125,
      "learning_rate": 9.256816182937556e-05,
      "loss": 2.7647,
      "step": 339
    },
    {
      "epoch": 0.22427440633245382,
      "grad_norm": 20.97213363647461,
      "learning_rate": 9.254617414248021e-05,
      "loss": 1.0953,
      "step": 340
    },
    {
      "epoch": 0.224934036939314,
      "grad_norm": 11.386876106262207,
      "learning_rate": 9.252418645558487e-05,
      "loss": 0.4688,
      "step": 341
    },
    {
      "epoch": 0.22559366754617413,
      "grad_norm": 3.085404634475708,
      "learning_rate": 9.250219876868954e-05,
      "loss": 0.0994,
      "step": 342
    },
    {
      "epoch": 0.2262532981530343,
      "grad_norm": 15.992936134338379,
      "learning_rate": 9.24802110817942e-05,
      "loss": 0.9143,
      "step": 343
    },
    {
      "epoch": 0.22691292875989447,
      "grad_norm": 12.405535697937012,
      "learning_rate": 9.245822339489885e-05,
      "loss": 1.3734,
      "step": 344
    },
    {
      "epoch": 0.2275725593667546,
      "grad_norm": 7.5888471603393555,
      "learning_rate": 9.243623570800352e-05,
      "loss": 0.9666,
      "step": 345
    },
    {
      "epoch": 0.22823218997361477,
      "grad_norm": 13.028181076049805,
      "learning_rate": 9.241424802110818e-05,
      "loss": 0.7829,
      "step": 346
    },
    {
      "epoch": 0.22889182058047494,
      "grad_norm": 6.226950168609619,
      "learning_rate": 9.239226033421284e-05,
      "loss": 0.5331,
      "step": 347
    },
    {
      "epoch": 0.22955145118733508,
      "grad_norm": 3.5844147205352783,
      "learning_rate": 9.23702726473175e-05,
      "loss": 0.3613,
      "step": 348
    },
    {
      "epoch": 0.23021108179419525,
      "grad_norm": 3.3005380630493164,
      "learning_rate": 9.234828496042217e-05,
      "loss": 0.3476,
      "step": 349
    },
    {
      "epoch": 0.23087071240105542,
      "grad_norm": 2.001451015472412,
      "learning_rate": 9.232629727352682e-05,
      "loss": 0.3811,
      "step": 350
    },
    {
      "epoch": 0.23153034300791556,
      "grad_norm": 2.5706796646118164,
      "learning_rate": 9.23043095866315e-05,
      "loss": 0.3328,
      "step": 351
    },
    {
      "epoch": 0.23218997361477572,
      "grad_norm": 2.068180799484253,
      "learning_rate": 9.228232189973616e-05,
      "loss": 0.3622,
      "step": 352
    },
    {
      "epoch": 0.2328496042216359,
      "grad_norm": 5.141445159912109,
      "learning_rate": 9.226033421284082e-05,
      "loss": 0.3676,
      "step": 353
    },
    {
      "epoch": 0.23350923482849603,
      "grad_norm": 5.901932716369629,
      "learning_rate": 9.223834652594548e-05,
      "loss": 0.9401,
      "step": 354
    },
    {
      "epoch": 0.2341688654353562,
      "grad_norm": 6.831417083740234,
      "learning_rate": 9.221635883905013e-05,
      "loss": 0.4863,
      "step": 355
    },
    {
      "epoch": 0.23482849604221637,
      "grad_norm": 3.3002476692199707,
      "learning_rate": 9.21943711521548e-05,
      "loss": 0.4143,
      "step": 356
    },
    {
      "epoch": 0.2354881266490765,
      "grad_norm": 2.08404278755188,
      "learning_rate": 9.217238346525946e-05,
      "loss": 0.3246,
      "step": 357
    },
    {
      "epoch": 0.23614775725593667,
      "grad_norm": 1.6094441413879395,
      "learning_rate": 9.215039577836412e-05,
      "loss": 0.2499,
      "step": 358
    },
    {
      "epoch": 0.23680738786279684,
      "grad_norm": 3.754490613937378,
      "learning_rate": 9.212840809146878e-05,
      "loss": 0.4671,
      "step": 359
    },
    {
      "epoch": 0.23746701846965698,
      "grad_norm": 6.186951160430908,
      "learning_rate": 9.210642040457345e-05,
      "loss": 0.421,
      "step": 360
    },
    {
      "epoch": 0.23812664907651715,
      "grad_norm": 6.24514102935791,
      "learning_rate": 9.20844327176781e-05,
      "loss": 0.4959,
      "step": 361
    },
    {
      "epoch": 0.23878627968337732,
      "grad_norm": 6.280337810516357,
      "learning_rate": 9.206244503078276e-05,
      "loss": 0.7579,
      "step": 362
    },
    {
      "epoch": 0.23944591029023746,
      "grad_norm": 6.125627040863037,
      "learning_rate": 9.204045734388743e-05,
      "loss": 0.6258,
      "step": 363
    },
    {
      "epoch": 0.24010554089709762,
      "grad_norm": 1.4763375520706177,
      "learning_rate": 9.201846965699209e-05,
      "loss": 0.2026,
      "step": 364
    },
    {
      "epoch": 0.2407651715039578,
      "grad_norm": 1.2312299013137817,
      "learning_rate": 9.199648197009675e-05,
      "loss": 0.1782,
      "step": 365
    },
    {
      "epoch": 0.24142480211081793,
      "grad_norm": 4.073061466217041,
      "learning_rate": 9.19744942832014e-05,
      "loss": 0.3927,
      "step": 366
    },
    {
      "epoch": 0.2420844327176781,
      "grad_norm": 1.8968424797058105,
      "learning_rate": 9.195250659630607e-05,
      "loss": 0.2511,
      "step": 367
    },
    {
      "epoch": 0.24274406332453827,
      "grad_norm": 3.5699281692504883,
      "learning_rate": 9.193051890941073e-05,
      "loss": 0.4078,
      "step": 368
    },
    {
      "epoch": 0.2434036939313984,
      "grad_norm": 1.662182331085205,
      "learning_rate": 9.190853122251539e-05,
      "loss": 0.2973,
      "step": 369
    },
    {
      "epoch": 0.24406332453825857,
      "grad_norm": 4.712750434875488,
      "learning_rate": 9.188654353562006e-05,
      "loss": 0.3627,
      "step": 370
    },
    {
      "epoch": 0.24472295514511874,
      "grad_norm": 2.797128438949585,
      "learning_rate": 9.186455584872471e-05,
      "loss": 0.4041,
      "step": 371
    },
    {
      "epoch": 0.24538258575197888,
      "grad_norm": 3.2958638668060303,
      "learning_rate": 9.184256816182938e-05,
      "loss": 0.4272,
      "step": 372
    },
    {
      "epoch": 0.24604221635883905,
      "grad_norm": 2.5601389408111572,
      "learning_rate": 9.182058047493404e-05,
      "loss": 0.3361,
      "step": 373
    },
    {
      "epoch": 0.24670184696569922,
      "grad_norm": 3.2534117698669434,
      "learning_rate": 9.179859278803871e-05,
      "loss": 0.3199,
      "step": 374
    },
    {
      "epoch": 0.24736147757255936,
      "grad_norm": 2.973487615585327,
      "learning_rate": 9.177660510114337e-05,
      "loss": 0.2336,
      "step": 375
    },
    {
      "epoch": 0.24802110817941952,
      "grad_norm": 2.1475892066955566,
      "learning_rate": 9.175461741424803e-05,
      "loss": 0.2939,
      "step": 376
    },
    {
      "epoch": 0.2486807387862797,
      "grad_norm": 5.3070149421691895,
      "learning_rate": 9.173262972735268e-05,
      "loss": 0.6215,
      "step": 377
    },
    {
      "epoch": 0.24934036939313983,
      "grad_norm": 8.021796226501465,
      "learning_rate": 9.171064204045735e-05,
      "loss": 0.4619,
      "step": 378
    },
    {
      "epoch": 0.25,
      "grad_norm": 4.105077743530273,
      "learning_rate": 9.168865435356201e-05,
      "loss": 0.3498,
      "step": 379
    },
    {
      "epoch": 0.25065963060686014,
      "grad_norm": 5.693858623504639,
      "learning_rate": 9.166666666666667e-05,
      "loss": 0.357,
      "step": 380
    },
    {
      "epoch": 0.25131926121372034,
      "grad_norm": 13.102690696716309,
      "learning_rate": 9.164467897977134e-05,
      "loss": 1.0718,
      "step": 381
    },
    {
      "epoch": 0.2519788918205805,
      "grad_norm": 7.079848766326904,
      "learning_rate": 9.1622691292876e-05,
      "loss": 0.4513,
      "step": 382
    },
    {
      "epoch": 0.2526385224274406,
      "grad_norm": 1.3577038049697876,
      "learning_rate": 9.160070360598065e-05,
      "loss": 0.2105,
      "step": 383
    },
    {
      "epoch": 0.2532981530343008,
      "grad_norm": 3.447260856628418,
      "learning_rate": 9.157871591908531e-05,
      "loss": 0.1994,
      "step": 384
    },
    {
      "epoch": 0.25395778364116095,
      "grad_norm": 4.097410202026367,
      "learning_rate": 9.155672823218998e-05,
      "loss": 0.2412,
      "step": 385
    },
    {
      "epoch": 0.2546174142480211,
      "grad_norm": 0.7140834927558899,
      "learning_rate": 9.153474054529464e-05,
      "loss": 0.0977,
      "step": 386
    },
    {
      "epoch": 0.2552770448548813,
      "grad_norm": 4.85173225402832,
      "learning_rate": 9.15127528583993e-05,
      "loss": 0.2108,
      "step": 387
    },
    {
      "epoch": 0.2559366754617414,
      "grad_norm": 14.205138206481934,
      "learning_rate": 9.149076517150396e-05,
      "loss": 0.5197,
      "step": 388
    },
    {
      "epoch": 0.25659630606860157,
      "grad_norm": 11.7460355758667,
      "learning_rate": 9.146877748460862e-05,
      "loss": 0.5943,
      "step": 389
    },
    {
      "epoch": 0.25725593667546176,
      "grad_norm": 1.0060454607009888,
      "learning_rate": 9.144678979771328e-05,
      "loss": 0.0846,
      "step": 390
    },
    {
      "epoch": 0.2579155672823219,
      "grad_norm": 10.49466609954834,
      "learning_rate": 9.142480211081795e-05,
      "loss": 0.384,
      "step": 391
    },
    {
      "epoch": 0.25857519788918204,
      "grad_norm": 1.5218459367752075,
      "learning_rate": 9.14028144239226e-05,
      "loss": 0.1276,
      "step": 392
    },
    {
      "epoch": 0.25923482849604224,
      "grad_norm": 3.103940010070801,
      "learning_rate": 9.138082673702728e-05,
      "loss": 0.1844,
      "step": 393
    },
    {
      "epoch": 0.2598944591029024,
      "grad_norm": 1.5325329303741455,
      "learning_rate": 9.135883905013193e-05,
      "loss": 0.1148,
      "step": 394
    },
    {
      "epoch": 0.2605540897097625,
      "grad_norm": 5.3918070793151855,
      "learning_rate": 9.13368513632366e-05,
      "loss": 0.2928,
      "step": 395
    },
    {
      "epoch": 0.2612137203166227,
      "grad_norm": 2.7727065086364746,
      "learning_rate": 9.131486367634126e-05,
      "loss": 0.1757,
      "step": 396
    },
    {
      "epoch": 0.26187335092348285,
      "grad_norm": 4.099031925201416,
      "learning_rate": 9.129287598944592e-05,
      "loss": 0.1723,
      "step": 397
    },
    {
      "epoch": 0.262532981530343,
      "grad_norm": 9.121962547302246,
      "learning_rate": 9.127088830255057e-05,
      "loss": 0.481,
      "step": 398
    },
    {
      "epoch": 0.2631926121372032,
      "grad_norm": 9.713727951049805,
      "learning_rate": 9.124890061565525e-05,
      "loss": 0.644,
      "step": 399
    },
    {
      "epoch": 0.2638522427440633,
      "grad_norm": 1.7543517351150513,
      "learning_rate": 9.12269129287599e-05,
      "loss": 0.0918,
      "step": 400
    },
    {
      "epoch": 0.26451187335092347,
      "grad_norm": 17.678936004638672,
      "learning_rate": 9.120492524186456e-05,
      "loss": 1.0611,
      "step": 401
    },
    {
      "epoch": 0.26517150395778366,
      "grad_norm": 3.0806643962860107,
      "learning_rate": 9.118293755496922e-05,
      "loss": 0.1757,
      "step": 402
    },
    {
      "epoch": 0.2658311345646438,
      "grad_norm": 2.215322971343994,
      "learning_rate": 9.116094986807389e-05,
      "loss": 0.1003,
      "step": 403
    },
    {
      "epoch": 0.26649076517150394,
      "grad_norm": 10.542194366455078,
      "learning_rate": 9.113896218117854e-05,
      "loss": 1.5662,
      "step": 404
    },
    {
      "epoch": 0.26715039577836414,
      "grad_norm": 6.559330463409424,
      "learning_rate": 9.11169744942832e-05,
      "loss": 0.3628,
      "step": 405
    },
    {
      "epoch": 0.2678100263852243,
      "grad_norm": 2.5351755619049072,
      "learning_rate": 9.109498680738787e-05,
      "loss": 0.1248,
      "step": 406
    },
    {
      "epoch": 0.2684696569920844,
      "grad_norm": 1.4812602996826172,
      "learning_rate": 9.107299912049253e-05,
      "loss": 0.0844,
      "step": 407
    },
    {
      "epoch": 0.2691292875989446,
      "grad_norm": 14.78693962097168,
      "learning_rate": 9.105101143359719e-05,
      "loss": 1.0042,
      "step": 408
    },
    {
      "epoch": 0.26978891820580475,
      "grad_norm": 4.528454303741455,
      "learning_rate": 9.102902374670184e-05,
      "loss": 0.1381,
      "step": 409
    },
    {
      "epoch": 0.2704485488126649,
      "grad_norm": 1.2214003801345825,
      "learning_rate": 9.100703605980651e-05,
      "loss": 0.0987,
      "step": 410
    },
    {
      "epoch": 0.2711081794195251,
      "grad_norm": 3.645660877227783,
      "learning_rate": 9.098504837291117e-05,
      "loss": 0.1157,
      "step": 411
    },
    {
      "epoch": 0.2717678100263852,
      "grad_norm": 13.388525009155273,
      "learning_rate": 9.096306068601583e-05,
      "loss": 0.8872,
      "step": 412
    },
    {
      "epoch": 0.27242744063324537,
      "grad_norm": 7.8114705085754395,
      "learning_rate": 9.09410729991205e-05,
      "loss": 0.921,
      "step": 413
    },
    {
      "epoch": 0.27308707124010556,
      "grad_norm": 24.907121658325195,
      "learning_rate": 9.091908531222515e-05,
      "loss": 1.7651,
      "step": 414
    },
    {
      "epoch": 0.2737467018469657,
      "grad_norm": 2.359736442565918,
      "learning_rate": 9.089709762532982e-05,
      "loss": 0.0901,
      "step": 415
    },
    {
      "epoch": 0.27440633245382584,
      "grad_norm": 1.7397414445877075,
      "learning_rate": 9.087510993843448e-05,
      "loss": 0.0821,
      "step": 416
    },
    {
      "epoch": 0.27506596306068604,
      "grad_norm": 12.62512493133545,
      "learning_rate": 9.085312225153915e-05,
      "loss": 0.9629,
      "step": 417
    },
    {
      "epoch": 0.2757255936675462,
      "grad_norm": 5.5620856285095215,
      "learning_rate": 9.083113456464381e-05,
      "loss": 0.294,
      "step": 418
    },
    {
      "epoch": 0.2763852242744063,
      "grad_norm": 16.266460418701172,
      "learning_rate": 9.080914687774847e-05,
      "loss": 0.6693,
      "step": 419
    },
    {
      "epoch": 0.2770448548812665,
      "grad_norm": 20.879619598388672,
      "learning_rate": 9.078715919085312e-05,
      "loss": 0.8273,
      "step": 420
    },
    {
      "epoch": 0.27770448548812665,
      "grad_norm": 5.133668899536133,
      "learning_rate": 9.07651715039578e-05,
      "loss": 0.2798,
      "step": 421
    },
    {
      "epoch": 0.2783641160949868,
      "grad_norm": 4.368912220001221,
      "learning_rate": 9.074318381706245e-05,
      "loss": 0.2447,
      "step": 422
    },
    {
      "epoch": 0.279023746701847,
      "grad_norm": 1.742450475692749,
      "learning_rate": 9.072119613016711e-05,
      "loss": 0.1889,
      "step": 423
    },
    {
      "epoch": 0.2796833773087071,
      "grad_norm": 4.552252292633057,
      "learning_rate": 9.069920844327178e-05,
      "loss": 0.4499,
      "step": 424
    },
    {
      "epoch": 0.28034300791556727,
      "grad_norm": 3.0797879695892334,
      "learning_rate": 9.067722075637644e-05,
      "loss": 0.3575,
      "step": 425
    },
    {
      "epoch": 0.28100263852242746,
      "grad_norm": 1.2407945394515991,
      "learning_rate": 9.065523306948109e-05,
      "loss": 0.1936,
      "step": 426
    },
    {
      "epoch": 0.2816622691292876,
      "grad_norm": 11.210232734680176,
      "learning_rate": 9.063324538258575e-05,
      "loss": 1.3216,
      "step": 427
    },
    {
      "epoch": 0.28232189973614774,
      "grad_norm": 2.6400132179260254,
      "learning_rate": 9.061125769569042e-05,
      "loss": 0.1574,
      "step": 428
    },
    {
      "epoch": 0.28298153034300794,
      "grad_norm": 2.098757266998291,
      "learning_rate": 9.058927000879508e-05,
      "loss": 0.2319,
      "step": 429
    },
    {
      "epoch": 0.2836411609498681,
      "grad_norm": 4.432528972625732,
      "learning_rate": 9.056728232189973e-05,
      "loss": 0.3111,
      "step": 430
    },
    {
      "epoch": 0.2843007915567282,
      "grad_norm": 3.9680166244506836,
      "learning_rate": 9.05452946350044e-05,
      "loss": 0.2568,
      "step": 431
    },
    {
      "epoch": 0.2849604221635884,
      "grad_norm": 2.7051398754119873,
      "learning_rate": 9.052330694810906e-05,
      "loss": 0.2808,
      "step": 432
    },
    {
      "epoch": 0.28562005277044855,
      "grad_norm": 3.7328131198883057,
      "learning_rate": 9.050131926121372e-05,
      "loss": 0.2765,
      "step": 433
    },
    {
      "epoch": 0.2862796833773087,
      "grad_norm": 4.417738437652588,
      "learning_rate": 9.047933157431839e-05,
      "loss": 0.3619,
      "step": 434
    },
    {
      "epoch": 0.2869393139841689,
      "grad_norm": 10.154789924621582,
      "learning_rate": 9.045734388742305e-05,
      "loss": 0.7811,
      "step": 435
    },
    {
      "epoch": 0.287598944591029,
      "grad_norm": 3.5787034034729004,
      "learning_rate": 9.043535620052772e-05,
      "loss": 0.3104,
      "step": 436
    },
    {
      "epoch": 0.28825857519788917,
      "grad_norm": 5.45831823348999,
      "learning_rate": 9.041336851363237e-05,
      "loss": 0.2671,
      "step": 437
    },
    {
      "epoch": 0.28891820580474936,
      "grad_norm": 8.759632110595703,
      "learning_rate": 9.039138082673703e-05,
      "loss": 1.0447,
      "step": 438
    },
    {
      "epoch": 0.2895778364116095,
      "grad_norm": 21.6894588470459,
      "learning_rate": 9.03693931398417e-05,
      "loss": 0.7846,
      "step": 439
    },
    {
      "epoch": 0.29023746701846964,
      "grad_norm": 4.7036967277526855,
      "learning_rate": 9.034740545294636e-05,
      "loss": 0.2917,
      "step": 440
    },
    {
      "epoch": 0.29089709762532984,
      "grad_norm": 2.0186500549316406,
      "learning_rate": 9.032541776605101e-05,
      "loss": 0.1595,
      "step": 441
    },
    {
      "epoch": 0.29155672823219,
      "grad_norm": 5.234262943267822,
      "learning_rate": 9.030343007915569e-05,
      "loss": 0.4472,
      "step": 442
    },
    {
      "epoch": 0.2922163588390501,
      "grad_norm": 4.342545032501221,
      "learning_rate": 9.028144239226034e-05,
      "loss": 0.2755,
      "step": 443
    },
    {
      "epoch": 0.2928759894459103,
      "grad_norm": 4.516271591186523,
      "learning_rate": 9.0259454705365e-05,
      "loss": 0.3599,
      "step": 444
    },
    {
      "epoch": 0.29353562005277045,
      "grad_norm": 1.2405375242233276,
      "learning_rate": 9.023746701846966e-05,
      "loss": 0.1536,
      "step": 445
    },
    {
      "epoch": 0.2941952506596306,
      "grad_norm": 4.88320779800415,
      "learning_rate": 9.021547933157433e-05,
      "loss": 0.2947,
      "step": 446
    },
    {
      "epoch": 0.2948548812664908,
      "grad_norm": 2.9292290210723877,
      "learning_rate": 9.019349164467898e-05,
      "loss": 0.1801,
      "step": 447
    },
    {
      "epoch": 0.2955145118733509,
      "grad_norm": 6.61607027053833,
      "learning_rate": 9.017150395778364e-05,
      "loss": 0.4074,
      "step": 448
    },
    {
      "epoch": 0.29617414248021107,
      "grad_norm": 8.811742782592773,
      "learning_rate": 9.014951627088831e-05,
      "loss": 0.5815,
      "step": 449
    },
    {
      "epoch": 0.29683377308707126,
      "grad_norm": 4.767643928527832,
      "learning_rate": 9.012752858399297e-05,
      "loss": 0.3542,
      "step": 450
    },
    {
      "epoch": 0.2974934036939314,
      "grad_norm": 6.349925518035889,
      "learning_rate": 9.010554089709763e-05,
      "loss": 0.6576,
      "step": 451
    },
    {
      "epoch": 0.29815303430079154,
      "grad_norm": 1.1197857856750488,
      "learning_rate": 9.008355321020228e-05,
      "loss": 0.1046,
      "step": 452
    },
    {
      "epoch": 0.29881266490765174,
      "grad_norm": 8.122859954833984,
      "learning_rate": 9.006156552330695e-05,
      "loss": 0.5536,
      "step": 453
    },
    {
      "epoch": 0.2994722955145119,
      "grad_norm": 4.923213958740234,
      "learning_rate": 9.003957783641161e-05,
      "loss": 0.2103,
      "step": 454
    },
    {
      "epoch": 0.300131926121372,
      "grad_norm": 9.104116439819336,
      "learning_rate": 9.001759014951627e-05,
      "loss": 0.4111,
      "step": 455
    },
    {
      "epoch": 0.3007915567282322,
      "grad_norm": 8.334168434143066,
      "learning_rate": 8.999560246262094e-05,
      "loss": 0.7942,
      "step": 456
    },
    {
      "epoch": 0.30145118733509235,
      "grad_norm": 6.207230567932129,
      "learning_rate": 8.997361477572561e-05,
      "loss": 0.6918,
      "step": 457
    },
    {
      "epoch": 0.3021108179419525,
      "grad_norm": 3.2731363773345947,
      "learning_rate": 8.995162708883026e-05,
      "loss": 0.2109,
      "step": 458
    },
    {
      "epoch": 0.3027704485488127,
      "grad_norm": 2.555839776992798,
      "learning_rate": 8.992963940193492e-05,
      "loss": 0.2763,
      "step": 459
    },
    {
      "epoch": 0.3034300791556728,
      "grad_norm": 3.9017181396484375,
      "learning_rate": 8.990765171503959e-05,
      "loss": 0.3016,
      "step": 460
    },
    {
      "epoch": 0.30408970976253297,
      "grad_norm": 7.232858657836914,
      "learning_rate": 8.988566402814425e-05,
      "loss": 0.3308,
      "step": 461
    },
    {
      "epoch": 0.30474934036939316,
      "grad_norm": 2.9371776580810547,
      "learning_rate": 8.98636763412489e-05,
      "loss": 0.2372,
      "step": 462
    },
    {
      "epoch": 0.3054089709762533,
      "grad_norm": 2.3194684982299805,
      "learning_rate": 8.984168865435356e-05,
      "loss": 0.1596,
      "step": 463
    },
    {
      "epoch": 0.30606860158311344,
      "grad_norm": 2.3812754154205322,
      "learning_rate": 8.981970096745823e-05,
      "loss": 0.2009,
      "step": 464
    },
    {
      "epoch": 0.30672823218997364,
      "grad_norm": 2.9123404026031494,
      "learning_rate": 8.979771328056289e-05,
      "loss": 0.2676,
      "step": 465
    },
    {
      "epoch": 0.3073878627968338,
      "grad_norm": 3.5506749153137207,
      "learning_rate": 8.977572559366755e-05,
      "loss": 0.1697,
      "step": 466
    },
    {
      "epoch": 0.3080474934036939,
      "grad_norm": 1.8470388650894165,
      "learning_rate": 8.975373790677222e-05,
      "loss": 0.1461,
      "step": 467
    },
    {
      "epoch": 0.3087071240105541,
      "grad_norm": 2.2053351402282715,
      "learning_rate": 8.973175021987688e-05,
      "loss": 0.108,
      "step": 468
    },
    {
      "epoch": 0.30936675461741425,
      "grad_norm": 9.822685241699219,
      "learning_rate": 8.970976253298153e-05,
      "loss": 0.7805,
      "step": 469
    },
    {
      "epoch": 0.3100263852242744,
      "grad_norm": 2.2294838428497314,
      "learning_rate": 8.968777484608619e-05,
      "loss": 0.1213,
      "step": 470
    },
    {
      "epoch": 0.3106860158311346,
      "grad_norm": 6.62475061416626,
      "learning_rate": 8.966578715919086e-05,
      "loss": 0.3155,
      "step": 471
    },
    {
      "epoch": 0.3113456464379947,
      "grad_norm": 15.616621971130371,
      "learning_rate": 8.964379947229552e-05,
      "loss": 1.9674,
      "step": 472
    },
    {
      "epoch": 0.31200527704485487,
      "grad_norm": 9.56424331665039,
      "learning_rate": 8.962181178540017e-05,
      "loss": 1.0543,
      "step": 473
    },
    {
      "epoch": 0.31266490765171506,
      "grad_norm": 7.450915813446045,
      "learning_rate": 8.959982409850483e-05,
      "loss": 0.3146,
      "step": 474
    },
    {
      "epoch": 0.3133245382585752,
      "grad_norm": 13.64261245727539,
      "learning_rate": 8.95778364116095e-05,
      "loss": 0.8299,
      "step": 475
    },
    {
      "epoch": 0.31398416886543534,
      "grad_norm": 11.607853889465332,
      "learning_rate": 8.955584872471416e-05,
      "loss": 0.822,
      "step": 476
    },
    {
      "epoch": 0.31464379947229554,
      "grad_norm": 1.1483771800994873,
      "learning_rate": 8.953386103781883e-05,
      "loss": 0.113,
      "step": 477
    },
    {
      "epoch": 0.3153034300791557,
      "grad_norm": 14.526041984558105,
      "learning_rate": 8.951187335092349e-05,
      "loss": 0.699,
      "step": 478
    },
    {
      "epoch": 0.3159630606860158,
      "grad_norm": 1.1255441904067993,
      "learning_rate": 8.948988566402816e-05,
      "loss": 0.0791,
      "step": 479
    },
    {
      "epoch": 0.316622691292876,
      "grad_norm": 3.346407413482666,
      "learning_rate": 8.946789797713281e-05,
      "loss": 0.2259,
      "step": 480
    },
    {
      "epoch": 0.31728232189973615,
      "grad_norm": 10.267210960388184,
      "learning_rate": 8.944591029023747e-05,
      "loss": 0.9328,
      "step": 481
    },
    {
      "epoch": 0.3179419525065963,
      "grad_norm": 8.919878005981445,
      "learning_rate": 8.942392260334214e-05,
      "loss": 1.0718,
      "step": 482
    },
    {
      "epoch": 0.3186015831134565,
      "grad_norm": 1.6874467134475708,
      "learning_rate": 8.94019349164468e-05,
      "loss": 0.2607,
      "step": 483
    },
    {
      "epoch": 0.31926121372031663,
      "grad_norm": 4.967100620269775,
      "learning_rate": 8.937994722955145e-05,
      "loss": 0.3271,
      "step": 484
    },
    {
      "epoch": 0.31992084432717677,
      "grad_norm": 5.107692241668701,
      "learning_rate": 8.935795954265613e-05,
      "loss": 0.3764,
      "step": 485
    },
    {
      "epoch": 0.32058047493403696,
      "grad_norm": 7.359992027282715,
      "learning_rate": 8.933597185576078e-05,
      "loss": 0.5064,
      "step": 486
    },
    {
      "epoch": 0.3212401055408971,
      "grad_norm": 3.0724503993988037,
      "learning_rate": 8.931398416886544e-05,
      "loss": 0.1893,
      "step": 487
    },
    {
      "epoch": 0.32189973614775724,
      "grad_norm": 2.3116583824157715,
      "learning_rate": 8.92919964819701e-05,
      "loss": 0.1585,
      "step": 488
    },
    {
      "epoch": 0.32255936675461744,
      "grad_norm": 2.5600361824035645,
      "learning_rate": 8.927000879507477e-05,
      "loss": 0.2154,
      "step": 489
    },
    {
      "epoch": 0.3232189973614776,
      "grad_norm": 4.08428430557251,
      "learning_rate": 8.924802110817942e-05,
      "loss": 0.2304,
      "step": 490
    },
    {
      "epoch": 0.3238786279683377,
      "grad_norm": 3.712628126144409,
      "learning_rate": 8.922603342128408e-05,
      "loss": 0.3426,
      "step": 491
    },
    {
      "epoch": 0.3245382585751979,
      "grad_norm": 6.688517093658447,
      "learning_rate": 8.920404573438874e-05,
      "loss": 0.4188,
      "step": 492
    },
    {
      "epoch": 0.32519788918205805,
      "grad_norm": 4.609042644500732,
      "learning_rate": 8.918205804749341e-05,
      "loss": 0.4682,
      "step": 493
    },
    {
      "epoch": 0.3258575197889182,
      "grad_norm": 2.709615707397461,
      "learning_rate": 8.916007036059806e-05,
      "loss": 0.1498,
      "step": 494
    },
    {
      "epoch": 0.3265171503957784,
      "grad_norm": 3.9310314655303955,
      "learning_rate": 8.913808267370272e-05,
      "loss": 0.264,
      "step": 495
    },
    {
      "epoch": 0.32717678100263853,
      "grad_norm": 6.242100238800049,
      "learning_rate": 8.911609498680739e-05,
      "loss": 0.2887,
      "step": 496
    },
    {
      "epoch": 0.32783641160949867,
      "grad_norm": 9.558406829833984,
      "learning_rate": 8.909410729991205e-05,
      "loss": 0.6099,
      "step": 497
    },
    {
      "epoch": 0.32849604221635886,
      "grad_norm": 1.541845440864563,
      "learning_rate": 8.907211961301672e-05,
      "loss": 0.1616,
      "step": 498
    },
    {
      "epoch": 0.329155672823219,
      "grad_norm": 7.824613571166992,
      "learning_rate": 8.905013192612138e-05,
      "loss": 0.5916,
      "step": 499
    },
    {
      "epoch": 0.32981530343007914,
      "grad_norm": 1.1538023948669434,
      "learning_rate": 8.902814423922605e-05,
      "loss": 0.1405,
      "step": 500
    },
    {
      "epoch": 0.33047493403693934,
      "grad_norm": 4.675868034362793,
      "learning_rate": 8.90061565523307e-05,
      "loss": 0.2508,
      "step": 501
    },
    {
      "epoch": 0.3311345646437995,
      "grad_norm": 2.808488130569458,
      "learning_rate": 8.898416886543536e-05,
      "loss": 0.269,
      "step": 502
    },
    {
      "epoch": 0.3317941952506596,
      "grad_norm": 2.50015926361084,
      "learning_rate": 8.896218117854003e-05,
      "loss": 0.225,
      "step": 503
    },
    {
      "epoch": 0.3324538258575198,
      "grad_norm": 3.033926248550415,
      "learning_rate": 8.894019349164469e-05,
      "loss": 0.2308,
      "step": 504
    },
    {
      "epoch": 0.33311345646437995,
      "grad_norm": 12.407211303710938,
      "learning_rate": 8.891820580474935e-05,
      "loss": 0.5624,
      "step": 505
    },
    {
      "epoch": 0.3337730870712401,
      "grad_norm": 8.017393112182617,
      "learning_rate": 8.8896218117854e-05,
      "loss": 0.6654,
      "step": 506
    },
    {
      "epoch": 0.3344327176781003,
      "grad_norm": 3.2478342056274414,
      "learning_rate": 8.887423043095867e-05,
      "loss": 0.24,
      "step": 507
    },
    {
      "epoch": 0.33509234828496043,
      "grad_norm": 6.669556140899658,
      "learning_rate": 8.885224274406333e-05,
      "loss": 0.3439,
      "step": 508
    },
    {
      "epoch": 0.33575197889182057,
      "grad_norm": 6.317419052124023,
      "learning_rate": 8.883025505716799e-05,
      "loss": 0.4633,
      "step": 509
    },
    {
      "epoch": 0.33641160949868076,
      "grad_norm": 2.7643561363220215,
      "learning_rate": 8.880826737027264e-05,
      "loss": 0.1982,
      "step": 510
    },
    {
      "epoch": 0.3370712401055409,
      "grad_norm": 6.673772811889648,
      "learning_rate": 8.878627968337731e-05,
      "loss": 0.3843,
      "step": 511
    },
    {
      "epoch": 0.33773087071240104,
      "grad_norm": 2.2649452686309814,
      "learning_rate": 8.876429199648197e-05,
      "loss": 0.2258,
      "step": 512
    },
    {
      "epoch": 0.33839050131926124,
      "grad_norm": 2.1154727935791016,
      "learning_rate": 8.874230430958663e-05,
      "loss": 0.1475,
      "step": 513
    },
    {
      "epoch": 0.3390501319261214,
      "grad_norm": 3.808337926864624,
      "learning_rate": 8.87203166226913e-05,
      "loss": 0.348,
      "step": 514
    },
    {
      "epoch": 0.3397097625329815,
      "grad_norm": 4.505814075469971,
      "learning_rate": 8.869832893579596e-05,
      "loss": 0.2869,
      "step": 515
    },
    {
      "epoch": 0.3403693931398417,
      "grad_norm": 6.735334396362305,
      "learning_rate": 8.867634124890061e-05,
      "loss": 0.4025,
      "step": 516
    },
    {
      "epoch": 0.34102902374670185,
      "grad_norm": 9.057083129882812,
      "learning_rate": 8.865435356200527e-05,
      "loss": 0.6653,
      "step": 517
    },
    {
      "epoch": 0.341688654353562,
      "grad_norm": 5.825721263885498,
      "learning_rate": 8.863236587510994e-05,
      "loss": 0.3076,
      "step": 518
    },
    {
      "epoch": 0.3423482849604222,
      "grad_norm": 7.597251892089844,
      "learning_rate": 8.86103781882146e-05,
      "loss": 0.6528,
      "step": 519
    },
    {
      "epoch": 0.34300791556728233,
      "grad_norm": 2.8945202827453613,
      "learning_rate": 8.858839050131927e-05,
      "loss": 0.2284,
      "step": 520
    },
    {
      "epoch": 0.34366754617414247,
      "grad_norm": 4.102789878845215,
      "learning_rate": 8.856640281442393e-05,
      "loss": 0.2612,
      "step": 521
    },
    {
      "epoch": 0.34432717678100266,
      "grad_norm": 4.723498344421387,
      "learning_rate": 8.85444151275286e-05,
      "loss": 0.1803,
      "step": 522
    },
    {
      "epoch": 0.3449868073878628,
      "grad_norm": 2.0659050941467285,
      "learning_rate": 8.852242744063325e-05,
      "loss": 0.1405,
      "step": 523
    },
    {
      "epoch": 0.34564643799472294,
      "grad_norm": 5.03515100479126,
      "learning_rate": 8.850043975373791e-05,
      "loss": 0.3891,
      "step": 524
    },
    {
      "epoch": 0.34630606860158314,
      "grad_norm": 1.8038629293441772,
      "learning_rate": 8.847845206684258e-05,
      "loss": 0.1845,
      "step": 525
    },
    {
      "epoch": 0.3469656992084433,
      "grad_norm": 12.87426471710205,
      "learning_rate": 8.845646437994724e-05,
      "loss": 0.752,
      "step": 526
    },
    {
      "epoch": 0.3476253298153034,
      "grad_norm": 5.238137722015381,
      "learning_rate": 8.84344766930519e-05,
      "loss": 0.4134,
      "step": 527
    },
    {
      "epoch": 0.3482849604221636,
      "grad_norm": 9.478986740112305,
      "learning_rate": 8.841248900615655e-05,
      "loss": 0.575,
      "step": 528
    },
    {
      "epoch": 0.34894459102902375,
      "grad_norm": 1.8734304904937744,
      "learning_rate": 8.839050131926122e-05,
      "loss": 0.1769,
      "step": 529
    },
    {
      "epoch": 0.3496042216358839,
      "grad_norm": 3.548351287841797,
      "learning_rate": 8.836851363236588e-05,
      "loss": 0.2154,
      "step": 530
    },
    {
      "epoch": 0.3502638522427441,
      "grad_norm": 2.498629570007324,
      "learning_rate": 8.834652594547054e-05,
      "loss": 0.1617,
      "step": 531
    },
    {
      "epoch": 0.35092348284960423,
      "grad_norm": 4.70318603515625,
      "learning_rate": 8.83245382585752e-05,
      "loss": 0.418,
      "step": 532
    },
    {
      "epoch": 0.35158311345646437,
      "grad_norm": 3.1421802043914795,
      "learning_rate": 8.830255057167986e-05,
      "loss": 0.3674,
      "step": 533
    },
    {
      "epoch": 0.35224274406332456,
      "grad_norm": 5.147050380706787,
      "learning_rate": 8.828056288478452e-05,
      "loss": 0.3988,
      "step": 534
    },
    {
      "epoch": 0.3529023746701847,
      "grad_norm": 5.162676811218262,
      "learning_rate": 8.825857519788918e-05,
      "loss": 0.464,
      "step": 535
    },
    {
      "epoch": 0.35356200527704484,
      "grad_norm": 7.638882637023926,
      "learning_rate": 8.823658751099385e-05,
      "loss": 0.5002,
      "step": 536
    },
    {
      "epoch": 0.35422163588390504,
      "grad_norm": 5.643865585327148,
      "learning_rate": 8.82145998240985e-05,
      "loss": 0.3346,
      "step": 537
    },
    {
      "epoch": 0.3548812664907652,
      "grad_norm": 5.350941181182861,
      "learning_rate": 8.819261213720316e-05,
      "loss": 0.394,
      "step": 538
    },
    {
      "epoch": 0.3555408970976253,
      "grad_norm": 4.610873222351074,
      "learning_rate": 8.817062445030783e-05,
      "loss": 0.3729,
      "step": 539
    },
    {
      "epoch": 0.3562005277044855,
      "grad_norm": 7.535212516784668,
      "learning_rate": 8.814863676341249e-05,
      "loss": 0.4187,
      "step": 540
    },
    {
      "epoch": 0.35686015831134565,
      "grad_norm": 3.2134227752685547,
      "learning_rate": 8.812664907651716e-05,
      "loss": 0.2752,
      "step": 541
    },
    {
      "epoch": 0.3575197889182058,
      "grad_norm": 4.723737716674805,
      "learning_rate": 8.810466138962182e-05,
      "loss": 0.2245,
      "step": 542
    },
    {
      "epoch": 0.358179419525066,
      "grad_norm": 1.6374021768569946,
      "learning_rate": 8.808267370272649e-05,
      "loss": 0.2232,
      "step": 543
    },
    {
      "epoch": 0.35883905013192613,
      "grad_norm": 5.564384937286377,
      "learning_rate": 8.806068601583114e-05,
      "loss": 0.4857,
      "step": 544
    },
    {
      "epoch": 0.35949868073878627,
      "grad_norm": 3.8699839115142822,
      "learning_rate": 8.80386983289358e-05,
      "loss": 0.2365,
      "step": 545
    },
    {
      "epoch": 0.36015831134564646,
      "grad_norm": 1.0916024446487427,
      "learning_rate": 8.801671064204046e-05,
      "loss": 0.1193,
      "step": 546
    },
    {
      "epoch": 0.3608179419525066,
      "grad_norm": 2.3746724128723145,
      "learning_rate": 8.799472295514513e-05,
      "loss": 0.2908,
      "step": 547
    },
    {
      "epoch": 0.36147757255936674,
      "grad_norm": 2.222017765045166,
      "learning_rate": 8.797273526824979e-05,
      "loss": 0.1399,
      "step": 548
    },
    {
      "epoch": 0.36213720316622694,
      "grad_norm": 8.104708671569824,
      "learning_rate": 8.795074758135444e-05,
      "loss": 0.367,
      "step": 549
    },
    {
      "epoch": 0.3627968337730871,
      "grad_norm": 2.0717368125915527,
      "learning_rate": 8.792875989445911e-05,
      "loss": 0.1045,
      "step": 550
    },
    {
      "epoch": 0.3634564643799472,
      "grad_norm": 1.8206852674484253,
      "learning_rate": 8.790677220756377e-05,
      "loss": 0.0858,
      "step": 551
    },
    {
      "epoch": 0.3641160949868074,
      "grad_norm": 1.395050048828125,
      "learning_rate": 8.788478452066843e-05,
      "loss": 0.0778,
      "step": 552
    },
    {
      "epoch": 0.36477572559366755,
      "grad_norm": 6.295565128326416,
      "learning_rate": 8.786279683377308e-05,
      "loss": 0.25,
      "step": 553
    },
    {
      "epoch": 0.3654353562005277,
      "grad_norm": 2.9075002670288086,
      "learning_rate": 8.784080914687775e-05,
      "loss": 0.1245,
      "step": 554
    },
    {
      "epoch": 0.3660949868073879,
      "grad_norm": 13.625897407531738,
      "learning_rate": 8.781882145998241e-05,
      "loss": 0.8693,
      "step": 555
    },
    {
      "epoch": 0.36675461741424803,
      "grad_norm": 4.761309623718262,
      "learning_rate": 8.779683377308707e-05,
      "loss": 0.1497,
      "step": 556
    },
    {
      "epoch": 0.36741424802110817,
      "grad_norm": 17.396320343017578,
      "learning_rate": 8.777484608619174e-05,
      "loss": 1.1062,
      "step": 557
    },
    {
      "epoch": 0.36807387862796836,
      "grad_norm": 16.49413299560547,
      "learning_rate": 8.77528583992964e-05,
      "loss": 1.5617,
      "step": 558
    },
    {
      "epoch": 0.3687335092348285,
      "grad_norm": 12.435603141784668,
      "learning_rate": 8.773087071240105e-05,
      "loss": 0.6724,
      "step": 559
    },
    {
      "epoch": 0.36939313984168864,
      "grad_norm": 11.790371894836426,
      "learning_rate": 8.770888302550571e-05,
      "loss": 1.4632,
      "step": 560
    },
    {
      "epoch": 0.37005277044854884,
      "grad_norm": 6.195546627044678,
      "learning_rate": 8.768689533861038e-05,
      "loss": 0.216,
      "step": 561
    },
    {
      "epoch": 0.370712401055409,
      "grad_norm": 0.7611521482467651,
      "learning_rate": 8.766490765171505e-05,
      "loss": 0.0563,
      "step": 562
    },
    {
      "epoch": 0.3713720316622691,
      "grad_norm": 0.7102899551391602,
      "learning_rate": 8.764291996481971e-05,
      "loss": 0.0626,
      "step": 563
    },
    {
      "epoch": 0.3720316622691293,
      "grad_norm": 9.8390531539917,
      "learning_rate": 8.762093227792437e-05,
      "loss": 0.5684,
      "step": 564
    },
    {
      "epoch": 0.37269129287598945,
      "grad_norm": 12.986096382141113,
      "learning_rate": 8.759894459102904e-05,
      "loss": 1.5401,
      "step": 565
    },
    {
      "epoch": 0.3733509234828496,
      "grad_norm": 2.567634344100952,
      "learning_rate": 8.757695690413369e-05,
      "loss": 0.129,
      "step": 566
    },
    {
      "epoch": 0.3740105540897098,
      "grad_norm": 6.2790913581848145,
      "learning_rate": 8.755496921723835e-05,
      "loss": 0.3093,
      "step": 567
    },
    {
      "epoch": 0.37467018469656993,
      "grad_norm": 1.7939209938049316,
      "learning_rate": 8.753298153034302e-05,
      "loss": 0.1018,
      "step": 568
    },
    {
      "epoch": 0.37532981530343007,
      "grad_norm": 0.9751856923103333,
      "learning_rate": 8.751099384344768e-05,
      "loss": 0.0926,
      "step": 569
    },
    {
      "epoch": 0.3759894459102902,
      "grad_norm": 6.794933795928955,
      "learning_rate": 8.748900615655233e-05,
      "loss": 0.2959,
      "step": 570
    },
    {
      "epoch": 0.3766490765171504,
      "grad_norm": 9.430303573608398,
      "learning_rate": 8.746701846965699e-05,
      "loss": 1.5925,
      "step": 571
    },
    {
      "epoch": 0.37730870712401055,
      "grad_norm": 1.7484562397003174,
      "learning_rate": 8.744503078276166e-05,
      "loss": 0.1052,
      "step": 572
    },
    {
      "epoch": 0.3779683377308707,
      "grad_norm": 2.570610761642456,
      "learning_rate": 8.742304309586632e-05,
      "loss": 0.158,
      "step": 573
    },
    {
      "epoch": 0.3786279683377309,
      "grad_norm": 10.450345039367676,
      "learning_rate": 8.740105540897098e-05,
      "loss": 0.6908,
      "step": 574
    },
    {
      "epoch": 0.379287598944591,
      "grad_norm": 1.6002728939056396,
      "learning_rate": 8.737906772207565e-05,
      "loss": 0.1427,
      "step": 575
    },
    {
      "epoch": 0.37994722955145116,
      "grad_norm": 1.00077223777771,
      "learning_rate": 8.73570800351803e-05,
      "loss": 0.1116,
      "step": 576
    },
    {
      "epoch": 0.38060686015831136,
      "grad_norm": 2.197131633758545,
      "learning_rate": 8.733509234828496e-05,
      "loss": 0.1748,
      "step": 577
    },
    {
      "epoch": 0.3812664907651715,
      "grad_norm": 2.261547088623047,
      "learning_rate": 8.731310466138962e-05,
      "loss": 0.1731,
      "step": 578
    },
    {
      "epoch": 0.38192612137203164,
      "grad_norm": 5.828131675720215,
      "learning_rate": 8.729111697449429e-05,
      "loss": 0.2255,
      "step": 579
    },
    {
      "epoch": 0.38258575197889183,
      "grad_norm": 0.9501099586486816,
      "learning_rate": 8.726912928759894e-05,
      "loss": 0.1566,
      "step": 580
    },
    {
      "epoch": 0.38324538258575197,
      "grad_norm": 1.2395963668823242,
      "learning_rate": 8.72471416007036e-05,
      "loss": 0.1212,
      "step": 581
    },
    {
      "epoch": 0.3839050131926121,
      "grad_norm": 19.275827407836914,
      "learning_rate": 8.722515391380827e-05,
      "loss": 1.1388,
      "step": 582
    },
    {
      "epoch": 0.3845646437994723,
      "grad_norm": 11.57835865020752,
      "learning_rate": 8.720316622691293e-05,
      "loss": 0.6881,
      "step": 583
    },
    {
      "epoch": 0.38522427440633245,
      "grad_norm": 2.531592607498169,
      "learning_rate": 8.71811785400176e-05,
      "loss": 0.1893,
      "step": 584
    },
    {
      "epoch": 0.3858839050131926,
      "grad_norm": 2.6495440006256104,
      "learning_rate": 8.715919085312226e-05,
      "loss": 0.1451,
      "step": 585
    },
    {
      "epoch": 0.3865435356200528,
      "grad_norm": 8.207498550415039,
      "learning_rate": 8.713720316622693e-05,
      "loss": 0.5733,
      "step": 586
    },
    {
      "epoch": 0.3872031662269129,
      "grad_norm": 2.630970001220703,
      "learning_rate": 8.711521547933158e-05,
      "loss": 0.1432,
      "step": 587
    },
    {
      "epoch": 0.38786279683377306,
      "grad_norm": 5.959112644195557,
      "learning_rate": 8.709322779243624e-05,
      "loss": 0.503,
      "step": 588
    },
    {
      "epoch": 0.38852242744063326,
      "grad_norm": 6.437242031097412,
      "learning_rate": 8.70712401055409e-05,
      "loss": 1.1141,
      "step": 589
    },
    {
      "epoch": 0.3891820580474934,
      "grad_norm": 1.5802713632583618,
      "learning_rate": 8.704925241864557e-05,
      "loss": 0.1206,
      "step": 590
    },
    {
      "epoch": 0.38984168865435354,
      "grad_norm": 4.1992082595825195,
      "learning_rate": 8.702726473175023e-05,
      "loss": 0.1988,
      "step": 591
    },
    {
      "epoch": 0.39050131926121373,
      "grad_norm": 11.666790008544922,
      "learning_rate": 8.700527704485488e-05,
      "loss": 0.925,
      "step": 592
    },
    {
      "epoch": 0.39116094986807387,
      "grad_norm": 9.101651191711426,
      "learning_rate": 8.698328935795955e-05,
      "loss": 0.8508,
      "step": 593
    },
    {
      "epoch": 0.391820580474934,
      "grad_norm": 6.387360095977783,
      "learning_rate": 8.696130167106421e-05,
      "loss": 0.6986,
      "step": 594
    },
    {
      "epoch": 0.3924802110817942,
      "grad_norm": 0.7755548357963562,
      "learning_rate": 8.693931398416887e-05,
      "loss": 0.083,
      "step": 595
    },
    {
      "epoch": 0.39313984168865435,
      "grad_norm": 0.8583356142044067,
      "learning_rate": 8.691732629727352e-05,
      "loss": 0.0951,
      "step": 596
    },
    {
      "epoch": 0.3937994722955145,
      "grad_norm": 1.6900720596313477,
      "learning_rate": 8.68953386103782e-05,
      "loss": 0.101,
      "step": 597
    },
    {
      "epoch": 0.3944591029023747,
      "grad_norm": 1.52247953414917,
      "learning_rate": 8.687335092348285e-05,
      "loss": 0.1792,
      "step": 598
    },
    {
      "epoch": 0.3951187335092348,
      "grad_norm": 1.4367378950119019,
      "learning_rate": 8.685136323658751e-05,
      "loss": 0.1197,
      "step": 599
    },
    {
      "epoch": 0.39577836411609496,
      "grad_norm": 10.097174644470215,
      "learning_rate": 8.682937554969217e-05,
      "loss": 0.8928,
      "step": 600
    },
    {
      "epoch": 0.39643799472295516,
      "grad_norm": 5.672211170196533,
      "learning_rate": 8.680738786279684e-05,
      "loss": 0.301,
      "step": 601
    },
    {
      "epoch": 0.3970976253298153,
      "grad_norm": 10.202777862548828,
      "learning_rate": 8.67854001759015e-05,
      "loss": 0.7057,
      "step": 602
    },
    {
      "epoch": 0.39775725593667544,
      "grad_norm": 8.287519454956055,
      "learning_rate": 8.676341248900616e-05,
      "loss": 0.6223,
      "step": 603
    },
    {
      "epoch": 0.39841688654353563,
      "grad_norm": 2.606781482696533,
      "learning_rate": 8.674142480211082e-05,
      "loss": 0.2158,
      "step": 604
    },
    {
      "epoch": 0.39907651715039577,
      "grad_norm": 1.0042611360549927,
      "learning_rate": 8.671943711521549e-05,
      "loss": 0.0995,
      "step": 605
    },
    {
      "epoch": 0.3997361477572559,
      "grad_norm": 10.3836030960083,
      "learning_rate": 8.669744942832015e-05,
      "loss": 0.9049,
      "step": 606
    },
    {
      "epoch": 0.4003957783641161,
      "grad_norm": 6.2848920822143555,
      "learning_rate": 8.66754617414248e-05,
      "loss": 0.6672,
      "step": 607
    },
    {
      "epoch": 0.40105540897097625,
      "grad_norm": 5.111202239990234,
      "learning_rate": 8.665347405452948e-05,
      "loss": 0.3969,
      "step": 608
    },
    {
      "epoch": 0.4017150395778364,
      "grad_norm": 3.5611448287963867,
      "learning_rate": 8.663148636763413e-05,
      "loss": 0.2368,
      "step": 609
    },
    {
      "epoch": 0.4023746701846966,
      "grad_norm": 1.600982904434204,
      "learning_rate": 8.660949868073879e-05,
      "loss": 0.134,
      "step": 610
    },
    {
      "epoch": 0.4030343007915567,
      "grad_norm": 3.067080020904541,
      "learning_rate": 8.658751099384346e-05,
      "loss": 0.3687,
      "step": 611
    },
    {
      "epoch": 0.40369393139841686,
      "grad_norm": 4.600856781005859,
      "learning_rate": 8.656552330694812e-05,
      "loss": 0.5529,
      "step": 612
    },
    {
      "epoch": 0.40435356200527706,
      "grad_norm": 2.090303659439087,
      "learning_rate": 8.654353562005277e-05,
      "loss": 0.2232,
      "step": 613
    },
    {
      "epoch": 0.4050131926121372,
      "grad_norm": 4.23403263092041,
      "learning_rate": 8.652154793315743e-05,
      "loss": 0.325,
      "step": 614
    },
    {
      "epoch": 0.40567282321899734,
      "grad_norm": 3.722106695175171,
      "learning_rate": 8.64995602462621e-05,
      "loss": 0.3519,
      "step": 615
    },
    {
      "epoch": 0.40633245382585753,
      "grad_norm": 1.7215821743011475,
      "learning_rate": 8.647757255936676e-05,
      "loss": 0.1491,
      "step": 616
    },
    {
      "epoch": 0.40699208443271767,
      "grad_norm": 3.2589852809906006,
      "learning_rate": 8.645558487247142e-05,
      "loss": 0.2597,
      "step": 617
    },
    {
      "epoch": 0.4076517150395778,
      "grad_norm": 1.977856159210205,
      "learning_rate": 8.643359718557607e-05,
      "loss": 0.1337,
      "step": 618
    },
    {
      "epoch": 0.408311345646438,
      "grad_norm": 8.176034927368164,
      "learning_rate": 8.641160949868074e-05,
      "loss": 0.4979,
      "step": 619
    },
    {
      "epoch": 0.40897097625329815,
      "grad_norm": 2.9159367084503174,
      "learning_rate": 8.63896218117854e-05,
      "loss": 0.1486,
      "step": 620
    },
    {
      "epoch": 0.4096306068601583,
      "grad_norm": 1.1946992874145508,
      "learning_rate": 8.636763412489006e-05,
      "loss": 0.1094,
      "step": 621
    },
    {
      "epoch": 0.4102902374670185,
      "grad_norm": 15.224732398986816,
      "learning_rate": 8.634564643799473e-05,
      "loss": 0.6547,
      "step": 622
    },
    {
      "epoch": 0.4109498680738786,
      "grad_norm": 15.671095848083496,
      "learning_rate": 8.632365875109938e-05,
      "loss": 0.7704,
      "step": 623
    },
    {
      "epoch": 0.41160949868073876,
      "grad_norm": 14.50412368774414,
      "learning_rate": 8.630167106420404e-05,
      "loss": 1.5145,
      "step": 624
    },
    {
      "epoch": 0.41226912928759896,
      "grad_norm": 11.830679893493652,
      "learning_rate": 8.627968337730871e-05,
      "loss": 0.9928,
      "step": 625
    },
    {
      "epoch": 0.4129287598944591,
      "grad_norm": 9.37365436553955,
      "learning_rate": 8.625769569041337e-05,
      "loss": 0.6977,
      "step": 626
    },
    {
      "epoch": 0.41358839050131924,
      "grad_norm": 9.755638122558594,
      "learning_rate": 8.623570800351804e-05,
      "loss": 0.8478,
      "step": 627
    },
    {
      "epoch": 0.41424802110817943,
      "grad_norm": 1.6091463565826416,
      "learning_rate": 8.62137203166227e-05,
      "loss": 0.0796,
      "step": 628
    },
    {
      "epoch": 0.41490765171503957,
      "grad_norm": 1.973203182220459,
      "learning_rate": 8.619173262972737e-05,
      "loss": 0.0934,
      "step": 629
    },
    {
      "epoch": 0.4155672823218997,
      "grad_norm": 4.059591293334961,
      "learning_rate": 8.616974494283202e-05,
      "loss": 0.2056,
      "step": 630
    },
    {
      "epoch": 0.4162269129287599,
      "grad_norm": 0.8210698366165161,
      "learning_rate": 8.614775725593668e-05,
      "loss": 0.0815,
      "step": 631
    },
    {
      "epoch": 0.41688654353562005,
      "grad_norm": 4.548077583312988,
      "learning_rate": 8.612576956904134e-05,
      "loss": 0.1858,
      "step": 632
    },
    {
      "epoch": 0.4175461741424802,
      "grad_norm": 9.904218673706055,
      "learning_rate": 8.610378188214601e-05,
      "loss": 0.6122,
      "step": 633
    },
    {
      "epoch": 0.4182058047493404,
      "grad_norm": 1.9664099216461182,
      "learning_rate": 8.608179419525067e-05,
      "loss": 0.1061,
      "step": 634
    },
    {
      "epoch": 0.4188654353562005,
      "grad_norm": 8.880142211914062,
      "learning_rate": 8.605980650835532e-05,
      "loss": 0.49,
      "step": 635
    },
    {
      "epoch": 0.41952506596306066,
      "grad_norm": 4.383951663970947,
      "learning_rate": 8.603781882145998e-05,
      "loss": 0.2107,
      "step": 636
    },
    {
      "epoch": 0.42018469656992086,
      "grad_norm": 1.916690707206726,
      "learning_rate": 8.601583113456465e-05,
      "loss": 0.1502,
      "step": 637
    },
    {
      "epoch": 0.420844327176781,
      "grad_norm": 1.9417039155960083,
      "learning_rate": 8.599384344766931e-05,
      "loss": 0.1021,
      "step": 638
    },
    {
      "epoch": 0.42150395778364114,
      "grad_norm": 3.0885074138641357,
      "learning_rate": 8.597185576077396e-05,
      "loss": 0.1217,
      "step": 639
    },
    {
      "epoch": 0.42216358839050133,
      "grad_norm": 3.5536720752716064,
      "learning_rate": 8.594986807387863e-05,
      "loss": 0.2131,
      "step": 640
    },
    {
      "epoch": 0.42282321899736147,
      "grad_norm": 9.881816864013672,
      "learning_rate": 8.592788038698329e-05,
      "loss": 0.8697,
      "step": 641
    },
    {
      "epoch": 0.4234828496042216,
      "grad_norm": 4.300847053527832,
      "learning_rate": 8.590589270008795e-05,
      "loss": 0.2207,
      "step": 642
    },
    {
      "epoch": 0.4241424802110818,
      "grad_norm": 3.8750839233398438,
      "learning_rate": 8.58839050131926e-05,
      "loss": 0.231,
      "step": 643
    },
    {
      "epoch": 0.42480211081794195,
      "grad_norm": 4.3404316902160645,
      "learning_rate": 8.586191732629728e-05,
      "loss": 0.2328,
      "step": 644
    },
    {
      "epoch": 0.4254617414248021,
      "grad_norm": 5.156894207000732,
      "learning_rate": 8.583992963940193e-05,
      "loss": 0.5454,
      "step": 645
    },
    {
      "epoch": 0.4261213720316623,
      "grad_norm": 4.097331523895264,
      "learning_rate": 8.58179419525066e-05,
      "loss": 0.2822,
      "step": 646
    },
    {
      "epoch": 0.4267810026385224,
      "grad_norm": 1.8232942819595337,
      "learning_rate": 8.579595426561126e-05,
      "loss": 0.2111,
      "step": 647
    },
    {
      "epoch": 0.42744063324538256,
      "grad_norm": 7.204232692718506,
      "learning_rate": 8.577396657871593e-05,
      "loss": 0.5235,
      "step": 648
    },
    {
      "epoch": 0.42810026385224276,
      "grad_norm": 4.2446513175964355,
      "learning_rate": 8.575197889182059e-05,
      "loss": 0.3654,
      "step": 649
    },
    {
      "epoch": 0.4287598944591029,
      "grad_norm": 1.7477812767028809,
      "learning_rate": 8.572999120492525e-05,
      "loss": 0.1841,
      "step": 650
    },
    {
      "epoch": 0.42941952506596304,
      "grad_norm": 1.983232855796814,
      "learning_rate": 8.570800351802992e-05,
      "loss": 0.1578,
      "step": 651
    },
    {
      "epoch": 0.43007915567282323,
      "grad_norm": 2.889765977859497,
      "learning_rate": 8.568601583113457e-05,
      "loss": 0.2428,
      "step": 652
    },
    {
      "epoch": 0.43073878627968337,
      "grad_norm": 4.3378424644470215,
      "learning_rate": 8.566402814423923e-05,
      "loss": 0.2469,
      "step": 653
    },
    {
      "epoch": 0.4313984168865435,
      "grad_norm": 6.2121076583862305,
      "learning_rate": 8.564204045734389e-05,
      "loss": 0.5114,
      "step": 654
    },
    {
      "epoch": 0.4320580474934037,
      "grad_norm": 2.541395902633667,
      "learning_rate": 8.562005277044856e-05,
      "loss": 0.1685,
      "step": 655
    },
    {
      "epoch": 0.43271767810026385,
      "grad_norm": 9.130796432495117,
      "learning_rate": 8.559806508355321e-05,
      "loss": 0.798,
      "step": 656
    },
    {
      "epoch": 0.433377308707124,
      "grad_norm": 5.35709285736084,
      "learning_rate": 8.557607739665787e-05,
      "loss": 0.3836,
      "step": 657
    },
    {
      "epoch": 0.4340369393139842,
      "grad_norm": 5.616968631744385,
      "learning_rate": 8.555408970976254e-05,
      "loss": 0.316,
      "step": 658
    },
    {
      "epoch": 0.4346965699208443,
      "grad_norm": 12.799691200256348,
      "learning_rate": 8.55321020228672e-05,
      "loss": 0.5408,
      "step": 659
    },
    {
      "epoch": 0.43535620052770446,
      "grad_norm": 7.587985992431641,
      "learning_rate": 8.551011433597186e-05,
      "loss": 0.4823,
      "step": 660
    },
    {
      "epoch": 0.43601583113456466,
      "grad_norm": 9.356327056884766,
      "learning_rate": 8.548812664907651e-05,
      "loss": 0.7358,
      "step": 661
    },
    {
      "epoch": 0.4366754617414248,
      "grad_norm": 4.119976043701172,
      "learning_rate": 8.546613896218118e-05,
      "loss": 0.2529,
      "step": 662
    },
    {
      "epoch": 0.43733509234828494,
      "grad_norm": 7.287176609039307,
      "learning_rate": 8.544415127528584e-05,
      "loss": 0.4298,
      "step": 663
    },
    {
      "epoch": 0.43799472295514513,
      "grad_norm": 4.719658374786377,
      "learning_rate": 8.54221635883905e-05,
      "loss": 0.249,
      "step": 664
    },
    {
      "epoch": 0.4386543535620053,
      "grad_norm": 5.719143390655518,
      "learning_rate": 8.540017590149517e-05,
      "loss": 0.3589,
      "step": 665
    },
    {
      "epoch": 0.4393139841688654,
      "grad_norm": 8.86751651763916,
      "learning_rate": 8.537818821459982e-05,
      "loss": 1.1464,
      "step": 666
    },
    {
      "epoch": 0.4399736147757256,
      "grad_norm": 2.6724648475646973,
      "learning_rate": 8.53562005277045e-05,
      "loss": 0.324,
      "step": 667
    },
    {
      "epoch": 0.44063324538258575,
      "grad_norm": 1.5311839580535889,
      "learning_rate": 8.533421284080915e-05,
      "loss": 0.2172,
      "step": 668
    },
    {
      "epoch": 0.4412928759894459,
      "grad_norm": 2.214045524597168,
      "learning_rate": 8.531222515391382e-05,
      "loss": 0.1895,
      "step": 669
    },
    {
      "epoch": 0.4419525065963061,
      "grad_norm": 2.0543224811553955,
      "learning_rate": 8.529023746701848e-05,
      "loss": 0.2533,
      "step": 670
    },
    {
      "epoch": 0.4426121372031662,
      "grad_norm": 1.672110676765442,
      "learning_rate": 8.526824978012314e-05,
      "loss": 0.1254,
      "step": 671
    },
    {
      "epoch": 0.44327176781002636,
      "grad_norm": 2.8828461170196533,
      "learning_rate": 8.52462620932278e-05,
      "loss": 0.1917,
      "step": 672
    },
    {
      "epoch": 0.44393139841688656,
      "grad_norm": 8.137594223022461,
      "learning_rate": 8.522427440633246e-05,
      "loss": 0.784,
      "step": 673
    },
    {
      "epoch": 0.4445910290237467,
      "grad_norm": 3.6377880573272705,
      "learning_rate": 8.520228671943712e-05,
      "loss": 0.2258,
      "step": 674
    },
    {
      "epoch": 0.44525065963060684,
      "grad_norm": 3.8083198070526123,
      "learning_rate": 8.518029903254178e-05,
      "loss": 0.2379,
      "step": 675
    },
    {
      "epoch": 0.44591029023746703,
      "grad_norm": 8.895240783691406,
      "learning_rate": 8.515831134564645e-05,
      "loss": 0.522,
      "step": 676
    },
    {
      "epoch": 0.4465699208443272,
      "grad_norm": 4.980997562408447,
      "learning_rate": 8.51363236587511e-05,
      "loss": 0.1919,
      "step": 677
    },
    {
      "epoch": 0.4472295514511873,
      "grad_norm": 6.29743766784668,
      "learning_rate": 8.511433597185576e-05,
      "loss": 0.4591,
      "step": 678
    },
    {
      "epoch": 0.4478891820580475,
      "grad_norm": 3.620671033859253,
      "learning_rate": 8.509234828496042e-05,
      "loss": 0.3099,
      "step": 679
    },
    {
      "epoch": 0.44854881266490765,
      "grad_norm": 13.95104694366455,
      "learning_rate": 8.507036059806509e-05,
      "loss": 0.1516,
      "step": 680
    },
    {
      "epoch": 0.4492084432717678,
      "grad_norm": 6.67484188079834,
      "learning_rate": 8.504837291116975e-05,
      "loss": 0.2538,
      "step": 681
    },
    {
      "epoch": 0.449868073878628,
      "grad_norm": 3.310877799987793,
      "learning_rate": 8.50263852242744e-05,
      "loss": 0.305,
      "step": 682
    },
    {
      "epoch": 0.4505277044854881,
      "grad_norm": 2.549614191055298,
      "learning_rate": 8.500439753737907e-05,
      "loss": 0.2698,
      "step": 683
    },
    {
      "epoch": 0.45118733509234826,
      "grad_norm": 2.139801025390625,
      "learning_rate": 8.498240985048373e-05,
      "loss": 0.2677,
      "step": 684
    },
    {
      "epoch": 0.45184696569920846,
      "grad_norm": 1.6720401048660278,
      "learning_rate": 8.496042216358839e-05,
      "loss": 0.2442,
      "step": 685
    },
    {
      "epoch": 0.4525065963060686,
      "grad_norm": 3.917452812194824,
      "learning_rate": 8.493843447669305e-05,
      "loss": 0.2846,
      "step": 686
    },
    {
      "epoch": 0.45316622691292874,
      "grad_norm": 2.357390880584717,
      "learning_rate": 8.491644678979772e-05,
      "loss": 0.2401,
      "step": 687
    },
    {
      "epoch": 0.45382585751978893,
      "grad_norm": 4.968775272369385,
      "learning_rate": 8.489445910290237e-05,
      "loss": 0.2984,
      "step": 688
    },
    {
      "epoch": 0.4544854881266491,
      "grad_norm": 3.5178682804107666,
      "learning_rate": 8.487247141600704e-05,
      "loss": 0.2806,
      "step": 689
    },
    {
      "epoch": 0.4551451187335092,
      "grad_norm": 7.626011848449707,
      "learning_rate": 8.48504837291117e-05,
      "loss": 0.6425,
      "step": 690
    },
    {
      "epoch": 0.4558047493403694,
      "grad_norm": 7.072492599487305,
      "learning_rate": 8.482849604221637e-05,
      "loss": 0.3183,
      "step": 691
    },
    {
      "epoch": 0.45646437994722955,
      "grad_norm": 4.356438636779785,
      "learning_rate": 8.480650835532103e-05,
      "loss": 0.2434,
      "step": 692
    },
    {
      "epoch": 0.4571240105540897,
      "grad_norm": 1.0624336004257202,
      "learning_rate": 8.478452066842569e-05,
      "loss": 0.123,
      "step": 693
    },
    {
      "epoch": 0.4577836411609499,
      "grad_norm": 3.313631057739258,
      "learning_rate": 8.476253298153036e-05,
      "loss": 0.1705,
      "step": 694
    },
    {
      "epoch": 0.45844327176781,
      "grad_norm": 8.258650779724121,
      "learning_rate": 8.474054529463501e-05,
      "loss": 0.5844,
      "step": 695
    },
    {
      "epoch": 0.45910290237467016,
      "grad_norm": 3.473341703414917,
      "learning_rate": 8.471855760773967e-05,
      "loss": 0.1949,
      "step": 696
    },
    {
      "epoch": 0.45976253298153036,
      "grad_norm": 2.259833335876465,
      "learning_rate": 8.469656992084433e-05,
      "loss": 0.1943,
      "step": 697
    },
    {
      "epoch": 0.4604221635883905,
      "grad_norm": 7.889392852783203,
      "learning_rate": 8.4674582233949e-05,
      "loss": 0.4887,
      "step": 698
    },
    {
      "epoch": 0.46108179419525064,
      "grad_norm": 5.564690589904785,
      "learning_rate": 8.465259454705365e-05,
      "loss": 0.3855,
      "step": 699
    },
    {
      "epoch": 0.46174142480211083,
      "grad_norm": 3.133204698562622,
      "learning_rate": 8.463060686015831e-05,
      "loss": 0.1727,
      "step": 700
    },
    {
      "epoch": 0.462401055408971,
      "grad_norm": 6.4977335929870605,
      "learning_rate": 8.460861917326298e-05,
      "loss": 0.3853,
      "step": 701
    },
    {
      "epoch": 0.4630606860158311,
      "grad_norm": 4.38666296005249,
      "learning_rate": 8.458663148636764e-05,
      "loss": 0.2063,
      "step": 702
    },
    {
      "epoch": 0.4637203166226913,
      "grad_norm": 1.6428747177124023,
      "learning_rate": 8.45646437994723e-05,
      "loss": 0.1958,
      "step": 703
    },
    {
      "epoch": 0.46437994722955145,
      "grad_norm": 3.9250547885894775,
      "learning_rate": 8.454265611257695e-05,
      "loss": 0.2024,
      "step": 704
    },
    {
      "epoch": 0.4650395778364116,
      "grad_norm": 7.32628870010376,
      "learning_rate": 8.452066842568162e-05,
      "loss": 0.9612,
      "step": 705
    },
    {
      "epoch": 0.4656992084432718,
      "grad_norm": 7.076186180114746,
      "learning_rate": 8.449868073878628e-05,
      "loss": 0.4701,
      "step": 706
    },
    {
      "epoch": 0.4663588390501319,
      "grad_norm": 1.1656415462493896,
      "learning_rate": 8.447669305189094e-05,
      "loss": 0.1018,
      "step": 707
    },
    {
      "epoch": 0.46701846965699206,
      "grad_norm": 2.779819965362549,
      "learning_rate": 8.445470536499561e-05,
      "loss": 0.2245,
      "step": 708
    },
    {
      "epoch": 0.46767810026385226,
      "grad_norm": 1.992388367652893,
      "learning_rate": 8.443271767810026e-05,
      "loss": 0.1652,
      "step": 709
    },
    {
      "epoch": 0.4683377308707124,
      "grad_norm": 2.6740000247955322,
      "learning_rate": 8.441072999120494e-05,
      "loss": 0.1916,
      "step": 710
    },
    {
      "epoch": 0.46899736147757254,
      "grad_norm": 11.493885040283203,
      "learning_rate": 8.438874230430959e-05,
      "loss": 0.5583,
      "step": 711
    },
    {
      "epoch": 0.46965699208443273,
      "grad_norm": 4.33714485168457,
      "learning_rate": 8.436675461741426e-05,
      "loss": 0.3577,
      "step": 712
    },
    {
      "epoch": 0.4703166226912929,
      "grad_norm": 7.468125820159912,
      "learning_rate": 8.434476693051892e-05,
      "loss": 0.3115,
      "step": 713
    },
    {
      "epoch": 0.470976253298153,
      "grad_norm": 2.683070659637451,
      "learning_rate": 8.432277924362358e-05,
      "loss": 0.1853,
      "step": 714
    },
    {
      "epoch": 0.4716358839050132,
      "grad_norm": 3.4519684314727783,
      "learning_rate": 8.430079155672823e-05,
      "loss": 0.2207,
      "step": 715
    },
    {
      "epoch": 0.47229551451187335,
      "grad_norm": 3.1449670791625977,
      "learning_rate": 8.42788038698329e-05,
      "loss": 0.1918,
      "step": 716
    },
    {
      "epoch": 0.4729551451187335,
      "grad_norm": 2.915945529937744,
      "learning_rate": 8.425681618293756e-05,
      "loss": 0.2811,
      "step": 717
    },
    {
      "epoch": 0.4736147757255937,
      "grad_norm": 1.2807800769805908,
      "learning_rate": 8.423482849604222e-05,
      "loss": 0.124,
      "step": 718
    },
    {
      "epoch": 0.4742744063324538,
      "grad_norm": 2.1772918701171875,
      "learning_rate": 8.421284080914689e-05,
      "loss": 0.1397,
      "step": 719
    },
    {
      "epoch": 0.47493403693931396,
      "grad_norm": 13.47558879852295,
      "learning_rate": 8.419085312225155e-05,
      "loss": 0.4071,
      "step": 720
    },
    {
      "epoch": 0.47559366754617416,
      "grad_norm": 9.535431861877441,
      "learning_rate": 8.41688654353562e-05,
      "loss": 0.4458,
      "step": 721
    },
    {
      "epoch": 0.4762532981530343,
      "grad_norm": 0.683192789554596,
      "learning_rate": 8.414687774846086e-05,
      "loss": 0.0643,
      "step": 722
    },
    {
      "epoch": 0.47691292875989444,
      "grad_norm": 1.7384600639343262,
      "learning_rate": 8.412489006156553e-05,
      "loss": 0.1188,
      "step": 723
    },
    {
      "epoch": 0.47757255936675463,
      "grad_norm": 2.6806564331054688,
      "learning_rate": 8.410290237467019e-05,
      "loss": 0.1416,
      "step": 724
    },
    {
      "epoch": 0.4782321899736148,
      "grad_norm": 8.589217185974121,
      "learning_rate": 8.408091468777484e-05,
      "loss": 0.3274,
      "step": 725
    },
    {
      "epoch": 0.4788918205804749,
      "grad_norm": 13.8891019821167,
      "learning_rate": 8.40589270008795e-05,
      "loss": 0.8671,
      "step": 726
    },
    {
      "epoch": 0.4795514511873351,
      "grad_norm": 10.130946159362793,
      "learning_rate": 8.403693931398417e-05,
      "loss": 0.5062,
      "step": 727
    },
    {
      "epoch": 0.48021108179419525,
      "grad_norm": 10.789441108703613,
      "learning_rate": 8.401495162708883e-05,
      "loss": 0.3942,
      "step": 728
    },
    {
      "epoch": 0.4808707124010554,
      "grad_norm": 8.165515899658203,
      "learning_rate": 8.399296394019349e-05,
      "loss": 0.2844,
      "step": 729
    },
    {
      "epoch": 0.4815303430079156,
      "grad_norm": 8.477927207946777,
      "learning_rate": 8.397097625329816e-05,
      "loss": 0.3236,
      "step": 730
    },
    {
      "epoch": 0.4821899736147757,
      "grad_norm": 1.4024276733398438,
      "learning_rate": 8.394898856640281e-05,
      "loss": 0.1563,
      "step": 731
    },
    {
      "epoch": 0.48284960422163586,
      "grad_norm": 5.369033336639404,
      "learning_rate": 8.392700087950748e-05,
      "loss": 0.1838,
      "step": 732
    },
    {
      "epoch": 0.48350923482849606,
      "grad_norm": 2.0200257301330566,
      "learning_rate": 8.390501319261214e-05,
      "loss": 0.1096,
      "step": 733
    },
    {
      "epoch": 0.4841688654353562,
      "grad_norm": 58.11643600463867,
      "learning_rate": 8.388302550571681e-05,
      "loss": 0.3966,
      "step": 734
    },
    {
      "epoch": 0.48482849604221634,
      "grad_norm": 3.1665260791778564,
      "learning_rate": 8.386103781882147e-05,
      "loss": 0.1614,
      "step": 735
    },
    {
      "epoch": 0.48548812664907653,
      "grad_norm": 7.957869052886963,
      "learning_rate": 8.383905013192613e-05,
      "loss": 0.6752,
      "step": 736
    },
    {
      "epoch": 0.4861477572559367,
      "grad_norm": 2.4993457794189453,
      "learning_rate": 8.38170624450308e-05,
      "loss": 0.1809,
      "step": 737
    },
    {
      "epoch": 0.4868073878627968,
      "grad_norm": 10.142062187194824,
      "learning_rate": 8.379507475813545e-05,
      "loss": 0.2613,
      "step": 738
    },
    {
      "epoch": 0.487467018469657,
      "grad_norm": 11.050564765930176,
      "learning_rate": 8.377308707124011e-05,
      "loss": 1.0889,
      "step": 739
    },
    {
      "epoch": 0.48812664907651715,
      "grad_norm": 4.517742156982422,
      "learning_rate": 8.375109938434477e-05,
      "loss": 0.2549,
      "step": 740
    },
    {
      "epoch": 0.4887862796833773,
      "grad_norm": 6.305844306945801,
      "learning_rate": 8.372911169744944e-05,
      "loss": 0.4024,
      "step": 741
    },
    {
      "epoch": 0.4894459102902375,
      "grad_norm": 2.1026499271392822,
      "learning_rate": 8.37071240105541e-05,
      "loss": 0.2599,
      "step": 742
    },
    {
      "epoch": 0.4901055408970976,
      "grad_norm": 4.216249942779541,
      "learning_rate": 8.368513632365875e-05,
      "loss": 0.2617,
      "step": 743
    },
    {
      "epoch": 0.49076517150395776,
      "grad_norm": 6.493701457977295,
      "learning_rate": 8.366314863676341e-05,
      "loss": 0.4518,
      "step": 744
    },
    {
      "epoch": 0.49142480211081796,
      "grad_norm": 6.630246639251709,
      "learning_rate": 8.364116094986808e-05,
      "loss": 0.435,
      "step": 745
    },
    {
      "epoch": 0.4920844327176781,
      "grad_norm": 2.083435535430908,
      "learning_rate": 8.361917326297274e-05,
      "loss": 0.1639,
      "step": 746
    },
    {
      "epoch": 0.49274406332453824,
      "grad_norm": 3.1521201133728027,
      "learning_rate": 8.359718557607739e-05,
      "loss": 0.2952,
      "step": 747
    },
    {
      "epoch": 0.49340369393139843,
      "grad_norm": 12.91403579711914,
      "learning_rate": 8.357519788918206e-05,
      "loss": 0.9237,
      "step": 748
    },
    {
      "epoch": 0.4940633245382586,
      "grad_norm": 17.318191528320312,
      "learning_rate": 8.355321020228672e-05,
      "loss": 0.9305,
      "step": 749
    },
    {
      "epoch": 0.4947229551451187,
      "grad_norm": 2.4589459896087646,
      "learning_rate": 8.353122251539138e-05,
      "loss": 0.1311,
      "step": 750
    },
    {
      "epoch": 0.4953825857519789,
      "grad_norm": 2.231827974319458,
      "learning_rate": 8.350923482849605e-05,
      "loss": 0.1279,
      "step": 751
    },
    {
      "epoch": 0.49604221635883905,
      "grad_norm": 12.755821228027344,
      "learning_rate": 8.34872471416007e-05,
      "loss": 0.7319,
      "step": 752
    },
    {
      "epoch": 0.4967018469656992,
      "grad_norm": 6.303048610687256,
      "learning_rate": 8.346525945470538e-05,
      "loss": 0.2614,
      "step": 753
    },
    {
      "epoch": 0.4973614775725594,
      "grad_norm": 7.545900344848633,
      "learning_rate": 8.344327176781003e-05,
      "loss": 0.3404,
      "step": 754
    },
    {
      "epoch": 0.4980211081794195,
      "grad_norm": 9.888914108276367,
      "learning_rate": 8.34212840809147e-05,
      "loss": 0.5513,
      "step": 755
    },
    {
      "epoch": 0.49868073878627966,
      "grad_norm": 13.955513954162598,
      "learning_rate": 8.339929639401936e-05,
      "loss": 0.9798,
      "step": 756
    },
    {
      "epoch": 0.49934036939313986,
      "grad_norm": 11.227166175842285,
      "learning_rate": 8.337730870712402e-05,
      "loss": 0.5435,
      "step": 757
    },
    {
      "epoch": 0.5,
      "grad_norm": 7.754158020019531,
      "learning_rate": 8.335532102022867e-05,
      "loss": 0.4945,
      "step": 758
    },
    {
      "epoch": 0.5006596306068601,
      "grad_norm": 1.1494914293289185,
      "learning_rate": 8.333333333333334e-05,
      "loss": 0.0692,
      "step": 759
    },
    {
      "epoch": 0.5013192612137203,
      "grad_norm": 8.00858211517334,
      "learning_rate": 8.3311345646438e-05,
      "loss": 0.3552,
      "step": 760
    },
    {
      "epoch": 0.5019788918205804,
      "grad_norm": 3.9932360649108887,
      "learning_rate": 8.328935795954266e-05,
      "loss": 0.2343,
      "step": 761
    },
    {
      "epoch": 0.5026385224274407,
      "grad_norm": 0.9175379872322083,
      "learning_rate": 8.326737027264733e-05,
      "loss": 0.1232,
      "step": 762
    },
    {
      "epoch": 0.5032981530343008,
      "grad_norm": 1.5915336608886719,
      "learning_rate": 8.324538258575199e-05,
      "loss": 0.1845,
      "step": 763
    },
    {
      "epoch": 0.503957783641161,
      "grad_norm": 1.2917506694793701,
      "learning_rate": 8.322339489885664e-05,
      "loss": 0.128,
      "step": 764
    },
    {
      "epoch": 0.5046174142480211,
      "grad_norm": 3.410529375076294,
      "learning_rate": 8.32014072119613e-05,
      "loss": 0.2335,
      "step": 765
    },
    {
      "epoch": 0.5052770448548812,
      "grad_norm": 1.582959771156311,
      "learning_rate": 8.317941952506597e-05,
      "loss": 0.175,
      "step": 766
    },
    {
      "epoch": 0.5059366754617414,
      "grad_norm": 2.9041779041290283,
      "learning_rate": 8.315743183817063e-05,
      "loss": 0.1806,
      "step": 767
    },
    {
      "epoch": 0.5065963060686016,
      "grad_norm": 2.046766996383667,
      "learning_rate": 8.313544415127528e-05,
      "loss": 0.2056,
      "step": 768
    },
    {
      "epoch": 0.5072559366754618,
      "grad_norm": 1.8777587413787842,
      "learning_rate": 8.311345646437994e-05,
      "loss": 0.1689,
      "step": 769
    },
    {
      "epoch": 0.5079155672823219,
      "grad_norm": 6.285266876220703,
      "learning_rate": 8.309146877748461e-05,
      "loss": 0.3846,
      "step": 770
    },
    {
      "epoch": 0.508575197889182,
      "grad_norm": 2.253115653991699,
      "learning_rate": 8.306948109058927e-05,
      "loss": 0.2251,
      "step": 771
    },
    {
      "epoch": 0.5092348284960422,
      "grad_norm": 3.0486576557159424,
      "learning_rate": 8.304749340369393e-05,
      "loss": 0.2096,
      "step": 772
    },
    {
      "epoch": 0.5098944591029023,
      "grad_norm": 1.384106159210205,
      "learning_rate": 8.30255057167986e-05,
      "loss": 0.1559,
      "step": 773
    },
    {
      "epoch": 0.5105540897097626,
      "grad_norm": 5.6139726638793945,
      "learning_rate": 8.300351802990327e-05,
      "loss": 0.4474,
      "step": 774
    },
    {
      "epoch": 0.5112137203166227,
      "grad_norm": 5.164905548095703,
      "learning_rate": 8.298153034300792e-05,
      "loss": 0.3982,
      "step": 775
    },
    {
      "epoch": 0.5118733509234829,
      "grad_norm": 2.5720717906951904,
      "learning_rate": 8.295954265611258e-05,
      "loss": 0.1732,
      "step": 776
    },
    {
      "epoch": 0.512532981530343,
      "grad_norm": 4.93599271774292,
      "learning_rate": 8.293755496921725e-05,
      "loss": 0.2552,
      "step": 777
    },
    {
      "epoch": 0.5131926121372031,
      "grad_norm": 0.9488899111747742,
      "learning_rate": 8.291556728232191e-05,
      "loss": 0.1077,
      "step": 778
    },
    {
      "epoch": 0.5138522427440633,
      "grad_norm": 3.5257153511047363,
      "learning_rate": 8.289357959542657e-05,
      "loss": 0.1795,
      "step": 779
    },
    {
      "epoch": 0.5145118733509235,
      "grad_norm": 0.5538566708564758,
      "learning_rate": 8.287159190853124e-05,
      "loss": 0.0683,
      "step": 780
    },
    {
      "epoch": 0.5151715039577837,
      "grad_norm": 1.5285289287567139,
      "learning_rate": 8.284960422163589e-05,
      "loss": 0.145,
      "step": 781
    },
    {
      "epoch": 0.5158311345646438,
      "grad_norm": 1.17994225025177,
      "learning_rate": 8.282761653474055e-05,
      "loss": 0.0744,
      "step": 782
    },
    {
      "epoch": 0.5164907651715039,
      "grad_norm": 18.709861755371094,
      "learning_rate": 8.28056288478452e-05,
      "loss": 1.5182,
      "step": 783
    },
    {
      "epoch": 0.5171503957783641,
      "grad_norm": 6.937044620513916,
      "learning_rate": 8.278364116094988e-05,
      "loss": 0.2421,
      "step": 784
    },
    {
      "epoch": 0.5178100263852242,
      "grad_norm": 1.4790068864822388,
      "learning_rate": 8.276165347405453e-05,
      "loss": 0.1088,
      "step": 785
    },
    {
      "epoch": 0.5184696569920845,
      "grad_norm": 1.493061900138855,
      "learning_rate": 8.273966578715919e-05,
      "loss": 0.0747,
      "step": 786
    },
    {
      "epoch": 0.5191292875989446,
      "grad_norm": 5.21042013168335,
      "learning_rate": 8.271767810026385e-05,
      "loss": 0.1987,
      "step": 787
    },
    {
      "epoch": 0.5197889182058048,
      "grad_norm": 0.6577551960945129,
      "learning_rate": 8.269569041336852e-05,
      "loss": 0.0298,
      "step": 788
    },
    {
      "epoch": 0.5204485488126649,
      "grad_norm": 8.040680885314941,
      "learning_rate": 8.267370272647318e-05,
      "loss": 0.5431,
      "step": 789
    },
    {
      "epoch": 0.521108179419525,
      "grad_norm": 12.845093727111816,
      "learning_rate": 8.265171503957783e-05,
      "loss": 0.4976,
      "step": 790
    },
    {
      "epoch": 0.5217678100263852,
      "grad_norm": 8.373961448669434,
      "learning_rate": 8.26297273526825e-05,
      "loss": 0.44,
      "step": 791
    },
    {
      "epoch": 0.5224274406332454,
      "grad_norm": 1.3464038372039795,
      "learning_rate": 8.260773966578716e-05,
      "loss": 0.0647,
      "step": 792
    },
    {
      "epoch": 0.5230870712401056,
      "grad_norm": 3.0908925533294678,
      "learning_rate": 8.258575197889182e-05,
      "loss": 0.0994,
      "step": 793
    },
    {
      "epoch": 0.5237467018469657,
      "grad_norm": 1.6547890901565552,
      "learning_rate": 8.256376429199649e-05,
      "loss": 0.1011,
      "step": 794
    },
    {
      "epoch": 0.5244063324538258,
      "grad_norm": 1.5940556526184082,
      "learning_rate": 8.254177660510114e-05,
      "loss": 0.0427,
      "step": 795
    },
    {
      "epoch": 0.525065963060686,
      "grad_norm": 0.47416016459465027,
      "learning_rate": 8.251978891820582e-05,
      "loss": 0.0433,
      "step": 796
    },
    {
      "epoch": 0.5257255936675461,
      "grad_norm": 13.011704444885254,
      "learning_rate": 8.249780123131047e-05,
      "loss": 1.5686,
      "step": 797
    },
    {
      "epoch": 0.5263852242744064,
      "grad_norm": 0.8302112817764282,
      "learning_rate": 8.247581354441514e-05,
      "loss": 0.0568,
      "step": 798
    },
    {
      "epoch": 0.5270448548812665,
      "grad_norm": 0.5757842063903809,
      "learning_rate": 8.24538258575198e-05,
      "loss": 0.0585,
      "step": 799
    },
    {
      "epoch": 0.5277044854881267,
      "grad_norm": 8.629563331604004,
      "learning_rate": 8.243183817062446e-05,
      "loss": 0.4018,
      "step": 800
    },
    {
      "epoch": 0.5283641160949868,
      "grad_norm": 1.0420278310775757,
      "learning_rate": 8.240985048372911e-05,
      "loss": 0.0719,
      "step": 801
    },
    {
      "epoch": 0.5290237467018469,
      "grad_norm": 1.4710733890533447,
      "learning_rate": 8.238786279683378e-05,
      "loss": 0.1058,
      "step": 802
    },
    {
      "epoch": 0.5296833773087071,
      "grad_norm": 8.229145050048828,
      "learning_rate": 8.236587510993844e-05,
      "loss": 0.5722,
      "step": 803
    },
    {
      "epoch": 0.5303430079155673,
      "grad_norm": 3.466040849685669,
      "learning_rate": 8.23438874230431e-05,
      "loss": 0.1719,
      "step": 804
    },
    {
      "epoch": 0.5310026385224275,
      "grad_norm": 1.3601408004760742,
      "learning_rate": 8.232189973614775e-05,
      "loss": 0.0975,
      "step": 805
    },
    {
      "epoch": 0.5316622691292876,
      "grad_norm": 1.2258623838424683,
      "learning_rate": 8.229991204925243e-05,
      "loss": 0.1137,
      "step": 806
    },
    {
      "epoch": 0.5323218997361477,
      "grad_norm": 4.365675926208496,
      "learning_rate": 8.227792436235708e-05,
      "loss": 0.2301,
      "step": 807
    },
    {
      "epoch": 0.5329815303430079,
      "grad_norm": 3.282942056655884,
      "learning_rate": 8.225593667546174e-05,
      "loss": 0.2045,
      "step": 808
    },
    {
      "epoch": 0.533641160949868,
      "grad_norm": 11.609478950500488,
      "learning_rate": 8.223394898856641e-05,
      "loss": 0.6779,
      "step": 809
    },
    {
      "epoch": 0.5343007915567283,
      "grad_norm": 11.387365341186523,
      "learning_rate": 8.221196130167107e-05,
      "loss": 1.3136,
      "step": 810
    },
    {
      "epoch": 0.5349604221635884,
      "grad_norm": 1.2844181060791016,
      "learning_rate": 8.218997361477572e-05,
      "loss": 0.0904,
      "step": 811
    },
    {
      "epoch": 0.5356200527704486,
      "grad_norm": 3.0390374660491943,
      "learning_rate": 8.216798592788038e-05,
      "loss": 0.1906,
      "step": 812
    },
    {
      "epoch": 0.5362796833773087,
      "grad_norm": 6.880462169647217,
      "learning_rate": 8.214599824098505e-05,
      "loss": 0.3057,
      "step": 813
    },
    {
      "epoch": 0.5369393139841688,
      "grad_norm": 14.775864601135254,
      "learning_rate": 8.212401055408971e-05,
      "loss": 1.2876,
      "step": 814
    },
    {
      "epoch": 0.537598944591029,
      "grad_norm": 3.0483670234680176,
      "learning_rate": 8.210202286719438e-05,
      "loss": 0.1814,
      "step": 815
    },
    {
      "epoch": 0.5382585751978892,
      "grad_norm": 15.551091194152832,
      "learning_rate": 8.208003518029904e-05,
      "loss": 1.1173,
      "step": 816
    },
    {
      "epoch": 0.5389182058047494,
      "grad_norm": 2.496610403060913,
      "learning_rate": 8.20580474934037e-05,
      "loss": 0.1645,
      "step": 817
    },
    {
      "epoch": 0.5395778364116095,
      "grad_norm": 1.428332805633545,
      "learning_rate": 8.203605980650836e-05,
      "loss": 0.0787,
      "step": 818
    },
    {
      "epoch": 0.5402374670184696,
      "grad_norm": 1.1645410060882568,
      "learning_rate": 8.201407211961302e-05,
      "loss": 0.1264,
      "step": 819
    },
    {
      "epoch": 0.5408970976253298,
      "grad_norm": 10.182646751403809,
      "learning_rate": 8.199208443271769e-05,
      "loss": 0.525,
      "step": 820
    },
    {
      "epoch": 0.5415567282321899,
      "grad_norm": 21.445581436157227,
      "learning_rate": 8.197009674582235e-05,
      "loss": 1.6631,
      "step": 821
    },
    {
      "epoch": 0.5422163588390502,
      "grad_norm": 1.01560640335083,
      "learning_rate": 8.1948109058927e-05,
      "loss": 0.0962,
      "step": 822
    },
    {
      "epoch": 0.5428759894459103,
      "grad_norm": 1.829500436782837,
      "learning_rate": 8.192612137203166e-05,
      "loss": 0.1249,
      "step": 823
    },
    {
      "epoch": 0.5435356200527705,
      "grad_norm": 9.010458946228027,
      "learning_rate": 8.190413368513633e-05,
      "loss": 0.6098,
      "step": 824
    },
    {
      "epoch": 0.5441952506596306,
      "grad_norm": 3.2889444828033447,
      "learning_rate": 8.188214599824099e-05,
      "loss": 0.1335,
      "step": 825
    },
    {
      "epoch": 0.5448548812664907,
      "grad_norm": 17.699501037597656,
      "learning_rate": 8.186015831134565e-05,
      "loss": 1.4261,
      "step": 826
    },
    {
      "epoch": 0.5455145118733509,
      "grad_norm": 1.4797042608261108,
      "learning_rate": 8.183817062445032e-05,
      "loss": 0.0949,
      "step": 827
    },
    {
      "epoch": 0.5461741424802111,
      "grad_norm": 11.64783763885498,
      "learning_rate": 8.181618293755497e-05,
      "loss": 1.707,
      "step": 828
    },
    {
      "epoch": 0.5468337730870713,
      "grad_norm": 0.6900449991226196,
      "learning_rate": 8.179419525065963e-05,
      "loss": 0.0532,
      "step": 829
    },
    {
      "epoch": 0.5474934036939314,
      "grad_norm": 11.382604598999023,
      "learning_rate": 8.177220756376429e-05,
      "loss": 1.0562,
      "step": 830
    },
    {
      "epoch": 0.5481530343007915,
      "grad_norm": 10.58116340637207,
      "learning_rate": 8.175021987686896e-05,
      "loss": 1.269,
      "step": 831
    },
    {
      "epoch": 0.5488126649076517,
      "grad_norm": 3.746049642562866,
      "learning_rate": 8.172823218997362e-05,
      "loss": 0.1658,
      "step": 832
    },
    {
      "epoch": 0.5494722955145118,
      "grad_norm": 1.335852861404419,
      "learning_rate": 8.170624450307827e-05,
      "loss": 0.0681,
      "step": 833
    },
    {
      "epoch": 0.5501319261213721,
      "grad_norm": 0.9521579742431641,
      "learning_rate": 8.168425681618294e-05,
      "loss": 0.0753,
      "step": 834
    },
    {
      "epoch": 0.5507915567282322,
      "grad_norm": 1.3966480493545532,
      "learning_rate": 8.16622691292876e-05,
      "loss": 0.0686,
      "step": 835
    },
    {
      "epoch": 0.5514511873350924,
      "grad_norm": 6.643986225128174,
      "learning_rate": 8.164028144239226e-05,
      "loss": 0.6037,
      "step": 836
    },
    {
      "epoch": 0.5521108179419525,
      "grad_norm": 15.072859764099121,
      "learning_rate": 8.161829375549693e-05,
      "loss": 1.6164,
      "step": 837
    },
    {
      "epoch": 0.5527704485488126,
      "grad_norm": 7.6694817543029785,
      "learning_rate": 8.159630606860158e-05,
      "loss": 0.2708,
      "step": 838
    },
    {
      "epoch": 0.5534300791556728,
      "grad_norm": 8.183963775634766,
      "learning_rate": 8.157431838170625e-05,
      "loss": 0.6714,
      "step": 839
    },
    {
      "epoch": 0.554089709762533,
      "grad_norm": 1.0781593322753906,
      "learning_rate": 8.155233069481091e-05,
      "loss": 0.1038,
      "step": 840
    },
    {
      "epoch": 0.5547493403693932,
      "grad_norm": 8.880059242248535,
      "learning_rate": 8.153034300791557e-05,
      "loss": 0.6287,
      "step": 841
    },
    {
      "epoch": 0.5554089709762533,
      "grad_norm": 1.1260709762573242,
      "learning_rate": 8.150835532102024e-05,
      "loss": 0.1207,
      "step": 842
    },
    {
      "epoch": 0.5560686015831134,
      "grad_norm": 2.6418700218200684,
      "learning_rate": 8.14863676341249e-05,
      "loss": 0.1778,
      "step": 843
    },
    {
      "epoch": 0.5567282321899736,
      "grad_norm": 1.7103650569915771,
      "learning_rate": 8.146437994722955e-05,
      "loss": 0.1209,
      "step": 844
    },
    {
      "epoch": 0.5573878627968337,
      "grad_norm": 3.587876558303833,
      "learning_rate": 8.144239226033422e-05,
      "loss": 0.2333,
      "step": 845
    },
    {
      "epoch": 0.558047493403694,
      "grad_norm": 6.15562105178833,
      "learning_rate": 8.142040457343888e-05,
      "loss": 0.448,
      "step": 846
    },
    {
      "epoch": 0.5587071240105541,
      "grad_norm": 10.017584800720215,
      "learning_rate": 8.139841688654354e-05,
      "loss": 0.9718,
      "step": 847
    },
    {
      "epoch": 0.5593667546174143,
      "grad_norm": 4.338993072509766,
      "learning_rate": 8.13764291996482e-05,
      "loss": 0.3933,
      "step": 848
    },
    {
      "epoch": 0.5600263852242744,
      "grad_norm": 2.7830042839050293,
      "learning_rate": 8.135444151275287e-05,
      "loss": 0.2001,
      "step": 849
    },
    {
      "epoch": 0.5606860158311345,
      "grad_norm": 2.846414804458618,
      "learning_rate": 8.133245382585752e-05,
      "loss": 0.2388,
      "step": 850
    },
    {
      "epoch": 0.5613456464379947,
      "grad_norm": 5.379751682281494,
      "learning_rate": 8.131046613896218e-05,
      "loss": 0.4963,
      "step": 851
    },
    {
      "epoch": 0.5620052770448549,
      "grad_norm": 2.3737001419067383,
      "learning_rate": 8.128847845206685e-05,
      "loss": 0.1967,
      "step": 852
    },
    {
      "epoch": 0.5626649076517151,
      "grad_norm": 1.8901705741882324,
      "learning_rate": 8.126649076517151e-05,
      "loss": 0.1933,
      "step": 853
    },
    {
      "epoch": 0.5633245382585752,
      "grad_norm": 2.280057668685913,
      "learning_rate": 8.124450307827616e-05,
      "loss": 0.2496,
      "step": 854
    },
    {
      "epoch": 0.5639841688654353,
      "grad_norm": 13.76511001586914,
      "learning_rate": 8.122251539138082e-05,
      "loss": 0.8798,
      "step": 855
    },
    {
      "epoch": 0.5646437994722955,
      "grad_norm": 3.3847827911376953,
      "learning_rate": 8.120052770448549e-05,
      "loss": 0.2272,
      "step": 856
    },
    {
      "epoch": 0.5653034300791556,
      "grad_norm": 6.6845011711120605,
      "learning_rate": 8.117854001759015e-05,
      "loss": 0.7103,
      "step": 857
    },
    {
      "epoch": 0.5659630606860159,
      "grad_norm": 0.9186415672302246,
      "learning_rate": 8.115655233069482e-05,
      "loss": 0.1279,
      "step": 858
    },
    {
      "epoch": 0.566622691292876,
      "grad_norm": 3.5516486167907715,
      "learning_rate": 8.113456464379948e-05,
      "loss": 0.3003,
      "step": 859
    },
    {
      "epoch": 0.5672823218997362,
      "grad_norm": 1.8111193180084229,
      "learning_rate": 8.111257695690415e-05,
      "loss": 0.1808,
      "step": 860
    },
    {
      "epoch": 0.5679419525065963,
      "grad_norm": 1.703894019126892,
      "learning_rate": 8.10905892700088e-05,
      "loss": 0.2071,
      "step": 861
    },
    {
      "epoch": 0.5686015831134564,
      "grad_norm": 2.405061960220337,
      "learning_rate": 8.106860158311346e-05,
      "loss": 0.1871,
      "step": 862
    },
    {
      "epoch": 0.5692612137203166,
      "grad_norm": 2.8390278816223145,
      "learning_rate": 8.104661389621813e-05,
      "loss": 0.2246,
      "step": 863
    },
    {
      "epoch": 0.5699208443271768,
      "grad_norm": 3.0829575061798096,
      "learning_rate": 8.102462620932279e-05,
      "loss": 0.2063,
      "step": 864
    },
    {
      "epoch": 0.570580474934037,
      "grad_norm": 2.7274324893951416,
      "learning_rate": 8.100263852242744e-05,
      "loss": 0.2529,
      "step": 865
    },
    {
      "epoch": 0.5712401055408971,
      "grad_norm": 2.440918207168579,
      "learning_rate": 8.09806508355321e-05,
      "loss": 0.1685,
      "step": 866
    },
    {
      "epoch": 0.5718997361477572,
      "grad_norm": 1.7544569969177246,
      "learning_rate": 8.095866314863677e-05,
      "loss": 0.1462,
      "step": 867
    },
    {
      "epoch": 0.5725593667546174,
      "grad_norm": 1.0617033243179321,
      "learning_rate": 8.093667546174143e-05,
      "loss": 0.1486,
      "step": 868
    },
    {
      "epoch": 0.5732189973614775,
      "grad_norm": 4.032690048217773,
      "learning_rate": 8.091468777484609e-05,
      "loss": 0.2825,
      "step": 869
    },
    {
      "epoch": 0.5738786279683378,
      "grad_norm": 1.1907655000686646,
      "learning_rate": 8.089270008795076e-05,
      "loss": 0.1196,
      "step": 870
    },
    {
      "epoch": 0.5745382585751979,
      "grad_norm": 1.4916976690292358,
      "learning_rate": 8.087071240105541e-05,
      "loss": 0.1241,
      "step": 871
    },
    {
      "epoch": 0.575197889182058,
      "grad_norm": 4.855848789215088,
      "learning_rate": 8.084872471416007e-05,
      "loss": 0.3089,
      "step": 872
    },
    {
      "epoch": 0.5758575197889182,
      "grad_norm": 10.963858604431152,
      "learning_rate": 8.082673702726473e-05,
      "loss": 1.0443,
      "step": 873
    },
    {
      "epoch": 0.5765171503957783,
      "grad_norm": 3.3197383880615234,
      "learning_rate": 8.08047493403694e-05,
      "loss": 0.2236,
      "step": 874
    },
    {
      "epoch": 0.5771767810026385,
      "grad_norm": 10.820455551147461,
      "learning_rate": 8.078276165347406e-05,
      "loss": 0.7766,
      "step": 875
    },
    {
      "epoch": 0.5778364116094987,
      "grad_norm": 1.363017201423645,
      "learning_rate": 8.076077396657871e-05,
      "loss": 0.1471,
      "step": 876
    },
    {
      "epoch": 0.5784960422163589,
      "grad_norm": 4.7707109451293945,
      "learning_rate": 8.073878627968337e-05,
      "loss": 0.2688,
      "step": 877
    },
    {
      "epoch": 0.579155672823219,
      "grad_norm": 2.9365077018737793,
      "learning_rate": 8.071679859278804e-05,
      "loss": 0.2315,
      "step": 878
    },
    {
      "epoch": 0.5798153034300791,
      "grad_norm": 5.155881404876709,
      "learning_rate": 8.069481090589271e-05,
      "loss": 0.3975,
      "step": 879
    },
    {
      "epoch": 0.5804749340369393,
      "grad_norm": 6.583662986755371,
      "learning_rate": 8.067282321899737e-05,
      "loss": 0.4597,
      "step": 880
    },
    {
      "epoch": 0.5811345646437994,
      "grad_norm": 2.2623348236083984,
      "learning_rate": 8.065083553210204e-05,
      "loss": 0.2928,
      "step": 881
    },
    {
      "epoch": 0.5817941952506597,
      "grad_norm": 7.089635848999023,
      "learning_rate": 8.06288478452067e-05,
      "loss": 0.4555,
      "step": 882
    },
    {
      "epoch": 0.5824538258575198,
      "grad_norm": 6.526857376098633,
      "learning_rate": 8.060686015831135e-05,
      "loss": 0.881,
      "step": 883
    },
    {
      "epoch": 0.58311345646438,
      "grad_norm": 1.6813597679138184,
      "learning_rate": 8.058487247141601e-05,
      "loss": 0.1862,
      "step": 884
    },
    {
      "epoch": 0.5837730870712401,
      "grad_norm": 4.6755146980285645,
      "learning_rate": 8.056288478452068e-05,
      "loss": 0.3931,
      "step": 885
    },
    {
      "epoch": 0.5844327176781002,
      "grad_norm": 6.419981002807617,
      "learning_rate": 8.054089709762534e-05,
      "loss": 0.4934,
      "step": 886
    },
    {
      "epoch": 0.5850923482849604,
      "grad_norm": 4.037771701812744,
      "learning_rate": 8.051890941073e-05,
      "loss": 0.367,
      "step": 887
    },
    {
      "epoch": 0.5857519788918206,
      "grad_norm": 3.436342477798462,
      "learning_rate": 8.049692172383466e-05,
      "loss": 0.3835,
      "step": 888
    },
    {
      "epoch": 0.5864116094986808,
      "grad_norm": 1.9861974716186523,
      "learning_rate": 8.047493403693932e-05,
      "loss": 0.2393,
      "step": 889
    },
    {
      "epoch": 0.5870712401055409,
      "grad_norm": 5.349773406982422,
      "learning_rate": 8.045294635004398e-05,
      "loss": 0.3729,
      "step": 890
    },
    {
      "epoch": 0.587730870712401,
      "grad_norm": 6.713428497314453,
      "learning_rate": 8.043095866314863e-05,
      "loss": 0.4789,
      "step": 891
    },
    {
      "epoch": 0.5883905013192612,
      "grad_norm": 5.769681930541992,
      "learning_rate": 8.04089709762533e-05,
      "loss": 0.3989,
      "step": 892
    },
    {
      "epoch": 0.5890501319261213,
      "grad_norm": 2.173945665359497,
      "learning_rate": 8.038698328935796e-05,
      "loss": 0.2033,
      "step": 893
    },
    {
      "epoch": 0.5897097625329816,
      "grad_norm": 4.096983909606934,
      "learning_rate": 8.036499560246262e-05,
      "loss": 0.2443,
      "step": 894
    },
    {
      "epoch": 0.5903693931398417,
      "grad_norm": 3.0052592754364014,
      "learning_rate": 8.034300791556728e-05,
      "loss": 0.201,
      "step": 895
    },
    {
      "epoch": 0.5910290237467019,
      "grad_norm": 0.6351921558380127,
      "learning_rate": 8.032102022867195e-05,
      "loss": 0.1096,
      "step": 896
    },
    {
      "epoch": 0.591688654353562,
      "grad_norm": 3.0675697326660156,
      "learning_rate": 8.02990325417766e-05,
      "loss": 0.2016,
      "step": 897
    },
    {
      "epoch": 0.5923482849604221,
      "grad_norm": 2.842473030090332,
      "learning_rate": 8.027704485488126e-05,
      "loss": 0.1149,
      "step": 898
    },
    {
      "epoch": 0.5930079155672823,
      "grad_norm": 7.444634914398193,
      "learning_rate": 8.025505716798593e-05,
      "loss": 0.5408,
      "step": 899
    },
    {
      "epoch": 0.5936675461741425,
      "grad_norm": 1.9643173217773438,
      "learning_rate": 8.023306948109059e-05,
      "loss": 0.1155,
      "step": 900
    },
    {
      "epoch": 0.5943271767810027,
      "grad_norm": 3.2139835357666016,
      "learning_rate": 8.021108179419526e-05,
      "loss": 0.188,
      "step": 901
    },
    {
      "epoch": 0.5949868073878628,
      "grad_norm": 1.359769582748413,
      "learning_rate": 8.018909410729992e-05,
      "loss": 0.0696,
      "step": 902
    },
    {
      "epoch": 0.5956464379947229,
      "grad_norm": 9.827093124389648,
      "learning_rate": 8.016710642040459e-05,
      "loss": 1.2749,
      "step": 903
    },
    {
      "epoch": 0.5963060686015831,
      "grad_norm": 9.357587814331055,
      "learning_rate": 8.014511873350924e-05,
      "loss": 0.6616,
      "step": 904
    },
    {
      "epoch": 0.5969656992084432,
      "grad_norm": 9.828413009643555,
      "learning_rate": 8.01231310466139e-05,
      "loss": 0.6054,
      "step": 905
    },
    {
      "epoch": 0.5976253298153035,
      "grad_norm": 11.59744644165039,
      "learning_rate": 8.010114335971857e-05,
      "loss": 1.44,
      "step": 906
    },
    {
      "epoch": 0.5982849604221636,
      "grad_norm": 2.791154384613037,
      "learning_rate": 8.007915567282323e-05,
      "loss": 0.1226,
      "step": 907
    },
    {
      "epoch": 0.5989445910290238,
      "grad_norm": 0.6947816610336304,
      "learning_rate": 8.005716798592788e-05,
      "loss": 0.067,
      "step": 908
    },
    {
      "epoch": 0.5996042216358839,
      "grad_norm": 1.6706640720367432,
      "learning_rate": 8.003518029903254e-05,
      "loss": 0.1314,
      "step": 909
    },
    {
      "epoch": 0.600263852242744,
      "grad_norm": 3.162368059158325,
      "learning_rate": 8.001319261213721e-05,
      "loss": 0.1834,
      "step": 910
    },
    {
      "epoch": 0.6009234828496042,
      "grad_norm": 0.7917658686637878,
      "learning_rate": 7.999120492524187e-05,
      "loss": 0.0949,
      "step": 911
    },
    {
      "epoch": 0.6015831134564644,
      "grad_norm": 8.68026065826416,
      "learning_rate": 7.996921723834653e-05,
      "loss": 0.4913,
      "step": 912
    },
    {
      "epoch": 0.6022427440633246,
      "grad_norm": 5.706587791442871,
      "learning_rate": 7.994722955145118e-05,
      "loss": 0.4152,
      "step": 913
    },
    {
      "epoch": 0.6029023746701847,
      "grad_norm": 1.5762215852737427,
      "learning_rate": 7.992524186455585e-05,
      "loss": 0.1588,
      "step": 914
    },
    {
      "epoch": 0.6035620052770448,
      "grad_norm": 2.1515586376190186,
      "learning_rate": 7.990325417766051e-05,
      "loss": 0.167,
      "step": 915
    },
    {
      "epoch": 0.604221635883905,
      "grad_norm": 2.5326318740844727,
      "learning_rate": 7.988126649076517e-05,
      "loss": 0.1882,
      "step": 916
    },
    {
      "epoch": 0.6048812664907651,
      "grad_norm": 5.20916223526001,
      "learning_rate": 7.985927880386984e-05,
      "loss": 0.5459,
      "step": 917
    },
    {
      "epoch": 0.6055408970976254,
      "grad_norm": 4.455801486968994,
      "learning_rate": 7.98372911169745e-05,
      "loss": 0.3506,
      "step": 918
    },
    {
      "epoch": 0.6062005277044855,
      "grad_norm": 3.090127944946289,
      "learning_rate": 7.981530343007915e-05,
      "loss": 0.2734,
      "step": 919
    },
    {
      "epoch": 0.6068601583113457,
      "grad_norm": 6.681058883666992,
      "learning_rate": 7.979331574318382e-05,
      "loss": 0.4279,
      "step": 920
    },
    {
      "epoch": 0.6075197889182058,
      "grad_norm": 1.0323739051818848,
      "learning_rate": 7.977132805628848e-05,
      "loss": 0.1477,
      "step": 921
    },
    {
      "epoch": 0.6081794195250659,
      "grad_norm": 1.4753963947296143,
      "learning_rate": 7.974934036939315e-05,
      "loss": 0.1427,
      "step": 922
    },
    {
      "epoch": 0.6088390501319261,
      "grad_norm": 2.5275847911834717,
      "learning_rate": 7.972735268249781e-05,
      "loss": 0.1886,
      "step": 923
    },
    {
      "epoch": 0.6094986807387863,
      "grad_norm": 2.8785853385925293,
      "learning_rate": 7.970536499560248e-05,
      "loss": 0.2256,
      "step": 924
    },
    {
      "epoch": 0.6101583113456465,
      "grad_norm": 4.018117427825928,
      "learning_rate": 7.968337730870713e-05,
      "loss": 0.3009,
      "step": 925
    },
    {
      "epoch": 0.6108179419525066,
      "grad_norm": 4.539083480834961,
      "learning_rate": 7.966138962181179e-05,
      "loss": 0.18,
      "step": 926
    },
    {
      "epoch": 0.6114775725593667,
      "grad_norm": 1.0869468450546265,
      "learning_rate": 7.963940193491645e-05,
      "loss": 0.1394,
      "step": 927
    },
    {
      "epoch": 0.6121372031662269,
      "grad_norm": 8.80084228515625,
      "learning_rate": 7.961741424802112e-05,
      "loss": 0.6948,
      "step": 928
    },
    {
      "epoch": 0.612796833773087,
      "grad_norm": 2.256512403488159,
      "learning_rate": 7.959542656112578e-05,
      "loss": 0.1297,
      "step": 929
    },
    {
      "epoch": 0.6134564643799473,
      "grad_norm": 1.5890642404556274,
      "learning_rate": 7.957343887423043e-05,
      "loss": 0.1015,
      "step": 930
    },
    {
      "epoch": 0.6141160949868074,
      "grad_norm": 1.316535234451294,
      "learning_rate": 7.955145118733509e-05,
      "loss": 0.1157,
      "step": 931
    },
    {
      "epoch": 0.6147757255936676,
      "grad_norm": 0.9953067302703857,
      "learning_rate": 7.952946350043976e-05,
      "loss": 0.0907,
      "step": 932
    },
    {
      "epoch": 0.6154353562005277,
      "grad_norm": 14.624872207641602,
      "learning_rate": 7.950747581354442e-05,
      "loss": 0.9191,
      "step": 933
    },
    {
      "epoch": 0.6160949868073878,
      "grad_norm": 1.2131636142730713,
      "learning_rate": 7.948548812664907e-05,
      "loss": 0.0648,
      "step": 934
    },
    {
      "epoch": 0.616754617414248,
      "grad_norm": 9.925443649291992,
      "learning_rate": 7.946350043975375e-05,
      "loss": 0.6189,
      "step": 935
    },
    {
      "epoch": 0.6174142480211082,
      "grad_norm": 0.9358710646629333,
      "learning_rate": 7.94415127528584e-05,
      "loss": 0.04,
      "step": 936
    },
    {
      "epoch": 0.6180738786279684,
      "grad_norm": 15.5637788772583,
      "learning_rate": 7.941952506596306e-05,
      "loss": 0.7879,
      "step": 937
    },
    {
      "epoch": 0.6187335092348285,
      "grad_norm": 1.7543128728866577,
      "learning_rate": 7.939753737906772e-05,
      "loss": 0.074,
      "step": 938
    },
    {
      "epoch": 0.6193931398416886,
      "grad_norm": 0.7455615997314453,
      "learning_rate": 7.937554969217239e-05,
      "loss": 0.0456,
      "step": 939
    },
    {
      "epoch": 0.6200527704485488,
      "grad_norm": 18.942581176757812,
      "learning_rate": 7.935356200527704e-05,
      "loss": 1.0371,
      "step": 940
    },
    {
      "epoch": 0.6207124010554089,
      "grad_norm": 19.99357795715332,
      "learning_rate": 7.93315743183817e-05,
      "loss": 0.8342,
      "step": 941
    },
    {
      "epoch": 0.6213720316622692,
      "grad_norm": 10.188753128051758,
      "learning_rate": 7.930958663148637e-05,
      "loss": 0.6472,
      "step": 942
    },
    {
      "epoch": 0.6220316622691293,
      "grad_norm": 12.600068092346191,
      "learning_rate": 7.928759894459103e-05,
      "loss": 0.8528,
      "step": 943
    },
    {
      "epoch": 0.6226912928759895,
      "grad_norm": 15.279541969299316,
      "learning_rate": 7.92656112576957e-05,
      "loss": 0.7909,
      "step": 944
    },
    {
      "epoch": 0.6233509234828496,
      "grad_norm": 12.661685943603516,
      "learning_rate": 7.924362357080036e-05,
      "loss": 0.5207,
      "step": 945
    },
    {
      "epoch": 0.6240105540897097,
      "grad_norm": 21.306596755981445,
      "learning_rate": 7.922163588390503e-05,
      "loss": 1.5871,
      "step": 946
    },
    {
      "epoch": 0.6246701846965699,
      "grad_norm": 0.5335755944252014,
      "learning_rate": 7.919964819700968e-05,
      "loss": 0.0556,
      "step": 947
    },
    {
      "epoch": 0.6253298153034301,
      "grad_norm": 2.8528363704681396,
      "learning_rate": 7.917766051011434e-05,
      "loss": 0.1131,
      "step": 948
    },
    {
      "epoch": 0.6259894459102903,
      "grad_norm": 16.75007438659668,
      "learning_rate": 7.9155672823219e-05,
      "loss": 2.2001,
      "step": 949
    },
    {
      "epoch": 0.6266490765171504,
      "grad_norm": 1.1333487033843994,
      "learning_rate": 7.913368513632367e-05,
      "loss": 0.1116,
      "step": 950
    },
    {
      "epoch": 0.6273087071240105,
      "grad_norm": 9.509688377380371,
      "learning_rate": 7.911169744942832e-05,
      "loss": 0.4198,
      "step": 951
    },
    {
      "epoch": 0.6279683377308707,
      "grad_norm": 0.796479344367981,
      "learning_rate": 7.908970976253298e-05,
      "loss": 0.0914,
      "step": 952
    },
    {
      "epoch": 0.6286279683377308,
      "grad_norm": 15.141663551330566,
      "learning_rate": 7.906772207563765e-05,
      "loss": 0.9725,
      "step": 953
    },
    {
      "epoch": 0.6292875989445911,
      "grad_norm": 4.277050495147705,
      "learning_rate": 7.904573438874231e-05,
      "loss": 0.3571,
      "step": 954
    },
    {
      "epoch": 0.6299472295514512,
      "grad_norm": 6.626742839813232,
      "learning_rate": 7.902374670184697e-05,
      "loss": 0.7528,
      "step": 955
    },
    {
      "epoch": 0.6306068601583114,
      "grad_norm": 4.68829345703125,
      "learning_rate": 7.900175901495162e-05,
      "loss": 0.3578,
      "step": 956
    },
    {
      "epoch": 0.6312664907651715,
      "grad_norm": 1.3070074319839478,
      "learning_rate": 7.89797713280563e-05,
      "loss": 0.1522,
      "step": 957
    },
    {
      "epoch": 0.6319261213720316,
      "grad_norm": 2.034397840499878,
      "learning_rate": 7.895778364116095e-05,
      "loss": 0.2446,
      "step": 958
    },
    {
      "epoch": 0.6325857519788918,
      "grad_norm": 5.413354396820068,
      "learning_rate": 7.893579595426561e-05,
      "loss": 0.3957,
      "step": 959
    },
    {
      "epoch": 0.633245382585752,
      "grad_norm": 18.802087783813477,
      "learning_rate": 7.891380826737028e-05,
      "loss": 0.84,
      "step": 960
    },
    {
      "epoch": 0.6339050131926122,
      "grad_norm": 5.001225471496582,
      "learning_rate": 7.889182058047494e-05,
      "loss": 0.3546,
      "step": 961
    },
    {
      "epoch": 0.6345646437994723,
      "grad_norm": 3.9555575847625732,
      "learning_rate": 7.886983289357959e-05,
      "loss": 0.326,
      "step": 962
    },
    {
      "epoch": 0.6352242744063324,
      "grad_norm": 1.1314188241958618,
      "learning_rate": 7.884784520668426e-05,
      "loss": 0.1045,
      "step": 963
    },
    {
      "epoch": 0.6358839050131926,
      "grad_norm": 1.334878921508789,
      "learning_rate": 7.882585751978892e-05,
      "loss": 0.2095,
      "step": 964
    },
    {
      "epoch": 0.6365435356200527,
      "grad_norm": 1.1509042978286743,
      "learning_rate": 7.880386983289359e-05,
      "loss": 0.1087,
      "step": 965
    },
    {
      "epoch": 0.637203166226913,
      "grad_norm": 5.682953834533691,
      "learning_rate": 7.878188214599825e-05,
      "loss": 0.6239,
      "step": 966
    },
    {
      "epoch": 0.6378627968337731,
      "grad_norm": 2.324690341949463,
      "learning_rate": 7.87598944591029e-05,
      "loss": 0.1768,
      "step": 967
    },
    {
      "epoch": 0.6385224274406333,
      "grad_norm": 3.1864209175109863,
      "learning_rate": 7.873790677220757e-05,
      "loss": 0.2334,
      "step": 968
    },
    {
      "epoch": 0.6391820580474934,
      "grad_norm": 1.3695348501205444,
      "learning_rate": 7.871591908531223e-05,
      "loss": 0.1434,
      "step": 969
    },
    {
      "epoch": 0.6398416886543535,
      "grad_norm": 5.425814151763916,
      "learning_rate": 7.869393139841689e-05,
      "loss": 0.3275,
      "step": 970
    },
    {
      "epoch": 0.6405013192612137,
      "grad_norm": 1.1858106851577759,
      "learning_rate": 7.867194371152156e-05,
      "loss": 0.1033,
      "step": 971
    },
    {
      "epoch": 0.6411609498680739,
      "grad_norm": 2.5600547790527344,
      "learning_rate": 7.864995602462622e-05,
      "loss": 0.156,
      "step": 972
    },
    {
      "epoch": 0.6418205804749341,
      "grad_norm": 3.952651023864746,
      "learning_rate": 7.862796833773087e-05,
      "loss": 0.2089,
      "step": 973
    },
    {
      "epoch": 0.6424802110817942,
      "grad_norm": 4.926373481750488,
      "learning_rate": 7.860598065083553e-05,
      "loss": 0.4624,
      "step": 974
    },
    {
      "epoch": 0.6431398416886543,
      "grad_norm": 4.689053058624268,
      "learning_rate": 7.85839929639402e-05,
      "loss": 0.2397,
      "step": 975
    },
    {
      "epoch": 0.6437994722955145,
      "grad_norm": 3.5382370948791504,
      "learning_rate": 7.856200527704486e-05,
      "loss": 0.2259,
      "step": 976
    },
    {
      "epoch": 0.6444591029023746,
      "grad_norm": 6.002260208129883,
      "learning_rate": 7.854001759014951e-05,
      "loss": 0.2546,
      "step": 977
    },
    {
      "epoch": 0.6451187335092349,
      "grad_norm": 2.735797643661499,
      "learning_rate": 7.851802990325419e-05,
      "loss": 0.1781,
      "step": 978
    },
    {
      "epoch": 0.645778364116095,
      "grad_norm": 1.293770670890808,
      "learning_rate": 7.849604221635884e-05,
      "loss": 0.1101,
      "step": 979
    },
    {
      "epoch": 0.6464379947229552,
      "grad_norm": 9.95289134979248,
      "learning_rate": 7.84740545294635e-05,
      "loss": 0.6975,
      "step": 980
    },
    {
      "epoch": 0.6470976253298153,
      "grad_norm": 1.5511865615844727,
      "learning_rate": 7.845206684256816e-05,
      "loss": 0.1025,
      "step": 981
    },
    {
      "epoch": 0.6477572559366754,
      "grad_norm": 8.106106758117676,
      "learning_rate": 7.843007915567283e-05,
      "loss": 1.0745,
      "step": 982
    },
    {
      "epoch": 0.6484168865435356,
      "grad_norm": 3.236959457397461,
      "learning_rate": 7.840809146877748e-05,
      "loss": 0.2419,
      "step": 983
    },
    {
      "epoch": 0.6490765171503958,
      "grad_norm": 1.950374722480774,
      "learning_rate": 7.838610378188215e-05,
      "loss": 0.1838,
      "step": 984
    },
    {
      "epoch": 0.649736147757256,
      "grad_norm": 2.6735873222351074,
      "learning_rate": 7.836411609498681e-05,
      "loss": 0.1961,
      "step": 985
    },
    {
      "epoch": 0.6503957783641161,
      "grad_norm": 4.606313228607178,
      "learning_rate": 7.834212840809148e-05,
      "loss": 0.2347,
      "step": 986
    },
    {
      "epoch": 0.6510554089709762,
      "grad_norm": 5.901972770690918,
      "learning_rate": 7.832014072119614e-05,
      "loss": 0.7527,
      "step": 987
    },
    {
      "epoch": 0.6517150395778364,
      "grad_norm": 7.111227989196777,
      "learning_rate": 7.82981530343008e-05,
      "loss": 0.4923,
      "step": 988
    },
    {
      "epoch": 0.6523746701846965,
      "grad_norm": 3.2108235359191895,
      "learning_rate": 7.827616534740547e-05,
      "loss": 0.209,
      "step": 989
    },
    {
      "epoch": 0.6530343007915568,
      "grad_norm": 2.377563238143921,
      "learning_rate": 7.825417766051012e-05,
      "loss": 0.1758,
      "step": 990
    },
    {
      "epoch": 0.6536939313984169,
      "grad_norm": 7.74413537979126,
      "learning_rate": 7.823218997361478e-05,
      "loss": 0.6252,
      "step": 991
    },
    {
      "epoch": 0.6543535620052771,
      "grad_norm": 3.0536892414093018,
      "learning_rate": 7.821020228671944e-05,
      "loss": 0.1885,
      "step": 992
    },
    {
      "epoch": 0.6550131926121372,
      "grad_norm": 2.0057616233825684,
      "learning_rate": 7.818821459982411e-05,
      "loss": 0.2181,
      "step": 993
    },
    {
      "epoch": 0.6556728232189973,
      "grad_norm": 5.60325813293457,
      "learning_rate": 7.816622691292876e-05,
      "loss": 0.7015,
      "step": 994
    },
    {
      "epoch": 0.6563324538258575,
      "grad_norm": 4.315613269805908,
      "learning_rate": 7.814423922603342e-05,
      "loss": 0.266,
      "step": 995
    },
    {
      "epoch": 0.6569920844327177,
      "grad_norm": 1.6200734376907349,
      "learning_rate": 7.812225153913809e-05,
      "loss": 0.131,
      "step": 996
    },
    {
      "epoch": 0.6576517150395779,
      "grad_norm": 1.6681832075119019,
      "learning_rate": 7.810026385224275e-05,
      "loss": 0.1977,
      "step": 997
    },
    {
      "epoch": 0.658311345646438,
      "grad_norm": 1.7149431705474854,
      "learning_rate": 7.80782761653474e-05,
      "loss": 0.1721,
      "step": 998
    },
    {
      "epoch": 0.6589709762532981,
      "grad_norm": 4.844252586364746,
      "learning_rate": 7.805628847845206e-05,
      "loss": 0.3003,
      "step": 999
    },
    {
      "epoch": 0.6596306068601583,
      "grad_norm": 0.9842169880867004,
      "learning_rate": 7.803430079155673e-05,
      "loss": 0.1115,
      "step": 1000
    },
    {
      "epoch": 0.6602902374670184,
      "grad_norm": 1.3315362930297852,
      "learning_rate": 7.801231310466139e-05,
      "loss": 0.1926,
      "step": 1001
    },
    {
      "epoch": 0.6609498680738787,
      "grad_norm": 2.432805299758911,
      "learning_rate": 7.799032541776605e-05,
      "loss": 0.2016,
      "step": 1002
    },
    {
      "epoch": 0.6616094986807388,
      "grad_norm": 2.927255868911743,
      "learning_rate": 7.79683377308707e-05,
      "loss": 0.204,
      "step": 1003
    },
    {
      "epoch": 0.662269129287599,
      "grad_norm": 9.391742706298828,
      "learning_rate": 7.794635004397538e-05,
      "loss": 0.9116,
      "step": 1004
    },
    {
      "epoch": 0.6629287598944591,
      "grad_norm": 2.4245035648345947,
      "learning_rate": 7.792436235708003e-05,
      "loss": 0.1643,
      "step": 1005
    },
    {
      "epoch": 0.6635883905013192,
      "grad_norm": 1.0191013813018799,
      "learning_rate": 7.79023746701847e-05,
      "loss": 0.1241,
      "step": 1006
    },
    {
      "epoch": 0.6642480211081794,
      "grad_norm": 0.9679897427558899,
      "learning_rate": 7.788038698328936e-05,
      "loss": 0.1152,
      "step": 1007
    },
    {
      "epoch": 0.6649076517150396,
      "grad_norm": 9.392921447753906,
      "learning_rate": 7.785839929639403e-05,
      "loss": 0.994,
      "step": 1008
    },
    {
      "epoch": 0.6655672823218998,
      "grad_norm": 4.272958278656006,
      "learning_rate": 7.783641160949869e-05,
      "loss": 0.2249,
      "step": 1009
    },
    {
      "epoch": 0.6662269129287599,
      "grad_norm": 12.045079231262207,
      "learning_rate": 7.781442392260334e-05,
      "loss": 1.2499,
      "step": 1010
    },
    {
      "epoch": 0.66688654353562,
      "grad_norm": 8.620349884033203,
      "learning_rate": 7.779243623570801e-05,
      "loss": 0.4221,
      "step": 1011
    },
    {
      "epoch": 0.6675461741424802,
      "grad_norm": 7.1377058029174805,
      "learning_rate": 7.777044854881267e-05,
      "loss": 0.4945,
      "step": 1012
    },
    {
      "epoch": 0.6682058047493403,
      "grad_norm": 7.252720355987549,
      "learning_rate": 7.774846086191733e-05,
      "loss": 0.4341,
      "step": 1013
    },
    {
      "epoch": 0.6688654353562006,
      "grad_norm": 0.855466365814209,
      "learning_rate": 7.7726473175022e-05,
      "loss": 0.0928,
      "step": 1014
    },
    {
      "epoch": 0.6695250659630607,
      "grad_norm": 5.823473930358887,
      "learning_rate": 7.770448548812666e-05,
      "loss": 0.3652,
      "step": 1015
    },
    {
      "epoch": 0.6701846965699209,
      "grad_norm": 1.7600139379501343,
      "learning_rate": 7.768249780123131e-05,
      "loss": 0.1443,
      "step": 1016
    },
    {
      "epoch": 0.670844327176781,
      "grad_norm": 8.690916061401367,
      "learning_rate": 7.766051011433597e-05,
      "loss": 0.8739,
      "step": 1017
    },
    {
      "epoch": 0.6715039577836411,
      "grad_norm": 5.236632823944092,
      "learning_rate": 7.763852242744064e-05,
      "loss": 0.7026,
      "step": 1018
    },
    {
      "epoch": 0.6721635883905013,
      "grad_norm": 2.117746114730835,
      "learning_rate": 7.76165347405453e-05,
      "loss": 0.2022,
      "step": 1019
    },
    {
      "epoch": 0.6728232189973615,
      "grad_norm": 3.0281031131744385,
      "learning_rate": 7.759454705364995e-05,
      "loss": 0.2892,
      "step": 1020
    },
    {
      "epoch": 0.6734828496042217,
      "grad_norm": 2.3062493801116943,
      "learning_rate": 7.757255936675461e-05,
      "loss": 0.2011,
      "step": 1021
    },
    {
      "epoch": 0.6741424802110818,
      "grad_norm": 6.052372932434082,
      "learning_rate": 7.755057167985928e-05,
      "loss": 0.4745,
      "step": 1022
    },
    {
      "epoch": 0.674802110817942,
      "grad_norm": 1.7145075798034668,
      "learning_rate": 7.752858399296394e-05,
      "loss": 0.1963,
      "step": 1023
    },
    {
      "epoch": 0.6754617414248021,
      "grad_norm": 22.130191802978516,
      "learning_rate": 7.75065963060686e-05,
      "loss": 0.5497,
      "step": 1024
    },
    {
      "epoch": 0.6761213720316622,
      "grad_norm": 12.286149024963379,
      "learning_rate": 7.748460861917327e-05,
      "loss": 0.416,
      "step": 1025
    },
    {
      "epoch": 0.6767810026385225,
      "grad_norm": 7.26080322265625,
      "learning_rate": 7.746262093227792e-05,
      "loss": 0.557,
      "step": 1026
    },
    {
      "epoch": 0.6774406332453826,
      "grad_norm": 2.3620874881744385,
      "learning_rate": 7.74406332453826e-05,
      "loss": 0.1856,
      "step": 1027
    },
    {
      "epoch": 0.6781002638522428,
      "grad_norm": 6.684014797210693,
      "learning_rate": 7.741864555848725e-05,
      "loss": 0.5078,
      "step": 1028
    },
    {
      "epoch": 0.6787598944591029,
      "grad_norm": 1.2564029693603516,
      "learning_rate": 7.739665787159192e-05,
      "loss": 0.1395,
      "step": 1029
    },
    {
      "epoch": 0.679419525065963,
      "grad_norm": 1.1266402006149292,
      "learning_rate": 7.737467018469658e-05,
      "loss": 0.1231,
      "step": 1030
    },
    {
      "epoch": 0.6800791556728232,
      "grad_norm": 5.695122718811035,
      "learning_rate": 7.735268249780124e-05,
      "loss": 0.3798,
      "step": 1031
    },
    {
      "epoch": 0.6807387862796834,
      "grad_norm": 3.055661201477051,
      "learning_rate": 7.73306948109059e-05,
      "loss": 0.2357,
      "step": 1032
    },
    {
      "epoch": 0.6813984168865436,
      "grad_norm": 4.0902886390686035,
      "learning_rate": 7.730870712401056e-05,
      "loss": 0.2369,
      "step": 1033
    },
    {
      "epoch": 0.6820580474934037,
      "grad_norm": 1.4043080806732178,
      "learning_rate": 7.728671943711522e-05,
      "loss": 0.1168,
      "step": 1034
    },
    {
      "epoch": 0.6827176781002638,
      "grad_norm": 1.651716947555542,
      "learning_rate": 7.726473175021988e-05,
      "loss": 0.1309,
      "step": 1035
    },
    {
      "epoch": 0.683377308707124,
      "grad_norm": 3.7356247901916504,
      "learning_rate": 7.724274406332455e-05,
      "loss": 0.275,
      "step": 1036
    },
    {
      "epoch": 0.6840369393139841,
      "grad_norm": 0.8962963223457336,
      "learning_rate": 7.72207563764292e-05,
      "loss": 0.1195,
      "step": 1037
    },
    {
      "epoch": 0.6846965699208444,
      "grad_norm": 8.246417999267578,
      "learning_rate": 7.719876868953386e-05,
      "loss": 0.9045,
      "step": 1038
    },
    {
      "epoch": 0.6853562005277045,
      "grad_norm": 9.135819435119629,
      "learning_rate": 7.717678100263852e-05,
      "loss": 0.6416,
      "step": 1039
    },
    {
      "epoch": 0.6860158311345647,
      "grad_norm": 1.6355764865875244,
      "learning_rate": 7.715479331574319e-05,
      "loss": 0.1209,
      "step": 1040
    },
    {
      "epoch": 0.6866754617414248,
      "grad_norm": 3.0069363117218018,
      "learning_rate": 7.713280562884785e-05,
      "loss": 0.1856,
      "step": 1041
    },
    {
      "epoch": 0.6873350923482849,
      "grad_norm": 1.3429369926452637,
      "learning_rate": 7.71108179419525e-05,
      "loss": 0.1893,
      "step": 1042
    },
    {
      "epoch": 0.6879947229551451,
      "grad_norm": 1.1850895881652832,
      "learning_rate": 7.708883025505717e-05,
      "loss": 0.0761,
      "step": 1043
    },
    {
      "epoch": 0.6886543535620053,
      "grad_norm": 1.1493849754333496,
      "learning_rate": 7.706684256816183e-05,
      "loss": 0.0859,
      "step": 1044
    },
    {
      "epoch": 0.6893139841688655,
      "grad_norm": 12.888643264770508,
      "learning_rate": 7.704485488126649e-05,
      "loss": 1.0317,
      "step": 1045
    },
    {
      "epoch": 0.6899736147757256,
      "grad_norm": 2.6974093914031982,
      "learning_rate": 7.702286719437114e-05,
      "loss": 0.1751,
      "step": 1046
    },
    {
      "epoch": 0.6906332453825857,
      "grad_norm": 9.93198013305664,
      "learning_rate": 7.700087950747582e-05,
      "loss": 0.5571,
      "step": 1047
    },
    {
      "epoch": 0.6912928759894459,
      "grad_norm": 0.8181663155555725,
      "learning_rate": 7.697889182058047e-05,
      "loss": 0.0694,
      "step": 1048
    },
    {
      "epoch": 0.691952506596306,
      "grad_norm": 7.375720500946045,
      "learning_rate": 7.695690413368514e-05,
      "loss": 0.4358,
      "step": 1049
    },
    {
      "epoch": 0.6926121372031663,
      "grad_norm": 1.3216954469680786,
      "learning_rate": 7.693491644678981e-05,
      "loss": 0.0712,
      "step": 1050
    },
    {
      "epoch": 0.6932717678100264,
      "grad_norm": 3.1906332969665527,
      "learning_rate": 7.691292875989447e-05,
      "loss": 0.1514,
      "step": 1051
    },
    {
      "epoch": 0.6939313984168866,
      "grad_norm": 14.177899360656738,
      "learning_rate": 7.689094107299913e-05,
      "loss": 1.572,
      "step": 1052
    },
    {
      "epoch": 0.6945910290237467,
      "grad_norm": 0.5329820513725281,
      "learning_rate": 7.686895338610378e-05,
      "loss": 0.082,
      "step": 1053
    },
    {
      "epoch": 0.6952506596306068,
      "grad_norm": 9.317948341369629,
      "learning_rate": 7.684696569920845e-05,
      "loss": 1.5045,
      "step": 1054
    },
    {
      "epoch": 0.695910290237467,
      "grad_norm": 6.466119289398193,
      "learning_rate": 7.682497801231311e-05,
      "loss": 0.3313,
      "step": 1055
    },
    {
      "epoch": 0.6965699208443272,
      "grad_norm": 0.9817763566970825,
      "learning_rate": 7.680299032541777e-05,
      "loss": 0.1139,
      "step": 1056
    },
    {
      "epoch": 0.6972295514511874,
      "grad_norm": 0.9545913338661194,
      "learning_rate": 7.678100263852243e-05,
      "loss": 0.0515,
      "step": 1057
    },
    {
      "epoch": 0.6978891820580475,
      "grad_norm": 1.3805409669876099,
      "learning_rate": 7.67590149516271e-05,
      "loss": 0.1231,
      "step": 1058
    },
    {
      "epoch": 0.6985488126649076,
      "grad_norm": 2.6688530445098877,
      "learning_rate": 7.673702726473175e-05,
      "loss": 0.1385,
      "step": 1059
    },
    {
      "epoch": 0.6992084432717678,
      "grad_norm": 0.6328195333480835,
      "learning_rate": 7.671503957783641e-05,
      "loss": 0.0772,
      "step": 1060
    },
    {
      "epoch": 0.6998680738786279,
      "grad_norm": 1.1651661396026611,
      "learning_rate": 7.669305189094108e-05,
      "loss": 0.1363,
      "step": 1061
    },
    {
      "epoch": 0.7005277044854882,
      "grad_norm": 1.3446882963180542,
      "learning_rate": 7.667106420404574e-05,
      "loss": 0.0946,
      "step": 1062
    },
    {
      "epoch": 0.7011873350923483,
      "grad_norm": 1.1306594610214233,
      "learning_rate": 7.66490765171504e-05,
      "loss": 0.0712,
      "step": 1063
    },
    {
      "epoch": 0.7018469656992085,
      "grad_norm": 4.598593235015869,
      "learning_rate": 7.662708883025505e-05,
      "loss": 0.1606,
      "step": 1064
    },
    {
      "epoch": 0.7025065963060686,
      "grad_norm": 5.129065036773682,
      "learning_rate": 7.660510114335972e-05,
      "loss": 0.1866,
      "step": 1065
    },
    {
      "epoch": 0.7031662269129287,
      "grad_norm": 7.5300750732421875,
      "learning_rate": 7.658311345646438e-05,
      "loss": 0.2436,
      "step": 1066
    },
    {
      "epoch": 0.7038258575197889,
      "grad_norm": 10.877668380737305,
      "learning_rate": 7.656112576956904e-05,
      "loss": 0.9879,
      "step": 1067
    },
    {
      "epoch": 0.7044854881266491,
      "grad_norm": 2.9022483825683594,
      "learning_rate": 7.65391380826737e-05,
      "loss": 0.1433,
      "step": 1068
    },
    {
      "epoch": 0.7051451187335093,
      "grad_norm": 0.7574637532234192,
      "learning_rate": 7.651715039577836e-05,
      "loss": 0.064,
      "step": 1069
    },
    {
      "epoch": 0.7058047493403694,
      "grad_norm": 1.0043786764144897,
      "learning_rate": 7.649516270888303e-05,
      "loss": 0.1071,
      "step": 1070
    },
    {
      "epoch": 0.7064643799472295,
      "grad_norm": 16.74319839477539,
      "learning_rate": 7.647317502198769e-05,
      "loss": 1.4133,
      "step": 1071
    },
    {
      "epoch": 0.7071240105540897,
      "grad_norm": 11.749259948730469,
      "learning_rate": 7.645118733509236e-05,
      "loss": 0.7526,
      "step": 1072
    },
    {
      "epoch": 0.7077836411609498,
      "grad_norm": 0.5796514749526978,
      "learning_rate": 7.642919964819702e-05,
      "loss": 0.0509,
      "step": 1073
    },
    {
      "epoch": 0.7084432717678101,
      "grad_norm": 0.8316157460212708,
      "learning_rate": 7.640721196130168e-05,
      "loss": 0.0679,
      "step": 1074
    },
    {
      "epoch": 0.7091029023746702,
      "grad_norm": 9.047161102294922,
      "learning_rate": 7.638522427440633e-05,
      "loss": 1.3636,
      "step": 1075
    },
    {
      "epoch": 0.7097625329815304,
      "grad_norm": 9.1492280960083,
      "learning_rate": 7.6363236587511e-05,
      "loss": 0.6228,
      "step": 1076
    },
    {
      "epoch": 0.7104221635883905,
      "grad_norm": 1.611647367477417,
      "learning_rate": 7.634124890061566e-05,
      "loss": 0.0716,
      "step": 1077
    },
    {
      "epoch": 0.7110817941952506,
      "grad_norm": 5.115839958190918,
      "learning_rate": 7.631926121372032e-05,
      "loss": 0.2301,
      "step": 1078
    },
    {
      "epoch": 0.7117414248021108,
      "grad_norm": 19.054431915283203,
      "learning_rate": 7.629727352682499e-05,
      "loss": 0.628,
      "step": 1079
    },
    {
      "epoch": 0.712401055408971,
      "grad_norm": 2.8728084564208984,
      "learning_rate": 7.627528583992964e-05,
      "loss": 0.1847,
      "step": 1080
    },
    {
      "epoch": 0.7130606860158312,
      "grad_norm": 9.149382591247559,
      "learning_rate": 7.62532981530343e-05,
      "loss": 0.7626,
      "step": 1081
    },
    {
      "epoch": 0.7137203166226913,
      "grad_norm": 12.843242645263672,
      "learning_rate": 7.623131046613896e-05,
      "loss": 1.125,
      "step": 1082
    },
    {
      "epoch": 0.7143799472295514,
      "grad_norm": 1.6112658977508545,
      "learning_rate": 7.620932277924363e-05,
      "loss": 0.1107,
      "step": 1083
    },
    {
      "epoch": 0.7150395778364116,
      "grad_norm": 6.347500801086426,
      "learning_rate": 7.618733509234829e-05,
      "loss": 0.6039,
      "step": 1084
    },
    {
      "epoch": 0.7156992084432717,
      "grad_norm": 0.6613885164260864,
      "learning_rate": 7.616534740545294e-05,
      "loss": 0.1114,
      "step": 1085
    },
    {
      "epoch": 0.716358839050132,
      "grad_norm": 1.3358752727508545,
      "learning_rate": 7.614335971855761e-05,
      "loss": 0.1559,
      "step": 1086
    },
    {
      "epoch": 0.7170184696569921,
      "grad_norm": 1.3077207803726196,
      "learning_rate": 7.612137203166227e-05,
      "loss": 0.1644,
      "step": 1087
    },
    {
      "epoch": 0.7176781002638523,
      "grad_norm": 1.2372804880142212,
      "learning_rate": 7.609938434476693e-05,
      "loss": 0.1143,
      "step": 1088
    },
    {
      "epoch": 0.7183377308707124,
      "grad_norm": 1.0159881114959717,
      "learning_rate": 7.60773966578716e-05,
      "loss": 0.1298,
      "step": 1089
    },
    {
      "epoch": 0.7189973614775725,
      "grad_norm": 1.2765467166900635,
      "learning_rate": 7.605540897097626e-05,
      "loss": 0.1117,
      "step": 1090
    },
    {
      "epoch": 0.7196569920844327,
      "grad_norm": 10.23522663116455,
      "learning_rate": 7.603342128408093e-05,
      "loss": 0.7527,
      "step": 1091
    },
    {
      "epoch": 0.7203166226912929,
      "grad_norm": 12.468811988830566,
      "learning_rate": 7.601143359718558e-05,
      "loss": 1.1263,
      "step": 1092
    },
    {
      "epoch": 0.7209762532981531,
      "grad_norm": 6.220778942108154,
      "learning_rate": 7.598944591029024e-05,
      "loss": 0.2623,
      "step": 1093
    },
    {
      "epoch": 0.7216358839050132,
      "grad_norm": 8.428770065307617,
      "learning_rate": 7.596745822339491e-05,
      "loss": 0.7465,
      "step": 1094
    },
    {
      "epoch": 0.7222955145118733,
      "grad_norm": 1.4703335762023926,
      "learning_rate": 7.594547053649957e-05,
      "loss": 0.1167,
      "step": 1095
    },
    {
      "epoch": 0.7229551451187335,
      "grad_norm": 11.140384674072266,
      "learning_rate": 7.592348284960422e-05,
      "loss": 0.7469,
      "step": 1096
    },
    {
      "epoch": 0.7236147757255936,
      "grad_norm": 1.9069324731826782,
      "learning_rate": 7.59014951627089e-05,
      "loss": 0.1186,
      "step": 1097
    },
    {
      "epoch": 0.7242744063324539,
      "grad_norm": 7.2934136390686035,
      "learning_rate": 7.587950747581355e-05,
      "loss": 0.4798,
      "step": 1098
    },
    {
      "epoch": 0.724934036939314,
      "grad_norm": 1.4924274682998657,
      "learning_rate": 7.585751978891821e-05,
      "loss": 0.1481,
      "step": 1099
    },
    {
      "epoch": 0.7255936675461742,
      "grad_norm": 2.9909322261810303,
      "learning_rate": 7.583553210202287e-05,
      "loss": 0.1934,
      "step": 1100
    },
    {
      "epoch": 0.7262532981530343,
      "grad_norm": 5.568381309509277,
      "learning_rate": 7.581354441512754e-05,
      "loss": 0.2316,
      "step": 1101
    },
    {
      "epoch": 0.7269129287598944,
      "grad_norm": 1.8208675384521484,
      "learning_rate": 7.579155672823219e-05,
      "loss": 0.1297,
      "step": 1102
    },
    {
      "epoch": 0.7275725593667546,
      "grad_norm": 1.7588130235671997,
      "learning_rate": 7.576956904133685e-05,
      "loss": 0.1287,
      "step": 1103
    },
    {
      "epoch": 0.7282321899736148,
      "grad_norm": 4.3070855140686035,
      "learning_rate": 7.574758135444152e-05,
      "loss": 0.2215,
      "step": 1104
    },
    {
      "epoch": 0.728891820580475,
      "grad_norm": 8.1346435546875,
      "learning_rate": 7.572559366754618e-05,
      "loss": 0.5196,
      "step": 1105
    },
    {
      "epoch": 0.7295514511873351,
      "grad_norm": 6.720842361450195,
      "learning_rate": 7.570360598065083e-05,
      "loss": 0.5592,
      "step": 1106
    },
    {
      "epoch": 0.7302110817941952,
      "grad_norm": 7.27770471572876,
      "learning_rate": 7.568161829375549e-05,
      "loss": 0.5273,
      "step": 1107
    },
    {
      "epoch": 0.7308707124010554,
      "grad_norm": 1.152502179145813,
      "learning_rate": 7.565963060686016e-05,
      "loss": 0.0975,
      "step": 1108
    },
    {
      "epoch": 0.7315303430079155,
      "grad_norm": 0.930152952671051,
      "learning_rate": 7.563764291996482e-05,
      "loss": 0.1039,
      "step": 1109
    },
    {
      "epoch": 0.7321899736147758,
      "grad_norm": 4.181188106536865,
      "learning_rate": 7.561565523306948e-05,
      "loss": 0.1865,
      "step": 1110
    },
    {
      "epoch": 0.7328496042216359,
      "grad_norm": 1.0133998394012451,
      "learning_rate": 7.559366754617415e-05,
      "loss": 0.1261,
      "step": 1111
    },
    {
      "epoch": 0.7335092348284961,
      "grad_norm": 11.247882843017578,
      "learning_rate": 7.55716798592788e-05,
      "loss": 0.6645,
      "step": 1112
    },
    {
      "epoch": 0.7341688654353562,
      "grad_norm": 2.430478572845459,
      "learning_rate": 7.554969217238347e-05,
      "loss": 0.1683,
      "step": 1113
    },
    {
      "epoch": 0.7348284960422163,
      "grad_norm": 7.247551441192627,
      "learning_rate": 7.552770448548813e-05,
      "loss": 0.5872,
      "step": 1114
    },
    {
      "epoch": 0.7354881266490765,
      "grad_norm": 3.395139217376709,
      "learning_rate": 7.55057167985928e-05,
      "loss": 0.2608,
      "step": 1115
    },
    {
      "epoch": 0.7361477572559367,
      "grad_norm": 2.8304736614227295,
      "learning_rate": 7.548372911169746e-05,
      "loss": 0.2061,
      "step": 1116
    },
    {
      "epoch": 0.7368073878627969,
      "grad_norm": 3.340054750442505,
      "learning_rate": 7.546174142480212e-05,
      "loss": 0.2516,
      "step": 1117
    },
    {
      "epoch": 0.737467018469657,
      "grad_norm": 2.055103063583374,
      "learning_rate": 7.543975373790677e-05,
      "loss": 0.222,
      "step": 1118
    },
    {
      "epoch": 0.7381266490765171,
      "grad_norm": 2.771186113357544,
      "learning_rate": 7.541776605101144e-05,
      "loss": 0.1838,
      "step": 1119
    },
    {
      "epoch": 0.7387862796833773,
      "grad_norm": 1.879564881324768,
      "learning_rate": 7.53957783641161e-05,
      "loss": 0.1312,
      "step": 1120
    },
    {
      "epoch": 0.7394459102902374,
      "grad_norm": 2.6744346618652344,
      "learning_rate": 7.537379067722076e-05,
      "loss": 0.179,
      "step": 1121
    },
    {
      "epoch": 0.7401055408970977,
      "grad_norm": 3.5923221111297607,
      "learning_rate": 7.535180299032543e-05,
      "loss": 0.2547,
      "step": 1122
    },
    {
      "epoch": 0.7407651715039578,
      "grad_norm": 0.9588581919670105,
      "learning_rate": 7.532981530343008e-05,
      "loss": 0.1036,
      "step": 1123
    },
    {
      "epoch": 0.741424802110818,
      "grad_norm": 1.923675298690796,
      "learning_rate": 7.530782761653474e-05,
      "loss": 0.1481,
      "step": 1124
    },
    {
      "epoch": 0.7420844327176781,
      "grad_norm": 2.8191044330596924,
      "learning_rate": 7.52858399296394e-05,
      "loss": 0.1565,
      "step": 1125
    },
    {
      "epoch": 0.7427440633245382,
      "grad_norm": 13.495972633361816,
      "learning_rate": 7.526385224274407e-05,
      "loss": 1.1033,
      "step": 1126
    },
    {
      "epoch": 0.7434036939313984,
      "grad_norm": 8.3764066696167,
      "learning_rate": 7.524186455584873e-05,
      "loss": 0.9432,
      "step": 1127
    },
    {
      "epoch": 0.7440633245382586,
      "grad_norm": 2.4161765575408936,
      "learning_rate": 7.521987686895338e-05,
      "loss": 0.1484,
      "step": 1128
    },
    {
      "epoch": 0.7447229551451188,
      "grad_norm": 4.615076541900635,
      "learning_rate": 7.519788918205804e-05,
      "loss": 0.1976,
      "step": 1129
    },
    {
      "epoch": 0.7453825857519789,
      "grad_norm": 2.362576723098755,
      "learning_rate": 7.517590149516271e-05,
      "loss": 0.1951,
      "step": 1130
    },
    {
      "epoch": 0.746042216358839,
      "grad_norm": 1.187734842300415,
      "learning_rate": 7.515391380826737e-05,
      "loss": 0.1531,
      "step": 1131
    },
    {
      "epoch": 0.7467018469656992,
      "grad_norm": 4.299764633178711,
      "learning_rate": 7.513192612137204e-05,
      "loss": 0.2521,
      "step": 1132
    },
    {
      "epoch": 0.7473614775725593,
      "grad_norm": 5.023017406463623,
      "learning_rate": 7.51099384344767e-05,
      "loss": 0.3807,
      "step": 1133
    },
    {
      "epoch": 0.7480211081794196,
      "grad_norm": 4.599670886993408,
      "learning_rate": 7.508795074758137e-05,
      "loss": 0.4221,
      "step": 1134
    },
    {
      "epoch": 0.7486807387862797,
      "grad_norm": 2.810206651687622,
      "learning_rate": 7.506596306068602e-05,
      "loss": 0.2313,
      "step": 1135
    },
    {
      "epoch": 0.7493403693931399,
      "grad_norm": 1.7746119499206543,
      "learning_rate": 7.504397537379068e-05,
      "loss": 0.1875,
      "step": 1136
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.770570755004883,
      "learning_rate": 7.502198768689535e-05,
      "loss": 0.1689,
      "step": 1137
    },
    {
      "epoch": 0.7506596306068601,
      "grad_norm": 1.8628278970718384,
      "learning_rate": 7.500000000000001e-05,
      "loss": 0.0941,
      "step": 1138
    },
    {
      "epoch": 0.7513192612137203,
      "grad_norm": 8.61409854888916,
      "learning_rate": 7.497801231310466e-05,
      "loss": 0.3382,
      "step": 1139
    },
    {
      "epoch": 0.7519788918205804,
      "grad_norm": 8.75823974609375,
      "learning_rate": 7.495602462620933e-05,
      "loss": 0.5143,
      "step": 1140
    },
    {
      "epoch": 0.7526385224274407,
      "grad_norm": 1.5411545038223267,
      "learning_rate": 7.493403693931399e-05,
      "loss": 0.1872,
      "step": 1141
    },
    {
      "epoch": 0.7532981530343008,
      "grad_norm": 1.7158658504486084,
      "learning_rate": 7.491204925241865e-05,
      "loss": 0.16,
      "step": 1142
    },
    {
      "epoch": 0.753957783641161,
      "grad_norm": 1.2425768375396729,
      "learning_rate": 7.48900615655233e-05,
      "loss": 0.1221,
      "step": 1143
    },
    {
      "epoch": 0.7546174142480211,
      "grad_norm": 4.557229995727539,
      "learning_rate": 7.486807387862798e-05,
      "loss": 0.2223,
      "step": 1144
    },
    {
      "epoch": 0.7552770448548812,
      "grad_norm": 11.045930862426758,
      "learning_rate": 7.484608619173263e-05,
      "loss": 0.693,
      "step": 1145
    },
    {
      "epoch": 0.7559366754617414,
      "grad_norm": 2.276625871658325,
      "learning_rate": 7.482409850483729e-05,
      "loss": 0.1098,
      "step": 1146
    },
    {
      "epoch": 0.7565963060686016,
      "grad_norm": 5.6701130867004395,
      "learning_rate": 7.480211081794196e-05,
      "loss": 0.243,
      "step": 1147
    },
    {
      "epoch": 0.7572559366754618,
      "grad_norm": 8.682157516479492,
      "learning_rate": 7.478012313104662e-05,
      "loss": 0.3437,
      "step": 1148
    },
    {
      "epoch": 0.7579155672823219,
      "grad_norm": 5.736200332641602,
      "learning_rate": 7.475813544415127e-05,
      "loss": 0.3655,
      "step": 1149
    },
    {
      "epoch": 0.758575197889182,
      "grad_norm": 1.3048285245895386,
      "learning_rate": 7.473614775725593e-05,
      "loss": 0.1031,
      "step": 1150
    },
    {
      "epoch": 0.7592348284960422,
      "grad_norm": 0.9322561025619507,
      "learning_rate": 7.47141600703606e-05,
      "loss": 0.1228,
      "step": 1151
    },
    {
      "epoch": 0.7598944591029023,
      "grad_norm": 5.932257652282715,
      "learning_rate": 7.469217238346526e-05,
      "loss": 0.2727,
      "step": 1152
    },
    {
      "epoch": 0.7605540897097626,
      "grad_norm": 2.1204335689544678,
      "learning_rate": 7.467018469656992e-05,
      "loss": 0.132,
      "step": 1153
    },
    {
      "epoch": 0.7612137203166227,
      "grad_norm": 6.532655239105225,
      "learning_rate": 7.464819700967459e-05,
      "loss": 0.8242,
      "step": 1154
    },
    {
      "epoch": 0.7618733509234829,
      "grad_norm": 7.672903060913086,
      "learning_rate": 7.462620932277926e-05,
      "loss": 0.528,
      "step": 1155
    },
    {
      "epoch": 0.762532981530343,
      "grad_norm": 9.14714241027832,
      "learning_rate": 7.460422163588391e-05,
      "loss": 0.3812,
      "step": 1156
    },
    {
      "epoch": 0.7631926121372031,
      "grad_norm": 1.1271227598190308,
      "learning_rate": 7.458223394898857e-05,
      "loss": 0.118,
      "step": 1157
    },
    {
      "epoch": 0.7638522427440633,
      "grad_norm": 1.1786962747573853,
      "learning_rate": 7.456024626209324e-05,
      "loss": 0.1303,
      "step": 1158
    },
    {
      "epoch": 0.7645118733509235,
      "grad_norm": 2.248565912246704,
      "learning_rate": 7.45382585751979e-05,
      "loss": 0.1385,
      "step": 1159
    },
    {
      "epoch": 0.7651715039577837,
      "grad_norm": 9.07319164276123,
      "learning_rate": 7.451627088830256e-05,
      "loss": 0.6097,
      "step": 1160
    },
    {
      "epoch": 0.7658311345646438,
      "grad_norm": 1.7411022186279297,
      "learning_rate": 7.449428320140721e-05,
      "loss": 0.1227,
      "step": 1161
    },
    {
      "epoch": 0.7664907651715039,
      "grad_norm": 3.052371025085449,
      "learning_rate": 7.447229551451188e-05,
      "loss": 0.2174,
      "step": 1162
    },
    {
      "epoch": 0.7671503957783641,
      "grad_norm": 4.875460147857666,
      "learning_rate": 7.445030782761654e-05,
      "loss": 0.4368,
      "step": 1163
    },
    {
      "epoch": 0.7678100263852242,
      "grad_norm": 1.732859492301941,
      "learning_rate": 7.44283201407212e-05,
      "loss": 0.1659,
      "step": 1164
    },
    {
      "epoch": 0.7684696569920845,
      "grad_norm": 8.17945384979248,
      "learning_rate": 7.440633245382587e-05,
      "loss": 0.5741,
      "step": 1165
    },
    {
      "epoch": 0.7691292875989446,
      "grad_norm": 1.907379388809204,
      "learning_rate": 7.438434476693052e-05,
      "loss": 0.1003,
      "step": 1166
    },
    {
      "epoch": 0.7697889182058048,
      "grad_norm": 5.4178242683410645,
      "learning_rate": 7.436235708003518e-05,
      "loss": 0.2128,
      "step": 1167
    },
    {
      "epoch": 0.7704485488126649,
      "grad_norm": 0.7902146577835083,
      "learning_rate": 7.434036939313984e-05,
      "loss": 0.0903,
      "step": 1168
    },
    {
      "epoch": 0.771108179419525,
      "grad_norm": 3.7594783306121826,
      "learning_rate": 7.431838170624451e-05,
      "loss": 0.3173,
      "step": 1169
    },
    {
      "epoch": 0.7717678100263852,
      "grad_norm": 0.8513535261154175,
      "learning_rate": 7.429639401934917e-05,
      "loss": 0.0886,
      "step": 1170
    },
    {
      "epoch": 0.7724274406332454,
      "grad_norm": 3.035379409790039,
      "learning_rate": 7.427440633245382e-05,
      "loss": 0.1214,
      "step": 1171
    },
    {
      "epoch": 0.7730870712401056,
      "grad_norm": 9.969569206237793,
      "learning_rate": 7.425241864555848e-05,
      "loss": 0.4842,
      "step": 1172
    },
    {
      "epoch": 0.7737467018469657,
      "grad_norm": 2.0406064987182617,
      "learning_rate": 7.423043095866315e-05,
      "loss": 0.1211,
      "step": 1173
    },
    {
      "epoch": 0.7744063324538258,
      "grad_norm": 3.054861068725586,
      "learning_rate": 7.420844327176781e-05,
      "loss": 0.1852,
      "step": 1174
    },
    {
      "epoch": 0.775065963060686,
      "grad_norm": 1.097653865814209,
      "learning_rate": 7.418645558487248e-05,
      "loss": 0.0999,
      "step": 1175
    },
    {
      "epoch": 0.7757255936675461,
      "grad_norm": 2.9788050651550293,
      "learning_rate": 7.416446789797713e-05,
      "loss": 0.2333,
      "step": 1176
    },
    {
      "epoch": 0.7763852242744064,
      "grad_norm": 5.255477428436279,
      "learning_rate": 7.41424802110818e-05,
      "loss": 0.3789,
      "step": 1177
    },
    {
      "epoch": 0.7770448548812665,
      "grad_norm": 2.662280321121216,
      "learning_rate": 7.412049252418646e-05,
      "loss": 0.2276,
      "step": 1178
    },
    {
      "epoch": 0.7777044854881267,
      "grad_norm": 2.3209164142608643,
      "learning_rate": 7.409850483729112e-05,
      "loss": 0.1319,
      "step": 1179
    },
    {
      "epoch": 0.7783641160949868,
      "grad_norm": 10.789143562316895,
      "learning_rate": 7.407651715039579e-05,
      "loss": 1.2245,
      "step": 1180
    },
    {
      "epoch": 0.7790237467018469,
      "grad_norm": 3.887491226196289,
      "learning_rate": 7.405452946350045e-05,
      "loss": 0.1664,
      "step": 1181
    },
    {
      "epoch": 0.7796833773087071,
      "grad_norm": 1.6121047735214233,
      "learning_rate": 7.40325417766051e-05,
      "loss": 0.0857,
      "step": 1182
    },
    {
      "epoch": 0.7803430079155673,
      "grad_norm": 7.284989833831787,
      "learning_rate": 7.401055408970977e-05,
      "loss": 0.3815,
      "step": 1183
    },
    {
      "epoch": 0.7810026385224275,
      "grad_norm": 4.432650089263916,
      "learning_rate": 7.398856640281443e-05,
      "loss": 0.2732,
      "step": 1184
    },
    {
      "epoch": 0.7816622691292876,
      "grad_norm": 3.788809299468994,
      "learning_rate": 7.396657871591909e-05,
      "loss": 0.1873,
      "step": 1185
    },
    {
      "epoch": 0.7823218997361477,
      "grad_norm": 0.7817307114601135,
      "learning_rate": 7.394459102902375e-05,
      "loss": 0.0995,
      "step": 1186
    },
    {
      "epoch": 0.7829815303430079,
      "grad_norm": 8.454636573791504,
      "learning_rate": 7.392260334212842e-05,
      "loss": 0.5144,
      "step": 1187
    },
    {
      "epoch": 0.783641160949868,
      "grad_norm": 4.386679172515869,
      "learning_rate": 7.390061565523307e-05,
      "loss": 0.1617,
      "step": 1188
    },
    {
      "epoch": 0.7843007915567283,
      "grad_norm": 1.9116514921188354,
      "learning_rate": 7.387862796833773e-05,
      "loss": 0.1267,
      "step": 1189
    },
    {
      "epoch": 0.7849604221635884,
      "grad_norm": 10.690702438354492,
      "learning_rate": 7.385664028144239e-05,
      "loss": 0.6488,
      "step": 1190
    },
    {
      "epoch": 0.7856200527704486,
      "grad_norm": 3.145374059677124,
      "learning_rate": 7.383465259454706e-05,
      "loss": 0.201,
      "step": 1191
    },
    {
      "epoch": 0.7862796833773087,
      "grad_norm": 1.4167405366897583,
      "learning_rate": 7.381266490765171e-05,
      "loss": 0.1226,
      "step": 1192
    },
    {
      "epoch": 0.7869393139841688,
      "grad_norm": 0.6337651014328003,
      "learning_rate": 7.379067722075637e-05,
      "loss": 0.0965,
      "step": 1193
    },
    {
      "epoch": 0.787598944591029,
      "grad_norm": 2.1172056198120117,
      "learning_rate": 7.376868953386104e-05,
      "loss": 0.1413,
      "step": 1194
    },
    {
      "epoch": 0.7882585751978892,
      "grad_norm": 1.5609164237976074,
      "learning_rate": 7.37467018469657e-05,
      "loss": 0.1114,
      "step": 1195
    },
    {
      "epoch": 0.7889182058047494,
      "grad_norm": 1.2697992324829102,
      "learning_rate": 7.372471416007037e-05,
      "loss": 0.0941,
      "step": 1196
    },
    {
      "epoch": 0.7895778364116095,
      "grad_norm": 5.575024604797363,
      "learning_rate": 7.370272647317503e-05,
      "loss": 0.3626,
      "step": 1197
    },
    {
      "epoch": 0.7902374670184696,
      "grad_norm": 3.829204559326172,
      "learning_rate": 7.36807387862797e-05,
      "loss": 0.1837,
      "step": 1198
    },
    {
      "epoch": 0.7908970976253298,
      "grad_norm": 8.141222953796387,
      "learning_rate": 7.365875109938435e-05,
      "loss": 0.9849,
      "step": 1199
    },
    {
      "epoch": 0.7915567282321899,
      "grad_norm": 1.5222623348236084,
      "learning_rate": 7.363676341248901e-05,
      "loss": 0.1051,
      "step": 1200
    },
    {
      "epoch": 0.7922163588390502,
      "grad_norm": 0.8363921046257019,
      "learning_rate": 7.361477572559368e-05,
      "loss": 0.1197,
      "step": 1201
    },
    {
      "epoch": 0.7928759894459103,
      "grad_norm": 1.686952829360962,
      "learning_rate": 7.359278803869834e-05,
      "loss": 0.1508,
      "step": 1202
    },
    {
      "epoch": 0.7935356200527705,
      "grad_norm": 4.032611846923828,
      "learning_rate": 7.3570800351803e-05,
      "loss": 0.2914,
      "step": 1203
    },
    {
      "epoch": 0.7941952506596306,
      "grad_norm": 1.8421735763549805,
      "learning_rate": 7.354881266490765e-05,
      "loss": 0.1479,
      "step": 1204
    },
    {
      "epoch": 0.7948548812664907,
      "grad_norm": 2.6728782653808594,
      "learning_rate": 7.352682497801232e-05,
      "loss": 0.2263,
      "step": 1205
    },
    {
      "epoch": 0.7955145118733509,
      "grad_norm": 4.62345552444458,
      "learning_rate": 7.350483729111698e-05,
      "loss": 0.337,
      "step": 1206
    },
    {
      "epoch": 0.7961741424802111,
      "grad_norm": 1.9891915321350098,
      "learning_rate": 7.348284960422164e-05,
      "loss": 0.1414,
      "step": 1207
    },
    {
      "epoch": 0.7968337730870713,
      "grad_norm": 10.326050758361816,
      "learning_rate": 7.34608619173263e-05,
      "loss": 0.3979,
      "step": 1208
    },
    {
      "epoch": 0.7974934036939314,
      "grad_norm": 1.9226102828979492,
      "learning_rate": 7.343887423043096e-05,
      "loss": 0.2005,
      "step": 1209
    },
    {
      "epoch": 0.7981530343007915,
      "grad_norm": 1.563346028327942,
      "learning_rate": 7.341688654353562e-05,
      "loss": 0.1662,
      "step": 1210
    },
    {
      "epoch": 0.7988126649076517,
      "grad_norm": 1.2119908332824707,
      "learning_rate": 7.339489885664028e-05,
      "loss": 0.0824,
      "step": 1211
    },
    {
      "epoch": 0.7994722955145118,
      "grad_norm": 3.7893261909484863,
      "learning_rate": 7.337291116974495e-05,
      "loss": 0.2304,
      "step": 1212
    },
    {
      "epoch": 0.8001319261213721,
      "grad_norm": 2.0434305667877197,
      "learning_rate": 7.33509234828496e-05,
      "loss": 0.1301,
      "step": 1213
    },
    {
      "epoch": 0.8007915567282322,
      "grad_norm": 10.700847625732422,
      "learning_rate": 7.332893579595426e-05,
      "loss": 0.6454,
      "step": 1214
    },
    {
      "epoch": 0.8014511873350924,
      "grad_norm": 8.061247825622559,
      "learning_rate": 7.330694810905892e-05,
      "loss": 0.9974,
      "step": 1215
    },
    {
      "epoch": 0.8021108179419525,
      "grad_norm": 6.267648696899414,
      "learning_rate": 7.328496042216359e-05,
      "loss": 0.2211,
      "step": 1216
    },
    {
      "epoch": 0.8027704485488126,
      "grad_norm": 1.6094900369644165,
      "learning_rate": 7.326297273526825e-05,
      "loss": 0.1604,
      "step": 1217
    },
    {
      "epoch": 0.8034300791556728,
      "grad_norm": 2.47963809967041,
      "learning_rate": 7.324098504837292e-05,
      "loss": 0.1416,
      "step": 1218
    },
    {
      "epoch": 0.804089709762533,
      "grad_norm": 1.317921757698059,
      "learning_rate": 7.321899736147757e-05,
      "loss": 0.1011,
      "step": 1219
    },
    {
      "epoch": 0.8047493403693932,
      "grad_norm": 11.891366958618164,
      "learning_rate": 7.319700967458225e-05,
      "loss": 1.1452,
      "step": 1220
    },
    {
      "epoch": 0.8054089709762533,
      "grad_norm": 0.8147135376930237,
      "learning_rate": 7.31750219876869e-05,
      "loss": 0.0611,
      "step": 1221
    },
    {
      "epoch": 0.8060686015831134,
      "grad_norm": 13.418449401855469,
      "learning_rate": 7.315303430079156e-05,
      "loss": 0.6557,
      "step": 1222
    },
    {
      "epoch": 0.8067282321899736,
      "grad_norm": 2.441636085510254,
      "learning_rate": 7.313104661389623e-05,
      "loss": 0.1027,
      "step": 1223
    },
    {
      "epoch": 0.8073878627968337,
      "grad_norm": 0.8860911130905151,
      "learning_rate": 7.310905892700089e-05,
      "loss": 0.0844,
      "step": 1224
    },
    {
      "epoch": 0.808047493403694,
      "grad_norm": 2.434401750564575,
      "learning_rate": 7.308707124010554e-05,
      "loss": 0.1172,
      "step": 1225
    },
    {
      "epoch": 0.8087071240105541,
      "grad_norm": 11.067763328552246,
      "learning_rate": 7.30650835532102e-05,
      "loss": 0.3359,
      "step": 1226
    },
    {
      "epoch": 0.8093667546174143,
      "grad_norm": 18.672487258911133,
      "learning_rate": 7.304309586631487e-05,
      "loss": 0.9188,
      "step": 1227
    },
    {
      "epoch": 0.8100263852242744,
      "grad_norm": 6.836871147155762,
      "learning_rate": 7.302110817941953e-05,
      "loss": 0.9518,
      "step": 1228
    },
    {
      "epoch": 0.8106860158311345,
      "grad_norm": 9.7413911819458,
      "learning_rate": 7.299912049252419e-05,
      "loss": 0.447,
      "step": 1229
    },
    {
      "epoch": 0.8113456464379947,
      "grad_norm": 1.5182768106460571,
      "learning_rate": 7.297713280562886e-05,
      "loss": 0.1424,
      "step": 1230
    },
    {
      "epoch": 0.8120052770448549,
      "grad_norm": 2.1102705001831055,
      "learning_rate": 7.295514511873351e-05,
      "loss": 0.1281,
      "step": 1231
    },
    {
      "epoch": 0.8126649076517151,
      "grad_norm": 1.3725205659866333,
      "learning_rate": 7.293315743183817e-05,
      "loss": 0.1126,
      "step": 1232
    },
    {
      "epoch": 0.8133245382585752,
      "grad_norm": 1.1505591869354248,
      "learning_rate": 7.291116974494283e-05,
      "loss": 0.1138,
      "step": 1233
    },
    {
      "epoch": 0.8139841688654353,
      "grad_norm": 2.884002685546875,
      "learning_rate": 7.28891820580475e-05,
      "loss": 0.1709,
      "step": 1234
    },
    {
      "epoch": 0.8146437994722955,
      "grad_norm": 1.8248106241226196,
      "learning_rate": 7.286719437115215e-05,
      "loss": 0.1665,
      "step": 1235
    },
    {
      "epoch": 0.8153034300791556,
      "grad_norm": 1.4808790683746338,
      "learning_rate": 7.284520668425681e-05,
      "loss": 0.1387,
      "step": 1236
    },
    {
      "epoch": 0.8159630606860159,
      "grad_norm": 7.033433437347412,
      "learning_rate": 7.282321899736148e-05,
      "loss": 0.409,
      "step": 1237
    },
    {
      "epoch": 0.816622691292876,
      "grad_norm": 9.084525108337402,
      "learning_rate": 7.280123131046614e-05,
      "loss": 0.3544,
      "step": 1238
    },
    {
      "epoch": 0.8172823218997362,
      "grad_norm": 3.752854108810425,
      "learning_rate": 7.277924362357081e-05,
      "loss": 0.2256,
      "step": 1239
    },
    {
      "epoch": 0.8179419525065963,
      "grad_norm": 1.066298007965088,
      "learning_rate": 7.275725593667547e-05,
      "loss": 0.1038,
      "step": 1240
    },
    {
      "epoch": 0.8186015831134564,
      "grad_norm": 6.117469787597656,
      "learning_rate": 7.273526824978014e-05,
      "loss": 0.7175,
      "step": 1241
    },
    {
      "epoch": 0.8192612137203166,
      "grad_norm": 2.4609591960906982,
      "learning_rate": 7.27132805628848e-05,
      "loss": 0.229,
      "step": 1242
    },
    {
      "epoch": 0.8199208443271768,
      "grad_norm": 9.306368827819824,
      "learning_rate": 7.269129287598945e-05,
      "loss": 0.4868,
      "step": 1243
    },
    {
      "epoch": 0.820580474934037,
      "grad_norm": 2.5504956245422363,
      "learning_rate": 7.266930518909411e-05,
      "loss": 0.1964,
      "step": 1244
    },
    {
      "epoch": 0.8212401055408971,
      "grad_norm": 3.126267194747925,
      "learning_rate": 7.264731750219878e-05,
      "loss": 0.2432,
      "step": 1245
    },
    {
      "epoch": 0.8218997361477572,
      "grad_norm": 9.198246955871582,
      "learning_rate": 7.262532981530344e-05,
      "loss": 0.6958,
      "step": 1246
    },
    {
      "epoch": 0.8225593667546174,
      "grad_norm": 1.9426465034484863,
      "learning_rate": 7.260334212840809e-05,
      "loss": 0.135,
      "step": 1247
    },
    {
      "epoch": 0.8232189973614775,
      "grad_norm": 2.7409913539886475,
      "learning_rate": 7.258135444151276e-05,
      "loss": 0.2177,
      "step": 1248
    },
    {
      "epoch": 0.8238786279683378,
      "grad_norm": 7.184163570404053,
      "learning_rate": 7.255936675461742e-05,
      "loss": 0.2963,
      "step": 1249
    },
    {
      "epoch": 0.8245382585751979,
      "grad_norm": 4.934175491333008,
      "learning_rate": 7.253737906772208e-05,
      "loss": 0.248,
      "step": 1250
    },
    {
      "epoch": 0.825197889182058,
      "grad_norm": 1.8293273448944092,
      "learning_rate": 7.251539138082673e-05,
      "loss": 0.1229,
      "step": 1251
    },
    {
      "epoch": 0.8258575197889182,
      "grad_norm": 6.709878921508789,
      "learning_rate": 7.24934036939314e-05,
      "loss": 0.6703,
      "step": 1252
    },
    {
      "epoch": 0.8265171503957783,
      "grad_norm": 1.5328634977340698,
      "learning_rate": 7.247141600703606e-05,
      "loss": 0.1984,
      "step": 1253
    },
    {
      "epoch": 0.8271767810026385,
      "grad_norm": 1.8937844038009644,
      "learning_rate": 7.244942832014072e-05,
      "loss": 0.1263,
      "step": 1254
    },
    {
      "epoch": 0.8278364116094987,
      "grad_norm": 1.1109861135482788,
      "learning_rate": 7.242744063324539e-05,
      "loss": 0.0897,
      "step": 1255
    },
    {
      "epoch": 0.8284960422163589,
      "grad_norm": 12.431402206420898,
      "learning_rate": 7.240545294635005e-05,
      "loss": 0.7774,
      "step": 1256
    },
    {
      "epoch": 0.829155672823219,
      "grad_norm": 1.5568636655807495,
      "learning_rate": 7.23834652594547e-05,
      "loss": 0.0851,
      "step": 1257
    },
    {
      "epoch": 0.8298153034300791,
      "grad_norm": 13.243879318237305,
      "learning_rate": 7.236147757255936e-05,
      "loss": 0.61,
      "step": 1258
    },
    {
      "epoch": 0.8304749340369393,
      "grad_norm": 3.7683048248291016,
      "learning_rate": 7.233948988566403e-05,
      "loss": 0.167,
      "step": 1259
    },
    {
      "epoch": 0.8311345646437994,
      "grad_norm": 14.661237716674805,
      "learning_rate": 7.23175021987687e-05,
      "loss": 0.8642,
      "step": 1260
    },
    {
      "epoch": 0.8317941952506597,
      "grad_norm": 1.015993356704712,
      "learning_rate": 7.229551451187336e-05,
      "loss": 0.0983,
      "step": 1261
    },
    {
      "epoch": 0.8324538258575198,
      "grad_norm": 15.993131637573242,
      "learning_rate": 7.227352682497801e-05,
      "loss": 0.4326,
      "step": 1262
    },
    {
      "epoch": 0.83311345646438,
      "grad_norm": 0.7681789994239807,
      "learning_rate": 7.225153913808269e-05,
      "loss": 0.0639,
      "step": 1263
    },
    {
      "epoch": 0.8337730870712401,
      "grad_norm": 17.475637435913086,
      "learning_rate": 7.222955145118734e-05,
      "loss": 1.2777,
      "step": 1264
    },
    {
      "epoch": 0.8344327176781002,
      "grad_norm": 9.376352310180664,
      "learning_rate": 7.2207563764292e-05,
      "loss": 0.5052,
      "step": 1265
    },
    {
      "epoch": 0.8350923482849604,
      "grad_norm": 7.66080379486084,
      "learning_rate": 7.218557607739667e-05,
      "loss": 0.4109,
      "step": 1266
    },
    {
      "epoch": 0.8357519788918206,
      "grad_norm": 2.4443881511688232,
      "learning_rate": 7.216358839050133e-05,
      "loss": 0.1839,
      "step": 1267
    },
    {
      "epoch": 0.8364116094986808,
      "grad_norm": 1.6216665506362915,
      "learning_rate": 7.214160070360598e-05,
      "loss": 0.1367,
      "step": 1268
    },
    {
      "epoch": 0.8370712401055409,
      "grad_norm": 2.6289172172546387,
      "learning_rate": 7.211961301671064e-05,
      "loss": 0.2049,
      "step": 1269
    },
    {
      "epoch": 0.837730870712401,
      "grad_norm": 8.450302124023438,
      "learning_rate": 7.209762532981531e-05,
      "loss": 0.54,
      "step": 1270
    },
    {
      "epoch": 0.8383905013192612,
      "grad_norm": 1.1133506298065186,
      "learning_rate": 7.207563764291997e-05,
      "loss": 0.0803,
      "step": 1271
    },
    {
      "epoch": 0.8390501319261213,
      "grad_norm": 0.9511915445327759,
      "learning_rate": 7.205364995602463e-05,
      "loss": 0.0933,
      "step": 1272
    },
    {
      "epoch": 0.8397097625329816,
      "grad_norm": 8.724719047546387,
      "learning_rate": 7.20316622691293e-05,
      "loss": 0.8569,
      "step": 1273
    },
    {
      "epoch": 0.8403693931398417,
      "grad_norm": 8.587272644042969,
      "learning_rate": 7.200967458223395e-05,
      "loss": 0.1908,
      "step": 1274
    },
    {
      "epoch": 0.8410290237467019,
      "grad_norm": 7.499882221221924,
      "learning_rate": 7.198768689533861e-05,
      "loss": 0.3806,
      "step": 1275
    },
    {
      "epoch": 0.841688654353562,
      "grad_norm": 4.631711959838867,
      "learning_rate": 7.196569920844327e-05,
      "loss": 0.2178,
      "step": 1276
    },
    {
      "epoch": 0.8423482849604221,
      "grad_norm": 11.484779357910156,
      "learning_rate": 7.194371152154794e-05,
      "loss": 0.7807,
      "step": 1277
    },
    {
      "epoch": 0.8430079155672823,
      "grad_norm": 2.7092576026916504,
      "learning_rate": 7.19217238346526e-05,
      "loss": 0.1444,
      "step": 1278
    },
    {
      "epoch": 0.8436675461741425,
      "grad_norm": 1.6325404644012451,
      "learning_rate": 7.189973614775725e-05,
      "loss": 0.0985,
      "step": 1279
    },
    {
      "epoch": 0.8443271767810027,
      "grad_norm": 1.9197297096252441,
      "learning_rate": 7.187774846086192e-05,
      "loss": 0.1218,
      "step": 1280
    },
    {
      "epoch": 0.8449868073878628,
      "grad_norm": 2.733705520629883,
      "learning_rate": 7.185576077396658e-05,
      "loss": 0.1621,
      "step": 1281
    },
    {
      "epoch": 0.8456464379947229,
      "grad_norm": 6.912718296051025,
      "learning_rate": 7.183377308707125e-05,
      "loss": 0.3676,
      "step": 1282
    },
    {
      "epoch": 0.8463060686015831,
      "grad_norm": 2.081939220428467,
      "learning_rate": 7.18117854001759e-05,
      "loss": 0.1231,
      "step": 1283
    },
    {
      "epoch": 0.8469656992084432,
      "grad_norm": 9.149785995483398,
      "learning_rate": 7.178979771328058e-05,
      "loss": 1.1909,
      "step": 1284
    },
    {
      "epoch": 0.8476253298153035,
      "grad_norm": 1.1184277534484863,
      "learning_rate": 7.176781002638523e-05,
      "loss": 0.0866,
      "step": 1285
    },
    {
      "epoch": 0.8482849604221636,
      "grad_norm": 7.467662811279297,
      "learning_rate": 7.174582233948989e-05,
      "loss": 0.2437,
      "step": 1286
    },
    {
      "epoch": 0.8489445910290238,
      "grad_norm": 1.1963495016098022,
      "learning_rate": 7.172383465259455e-05,
      "loss": 0.0848,
      "step": 1287
    },
    {
      "epoch": 0.8496042216358839,
      "grad_norm": 1.0388990640640259,
      "learning_rate": 7.170184696569922e-05,
      "loss": 0.1268,
      "step": 1288
    },
    {
      "epoch": 0.850263852242744,
      "grad_norm": 14.592671394348145,
      "learning_rate": 7.167985927880388e-05,
      "loss": 0.5202,
      "step": 1289
    },
    {
      "epoch": 0.8509234828496042,
      "grad_norm": 6.340848922729492,
      "learning_rate": 7.165787159190853e-05,
      "loss": 0.5715,
      "step": 1290
    },
    {
      "epoch": 0.8515831134564644,
      "grad_norm": 12.66623306274414,
      "learning_rate": 7.16358839050132e-05,
      "loss": 0.7604,
      "step": 1291
    },
    {
      "epoch": 0.8522427440633246,
      "grad_norm": 1.0338391065597534,
      "learning_rate": 7.161389621811786e-05,
      "loss": 0.1071,
      "step": 1292
    },
    {
      "epoch": 0.8529023746701847,
      "grad_norm": 5.9188737869262695,
      "learning_rate": 7.159190853122252e-05,
      "loss": 0.6484,
      "step": 1293
    },
    {
      "epoch": 0.8535620052770448,
      "grad_norm": 2.757664442062378,
      "learning_rate": 7.156992084432717e-05,
      "loss": 0.1383,
      "step": 1294
    },
    {
      "epoch": 0.854221635883905,
      "grad_norm": 3.918135643005371,
      "learning_rate": 7.154793315743184e-05,
      "loss": 0.2723,
      "step": 1295
    },
    {
      "epoch": 0.8548812664907651,
      "grad_norm": 1.5906606912612915,
      "learning_rate": 7.15259454705365e-05,
      "loss": 0.1207,
      "step": 1296
    },
    {
      "epoch": 0.8555408970976254,
      "grad_norm": 6.043204307556152,
      "learning_rate": 7.150395778364116e-05,
      "loss": 0.5028,
      "step": 1297
    },
    {
      "epoch": 0.8562005277044855,
      "grad_norm": 4.359861850738525,
      "learning_rate": 7.148197009674582e-05,
      "loss": 0.3282,
      "step": 1298
    },
    {
      "epoch": 0.8568601583113457,
      "grad_norm": 4.675388336181641,
      "learning_rate": 7.145998240985049e-05,
      "loss": 0.2683,
      "step": 1299
    },
    {
      "epoch": 0.8575197889182058,
      "grad_norm": 3.1145071983337402,
      "learning_rate": 7.143799472295514e-05,
      "loss": 0.242,
      "step": 1300
    },
    {
      "epoch": 0.8581794195250659,
      "grad_norm": 2.505929946899414,
      "learning_rate": 7.141600703605981e-05,
      "loss": 0.2399,
      "step": 1301
    },
    {
      "epoch": 0.8588390501319261,
      "grad_norm": 2.696861982345581,
      "learning_rate": 7.139401934916447e-05,
      "loss": 0.187,
      "step": 1302
    },
    {
      "epoch": 0.8594986807387863,
      "grad_norm": 2.193457841873169,
      "learning_rate": 7.137203166226914e-05,
      "loss": 0.1717,
      "step": 1303
    },
    {
      "epoch": 0.8601583113456465,
      "grad_norm": 1.7806284427642822,
      "learning_rate": 7.13500439753738e-05,
      "loss": 0.1434,
      "step": 1304
    },
    {
      "epoch": 0.8608179419525066,
      "grad_norm": 1.335363745689392,
      "learning_rate": 7.132805628847845e-05,
      "loss": 0.1176,
      "step": 1305
    },
    {
      "epoch": 0.8614775725593667,
      "grad_norm": 0.6049299240112305,
      "learning_rate": 7.130606860158313e-05,
      "loss": 0.0949,
      "step": 1306
    },
    {
      "epoch": 0.8621372031662269,
      "grad_norm": 2.297654390335083,
      "learning_rate": 7.128408091468778e-05,
      "loss": 0.1329,
      "step": 1307
    },
    {
      "epoch": 0.862796833773087,
      "grad_norm": 0.9257974624633789,
      "learning_rate": 7.126209322779244e-05,
      "loss": 0.0867,
      "step": 1308
    },
    {
      "epoch": 0.8634564643799473,
      "grad_norm": 14.553083419799805,
      "learning_rate": 7.124010554089711e-05,
      "loss": 0.9599,
      "step": 1309
    },
    {
      "epoch": 0.8641160949868074,
      "grad_norm": 0.601212739944458,
      "learning_rate": 7.121811785400177e-05,
      "loss": 0.0549,
      "step": 1310
    },
    {
      "epoch": 0.8647757255936676,
      "grad_norm": 11.095919609069824,
      "learning_rate": 7.119613016710642e-05,
      "loss": 0.9927,
      "step": 1311
    },
    {
      "epoch": 0.8654353562005277,
      "grad_norm": 9.059020042419434,
      "learning_rate": 7.117414248021108e-05,
      "loss": 0.6034,
      "step": 1312
    },
    {
      "epoch": 0.8660949868073878,
      "grad_norm": 1.2691235542297363,
      "learning_rate": 7.115215479331575e-05,
      "loss": 0.0787,
      "step": 1313
    },
    {
      "epoch": 0.866754617414248,
      "grad_norm": 17.570205688476562,
      "learning_rate": 7.113016710642041e-05,
      "loss": 1.3236,
      "step": 1314
    },
    {
      "epoch": 0.8674142480211082,
      "grad_norm": 15.04443359375,
      "learning_rate": 7.110817941952507e-05,
      "loss": 2.0051,
      "step": 1315
    },
    {
      "epoch": 0.8680738786279684,
      "grad_norm": 8.1328763961792,
      "learning_rate": 7.108619173262972e-05,
      "loss": 0.4223,
      "step": 1316
    },
    {
      "epoch": 0.8687335092348285,
      "grad_norm": 1.3752127885818481,
      "learning_rate": 7.106420404573439e-05,
      "loss": 0.0682,
      "step": 1317
    },
    {
      "epoch": 0.8693931398416886,
      "grad_norm": 14.429526329040527,
      "learning_rate": 7.104221635883905e-05,
      "loss": 0.4812,
      "step": 1318
    },
    {
      "epoch": 0.8700527704485488,
      "grad_norm": 10.521676063537598,
      "learning_rate": 7.10202286719437e-05,
      "loss": 0.8688,
      "step": 1319
    },
    {
      "epoch": 0.8707124010554089,
      "grad_norm": 4.552806377410889,
      "learning_rate": 7.099824098504838e-05,
      "loss": 0.1352,
      "step": 1320
    },
    {
      "epoch": 0.8713720316622692,
      "grad_norm": 6.958561897277832,
      "learning_rate": 7.097625329815303e-05,
      "loss": 0.3895,
      "step": 1321
    },
    {
      "epoch": 0.8720316622691293,
      "grad_norm": 4.6454644203186035,
      "learning_rate": 7.095426561125769e-05,
      "loss": 0.2103,
      "step": 1322
    },
    {
      "epoch": 0.8726912928759895,
      "grad_norm": 1.5674951076507568,
      "learning_rate": 7.093227792436236e-05,
      "loss": 0.1238,
      "step": 1323
    },
    {
      "epoch": 0.8733509234828496,
      "grad_norm": 1.044966220855713,
      "learning_rate": 7.091029023746702e-05,
      "loss": 0.0967,
      "step": 1324
    },
    {
      "epoch": 0.8740105540897097,
      "grad_norm": 1.6588327884674072,
      "learning_rate": 7.088830255057169e-05,
      "loss": 0.13,
      "step": 1325
    },
    {
      "epoch": 0.8746701846965699,
      "grad_norm": 5.550680637359619,
      "learning_rate": 7.086631486367635e-05,
      "loss": 0.5382,
      "step": 1326
    },
    {
      "epoch": 0.8753298153034301,
      "grad_norm": 8.825727462768555,
      "learning_rate": 7.084432717678102e-05,
      "loss": 0.7939,
      "step": 1327
    },
    {
      "epoch": 0.8759894459102903,
      "grad_norm": 2.121044397354126,
      "learning_rate": 7.082233948988567e-05,
      "loss": 0.1944,
      "step": 1328
    },
    {
      "epoch": 0.8766490765171504,
      "grad_norm": 1.7348387241363525,
      "learning_rate": 7.080035180299033e-05,
      "loss": 0.1624,
      "step": 1329
    },
    {
      "epoch": 0.8773087071240105,
      "grad_norm": 1.6122055053710938,
      "learning_rate": 7.077836411609499e-05,
      "loss": 0.2106,
      "step": 1330
    },
    {
      "epoch": 0.8779683377308707,
      "grad_norm": 2.1397647857666016,
      "learning_rate": 7.075637642919966e-05,
      "loss": 0.2306,
      "step": 1331
    },
    {
      "epoch": 0.8786279683377308,
      "grad_norm": 1.3226624727249146,
      "learning_rate": 7.073438874230432e-05,
      "loss": 0.139,
      "step": 1332
    },
    {
      "epoch": 0.8792875989445911,
      "grad_norm": 1.488722324371338,
      "learning_rate": 7.071240105540897e-05,
      "loss": 0.16,
      "step": 1333
    },
    {
      "epoch": 0.8799472295514512,
      "grad_norm": 6.499186992645264,
      "learning_rate": 7.069041336851363e-05,
      "loss": 0.3542,
      "step": 1334
    },
    {
      "epoch": 0.8806068601583114,
      "grad_norm": 12.483899116516113,
      "learning_rate": 7.06684256816183e-05,
      "loss": 0.7534,
      "step": 1335
    },
    {
      "epoch": 0.8812664907651715,
      "grad_norm": 5.885683536529541,
      "learning_rate": 7.064643799472296e-05,
      "loss": 0.5699,
      "step": 1336
    },
    {
      "epoch": 0.8819261213720316,
      "grad_norm": 1.3030096292495728,
      "learning_rate": 7.062445030782761e-05,
      "loss": 0.1287,
      "step": 1337
    },
    {
      "epoch": 0.8825857519788918,
      "grad_norm": 1.955776572227478,
      "learning_rate": 7.060246262093228e-05,
      "loss": 0.1658,
      "step": 1338
    },
    {
      "epoch": 0.883245382585752,
      "grad_norm": 1.0527215003967285,
      "learning_rate": 7.058047493403694e-05,
      "loss": 0.1398,
      "step": 1339
    },
    {
      "epoch": 0.8839050131926122,
      "grad_norm": 1.9756780862808228,
      "learning_rate": 7.05584872471416e-05,
      "loss": 0.1559,
      "step": 1340
    },
    {
      "epoch": 0.8845646437994723,
      "grad_norm": 1.8005578517913818,
      "learning_rate": 7.053649956024626e-05,
      "loss": 0.1157,
      "step": 1341
    },
    {
      "epoch": 0.8852242744063324,
      "grad_norm": 5.034745693206787,
      "learning_rate": 7.051451187335093e-05,
      "loss": 0.1693,
      "step": 1342
    },
    {
      "epoch": 0.8858839050131926,
      "grad_norm": 5.521919250488281,
      "learning_rate": 7.049252418645558e-05,
      "loss": 0.1511,
      "step": 1343
    },
    {
      "epoch": 0.8865435356200527,
      "grad_norm": 1.5968241691589355,
      "learning_rate": 7.047053649956025e-05,
      "loss": 0.129,
      "step": 1344
    },
    {
      "epoch": 0.887203166226913,
      "grad_norm": 8.477872848510742,
      "learning_rate": 7.044854881266491e-05,
      "loss": 0.3725,
      "step": 1345
    },
    {
      "epoch": 0.8878627968337731,
      "grad_norm": 1.8259507417678833,
      "learning_rate": 7.042656112576958e-05,
      "loss": 0.0994,
      "step": 1346
    },
    {
      "epoch": 0.8885224274406333,
      "grad_norm": 1.101580262184143,
      "learning_rate": 7.040457343887424e-05,
      "loss": 0.0906,
      "step": 1347
    },
    {
      "epoch": 0.8891820580474934,
      "grad_norm": 10.306282997131348,
      "learning_rate": 7.03825857519789e-05,
      "loss": 0.8782,
      "step": 1348
    },
    {
      "epoch": 0.8898416886543535,
      "grad_norm": 15.526986122131348,
      "learning_rate": 7.036059806508357e-05,
      "loss": 0.6501,
      "step": 1349
    },
    {
      "epoch": 0.8905013192612137,
      "grad_norm": 0.883723258972168,
      "learning_rate": 7.033861037818822e-05,
      "loss": 0.0598,
      "step": 1350
    },
    {
      "epoch": 0.8911609498680739,
      "grad_norm": 8.182527542114258,
      "learning_rate": 7.031662269129288e-05,
      "loss": 0.5607,
      "step": 1351
    },
    {
      "epoch": 0.8918205804749341,
      "grad_norm": 1.6464027166366577,
      "learning_rate": 7.029463500439754e-05,
      "loss": 0.1298,
      "step": 1352
    },
    {
      "epoch": 0.8924802110817942,
      "grad_norm": 14.568886756896973,
      "learning_rate": 7.02726473175022e-05,
      "loss": 0.8604,
      "step": 1353
    },
    {
      "epoch": 0.8931398416886543,
      "grad_norm": 9.215087890625,
      "learning_rate": 7.025065963060686e-05,
      "loss": 0.8393,
      "step": 1354
    },
    {
      "epoch": 0.8937994722955145,
      "grad_norm": 7.827467918395996,
      "learning_rate": 7.022867194371152e-05,
      "loss": 0.317,
      "step": 1355
    },
    {
      "epoch": 0.8944591029023746,
      "grad_norm": 3.778693914413452,
      "learning_rate": 7.020668425681619e-05,
      "loss": 0.2063,
      "step": 1356
    },
    {
      "epoch": 0.8951187335092349,
      "grad_norm": 1.649800181388855,
      "learning_rate": 7.018469656992085e-05,
      "loss": 0.1332,
      "step": 1357
    },
    {
      "epoch": 0.895778364116095,
      "grad_norm": 5.574481010437012,
      "learning_rate": 7.01627088830255e-05,
      "loss": 0.3543,
      "step": 1358
    },
    {
      "epoch": 0.8964379947229552,
      "grad_norm": 2.9780945777893066,
      "learning_rate": 7.014072119613016e-05,
      "loss": 0.2355,
      "step": 1359
    },
    {
      "epoch": 0.8970976253298153,
      "grad_norm": 1.052825927734375,
      "learning_rate": 7.011873350923483e-05,
      "loss": 0.1349,
      "step": 1360
    },
    {
      "epoch": 0.8977572559366754,
      "grad_norm": 14.091297149658203,
      "learning_rate": 7.009674582233949e-05,
      "loss": 0.477,
      "step": 1361
    },
    {
      "epoch": 0.8984168865435356,
      "grad_norm": 1.6434860229492188,
      "learning_rate": 7.007475813544415e-05,
      "loss": 0.152,
      "step": 1362
    },
    {
      "epoch": 0.8990765171503958,
      "grad_norm": 7.155645370483398,
      "learning_rate": 7.005277044854882e-05,
      "loss": 0.279,
      "step": 1363
    },
    {
      "epoch": 0.899736147757256,
      "grad_norm": 7.262573719024658,
      "learning_rate": 7.003078276165347e-05,
      "loss": 0.6331,
      "step": 1364
    },
    {
      "epoch": 0.9003957783641161,
      "grad_norm": 3.773361921310425,
      "learning_rate": 7.000879507475813e-05,
      "loss": 0.3248,
      "step": 1365
    },
    {
      "epoch": 0.9010554089709762,
      "grad_norm": 6.343410015106201,
      "learning_rate": 6.99868073878628e-05,
      "loss": 0.3485,
      "step": 1366
    },
    {
      "epoch": 0.9017150395778364,
      "grad_norm": 1.284759283065796,
      "learning_rate": 6.996481970096747e-05,
      "loss": 0.1925,
      "step": 1367
    },
    {
      "epoch": 0.9023746701846965,
      "grad_norm": 1.0382758378982544,
      "learning_rate": 6.994283201407213e-05,
      "loss": 0.1497,
      "step": 1368
    },
    {
      "epoch": 0.9030343007915568,
      "grad_norm": 1.4643335342407227,
      "learning_rate": 6.992084432717679e-05,
      "loss": 0.187,
      "step": 1369
    },
    {
      "epoch": 0.9036939313984169,
      "grad_norm": 6.773533344268799,
      "learning_rate": 6.989885664028144e-05,
      "loss": 0.344,
      "step": 1370
    },
    {
      "epoch": 0.9043535620052771,
      "grad_norm": 10.011722564697266,
      "learning_rate": 6.987686895338611e-05,
      "loss": 0.7951,
      "step": 1371
    },
    {
      "epoch": 0.9050131926121372,
      "grad_norm": 3.88635516166687,
      "learning_rate": 6.985488126649077e-05,
      "loss": 0.2803,
      "step": 1372
    },
    {
      "epoch": 0.9056728232189973,
      "grad_norm": 1.8780384063720703,
      "learning_rate": 6.983289357959543e-05,
      "loss": 0.1475,
      "step": 1373
    },
    {
      "epoch": 0.9063324538258575,
      "grad_norm": 2.3969504833221436,
      "learning_rate": 6.98109058927001e-05,
      "loss": 0.203,
      "step": 1374
    },
    {
      "epoch": 0.9069920844327177,
      "grad_norm": 2.9268898963928223,
      "learning_rate": 6.978891820580476e-05,
      "loss": 0.2214,
      "step": 1375
    },
    {
      "epoch": 0.9076517150395779,
      "grad_norm": 2.2129805088043213,
      "learning_rate": 6.976693051890941e-05,
      "loss": 0.2683,
      "step": 1376
    },
    {
      "epoch": 0.908311345646438,
      "grad_norm": 1.8175421953201294,
      "learning_rate": 6.974494283201407e-05,
      "loss": 0.1962,
      "step": 1377
    },
    {
      "epoch": 0.9089709762532981,
      "grad_norm": 1.6354306936264038,
      "learning_rate": 6.972295514511874e-05,
      "loss": 0.1746,
      "step": 1378
    },
    {
      "epoch": 0.9096306068601583,
      "grad_norm": 1.9106920957565308,
      "learning_rate": 6.97009674582234e-05,
      "loss": 0.2046,
      "step": 1379
    },
    {
      "epoch": 0.9102902374670184,
      "grad_norm": 1.0871697664260864,
      "learning_rate": 6.967897977132805e-05,
      "loss": 0.1396,
      "step": 1380
    },
    {
      "epoch": 0.9109498680738787,
      "grad_norm": 9.243202209472656,
      "learning_rate": 6.965699208443272e-05,
      "loss": 0.4248,
      "step": 1381
    },
    {
      "epoch": 0.9116094986807388,
      "grad_norm": 9.716400146484375,
      "learning_rate": 6.963500439753738e-05,
      "loss": 0.6353,
      "step": 1382
    },
    {
      "epoch": 0.912269129287599,
      "grad_norm": 1.5269137620925903,
      "learning_rate": 6.961301671064204e-05,
      "loss": 0.1254,
      "step": 1383
    },
    {
      "epoch": 0.9129287598944591,
      "grad_norm": 11.175103187561035,
      "learning_rate": 6.95910290237467e-05,
      "loss": 0.6459,
      "step": 1384
    },
    {
      "epoch": 0.9135883905013192,
      "grad_norm": 6.61058235168457,
      "learning_rate": 6.956904133685137e-05,
      "loss": 0.3206,
      "step": 1385
    },
    {
      "epoch": 0.9142480211081794,
      "grad_norm": 12.882307052612305,
      "learning_rate": 6.954705364995602e-05,
      "loss": 0.3598,
      "step": 1386
    },
    {
      "epoch": 0.9149076517150396,
      "grad_norm": 1.3296420574188232,
      "learning_rate": 6.952506596306069e-05,
      "loss": 0.097,
      "step": 1387
    },
    {
      "epoch": 0.9155672823218998,
      "grad_norm": 7.156212329864502,
      "learning_rate": 6.950307827616535e-05,
      "loss": 0.4558,
      "step": 1388
    },
    {
      "epoch": 0.9162269129287599,
      "grad_norm": 9.493928909301758,
      "learning_rate": 6.948109058927002e-05,
      "loss": 0.7985,
      "step": 1389
    },
    {
      "epoch": 0.91688654353562,
      "grad_norm": 1.6267640590667725,
      "learning_rate": 6.945910290237468e-05,
      "loss": 0.144,
      "step": 1390
    },
    {
      "epoch": 0.9175461741424802,
      "grad_norm": 6.859350204467773,
      "learning_rate": 6.943711521547933e-05,
      "loss": 0.3093,
      "step": 1391
    },
    {
      "epoch": 0.9182058047493403,
      "grad_norm": 8.689475059509277,
      "learning_rate": 6.9415127528584e-05,
      "loss": 0.2511,
      "step": 1392
    },
    {
      "epoch": 0.9188654353562006,
      "grad_norm": 7.370567798614502,
      "learning_rate": 6.939313984168866e-05,
      "loss": 0.398,
      "step": 1393
    },
    {
      "epoch": 0.9195250659630607,
      "grad_norm": 1.915027379989624,
      "learning_rate": 6.937115215479332e-05,
      "loss": 0.1973,
      "step": 1394
    },
    {
      "epoch": 0.9201846965699209,
      "grad_norm": 2.1181905269622803,
      "learning_rate": 6.934916446789798e-05,
      "loss": 0.1678,
      "step": 1395
    },
    {
      "epoch": 0.920844327176781,
      "grad_norm": 1.4119939804077148,
      "learning_rate": 6.932717678100265e-05,
      "loss": 0.1224,
      "step": 1396
    },
    {
      "epoch": 0.9215039577836411,
      "grad_norm": 8.195084571838379,
      "learning_rate": 6.93051890941073e-05,
      "loss": 0.4396,
      "step": 1397
    },
    {
      "epoch": 0.9221635883905013,
      "grad_norm": 2.342750072479248,
      "learning_rate": 6.928320140721196e-05,
      "loss": 0.1949,
      "step": 1398
    },
    {
      "epoch": 0.9228232189973615,
      "grad_norm": 8.263040542602539,
      "learning_rate": 6.926121372031663e-05,
      "loss": 0.9118,
      "step": 1399
    },
    {
      "epoch": 0.9234828496042217,
      "grad_norm": 8.073260307312012,
      "learning_rate": 6.923922603342129e-05,
      "loss": 0.4217,
      "step": 1400
    },
    {
      "epoch": 0.9241424802110818,
      "grad_norm": 1.8547745943069458,
      "learning_rate": 6.921723834652595e-05,
      "loss": 0.2321,
      "step": 1401
    },
    {
      "epoch": 0.924802110817942,
      "grad_norm": 5.850190162658691,
      "learning_rate": 6.91952506596306e-05,
      "loss": 0.3877,
      "step": 1402
    },
    {
      "epoch": 0.9254617414248021,
      "grad_norm": 15.066916465759277,
      "learning_rate": 6.917326297273527e-05,
      "loss": 0.5446,
      "step": 1403
    },
    {
      "epoch": 0.9261213720316622,
      "grad_norm": 2.5834875106811523,
      "learning_rate": 6.915127528583993e-05,
      "loss": 0.2179,
      "step": 1404
    },
    {
      "epoch": 0.9267810026385225,
      "grad_norm": 5.149223804473877,
      "learning_rate": 6.912928759894459e-05,
      "loss": 0.3453,
      "step": 1405
    },
    {
      "epoch": 0.9274406332453826,
      "grad_norm": 4.29860782623291,
      "learning_rate": 6.910729991204926e-05,
      "loss": 0.3036,
      "step": 1406
    },
    {
      "epoch": 0.9281002638522428,
      "grad_norm": 4.426950454711914,
      "learning_rate": 6.908531222515391e-05,
      "loss": 0.3574,
      "step": 1407
    },
    {
      "epoch": 0.9287598944591029,
      "grad_norm": 1.4163566827774048,
      "learning_rate": 6.906332453825858e-05,
      "loss": 0.1432,
      "step": 1408
    },
    {
      "epoch": 0.929419525065963,
      "grad_norm": 5.042421817779541,
      "learning_rate": 6.904133685136324e-05,
      "loss": 0.5603,
      "step": 1409
    },
    {
      "epoch": 0.9300791556728232,
      "grad_norm": 0.7768383026123047,
      "learning_rate": 6.901934916446791e-05,
      "loss": 0.0969,
      "step": 1410
    },
    {
      "epoch": 0.9307387862796834,
      "grad_norm": 9.220956802368164,
      "learning_rate": 6.899736147757257e-05,
      "loss": 0.5606,
      "step": 1411
    },
    {
      "epoch": 0.9313984168865436,
      "grad_norm": 3.6776247024536133,
      "learning_rate": 6.897537379067723e-05,
      "loss": 0.2715,
      "step": 1412
    },
    {
      "epoch": 0.9320580474934037,
      "grad_norm": 0.7779847979545593,
      "learning_rate": 6.895338610378188e-05,
      "loss": 0.1043,
      "step": 1413
    },
    {
      "epoch": 0.9327176781002638,
      "grad_norm": 1.802425503730774,
      "learning_rate": 6.893139841688655e-05,
      "loss": 0.1479,
      "step": 1414
    },
    {
      "epoch": 0.933377308707124,
      "grad_norm": 6.393472194671631,
      "learning_rate": 6.890941072999121e-05,
      "loss": 0.2325,
      "step": 1415
    },
    {
      "epoch": 0.9340369393139841,
      "grad_norm": 2.3182241916656494,
      "learning_rate": 6.888742304309587e-05,
      "loss": 0.1539,
      "step": 1416
    },
    {
      "epoch": 0.9346965699208444,
      "grad_norm": 1.9984432458877563,
      "learning_rate": 6.886543535620054e-05,
      "loss": 0.1416,
      "step": 1417
    },
    {
      "epoch": 0.9353562005277045,
      "grad_norm": 2.4230189323425293,
      "learning_rate": 6.88434476693052e-05,
      "loss": 0.2161,
      "step": 1418
    },
    {
      "epoch": 0.9360158311345647,
      "grad_norm": 3.0721182823181152,
      "learning_rate": 6.882145998240985e-05,
      "loss": 0.1622,
      "step": 1419
    },
    {
      "epoch": 0.9366754617414248,
      "grad_norm": 6.485748291015625,
      "learning_rate": 6.879947229551451e-05,
      "loss": 0.3859,
      "step": 1420
    },
    {
      "epoch": 0.9373350923482849,
      "grad_norm": 8.688453674316406,
      "learning_rate": 6.877748460861918e-05,
      "loss": 0.4692,
      "step": 1421
    },
    {
      "epoch": 0.9379947229551451,
      "grad_norm": 3.686521291732788,
      "learning_rate": 6.875549692172384e-05,
      "loss": 0.1758,
      "step": 1422
    },
    {
      "epoch": 0.9386543535620053,
      "grad_norm": 0.8288975954055786,
      "learning_rate": 6.87335092348285e-05,
      "loss": 0.1061,
      "step": 1423
    },
    {
      "epoch": 0.9393139841688655,
      "grad_norm": 1.314884066581726,
      "learning_rate": 6.871152154793315e-05,
      "loss": 0.0929,
      "step": 1424
    },
    {
      "epoch": 0.9399736147757256,
      "grad_norm": 9.108161926269531,
      "learning_rate": 6.868953386103782e-05,
      "loss": 0.8861,
      "step": 1425
    },
    {
      "epoch": 0.9406332453825857,
      "grad_norm": 3.5598487854003906,
      "learning_rate": 6.866754617414248e-05,
      "loss": 0.2297,
      "step": 1426
    },
    {
      "epoch": 0.9412928759894459,
      "grad_norm": 1.4332423210144043,
      "learning_rate": 6.864555848724713e-05,
      "loss": 0.1285,
      "step": 1427
    },
    {
      "epoch": 0.941952506596306,
      "grad_norm": 6.934497356414795,
      "learning_rate": 6.86235708003518e-05,
      "loss": 0.44,
      "step": 1428
    },
    {
      "epoch": 0.9426121372031663,
      "grad_norm": 1.583203673362732,
      "learning_rate": 6.860158311345646e-05,
      "loss": 0.1115,
      "step": 1429
    },
    {
      "epoch": 0.9432717678100264,
      "grad_norm": 10.974326133728027,
      "learning_rate": 6.857959542656113e-05,
      "loss": 1.0701,
      "step": 1430
    },
    {
      "epoch": 0.9439313984168866,
      "grad_norm": 2.9200496673583984,
      "learning_rate": 6.855760773966579e-05,
      "loss": 0.2252,
      "step": 1431
    },
    {
      "epoch": 0.9445910290237467,
      "grad_norm": 1.5554180145263672,
      "learning_rate": 6.853562005277046e-05,
      "loss": 0.1215,
      "step": 1432
    },
    {
      "epoch": 0.9452506596306068,
      "grad_norm": 1.8715732097625732,
      "learning_rate": 6.851363236587512e-05,
      "loss": 0.1302,
      "step": 1433
    },
    {
      "epoch": 0.945910290237467,
      "grad_norm": 2.8289904594421387,
      "learning_rate": 6.849164467897977e-05,
      "loss": 0.1527,
      "step": 1434
    },
    {
      "epoch": 0.9465699208443272,
      "grad_norm": 0.7461877465248108,
      "learning_rate": 6.846965699208445e-05,
      "loss": 0.0836,
      "step": 1435
    },
    {
      "epoch": 0.9472295514511874,
      "grad_norm": 10.16466999053955,
      "learning_rate": 6.84476693051891e-05,
      "loss": 1.1621,
      "step": 1436
    },
    {
      "epoch": 0.9478891820580475,
      "grad_norm": 1.7888789176940918,
      "learning_rate": 6.842568161829376e-05,
      "loss": 0.0899,
      "step": 1437
    },
    {
      "epoch": 0.9485488126649076,
      "grad_norm": 17.859243392944336,
      "learning_rate": 6.840369393139842e-05,
      "loss": 0.9886,
      "step": 1438
    },
    {
      "epoch": 0.9492084432717678,
      "grad_norm": 0.4080580174922943,
      "learning_rate": 6.838170624450309e-05,
      "loss": 0.0531,
      "step": 1439
    },
    {
      "epoch": 0.9498680738786279,
      "grad_norm": 1.2268081903457642,
      "learning_rate": 6.835971855760774e-05,
      "loss": 0.1145,
      "step": 1440
    },
    {
      "epoch": 0.9505277044854882,
      "grad_norm": 12.4158935546875,
      "learning_rate": 6.83377308707124e-05,
      "loss": 0.5261,
      "step": 1441
    },
    {
      "epoch": 0.9511873350923483,
      "grad_norm": 1.244718313217163,
      "learning_rate": 6.831574318381706e-05,
      "loss": 0.0879,
      "step": 1442
    },
    {
      "epoch": 0.9518469656992085,
      "grad_norm": 1.0271930694580078,
      "learning_rate": 6.829375549692173e-05,
      "loss": 0.0946,
      "step": 1443
    },
    {
      "epoch": 0.9525065963060686,
      "grad_norm": 0.8243055939674377,
      "learning_rate": 6.827176781002638e-05,
      "loss": 0.074,
      "step": 1444
    },
    {
      "epoch": 0.9531662269129287,
      "grad_norm": 1.5701357126235962,
      "learning_rate": 6.824978012313104e-05,
      "loss": 0.1057,
      "step": 1445
    },
    {
      "epoch": 0.9538258575197889,
      "grad_norm": 3.764120101928711,
      "learning_rate": 6.822779243623571e-05,
      "loss": 0.1242,
      "step": 1446
    },
    {
      "epoch": 0.9544854881266491,
      "grad_norm": 9.869458198547363,
      "learning_rate": 6.820580474934037e-05,
      "loss": 0.7837,
      "step": 1447
    },
    {
      "epoch": 0.9551451187335093,
      "grad_norm": 14.509734153747559,
      "learning_rate": 6.818381706244503e-05,
      "loss": 0.9897,
      "step": 1448
    },
    {
      "epoch": 0.9558047493403694,
      "grad_norm": 10.812620162963867,
      "learning_rate": 6.81618293755497e-05,
      "loss": 0.3179,
      "step": 1449
    },
    {
      "epoch": 0.9564643799472295,
      "grad_norm": 17.704566955566406,
      "learning_rate": 6.813984168865435e-05,
      "loss": 0.7873,
      "step": 1450
    },
    {
      "epoch": 0.9571240105540897,
      "grad_norm": 10.876144409179688,
      "learning_rate": 6.811785400175902e-05,
      "loss": 0.3212,
      "step": 1451
    },
    {
      "epoch": 0.9577836411609498,
      "grad_norm": 1.9635539054870605,
      "learning_rate": 6.809586631486368e-05,
      "loss": 0.1162,
      "step": 1452
    },
    {
      "epoch": 0.9584432717678101,
      "grad_norm": 9.559569358825684,
      "learning_rate": 6.807387862796835e-05,
      "loss": 0.6431,
      "step": 1453
    },
    {
      "epoch": 0.9591029023746702,
      "grad_norm": 2.624593496322632,
      "learning_rate": 6.805189094107301e-05,
      "loss": 0.1664,
      "step": 1454
    },
    {
      "epoch": 0.9597625329815304,
      "grad_norm": 3.5027010440826416,
      "learning_rate": 6.802990325417767e-05,
      "loss": 0.2677,
      "step": 1455
    },
    {
      "epoch": 0.9604221635883905,
      "grad_norm": 0.5535932779312134,
      "learning_rate": 6.800791556728232e-05,
      "loss": 0.0775,
      "step": 1456
    },
    {
      "epoch": 0.9610817941952506,
      "grad_norm": 0.688014566898346,
      "learning_rate": 6.7985927880387e-05,
      "loss": 0.0641,
      "step": 1457
    },
    {
      "epoch": 0.9617414248021108,
      "grad_norm": 1.3058034181594849,
      "learning_rate": 6.796394019349165e-05,
      "loss": 0.0958,
      "step": 1458
    },
    {
      "epoch": 0.962401055408971,
      "grad_norm": 2.560743808746338,
      "learning_rate": 6.794195250659631e-05,
      "loss": 0.1772,
      "step": 1459
    },
    {
      "epoch": 0.9630606860158312,
      "grad_norm": 0.518740177154541,
      "learning_rate": 6.791996481970096e-05,
      "loss": 0.0614,
      "step": 1460
    },
    {
      "epoch": 0.9637203166226913,
      "grad_norm": 10.888813972473145,
      "learning_rate": 6.789797713280563e-05,
      "loss": 0.7751,
      "step": 1461
    },
    {
      "epoch": 0.9643799472295514,
      "grad_norm": 8.2644624710083,
      "learning_rate": 6.787598944591029e-05,
      "loss": 1.0889,
      "step": 1462
    },
    {
      "epoch": 0.9650395778364116,
      "grad_norm": 12.899700164794922,
      "learning_rate": 6.785400175901495e-05,
      "loss": 0.5416,
      "step": 1463
    },
    {
      "epoch": 0.9656992084432717,
      "grad_norm": 8.39379596710205,
      "learning_rate": 6.783201407211962e-05,
      "loss": 0.618,
      "step": 1464
    },
    {
      "epoch": 0.966358839050132,
      "grad_norm": 8.322723388671875,
      "learning_rate": 6.781002638522428e-05,
      "loss": 0.3678,
      "step": 1465
    },
    {
      "epoch": 0.9670184696569921,
      "grad_norm": 9.560200691223145,
      "learning_rate": 6.778803869832893e-05,
      "loss": 0.4369,
      "step": 1466
    },
    {
      "epoch": 0.9676781002638523,
      "grad_norm": 2.0044496059417725,
      "learning_rate": 6.776605101143359e-05,
      "loss": 0.1595,
      "step": 1467
    },
    {
      "epoch": 0.9683377308707124,
      "grad_norm": 2.792081117630005,
      "learning_rate": 6.774406332453826e-05,
      "loss": 0.1681,
      "step": 1468
    },
    {
      "epoch": 0.9689973614775725,
      "grad_norm": 0.9214077591896057,
      "learning_rate": 6.772207563764292e-05,
      "loss": 0.0994,
      "step": 1469
    },
    {
      "epoch": 0.9696569920844327,
      "grad_norm": 1.334612488746643,
      "learning_rate": 6.770008795074757e-05,
      "loss": 0.1524,
      "step": 1470
    },
    {
      "epoch": 0.9703166226912929,
      "grad_norm": 1.475476861000061,
      "learning_rate": 6.767810026385225e-05,
      "loss": 0.1815,
      "step": 1471
    },
    {
      "epoch": 0.9709762532981531,
      "grad_norm": 3.212242364883423,
      "learning_rate": 6.765611257695692e-05,
      "loss": 0.2127,
      "step": 1472
    },
    {
      "epoch": 0.9716358839050132,
      "grad_norm": 7.480788707733154,
      "learning_rate": 6.763412489006157e-05,
      "loss": 0.8529,
      "step": 1473
    },
    {
      "epoch": 0.9722955145118733,
      "grad_norm": 2.2733495235443115,
      "learning_rate": 6.761213720316623e-05,
      "loss": 0.1598,
      "step": 1474
    },
    {
      "epoch": 0.9729551451187335,
      "grad_norm": 3.984562397003174,
      "learning_rate": 6.75901495162709e-05,
      "loss": 0.2661,
      "step": 1475
    },
    {
      "epoch": 0.9736147757255936,
      "grad_norm": 1.6655969619750977,
      "learning_rate": 6.756816182937556e-05,
      "loss": 0.1472,
      "step": 1476
    },
    {
      "epoch": 0.9742744063324539,
      "grad_norm": 2.278970241546631,
      "learning_rate": 6.754617414248021e-05,
      "loss": 0.136,
      "step": 1477
    },
    {
      "epoch": 0.974934036939314,
      "grad_norm": 3.410001516342163,
      "learning_rate": 6.752418645558487e-05,
      "loss": 0.2405,
      "step": 1478
    },
    {
      "epoch": 0.9755936675461742,
      "grad_norm": 2.948889970779419,
      "learning_rate": 6.750219876868954e-05,
      "loss": 0.1313,
      "step": 1479
    },
    {
      "epoch": 0.9762532981530343,
      "grad_norm": 1.9612771272659302,
      "learning_rate": 6.74802110817942e-05,
      "loss": 0.1412,
      "step": 1480
    },
    {
      "epoch": 0.9769129287598944,
      "grad_norm": 12.548494338989258,
      "learning_rate": 6.745822339489886e-05,
      "loss": 0.631,
      "step": 1481
    },
    {
      "epoch": 0.9775725593667546,
      "grad_norm": 5.040074348449707,
      "learning_rate": 6.743623570800353e-05,
      "loss": 0.2605,
      "step": 1482
    },
    {
      "epoch": 0.9782321899736148,
      "grad_norm": 1.060186505317688,
      "learning_rate": 6.741424802110818e-05,
      "loss": 0.0922,
      "step": 1483
    },
    {
      "epoch": 0.978891820580475,
      "grad_norm": 6.864157676696777,
      "learning_rate": 6.739226033421284e-05,
      "loss": 0.311,
      "step": 1484
    },
    {
      "epoch": 0.9795514511873351,
      "grad_norm": 2.1307573318481445,
      "learning_rate": 6.73702726473175e-05,
      "loss": 0.1292,
      "step": 1485
    },
    {
      "epoch": 0.9802110817941952,
      "grad_norm": 1.1524978876113892,
      "learning_rate": 6.734828496042217e-05,
      "loss": 0.1352,
      "step": 1486
    },
    {
      "epoch": 0.9808707124010554,
      "grad_norm": 1.9336726665496826,
      "learning_rate": 6.732629727352682e-05,
      "loss": 0.2072,
      "step": 1487
    },
    {
      "epoch": 0.9815303430079155,
      "grad_norm": 1.9258157014846802,
      "learning_rate": 6.730430958663148e-05,
      "loss": 0.1504,
      "step": 1488
    },
    {
      "epoch": 0.9821899736147758,
      "grad_norm": 3.2280192375183105,
      "learning_rate": 6.728232189973615e-05,
      "loss": 0.1399,
      "step": 1489
    },
    {
      "epoch": 0.9828496042216359,
      "grad_norm": 4.712566375732422,
      "learning_rate": 6.726033421284081e-05,
      "loss": 0.293,
      "step": 1490
    },
    {
      "epoch": 0.9835092348284961,
      "grad_norm": 1.3892525434494019,
      "learning_rate": 6.723834652594547e-05,
      "loss": 0.1241,
      "step": 1491
    },
    {
      "epoch": 0.9841688654353562,
      "grad_norm": 1.191867470741272,
      "learning_rate": 6.721635883905014e-05,
      "loss": 0.0996,
      "step": 1492
    },
    {
      "epoch": 0.9848284960422163,
      "grad_norm": 3.2587718963623047,
      "learning_rate": 6.71943711521548e-05,
      "loss": 0.2404,
      "step": 1493
    },
    {
      "epoch": 0.9854881266490765,
      "grad_norm": 1.0475373268127441,
      "learning_rate": 6.717238346525946e-05,
      "loss": 0.1147,
      "step": 1494
    },
    {
      "epoch": 0.9861477572559367,
      "grad_norm": 1.3513569831848145,
      "learning_rate": 6.715039577836412e-05,
      "loss": 0.0984,
      "step": 1495
    },
    {
      "epoch": 0.9868073878627969,
      "grad_norm": 7.677353858947754,
      "learning_rate": 6.712840809146878e-05,
      "loss": 0.268,
      "step": 1496
    },
    {
      "epoch": 0.987467018469657,
      "grad_norm": 8.097137451171875,
      "learning_rate": 6.710642040457345e-05,
      "loss": 0.3119,
      "step": 1497
    },
    {
      "epoch": 0.9881266490765171,
      "grad_norm": 6.218151569366455,
      "learning_rate": 6.70844327176781e-05,
      "loss": 0.2333,
      "step": 1498
    },
    {
      "epoch": 0.9887862796833773,
      "grad_norm": 2.4671053886413574,
      "learning_rate": 6.706244503078276e-05,
      "loss": 0.125,
      "step": 1499
    },
    {
      "epoch": 0.9894459102902374,
      "grad_norm": 9.668359756469727,
      "learning_rate": 6.704045734388743e-05,
      "loss": 0.4691,
      "step": 1500
    },
    {
      "epoch": 0.9901055408970977,
      "grad_norm": 11.276871681213379,
      "learning_rate": 6.701846965699209e-05,
      "loss": 0.6571,
      "step": 1501
    },
    {
      "epoch": 0.9907651715039578,
      "grad_norm": 4.616742134094238,
      "learning_rate": 6.699648197009675e-05,
      "loss": 0.2581,
      "step": 1502
    },
    {
      "epoch": 0.991424802110818,
      "grad_norm": 16.94306755065918,
      "learning_rate": 6.69744942832014e-05,
      "loss": 1.9458,
      "step": 1503
    },
    {
      "epoch": 0.9920844327176781,
      "grad_norm": 10.752487182617188,
      "learning_rate": 6.695250659630607e-05,
      "loss": 1.395,
      "step": 1504
    },
    {
      "epoch": 0.9927440633245382,
      "grad_norm": 3.353755474090576,
      "learning_rate": 6.693051890941073e-05,
      "loss": 0.2281,
      "step": 1505
    },
    {
      "epoch": 0.9934036939313984,
      "grad_norm": 1.7550222873687744,
      "learning_rate": 6.690853122251539e-05,
      "loss": 0.1397,
      "step": 1506
    },
    {
      "epoch": 0.9940633245382586,
      "grad_norm": 2.267163038253784,
      "learning_rate": 6.688654353562006e-05,
      "loss": 0.1605,
      "step": 1507
    },
    {
      "epoch": 0.9947229551451188,
      "grad_norm": 1.2815767526626587,
      "learning_rate": 6.686455584872472e-05,
      "loss": 0.1511,
      "step": 1508
    },
    {
      "epoch": 0.9953825857519789,
      "grad_norm": 0.7788172960281372,
      "learning_rate": 6.684256816182937e-05,
      "loss": 0.0566,
      "step": 1509
    },
    {
      "epoch": 0.996042216358839,
      "grad_norm": 0.5057218670845032,
      "learning_rate": 6.682058047493403e-05,
      "loss": 0.0682,
      "step": 1510
    },
    {
      "epoch": 0.9967018469656992,
      "grad_norm": 3.1654469966888428,
      "learning_rate": 6.67985927880387e-05,
      "loss": 0.2274,
      "step": 1511
    },
    {
      "epoch": 0.9973614775725593,
      "grad_norm": 8.347930908203125,
      "learning_rate": 6.677660510114336e-05,
      "loss": 1.1304,
      "step": 1512
    },
    {
      "epoch": 0.9980211081794196,
      "grad_norm": 4.7719621658325195,
      "learning_rate": 6.675461741424803e-05,
      "loss": 0.3275,
      "step": 1513
    },
    {
      "epoch": 0.9986807387862797,
      "grad_norm": 5.818892478942871,
      "learning_rate": 6.673262972735269e-05,
      "loss": 0.3219,
      "step": 1514
    },
    {
      "epoch": 0.9993403693931399,
      "grad_norm": 8.373933792114258,
      "learning_rate": 6.671064204045736e-05,
      "loss": 0.728,
      "step": 1515
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.753194272518158,
      "learning_rate": 6.668865435356201e-05,
      "loss": 0.0812,
      "step": 1516
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8527131782945736,
      "eval_f1": 0.8395102147721321,
      "eval_keras_BCE": 0.41633373498916626,
      "eval_loss": 0.42882341146469116,
      "eval_precision": 0.8089653874727406,
      "eval_recall": 0.8295454545454546,
      "eval_runtime": 3.9185,
      "eval_samples_per_second": 65.842,
      "eval_steps_per_second": 8.422,
      "eval_weighted BCE": 27.300519943237305,
      "step": 1516
    },
    {
      "epoch": 1.0006596306068603,
      "grad_norm": 6.005941867828369,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.298,
      "step": 1517
    },
    {
      "epoch": 1.0013192612137203,
      "grad_norm": 10.324078559875488,
      "learning_rate": 6.664467897977134e-05,
      "loss": 0.8087,
      "step": 1518
    },
    {
      "epoch": 1.0019788918205805,
      "grad_norm": 8.282354354858398,
      "learning_rate": 6.6622691292876e-05,
      "loss": 0.5012,
      "step": 1519
    },
    {
      "epoch": 1.0026385224274406,
      "grad_norm": 1.6567167043685913,
      "learning_rate": 6.660070360598065e-05,
      "loss": 0.1453,
      "step": 1520
    },
    {
      "epoch": 1.0032981530343008,
      "grad_norm": 2.9794583320617676,
      "learning_rate": 6.657871591908531e-05,
      "loss": 0.196,
      "step": 1521
    },
    {
      "epoch": 1.003957783641161,
      "grad_norm": 3.460114002227783,
      "learning_rate": 6.655672823218998e-05,
      "loss": 0.21,
      "step": 1522
    },
    {
      "epoch": 1.004617414248021,
      "grad_norm": 1.077682614326477,
      "learning_rate": 6.653474054529464e-05,
      "loss": 0.0973,
      "step": 1523
    },
    {
      "epoch": 1.0052770448548813,
      "grad_norm": 3.100623369216919,
      "learning_rate": 6.65127528583993e-05,
      "loss": 0.225,
      "step": 1524
    },
    {
      "epoch": 1.0059366754617414,
      "grad_norm": 11.174463272094727,
      "learning_rate": 6.649076517150397e-05,
      "loss": 0.5977,
      "step": 1525
    },
    {
      "epoch": 1.0065963060686016,
      "grad_norm": 0.7800473570823669,
      "learning_rate": 6.646877748460862e-05,
      "loss": 0.0823,
      "step": 1526
    },
    {
      "epoch": 1.0072559366754616,
      "grad_norm": 1.3491169214248657,
      "learning_rate": 6.644678979771328e-05,
      "loss": 0.1407,
      "step": 1527
    },
    {
      "epoch": 1.007915567282322,
      "grad_norm": 1.167577862739563,
      "learning_rate": 6.642480211081794e-05,
      "loss": 0.0834,
      "step": 1528
    },
    {
      "epoch": 1.0085751978891822,
      "grad_norm": 1.2533177137374878,
      "learning_rate": 6.640281442392261e-05,
      "loss": 0.094,
      "step": 1529
    },
    {
      "epoch": 1.0092348284960422,
      "grad_norm": 10.096944808959961,
      "learning_rate": 6.638082673702726e-05,
      "loss": 0.6558,
      "step": 1530
    },
    {
      "epoch": 1.0098944591029024,
      "grad_norm": 1.2886254787445068,
      "learning_rate": 6.635883905013192e-05,
      "loss": 0.0776,
      "step": 1531
    },
    {
      "epoch": 1.0105540897097625,
      "grad_norm": 10.714937210083008,
      "learning_rate": 6.633685136323659e-05,
      "loss": 0.9363,
      "step": 1532
    },
    {
      "epoch": 1.0112137203166227,
      "grad_norm": 23.84467887878418,
      "learning_rate": 6.631486367634125e-05,
      "loss": 1.2469,
      "step": 1533
    },
    {
      "epoch": 1.0118733509234827,
      "grad_norm": 2.294039487838745,
      "learning_rate": 6.62928759894459e-05,
      "loss": 0.101,
      "step": 1534
    },
    {
      "epoch": 1.012532981530343,
      "grad_norm": 2.405776023864746,
      "learning_rate": 6.627088830255058e-05,
      "loss": 0.1033,
      "step": 1535
    },
    {
      "epoch": 1.0131926121372032,
      "grad_norm": 19.32217788696289,
      "learning_rate": 6.624890061565523e-05,
      "loss": 0.865,
      "step": 1536
    },
    {
      "epoch": 1.0138522427440633,
      "grad_norm": 9.3198881149292,
      "learning_rate": 6.62269129287599e-05,
      "loss": 0.5372,
      "step": 1537
    },
    {
      "epoch": 1.0145118733509235,
      "grad_norm": 10.91188907623291,
      "learning_rate": 6.620492524186456e-05,
      "loss": 0.3797,
      "step": 1538
    },
    {
      "epoch": 1.0151715039577835,
      "grad_norm": 1.1451669931411743,
      "learning_rate": 6.618293755496922e-05,
      "loss": 0.078,
      "step": 1539
    },
    {
      "epoch": 1.0158311345646438,
      "grad_norm": 5.592898368835449,
      "learning_rate": 6.616094986807389e-05,
      "loss": 0.4153,
      "step": 1540
    },
    {
      "epoch": 1.016490765171504,
      "grad_norm": 0.7959641218185425,
      "learning_rate": 6.613896218117855e-05,
      "loss": 0.0596,
      "step": 1541
    },
    {
      "epoch": 1.017150395778364,
      "grad_norm": 1.5662912130355835,
      "learning_rate": 6.61169744942832e-05,
      "loss": 0.1115,
      "step": 1542
    },
    {
      "epoch": 1.0178100263852243,
      "grad_norm": 1.5152548551559448,
      "learning_rate": 6.609498680738787e-05,
      "loss": 0.0961,
      "step": 1543
    },
    {
      "epoch": 1.0184696569920844,
      "grad_norm": 5.637574672698975,
      "learning_rate": 6.607299912049253e-05,
      "loss": 0.3347,
      "step": 1544
    },
    {
      "epoch": 1.0191292875989446,
      "grad_norm": 2.3233823776245117,
      "learning_rate": 6.605101143359719e-05,
      "loss": 0.1386,
      "step": 1545
    },
    {
      "epoch": 1.0197889182058049,
      "grad_norm": 1.112757682800293,
      "learning_rate": 6.602902374670184e-05,
      "loss": 0.0926,
      "step": 1546
    },
    {
      "epoch": 1.020448548812665,
      "grad_norm": 1.463062047958374,
      "learning_rate": 6.600703605980651e-05,
      "loss": 0.0965,
      "step": 1547
    },
    {
      "epoch": 1.0211081794195251,
      "grad_norm": 0.7482707500457764,
      "learning_rate": 6.598504837291117e-05,
      "loss": 0.0539,
      "step": 1548
    },
    {
      "epoch": 1.0217678100263852,
      "grad_norm": 8.640124320983887,
      "learning_rate": 6.596306068601583e-05,
      "loss": 0.3134,
      "step": 1549
    },
    {
      "epoch": 1.0224274406332454,
      "grad_norm": 7.44297981262207,
      "learning_rate": 6.59410729991205e-05,
      "loss": 0.6153,
      "step": 1550
    },
    {
      "epoch": 1.0230870712401055,
      "grad_norm": 1.4148476123809814,
      "learning_rate": 6.591908531222516e-05,
      "loss": 0.1135,
      "step": 1551
    },
    {
      "epoch": 1.0237467018469657,
      "grad_norm": 0.5712911486625671,
      "learning_rate": 6.589709762532981e-05,
      "loss": 0.0484,
      "step": 1552
    },
    {
      "epoch": 1.024406332453826,
      "grad_norm": 0.5428562164306641,
      "learning_rate": 6.587510993843447e-05,
      "loss": 0.0398,
      "step": 1553
    },
    {
      "epoch": 1.025065963060686,
      "grad_norm": 1.4042888879776,
      "learning_rate": 6.585312225153914e-05,
      "loss": 0.0967,
      "step": 1554
    },
    {
      "epoch": 1.0257255936675462,
      "grad_norm": 2.648336172103882,
      "learning_rate": 6.58311345646438e-05,
      "loss": 0.1137,
      "step": 1555
    },
    {
      "epoch": 1.0263852242744063,
      "grad_norm": 12.126225471496582,
      "learning_rate": 6.580914687774847e-05,
      "loss": 1.1791,
      "step": 1556
    },
    {
      "epoch": 1.0270448548812665,
      "grad_norm": 0.6123808026313782,
      "learning_rate": 6.578715919085313e-05,
      "loss": 0.0346,
      "step": 1557
    },
    {
      "epoch": 1.0277044854881265,
      "grad_norm": 8.796405792236328,
      "learning_rate": 6.57651715039578e-05,
      "loss": 0.6972,
      "step": 1558
    },
    {
      "epoch": 1.0283641160949868,
      "grad_norm": 16.142414093017578,
      "learning_rate": 6.574318381706245e-05,
      "loss": 0.912,
      "step": 1559
    },
    {
      "epoch": 1.029023746701847,
      "grad_norm": 8.006193161010742,
      "learning_rate": 6.572119613016711e-05,
      "loss": 0.2835,
      "step": 1560
    },
    {
      "epoch": 1.029683377308707,
      "grad_norm": 16.182645797729492,
      "learning_rate": 6.569920844327178e-05,
      "loss": 0.4437,
      "step": 1561
    },
    {
      "epoch": 1.0303430079155673,
      "grad_norm": 6.822657108306885,
      "learning_rate": 6.567722075637644e-05,
      "loss": 0.3285,
      "step": 1562
    },
    {
      "epoch": 1.0310026385224274,
      "grad_norm": 1.0354825258255005,
      "learning_rate": 6.56552330694811e-05,
      "loss": 0.061,
      "step": 1563
    },
    {
      "epoch": 1.0316622691292876,
      "grad_norm": 6.232332706451416,
      "learning_rate": 6.563324538258575e-05,
      "loss": 0.7785,
      "step": 1564
    },
    {
      "epoch": 1.0323218997361479,
      "grad_norm": 5.950839042663574,
      "learning_rate": 6.561125769569042e-05,
      "loss": 0.2661,
      "step": 1565
    },
    {
      "epoch": 1.0329815303430079,
      "grad_norm": 13.13437271118164,
      "learning_rate": 6.558927000879508e-05,
      "loss": 0.735,
      "step": 1566
    },
    {
      "epoch": 1.0336411609498681,
      "grad_norm": 5.097231388092041,
      "learning_rate": 6.556728232189974e-05,
      "loss": 0.2764,
      "step": 1567
    },
    {
      "epoch": 1.0343007915567282,
      "grad_norm": 3.6611664295196533,
      "learning_rate": 6.55452946350044e-05,
      "loss": 0.146,
      "step": 1568
    },
    {
      "epoch": 1.0349604221635884,
      "grad_norm": 5.516593933105469,
      "learning_rate": 6.552330694810906e-05,
      "loss": 0.4151,
      "step": 1569
    },
    {
      "epoch": 1.0356200527704487,
      "grad_norm": 7.23544979095459,
      "learning_rate": 6.550131926121372e-05,
      "loss": 0.3528,
      "step": 1570
    },
    {
      "epoch": 1.0362796833773087,
      "grad_norm": 3.052121162414551,
      "learning_rate": 6.547933157431838e-05,
      "loss": 0.2177,
      "step": 1571
    },
    {
      "epoch": 1.036939313984169,
      "grad_norm": 4.441710472106934,
      "learning_rate": 6.545734388742305e-05,
      "loss": 0.2543,
      "step": 1572
    },
    {
      "epoch": 1.037598944591029,
      "grad_norm": 1.1120246648788452,
      "learning_rate": 6.54353562005277e-05,
      "loss": 0.1262,
      "step": 1573
    },
    {
      "epoch": 1.0382585751978892,
      "grad_norm": 8.532105445861816,
      "learning_rate": 6.541336851363236e-05,
      "loss": 0.5302,
      "step": 1574
    },
    {
      "epoch": 1.0389182058047493,
      "grad_norm": 2.3214147090911865,
      "learning_rate": 6.539138082673702e-05,
      "loss": 0.1495,
      "step": 1575
    },
    {
      "epoch": 1.0395778364116095,
      "grad_norm": 1.8826117515563965,
      "learning_rate": 6.536939313984169e-05,
      "loss": 0.2525,
      "step": 1576
    },
    {
      "epoch": 1.0402374670184698,
      "grad_norm": 1.336829423904419,
      "learning_rate": 6.534740545294636e-05,
      "loss": 0.1411,
      "step": 1577
    },
    {
      "epoch": 1.0408970976253298,
      "grad_norm": 2.2942943572998047,
      "learning_rate": 6.532541776605102e-05,
      "loss": 0.2351,
      "step": 1578
    },
    {
      "epoch": 1.04155672823219,
      "grad_norm": 3.072681188583374,
      "learning_rate": 6.530343007915569e-05,
      "loss": 0.2253,
      "step": 1579
    },
    {
      "epoch": 1.04221635883905,
      "grad_norm": 8.024415016174316,
      "learning_rate": 6.528144239226034e-05,
      "loss": 0.708,
      "step": 1580
    },
    {
      "epoch": 1.0428759894459103,
      "grad_norm": 0.782034695148468,
      "learning_rate": 6.5259454705365e-05,
      "loss": 0.0843,
      "step": 1581
    },
    {
      "epoch": 1.0435356200527703,
      "grad_norm": 4.053256988525391,
      "learning_rate": 6.523746701846966e-05,
      "loss": 0.2713,
      "step": 1582
    },
    {
      "epoch": 1.0441952506596306,
      "grad_norm": 1.4640785455703735,
      "learning_rate": 6.521547933157433e-05,
      "loss": 0.1187,
      "step": 1583
    },
    {
      "epoch": 1.0448548812664908,
      "grad_norm": 1.9294894933700562,
      "learning_rate": 6.519349164467899e-05,
      "loss": 0.1547,
      "step": 1584
    },
    {
      "epoch": 1.0455145118733509,
      "grad_norm": 2.7074666023254395,
      "learning_rate": 6.517150395778364e-05,
      "loss": 0.2649,
      "step": 1585
    },
    {
      "epoch": 1.0461741424802111,
      "grad_norm": 0.7509909272193909,
      "learning_rate": 6.514951627088831e-05,
      "loss": 0.0788,
      "step": 1586
    },
    {
      "epoch": 1.0468337730870712,
      "grad_norm": 0.8507603406906128,
      "learning_rate": 6.512752858399297e-05,
      "loss": 0.0781,
      "step": 1587
    },
    {
      "epoch": 1.0474934036939314,
      "grad_norm": 1.1885632276535034,
      "learning_rate": 6.510554089709763e-05,
      "loss": 0.1042,
      "step": 1588
    },
    {
      "epoch": 1.0481530343007917,
      "grad_norm": 0.6675496697425842,
      "learning_rate": 6.508355321020228e-05,
      "loss": 0.0717,
      "step": 1589
    },
    {
      "epoch": 1.0488126649076517,
      "grad_norm": 4.588112831115723,
      "learning_rate": 6.506156552330695e-05,
      "loss": 0.2591,
      "step": 1590
    },
    {
      "epoch": 1.049472295514512,
      "grad_norm": 5.417587757110596,
      "learning_rate": 6.503957783641161e-05,
      "loss": 0.2676,
      "step": 1591
    },
    {
      "epoch": 1.050131926121372,
      "grad_norm": 0.7481096386909485,
      "learning_rate": 6.501759014951627e-05,
      "loss": 0.0375,
      "step": 1592
    },
    {
      "epoch": 1.0507915567282322,
      "grad_norm": 8.994463920593262,
      "learning_rate": 6.499560246262093e-05,
      "loss": 0.2606,
      "step": 1593
    },
    {
      "epoch": 1.0514511873350922,
      "grad_norm": 0.8514439463615417,
      "learning_rate": 6.49736147757256e-05,
      "loss": 0.0371,
      "step": 1594
    },
    {
      "epoch": 1.0521108179419525,
      "grad_norm": 1.7756966352462769,
      "learning_rate": 6.495162708883025e-05,
      "loss": 0.0736,
      "step": 1595
    },
    {
      "epoch": 1.0527704485488127,
      "grad_norm": 1.0307620763778687,
      "learning_rate": 6.492963940193491e-05,
      "loss": 0.0645,
      "step": 1596
    },
    {
      "epoch": 1.0534300791556728,
      "grad_norm": 3.2814760208129883,
      "learning_rate": 6.490765171503958e-05,
      "loss": 0.1408,
      "step": 1597
    },
    {
      "epoch": 1.054089709762533,
      "grad_norm": 15.83477783203125,
      "learning_rate": 6.488566402814424e-05,
      "loss": 0.9011,
      "step": 1598
    },
    {
      "epoch": 1.054749340369393,
      "grad_norm": 5.224952697753906,
      "learning_rate": 6.486367634124891e-05,
      "loss": 0.1303,
      "step": 1599
    },
    {
      "epoch": 1.0554089709762533,
      "grad_norm": 0.8127080798149109,
      "learning_rate": 6.484168865435357e-05,
      "loss": 0.0544,
      "step": 1600
    },
    {
      "epoch": 1.0560686015831136,
      "grad_norm": 17.507831573486328,
      "learning_rate": 6.481970096745824e-05,
      "loss": 0.5876,
      "step": 1601
    },
    {
      "epoch": 1.0567282321899736,
      "grad_norm": 7.063808441162109,
      "learning_rate": 6.479771328056289e-05,
      "loss": 0.1893,
      "step": 1602
    },
    {
      "epoch": 1.0573878627968338,
      "grad_norm": 0.6225051879882812,
      "learning_rate": 6.477572559366755e-05,
      "loss": 0.073,
      "step": 1603
    },
    {
      "epoch": 1.0580474934036939,
      "grad_norm": 6.54349946975708,
      "learning_rate": 6.475373790677222e-05,
      "loss": 0.2232,
      "step": 1604
    },
    {
      "epoch": 1.0587071240105541,
      "grad_norm": 14.040131568908691,
      "learning_rate": 6.473175021987688e-05,
      "loss": 0.5635,
      "step": 1605
    },
    {
      "epoch": 1.0593667546174141,
      "grad_norm": 2.387244939804077,
      "learning_rate": 6.470976253298153e-05,
      "loss": 0.1352,
      "step": 1606
    },
    {
      "epoch": 1.0600263852242744,
      "grad_norm": 5.416718006134033,
      "learning_rate": 6.468777484608619e-05,
      "loss": 0.1841,
      "step": 1607
    },
    {
      "epoch": 1.0606860158311346,
      "grad_norm": 1.2518543004989624,
      "learning_rate": 6.466578715919086e-05,
      "loss": 0.0666,
      "step": 1608
    },
    {
      "epoch": 1.0613456464379947,
      "grad_norm": 1.3539800643920898,
      "learning_rate": 6.464379947229552e-05,
      "loss": 0.0871,
      "step": 1609
    },
    {
      "epoch": 1.062005277044855,
      "grad_norm": 1.7303061485290527,
      "learning_rate": 6.462181178540018e-05,
      "loss": 0.1296,
      "step": 1610
    },
    {
      "epoch": 1.062664907651715,
      "grad_norm": 0.2520149052143097,
      "learning_rate": 6.459982409850483e-05,
      "loss": 0.0295,
      "step": 1611
    },
    {
      "epoch": 1.0633245382585752,
      "grad_norm": 0.6636674404144287,
      "learning_rate": 6.45778364116095e-05,
      "loss": 0.0665,
      "step": 1612
    },
    {
      "epoch": 1.0639841688654355,
      "grad_norm": 1.1077919006347656,
      "learning_rate": 6.455584872471416e-05,
      "loss": 0.0946,
      "step": 1613
    },
    {
      "epoch": 1.0646437994722955,
      "grad_norm": 9.76638412475586,
      "learning_rate": 6.453386103781882e-05,
      "loss": 0.3874,
      "step": 1614
    },
    {
      "epoch": 1.0653034300791557,
      "grad_norm": 2.8747053146362305,
      "learning_rate": 6.451187335092349e-05,
      "loss": 0.1344,
      "step": 1615
    },
    {
      "epoch": 1.0659630606860158,
      "grad_norm": 2.346390724182129,
      "learning_rate": 6.448988566402814e-05,
      "loss": 0.13,
      "step": 1616
    },
    {
      "epoch": 1.066622691292876,
      "grad_norm": 7.559685707092285,
      "learning_rate": 6.44678979771328e-05,
      "loss": 0.4165,
      "step": 1617
    },
    {
      "epoch": 1.0672823218997363,
      "grad_norm": 0.522461473941803,
      "learning_rate": 6.444591029023747e-05,
      "loss": 0.0371,
      "step": 1618
    },
    {
      "epoch": 1.0679419525065963,
      "grad_norm": 11.140466690063477,
      "learning_rate": 6.442392260334213e-05,
      "loss": 0.6054,
      "step": 1619
    },
    {
      "epoch": 1.0686015831134565,
      "grad_norm": 5.682263374328613,
      "learning_rate": 6.44019349164468e-05,
      "loss": 0.1523,
      "step": 1620
    },
    {
      "epoch": 1.0692612137203166,
      "grad_norm": 17.95514488220215,
      "learning_rate": 6.437994722955146e-05,
      "loss": 1.4299,
      "step": 1621
    },
    {
      "epoch": 1.0699208443271768,
      "grad_norm": 6.082357883453369,
      "learning_rate": 6.435795954265613e-05,
      "loss": 0.1914,
      "step": 1622
    },
    {
      "epoch": 1.0705804749340369,
      "grad_norm": 14.097248077392578,
      "learning_rate": 6.433597185576078e-05,
      "loss": 0.7901,
      "step": 1623
    },
    {
      "epoch": 1.071240105540897,
      "grad_norm": 12.715086936950684,
      "learning_rate": 6.431398416886544e-05,
      "loss": 0.8403,
      "step": 1624
    },
    {
      "epoch": 1.0718997361477574,
      "grad_norm": 1.0159209966659546,
      "learning_rate": 6.42919964819701e-05,
      "loss": 0.051,
      "step": 1625
    },
    {
      "epoch": 1.0725593667546174,
      "grad_norm": 9.564268112182617,
      "learning_rate": 6.427000879507477e-05,
      "loss": 0.5608,
      "step": 1626
    },
    {
      "epoch": 1.0732189973614776,
      "grad_norm": 1.4073634147644043,
      "learning_rate": 6.424802110817943e-05,
      "loss": 0.0993,
      "step": 1627
    },
    {
      "epoch": 1.0738786279683377,
      "grad_norm": 2.030972957611084,
      "learning_rate": 6.422603342128408e-05,
      "loss": 0.1654,
      "step": 1628
    },
    {
      "epoch": 1.074538258575198,
      "grad_norm": 1.8813432455062866,
      "learning_rate": 6.420404573438874e-05,
      "loss": 0.1477,
      "step": 1629
    },
    {
      "epoch": 1.075197889182058,
      "grad_norm": 0.7364142537117004,
      "learning_rate": 6.418205804749341e-05,
      "loss": 0.0589,
      "step": 1630
    },
    {
      "epoch": 1.0758575197889182,
      "grad_norm": 2.2094833850860596,
      "learning_rate": 6.416007036059807e-05,
      "loss": 0.151,
      "step": 1631
    },
    {
      "epoch": 1.0765171503957784,
      "grad_norm": 1.6332944631576538,
      "learning_rate": 6.413808267370272e-05,
      "loss": 0.1343,
      "step": 1632
    },
    {
      "epoch": 1.0771767810026385,
      "grad_norm": 2.318570852279663,
      "learning_rate": 6.41160949868074e-05,
      "loss": 0.1332,
      "step": 1633
    },
    {
      "epoch": 1.0778364116094987,
      "grad_norm": 1.5523681640625,
      "learning_rate": 6.409410729991205e-05,
      "loss": 0.1237,
      "step": 1634
    },
    {
      "epoch": 1.0784960422163588,
      "grad_norm": 1.4637542963027954,
      "learning_rate": 6.407211961301671e-05,
      "loss": 0.1175,
      "step": 1635
    },
    {
      "epoch": 1.079155672823219,
      "grad_norm": 1.2481036186218262,
      "learning_rate": 6.405013192612137e-05,
      "loss": 0.1004,
      "step": 1636
    },
    {
      "epoch": 1.0798153034300793,
      "grad_norm": 9.221869468688965,
      "learning_rate": 6.402814423922604e-05,
      "loss": 0.1465,
      "step": 1637
    },
    {
      "epoch": 1.0804749340369393,
      "grad_norm": 7.877054214477539,
      "learning_rate": 6.400615655233069e-05,
      "loss": 0.7413,
      "step": 1638
    },
    {
      "epoch": 1.0811345646437995,
      "grad_norm": 10.193158149719238,
      "learning_rate": 6.398416886543535e-05,
      "loss": 0.3246,
      "step": 1639
    },
    {
      "epoch": 1.0817941952506596,
      "grad_norm": 8.405776977539062,
      "learning_rate": 6.396218117854002e-05,
      "loss": 1.5695,
      "step": 1640
    },
    {
      "epoch": 1.0824538258575198,
      "grad_norm": 1.873153805732727,
      "learning_rate": 6.394019349164468e-05,
      "loss": 0.1009,
      "step": 1641
    },
    {
      "epoch": 1.08311345646438,
      "grad_norm": 17.941913604736328,
      "learning_rate": 6.391820580474935e-05,
      "loss": 1.2267,
      "step": 1642
    },
    {
      "epoch": 1.08377308707124,
      "grad_norm": 20.51212501525879,
      "learning_rate": 6.3896218117854e-05,
      "loss": 2.153,
      "step": 1643
    },
    {
      "epoch": 1.0844327176781003,
      "grad_norm": 1.0359495878219604,
      "learning_rate": 6.387423043095868e-05,
      "loss": 0.06,
      "step": 1644
    },
    {
      "epoch": 1.0850923482849604,
      "grad_norm": 14.033687591552734,
      "learning_rate": 6.385224274406333e-05,
      "loss": 0.7213,
      "step": 1645
    },
    {
      "epoch": 1.0857519788918206,
      "grad_norm": 0.8462348580360413,
      "learning_rate": 6.383025505716799e-05,
      "loss": 0.046,
      "step": 1646
    },
    {
      "epoch": 1.0864116094986807,
      "grad_norm": 3.991656541824341,
      "learning_rate": 6.380826737027265e-05,
      "loss": 0.2774,
      "step": 1647
    },
    {
      "epoch": 1.087071240105541,
      "grad_norm": 7.71230936050415,
      "learning_rate": 6.378627968337732e-05,
      "loss": 0.8465,
      "step": 1648
    },
    {
      "epoch": 1.0877308707124012,
      "grad_norm": 2.9688241481781006,
      "learning_rate": 6.376429199648197e-05,
      "loss": 0.111,
      "step": 1649
    },
    {
      "epoch": 1.0883905013192612,
      "grad_norm": 1.1626635789871216,
      "learning_rate": 6.374230430958663e-05,
      "loss": 0.0957,
      "step": 1650
    },
    {
      "epoch": 1.0890501319261214,
      "grad_norm": 4.941929340362549,
      "learning_rate": 6.37203166226913e-05,
      "loss": 0.2564,
      "step": 1651
    },
    {
      "epoch": 1.0897097625329815,
      "grad_norm": 0.7568073272705078,
      "learning_rate": 6.369832893579596e-05,
      "loss": 0.0881,
      "step": 1652
    },
    {
      "epoch": 1.0903693931398417,
      "grad_norm": 1.2747069597244263,
      "learning_rate": 6.367634124890062e-05,
      "loss": 0.081,
      "step": 1653
    },
    {
      "epoch": 1.0910290237467017,
      "grad_norm": 0.7332210540771484,
      "learning_rate": 6.365435356200527e-05,
      "loss": 0.0976,
      "step": 1654
    },
    {
      "epoch": 1.091688654353562,
      "grad_norm": 1.2203267812728882,
      "learning_rate": 6.363236587510994e-05,
      "loss": 0.0833,
      "step": 1655
    },
    {
      "epoch": 1.0923482849604222,
      "grad_norm": 5.9018874168396,
      "learning_rate": 6.36103781882146e-05,
      "loss": 0.2245,
      "step": 1656
    },
    {
      "epoch": 1.0930079155672823,
      "grad_norm": 0.7762752175331116,
      "learning_rate": 6.358839050131926e-05,
      "loss": 0.0724,
      "step": 1657
    },
    {
      "epoch": 1.0936675461741425,
      "grad_norm": 1.286258339881897,
      "learning_rate": 6.356640281442393e-05,
      "loss": 0.1134,
      "step": 1658
    },
    {
      "epoch": 1.0943271767810026,
      "grad_norm": 7.1245927810668945,
      "learning_rate": 6.354441512752858e-05,
      "loss": 0.766,
      "step": 1659
    },
    {
      "epoch": 1.0949868073878628,
      "grad_norm": 2.447103977203369,
      "learning_rate": 6.352242744063324e-05,
      "loss": 0.1945,
      "step": 1660
    },
    {
      "epoch": 1.095646437994723,
      "grad_norm": 1.2115763425827026,
      "learning_rate": 6.350043975373791e-05,
      "loss": 0.1014,
      "step": 1661
    },
    {
      "epoch": 1.096306068601583,
      "grad_norm": 1.4450730085372925,
      "learning_rate": 6.347845206684257e-05,
      "loss": 0.0843,
      "step": 1662
    },
    {
      "epoch": 1.0969656992084433,
      "grad_norm": 2.414966344833374,
      "learning_rate": 6.345646437994724e-05,
      "loss": 0.1916,
      "step": 1663
    },
    {
      "epoch": 1.0976253298153034,
      "grad_norm": 1.9009560346603394,
      "learning_rate": 6.34344766930519e-05,
      "loss": 0.1866,
      "step": 1664
    },
    {
      "epoch": 1.0982849604221636,
      "grad_norm": 1.3612680435180664,
      "learning_rate": 6.341248900615655e-05,
      "loss": 0.0908,
      "step": 1665
    },
    {
      "epoch": 1.0989445910290236,
      "grad_norm": 8.596550941467285,
      "learning_rate": 6.339050131926122e-05,
      "loss": 0.4794,
      "step": 1666
    },
    {
      "epoch": 1.099604221635884,
      "grad_norm": 8.04526138305664,
      "learning_rate": 6.336851363236588e-05,
      "loss": 0.5133,
      "step": 1667
    },
    {
      "epoch": 1.1002638522427441,
      "grad_norm": 0.9859448671340942,
      "learning_rate": 6.334652594547054e-05,
      "loss": 0.091,
      "step": 1668
    },
    {
      "epoch": 1.1009234828496042,
      "grad_norm": 7.107202053070068,
      "learning_rate": 6.332453825857521e-05,
      "loss": 0.2827,
      "step": 1669
    },
    {
      "epoch": 1.1015831134564644,
      "grad_norm": 10.622777938842773,
      "learning_rate": 6.330255057167987e-05,
      "loss": 0.3558,
      "step": 1670
    },
    {
      "epoch": 1.1022427440633245,
      "grad_norm": 10.906068801879883,
      "learning_rate": 6.328056288478452e-05,
      "loss": 0.9372,
      "step": 1671
    },
    {
      "epoch": 1.1029023746701847,
      "grad_norm": 10.567413330078125,
      "learning_rate": 6.325857519788918e-05,
      "loss": 0.8951,
      "step": 1672
    },
    {
      "epoch": 1.103562005277045,
      "grad_norm": 0.8791478276252747,
      "learning_rate": 6.323658751099385e-05,
      "loss": 0.0674,
      "step": 1673
    },
    {
      "epoch": 1.104221635883905,
      "grad_norm": 4.236827850341797,
      "learning_rate": 6.321459982409851e-05,
      "loss": 0.4749,
      "step": 1674
    },
    {
      "epoch": 1.1048812664907652,
      "grad_norm": 9.513825416564941,
      "learning_rate": 6.319261213720316e-05,
      "loss": 1.3813,
      "step": 1675
    },
    {
      "epoch": 1.1055408970976253,
      "grad_norm": 2.8864235877990723,
      "learning_rate": 6.317062445030783e-05,
      "loss": 0.1717,
      "step": 1676
    },
    {
      "epoch": 1.1062005277044855,
      "grad_norm": 1.4488239288330078,
      "learning_rate": 6.314863676341249e-05,
      "loss": 0.1056,
      "step": 1677
    },
    {
      "epoch": 1.1068601583113455,
      "grad_norm": 1.7668235301971436,
      "learning_rate": 6.312664907651715e-05,
      "loss": 0.172,
      "step": 1678
    },
    {
      "epoch": 1.1075197889182058,
      "grad_norm": 1.8884162902832031,
      "learning_rate": 6.31046613896218e-05,
      "loss": 0.1537,
      "step": 1679
    },
    {
      "epoch": 1.108179419525066,
      "grad_norm": 7.173654079437256,
      "learning_rate": 6.308267370272648e-05,
      "loss": 0.6601,
      "step": 1680
    },
    {
      "epoch": 1.108839050131926,
      "grad_norm": 2.4848978519439697,
      "learning_rate": 6.306068601583113e-05,
      "loss": 0.2019,
      "step": 1681
    },
    {
      "epoch": 1.1094986807387863,
      "grad_norm": 1.5950409173965454,
      "learning_rate": 6.30386983289358e-05,
      "loss": 0.1528,
      "step": 1682
    },
    {
      "epoch": 1.1101583113456464,
      "grad_norm": 1.7162572145462036,
      "learning_rate": 6.301671064204046e-05,
      "loss": 0.1493,
      "step": 1683
    },
    {
      "epoch": 1.1108179419525066,
      "grad_norm": 1.7509305477142334,
      "learning_rate": 6.299472295514513e-05,
      "loss": 0.1643,
      "step": 1684
    },
    {
      "epoch": 1.1114775725593669,
      "grad_norm": 1.2619342803955078,
      "learning_rate": 6.297273526824979e-05,
      "loss": 0.1126,
      "step": 1685
    },
    {
      "epoch": 1.1121372031662269,
      "grad_norm": 1.7589374780654907,
      "learning_rate": 6.295074758135445e-05,
      "loss": 0.1411,
      "step": 1686
    },
    {
      "epoch": 1.1127968337730871,
      "grad_norm": 8.291616439819336,
      "learning_rate": 6.292875989445912e-05,
      "loss": 0.4111,
      "step": 1687
    },
    {
      "epoch": 1.1134564643799472,
      "grad_norm": 2.011521577835083,
      "learning_rate": 6.290677220756377e-05,
      "loss": 0.1281,
      "step": 1688
    },
    {
      "epoch": 1.1141160949868074,
      "grad_norm": 9.416946411132812,
      "learning_rate": 6.288478452066843e-05,
      "loss": 0.386,
      "step": 1689
    },
    {
      "epoch": 1.1147757255936674,
      "grad_norm": 1.8004533052444458,
      "learning_rate": 6.286279683377309e-05,
      "loss": 0.1094,
      "step": 1690
    },
    {
      "epoch": 1.1154353562005277,
      "grad_norm": 7.460055828094482,
      "learning_rate": 6.284080914687776e-05,
      "loss": 0.3512,
      "step": 1691
    },
    {
      "epoch": 1.116094986807388,
      "grad_norm": 5.266946792602539,
      "learning_rate": 6.281882145998241e-05,
      "loss": 0.225,
      "step": 1692
    },
    {
      "epoch": 1.116754617414248,
      "grad_norm": 0.926491916179657,
      "learning_rate": 6.279683377308707e-05,
      "loss": 0.1098,
      "step": 1693
    },
    {
      "epoch": 1.1174142480211082,
      "grad_norm": 1.4949383735656738,
      "learning_rate": 6.277484608619174e-05,
      "loss": 0.0976,
      "step": 1694
    },
    {
      "epoch": 1.1180738786279683,
      "grad_norm": 5.357132434844971,
      "learning_rate": 6.27528583992964e-05,
      "loss": 0.28,
      "step": 1695
    },
    {
      "epoch": 1.1187335092348285,
      "grad_norm": 4.17387580871582,
      "learning_rate": 6.273087071240106e-05,
      "loss": 0.1792,
      "step": 1696
    },
    {
      "epoch": 1.1193931398416888,
      "grad_norm": 1.0915091037750244,
      "learning_rate": 6.270888302550571e-05,
      "loss": 0.0755,
      "step": 1697
    },
    {
      "epoch": 1.1200527704485488,
      "grad_norm": 1.6613004207611084,
      "learning_rate": 6.268689533861038e-05,
      "loss": 0.1202,
      "step": 1698
    },
    {
      "epoch": 1.120712401055409,
      "grad_norm": 6.613598346710205,
      "learning_rate": 6.266490765171504e-05,
      "loss": 0.2646,
      "step": 1699
    },
    {
      "epoch": 1.121372031662269,
      "grad_norm": 1.6529217958450317,
      "learning_rate": 6.26429199648197e-05,
      "loss": 0.0899,
      "step": 1700
    },
    {
      "epoch": 1.1220316622691293,
      "grad_norm": 0.9814655780792236,
      "learning_rate": 6.262093227792435e-05,
      "loss": 0.0643,
      "step": 1701
    },
    {
      "epoch": 1.1226912928759893,
      "grad_norm": 6.300302505493164,
      "learning_rate": 6.259894459102902e-05,
      "loss": 0.2186,
      "step": 1702
    },
    {
      "epoch": 1.1233509234828496,
      "grad_norm": 1.145459532737732,
      "learning_rate": 6.257695690413368e-05,
      "loss": 0.0535,
      "step": 1703
    },
    {
      "epoch": 1.1240105540897098,
      "grad_norm": 0.8025560975074768,
      "learning_rate": 6.255496921723835e-05,
      "loss": 0.0655,
      "step": 1704
    },
    {
      "epoch": 1.1246701846965699,
      "grad_norm": 14.65117359161377,
      "learning_rate": 6.253298153034301e-05,
      "loss": 0.593,
      "step": 1705
    },
    {
      "epoch": 1.1253298153034301,
      "grad_norm": 4.047357559204102,
      "learning_rate": 6.251099384344768e-05,
      "loss": 0.153,
      "step": 1706
    },
    {
      "epoch": 1.1259894459102902,
      "grad_norm": 4.0400190353393555,
      "learning_rate": 6.248900615655234e-05,
      "loss": 0.1376,
      "step": 1707
    },
    {
      "epoch": 1.1266490765171504,
      "grad_norm": 10.280303001403809,
      "learning_rate": 6.2467018469657e-05,
      "loss": 0.7711,
      "step": 1708
    },
    {
      "epoch": 1.1273087071240107,
      "grad_norm": 1.461370587348938,
      "learning_rate": 6.244503078276166e-05,
      "loss": 0.0598,
      "step": 1709
    },
    {
      "epoch": 1.1279683377308707,
      "grad_norm": 7.030060291290283,
      "learning_rate": 6.242304309586632e-05,
      "loss": 0.2978,
      "step": 1710
    },
    {
      "epoch": 1.128627968337731,
      "grad_norm": 2.7316677570343018,
      "learning_rate": 6.240105540897098e-05,
      "loss": 0.0719,
      "step": 1711
    },
    {
      "epoch": 1.129287598944591,
      "grad_norm": 6.303080081939697,
      "learning_rate": 6.237906772207565e-05,
      "loss": 0.3601,
      "step": 1712
    },
    {
      "epoch": 1.1299472295514512,
      "grad_norm": 2.0246424674987793,
      "learning_rate": 6.23570800351803e-05,
      "loss": 0.062,
      "step": 1713
    },
    {
      "epoch": 1.1306068601583115,
      "grad_norm": 1.57013738155365,
      "learning_rate": 6.233509234828496e-05,
      "loss": 0.0795,
      "step": 1714
    },
    {
      "epoch": 1.1312664907651715,
      "grad_norm": 2.701568841934204,
      "learning_rate": 6.231310466138962e-05,
      "loss": 0.1102,
      "step": 1715
    },
    {
      "epoch": 1.1319261213720317,
      "grad_norm": 2.647603988647461,
      "learning_rate": 6.229111697449429e-05,
      "loss": 0.1804,
      "step": 1716
    },
    {
      "epoch": 1.1325857519788918,
      "grad_norm": 1.9169343709945679,
      "learning_rate": 6.226912928759895e-05,
      "loss": 0.1851,
      "step": 1717
    },
    {
      "epoch": 1.133245382585752,
      "grad_norm": 3.176306962966919,
      "learning_rate": 6.22471416007036e-05,
      "loss": 0.1685,
      "step": 1718
    },
    {
      "epoch": 1.133905013192612,
      "grad_norm": 3.7446720600128174,
      "learning_rate": 6.222515391380826e-05,
      "loss": 0.2035,
      "step": 1719
    },
    {
      "epoch": 1.1345646437994723,
      "grad_norm": 3.9696836471557617,
      "learning_rate": 6.220316622691293e-05,
      "loss": 0.411,
      "step": 1720
    },
    {
      "epoch": 1.1352242744063323,
      "grad_norm": 1.5942195653915405,
      "learning_rate": 6.218117854001759e-05,
      "loss": 0.1139,
      "step": 1721
    },
    {
      "epoch": 1.1358839050131926,
      "grad_norm": 3.4348361492156982,
      "learning_rate": 6.215919085312225e-05,
      "loss": 0.2642,
      "step": 1722
    },
    {
      "epoch": 1.1365435356200528,
      "grad_norm": 0.780624270439148,
      "learning_rate": 6.213720316622692e-05,
      "loss": 0.1051,
      "step": 1723
    },
    {
      "epoch": 1.1372031662269129,
      "grad_norm": 1.1439194679260254,
      "learning_rate": 6.211521547933157e-05,
      "loss": 0.0936,
      "step": 1724
    },
    {
      "epoch": 1.1378627968337731,
      "grad_norm": 12.991862297058105,
      "learning_rate": 6.209322779243624e-05,
      "loss": 1.121,
      "step": 1725
    },
    {
      "epoch": 1.1385224274406331,
      "grad_norm": 1.3192322254180908,
      "learning_rate": 6.20712401055409e-05,
      "loss": 0.0876,
      "step": 1726
    },
    {
      "epoch": 1.1391820580474934,
      "grad_norm": 8.442895889282227,
      "learning_rate": 6.204925241864557e-05,
      "loss": 0.3066,
      "step": 1727
    },
    {
      "epoch": 1.1398416886543536,
      "grad_norm": 16.595539093017578,
      "learning_rate": 6.202726473175023e-05,
      "loss": 0.4575,
      "step": 1728
    },
    {
      "epoch": 1.1405013192612137,
      "grad_norm": 0.7551815509796143,
      "learning_rate": 6.200527704485489e-05,
      "loss": 0.0705,
      "step": 1729
    },
    {
      "epoch": 1.141160949868074,
      "grad_norm": 3.5294430255889893,
      "learning_rate": 6.198328935795956e-05,
      "loss": 0.1514,
      "step": 1730
    },
    {
      "epoch": 1.141820580474934,
      "grad_norm": 1.890415072441101,
      "learning_rate": 6.196130167106421e-05,
      "loss": 0.179,
      "step": 1731
    },
    {
      "epoch": 1.1424802110817942,
      "grad_norm": 0.7255022525787354,
      "learning_rate": 6.193931398416887e-05,
      "loss": 0.0583,
      "step": 1732
    },
    {
      "epoch": 1.1431398416886545,
      "grad_norm": 2.294700860977173,
      "learning_rate": 6.191732629727353e-05,
      "loss": 0.148,
      "step": 1733
    },
    {
      "epoch": 1.1437994722955145,
      "grad_norm": 8.87644100189209,
      "learning_rate": 6.18953386103782e-05,
      "loss": 1.2446,
      "step": 1734
    },
    {
      "epoch": 1.1444591029023747,
      "grad_norm": 6.962162017822266,
      "learning_rate": 6.187335092348285e-05,
      "loss": 0.2209,
      "step": 1735
    },
    {
      "epoch": 1.1451187335092348,
      "grad_norm": 7.687117099761963,
      "learning_rate": 6.185136323658751e-05,
      "loss": 0.2611,
      "step": 1736
    },
    {
      "epoch": 1.145778364116095,
      "grad_norm": 7.281530857086182,
      "learning_rate": 6.182937554969217e-05,
      "loss": 0.311,
      "step": 1737
    },
    {
      "epoch": 1.1464379947229553,
      "grad_norm": 1.5023980140686035,
      "learning_rate": 6.180738786279684e-05,
      "loss": 0.1155,
      "step": 1738
    },
    {
      "epoch": 1.1470976253298153,
      "grad_norm": 2.4500346183776855,
      "learning_rate": 6.17854001759015e-05,
      "loss": 0.1311,
      "step": 1739
    },
    {
      "epoch": 1.1477572559366755,
      "grad_norm": 1.9012999534606934,
      "learning_rate": 6.176341248900615e-05,
      "loss": 0.1339,
      "step": 1740
    },
    {
      "epoch": 1.1484168865435356,
      "grad_norm": 8.424293518066406,
      "learning_rate": 6.174142480211082e-05,
      "loss": 0.261,
      "step": 1741
    },
    {
      "epoch": 1.1490765171503958,
      "grad_norm": 2.514281749725342,
      "learning_rate": 6.171943711521548e-05,
      "loss": 0.1616,
      "step": 1742
    },
    {
      "epoch": 1.1497361477572559,
      "grad_norm": 9.647392272949219,
      "learning_rate": 6.169744942832014e-05,
      "loss": 0.7566,
      "step": 1743
    },
    {
      "epoch": 1.150395778364116,
      "grad_norm": 2.0909478664398193,
      "learning_rate": 6.16754617414248e-05,
      "loss": 0.115,
      "step": 1744
    },
    {
      "epoch": 1.1510554089709761,
      "grad_norm": 1.3753434419631958,
      "learning_rate": 6.165347405452946e-05,
      "loss": 0.1063,
      "step": 1745
    },
    {
      "epoch": 1.1517150395778364,
      "grad_norm": 0.9999608993530273,
      "learning_rate": 6.163148636763412e-05,
      "loss": 0.1174,
      "step": 1746
    },
    {
      "epoch": 1.1523746701846966,
      "grad_norm": 0.7856355905532837,
      "learning_rate": 6.160949868073879e-05,
      "loss": 0.0824,
      "step": 1747
    },
    {
      "epoch": 1.1530343007915567,
      "grad_norm": 2.487933874130249,
      "learning_rate": 6.158751099384346e-05,
      "loss": 0.1208,
      "step": 1748
    },
    {
      "epoch": 1.153693931398417,
      "grad_norm": 6.332366943359375,
      "learning_rate": 6.156552330694812e-05,
      "loss": 0.2789,
      "step": 1749
    },
    {
      "epoch": 1.154353562005277,
      "grad_norm": 1.5945063829421997,
      "learning_rate": 6.154353562005278e-05,
      "loss": 0.1153,
      "step": 1750
    },
    {
      "epoch": 1.1550131926121372,
      "grad_norm": 4.4208855628967285,
      "learning_rate": 6.152154793315743e-05,
      "loss": 0.1774,
      "step": 1751
    },
    {
      "epoch": 1.1556728232189974,
      "grad_norm": 1.3315064907073975,
      "learning_rate": 6.14995602462621e-05,
      "loss": 0.0732,
      "step": 1752
    },
    {
      "epoch": 1.1563324538258575,
      "grad_norm": 0.6978708505630493,
      "learning_rate": 6.147757255936676e-05,
      "loss": 0.0855,
      "step": 1753
    },
    {
      "epoch": 1.1569920844327177,
      "grad_norm": 1.2415509223937988,
      "learning_rate": 6.145558487247142e-05,
      "loss": 0.13,
      "step": 1754
    },
    {
      "epoch": 1.1576517150395778,
      "grad_norm": 0.6227321028709412,
      "learning_rate": 6.143359718557607e-05,
      "loss": 0.0638,
      "step": 1755
    },
    {
      "epoch": 1.158311345646438,
      "grad_norm": 1.2925443649291992,
      "learning_rate": 6.141160949868075e-05,
      "loss": 0.076,
      "step": 1756
    },
    {
      "epoch": 1.1589709762532983,
      "grad_norm": 4.435283184051514,
      "learning_rate": 6.13896218117854e-05,
      "loss": 0.1498,
      "step": 1757
    },
    {
      "epoch": 1.1596306068601583,
      "grad_norm": 1.8738079071044922,
      "learning_rate": 6.136763412489006e-05,
      "loss": 0.1192,
      "step": 1758
    },
    {
      "epoch": 1.1602902374670185,
      "grad_norm": 18.725812911987305,
      "learning_rate": 6.134564643799473e-05,
      "loss": 0.6698,
      "step": 1759
    },
    {
      "epoch": 1.1609498680738786,
      "grad_norm": 8.47586727142334,
      "learning_rate": 6.132365875109939e-05,
      "loss": 0.2919,
      "step": 1760
    },
    {
      "epoch": 1.1616094986807388,
      "grad_norm": 5.861883640289307,
      "learning_rate": 6.130167106420404e-05,
      "loss": 0.198,
      "step": 1761
    },
    {
      "epoch": 1.162269129287599,
      "grad_norm": 4.711591720581055,
      "learning_rate": 6.12796833773087e-05,
      "loss": 0.126,
      "step": 1762
    },
    {
      "epoch": 1.162928759894459,
      "grad_norm": 9.066617965698242,
      "learning_rate": 6.125769569041337e-05,
      "loss": 0.3213,
      "step": 1763
    },
    {
      "epoch": 1.1635883905013193,
      "grad_norm": 9.637992858886719,
      "learning_rate": 6.123570800351803e-05,
      "loss": 0.3074,
      "step": 1764
    },
    {
      "epoch": 1.1642480211081794,
      "grad_norm": 1.0091103315353394,
      "learning_rate": 6.121372031662269e-05,
      "loss": 0.0634,
      "step": 1765
    },
    {
      "epoch": 1.1649076517150396,
      "grad_norm": 12.220274925231934,
      "learning_rate": 6.119173262972736e-05,
      "loss": 0.6077,
      "step": 1766
    },
    {
      "epoch": 1.1655672823218997,
      "grad_norm": 9.257524490356445,
      "learning_rate": 6.116974494283201e-05,
      "loss": 0.3509,
      "step": 1767
    },
    {
      "epoch": 1.16622691292876,
      "grad_norm": 5.330366611480713,
      "learning_rate": 6.114775725593668e-05,
      "loss": 0.2201,
      "step": 1768
    },
    {
      "epoch": 1.16688654353562,
      "grad_norm": 1.4015218019485474,
      "learning_rate": 6.112576956904134e-05,
      "loss": 0.1537,
      "step": 1769
    },
    {
      "epoch": 1.1675461741424802,
      "grad_norm": 2.9426255226135254,
      "learning_rate": 6.110378188214601e-05,
      "loss": 0.2526,
      "step": 1770
    },
    {
      "epoch": 1.1682058047493404,
      "grad_norm": 3.001042604446411,
      "learning_rate": 6.108179419525067e-05,
      "loss": 0.1348,
      "step": 1771
    },
    {
      "epoch": 1.1688654353562005,
      "grad_norm": 2.162287473678589,
      "learning_rate": 6.105980650835532e-05,
      "loss": 0.1684,
      "step": 1772
    },
    {
      "epoch": 1.1695250659630607,
      "grad_norm": 0.6782568693161011,
      "learning_rate": 6.103781882145998e-05,
      "loss": 0.0904,
      "step": 1773
    },
    {
      "epoch": 1.1701846965699207,
      "grad_norm": 2.2033274173736572,
      "learning_rate": 6.101583113456465e-05,
      "loss": 0.1528,
      "step": 1774
    },
    {
      "epoch": 1.170844327176781,
      "grad_norm": 5.658233165740967,
      "learning_rate": 6.099384344766931e-05,
      "loss": 0.5916,
      "step": 1775
    },
    {
      "epoch": 1.1715039577836412,
      "grad_norm": 4.961445331573486,
      "learning_rate": 6.0971855760773966e-05,
      "loss": 0.2693,
      "step": 1776
    },
    {
      "epoch": 1.1721635883905013,
      "grad_norm": 3.9981849193573,
      "learning_rate": 6.094986807387864e-05,
      "loss": 0.1511,
      "step": 1777
    },
    {
      "epoch": 1.1728232189973615,
      "grad_norm": 2.6721572875976562,
      "learning_rate": 6.0927880386983294e-05,
      "loss": 0.1841,
      "step": 1778
    },
    {
      "epoch": 1.1734828496042216,
      "grad_norm": 1.6461420059204102,
      "learning_rate": 6.090589270008795e-05,
      "loss": 0.1923,
      "step": 1779
    },
    {
      "epoch": 1.1741424802110818,
      "grad_norm": 7.65300178527832,
      "learning_rate": 6.088390501319261e-05,
      "loss": 0.3365,
      "step": 1780
    },
    {
      "epoch": 1.174802110817942,
      "grad_norm": 0.9392513036727905,
      "learning_rate": 6.086191732629728e-05,
      "loss": 0.1165,
      "step": 1781
    },
    {
      "epoch": 1.175461741424802,
      "grad_norm": 2.184304714202881,
      "learning_rate": 6.0839929639401935e-05,
      "loss": 0.1401,
      "step": 1782
    },
    {
      "epoch": 1.1761213720316623,
      "grad_norm": 3.0244576930999756,
      "learning_rate": 6.08179419525066e-05,
      "loss": 0.1265,
      "step": 1783
    },
    {
      "epoch": 1.1767810026385224,
      "grad_norm": 5.627179145812988,
      "learning_rate": 6.079595426561126e-05,
      "loss": 0.246,
      "step": 1784
    },
    {
      "epoch": 1.1774406332453826,
      "grad_norm": 8.895498275756836,
      "learning_rate": 6.077396657871593e-05,
      "loss": 0.4593,
      "step": 1785
    },
    {
      "epoch": 1.1781002638522429,
      "grad_norm": 16.216053009033203,
      "learning_rate": 6.0751978891820584e-05,
      "loss": 0.4911,
      "step": 1786
    },
    {
      "epoch": 1.178759894459103,
      "grad_norm": 7.240397930145264,
      "learning_rate": 6.072999120492524e-05,
      "loss": 0.5779,
      "step": 1787
    },
    {
      "epoch": 1.1794195250659631,
      "grad_norm": 0.5123213529586792,
      "learning_rate": 6.070800351802991e-05,
      "loss": 0.068,
      "step": 1788
    },
    {
      "epoch": 1.1800791556728232,
      "grad_norm": 17.844017028808594,
      "learning_rate": 6.068601583113457e-05,
      "loss": 0.4253,
      "step": 1789
    },
    {
      "epoch": 1.1807387862796834,
      "grad_norm": 2.9958038330078125,
      "learning_rate": 6.0664028144239225e-05,
      "loss": 0.1669,
      "step": 1790
    },
    {
      "epoch": 1.1813984168865435,
      "grad_norm": 0.8515878319740295,
      "learning_rate": 6.064204045734388e-05,
      "loss": 0.0838,
      "step": 1791
    },
    {
      "epoch": 1.1820580474934037,
      "grad_norm": 5.758019924163818,
      "learning_rate": 6.062005277044855e-05,
      "loss": 0.2725,
      "step": 1792
    },
    {
      "epoch": 1.1827176781002637,
      "grad_norm": 11.140812873840332,
      "learning_rate": 6.059806508355321e-05,
      "loss": 0.9452,
      "step": 1793
    },
    {
      "epoch": 1.183377308707124,
      "grad_norm": 1.6672816276550293,
      "learning_rate": 6.0576077396657873e-05,
      "loss": 0.126,
      "step": 1794
    },
    {
      "epoch": 1.1840369393139842,
      "grad_norm": 0.782555341720581,
      "learning_rate": 6.055408970976254e-05,
      "loss": 0.0757,
      "step": 1795
    },
    {
      "epoch": 1.1846965699208443,
      "grad_norm": 0.9582115411758423,
      "learning_rate": 6.05321020228672e-05,
      "loss": 0.1145,
      "step": 1796
    },
    {
      "epoch": 1.1853562005277045,
      "grad_norm": 0.8728346824645996,
      "learning_rate": 6.051011433597186e-05,
      "loss": 0.109,
      "step": 1797
    },
    {
      "epoch": 1.1860158311345645,
      "grad_norm": 15.34268856048584,
      "learning_rate": 6.0488126649076515e-05,
      "loss": 0.4183,
      "step": 1798
    },
    {
      "epoch": 1.1866754617414248,
      "grad_norm": 1.5343616008758545,
      "learning_rate": 6.0466138962181185e-05,
      "loss": 0.1102,
      "step": 1799
    },
    {
      "epoch": 1.187335092348285,
      "grad_norm": 1.9083642959594727,
      "learning_rate": 6.044415127528584e-05,
      "loss": 0.1682,
      "step": 1800
    },
    {
      "epoch": 1.187994722955145,
      "grad_norm": 1.2042814493179321,
      "learning_rate": 6.04221635883905e-05,
      "loss": 0.1088,
      "step": 1801
    },
    {
      "epoch": 1.1886543535620053,
      "grad_norm": 1.1762007474899292,
      "learning_rate": 6.040017590149517e-05,
      "loss": 0.0833,
      "step": 1802
    },
    {
      "epoch": 1.1893139841688654,
      "grad_norm": 2.468153953552246,
      "learning_rate": 6.037818821459983e-05,
      "loss": 0.1428,
      "step": 1803
    },
    {
      "epoch": 1.1899736147757256,
      "grad_norm": 1.0284830331802368,
      "learning_rate": 6.035620052770449e-05,
      "loss": 0.0755,
      "step": 1804
    },
    {
      "epoch": 1.1906332453825859,
      "grad_norm": 0.8405793905258179,
      "learning_rate": 6.033421284080915e-05,
      "loss": 0.0805,
      "step": 1805
    },
    {
      "epoch": 1.1912928759894459,
      "grad_norm": 1.4815400838851929,
      "learning_rate": 6.031222515391382e-05,
      "loss": 0.1071,
      "step": 1806
    },
    {
      "epoch": 1.1919525065963061,
      "grad_norm": 1.3657257556915283,
      "learning_rate": 6.0290237467018475e-05,
      "loss": 0.0904,
      "step": 1807
    },
    {
      "epoch": 1.1926121372031662,
      "grad_norm": 0.9099907875061035,
      "learning_rate": 6.026824978012313e-05,
      "loss": 0.1036,
      "step": 1808
    },
    {
      "epoch": 1.1932717678100264,
      "grad_norm": 0.5640824437141418,
      "learning_rate": 6.024626209322779e-05,
      "loss": 0.0647,
      "step": 1809
    },
    {
      "epoch": 1.1939313984168864,
      "grad_norm": 1.6245734691619873,
      "learning_rate": 6.022427440633246e-05,
      "loss": 0.0739,
      "step": 1810
    },
    {
      "epoch": 1.1945910290237467,
      "grad_norm": 9.176458358764648,
      "learning_rate": 6.020228671943712e-05,
      "loss": 0.4326,
      "step": 1811
    },
    {
      "epoch": 1.195250659630607,
      "grad_norm": 1.1545932292938232,
      "learning_rate": 6.0180299032541774e-05,
      "loss": 0.0973,
      "step": 1812
    },
    {
      "epoch": 1.195910290237467,
      "grad_norm": 14.269352912902832,
      "learning_rate": 6.0158311345646444e-05,
      "loss": 0.4142,
      "step": 1813
    },
    {
      "epoch": 1.1965699208443272,
      "grad_norm": 15.062041282653809,
      "learning_rate": 6.01363236587511e-05,
      "loss": 0.7279,
      "step": 1814
    },
    {
      "epoch": 1.1972295514511873,
      "grad_norm": 0.5685911774635315,
      "learning_rate": 6.0114335971855765e-05,
      "loss": 0.0384,
      "step": 1815
    },
    {
      "epoch": 1.1978891820580475,
      "grad_norm": 14.214585304260254,
      "learning_rate": 6.009234828496042e-05,
      "loss": 1.8415,
      "step": 1816
    },
    {
      "epoch": 1.1985488126649075,
      "grad_norm": 1.6399197578430176,
      "learning_rate": 6.007036059806509e-05,
      "loss": 0.064,
      "step": 1817
    },
    {
      "epoch": 1.1992084432717678,
      "grad_norm": 6.518251895904541,
      "learning_rate": 6.004837291116975e-05,
      "loss": 0.1902,
      "step": 1818
    },
    {
      "epoch": 1.199868073878628,
      "grad_norm": 7.883401393890381,
      "learning_rate": 6.0026385224274406e-05,
      "loss": 0.1764,
      "step": 1819
    },
    {
      "epoch": 1.200527704485488,
      "grad_norm": 3.2463629245758057,
      "learning_rate": 6.000439753737908e-05,
      "loss": 0.1096,
      "step": 1820
    },
    {
      "epoch": 1.2011873350923483,
      "grad_norm": 4.499895095825195,
      "learning_rate": 5.9982409850483734e-05,
      "loss": 0.2189,
      "step": 1821
    },
    {
      "epoch": 1.2018469656992083,
      "grad_norm": 1.0605117082595825,
      "learning_rate": 5.996042216358839e-05,
      "loss": 0.1128,
      "step": 1822
    },
    {
      "epoch": 1.2025065963060686,
      "grad_norm": 1.5067195892333984,
      "learning_rate": 5.993843447669305e-05,
      "loss": 0.1175,
      "step": 1823
    },
    {
      "epoch": 1.2031662269129288,
      "grad_norm": 0.9870205521583557,
      "learning_rate": 5.991644678979772e-05,
      "loss": 0.0637,
      "step": 1824
    },
    {
      "epoch": 1.2038258575197889,
      "grad_norm": 1.5366497039794922,
      "learning_rate": 5.9894459102902375e-05,
      "loss": 0.1218,
      "step": 1825
    },
    {
      "epoch": 1.2044854881266491,
      "grad_norm": 22.779603958129883,
      "learning_rate": 5.987247141600704e-05,
      "loss": 0.5281,
      "step": 1826
    },
    {
      "epoch": 1.2051451187335092,
      "grad_norm": 3.400331735610962,
      "learning_rate": 5.9850483729111696e-05,
      "loss": 0.2196,
      "step": 1827
    },
    {
      "epoch": 1.2058047493403694,
      "grad_norm": 1.353908896446228,
      "learning_rate": 5.982849604221637e-05,
      "loss": 0.1012,
      "step": 1828
    },
    {
      "epoch": 1.2064643799472297,
      "grad_norm": 1.5106431245803833,
      "learning_rate": 5.9806508355321024e-05,
      "loss": 0.1318,
      "step": 1829
    },
    {
      "epoch": 1.2071240105540897,
      "grad_norm": 0.9265422224998474,
      "learning_rate": 5.978452066842568e-05,
      "loss": 0.0658,
      "step": 1830
    },
    {
      "epoch": 1.20778364116095,
      "grad_norm": 1.9828261137008667,
      "learning_rate": 5.976253298153035e-05,
      "loss": 0.0623,
      "step": 1831
    },
    {
      "epoch": 1.20844327176781,
      "grad_norm": 0.7070003747940063,
      "learning_rate": 5.974054529463501e-05,
      "loss": 0.035,
      "step": 1832
    },
    {
      "epoch": 1.2091029023746702,
      "grad_norm": 0.673766016960144,
      "learning_rate": 5.9718557607739665e-05,
      "loss": 0.06,
      "step": 1833
    },
    {
      "epoch": 1.2097625329815302,
      "grad_norm": 11.928502082824707,
      "learning_rate": 5.969656992084432e-05,
      "loss": 0.3219,
      "step": 1834
    },
    {
      "epoch": 1.2104221635883905,
      "grad_norm": 0.5495604872703552,
      "learning_rate": 5.967458223394899e-05,
      "loss": 0.035,
      "step": 1835
    },
    {
      "epoch": 1.2110817941952507,
      "grad_norm": 16.048198699951172,
      "learning_rate": 5.965259454705365e-05,
      "loss": 1.0574,
      "step": 1836
    },
    {
      "epoch": 1.2117414248021108,
      "grad_norm": 1.381840467453003,
      "learning_rate": 5.963060686015831e-05,
      "loss": 0.0448,
      "step": 1837
    },
    {
      "epoch": 1.212401055408971,
      "grad_norm": 0.5490586757659912,
      "learning_rate": 5.9608619173262984e-05,
      "loss": 0.0336,
      "step": 1838
    },
    {
      "epoch": 1.213060686015831,
      "grad_norm": 0.934177577495575,
      "learning_rate": 5.958663148636764e-05,
      "loss": 0.0442,
      "step": 1839
    },
    {
      "epoch": 1.2137203166226913,
      "grad_norm": 18.90492057800293,
      "learning_rate": 5.95646437994723e-05,
      "loss": 1.4881,
      "step": 1840
    },
    {
      "epoch": 1.2143799472295513,
      "grad_norm": 0.5044822096824646,
      "learning_rate": 5.9542656112576955e-05,
      "loss": 0.0311,
      "step": 1841
    },
    {
      "epoch": 1.2150395778364116,
      "grad_norm": 12.415288925170898,
      "learning_rate": 5.9520668425681625e-05,
      "loss": 1.0971,
      "step": 1842
    },
    {
      "epoch": 1.2156992084432718,
      "grad_norm": 17.384138107299805,
      "learning_rate": 5.949868073878628e-05,
      "loss": 0.7637,
      "step": 1843
    },
    {
      "epoch": 1.2163588390501319,
      "grad_norm": 11.609200477600098,
      "learning_rate": 5.947669305189094e-05,
      "loss": 0.983,
      "step": 1844
    },
    {
      "epoch": 1.2170184696569921,
      "grad_norm": 4.259979248046875,
      "learning_rate": 5.94547053649956e-05,
      "loss": 0.1205,
      "step": 1845
    },
    {
      "epoch": 1.2176781002638521,
      "grad_norm": 11.686148643493652,
      "learning_rate": 5.943271767810027e-05,
      "loss": 0.5456,
      "step": 1846
    },
    {
      "epoch": 1.2183377308707124,
      "grad_norm": 19.246604919433594,
      "learning_rate": 5.941072999120493e-05,
      "loss": 0.3665,
      "step": 1847
    },
    {
      "epoch": 1.2189973614775726,
      "grad_norm": 15.775087356567383,
      "learning_rate": 5.938874230430959e-05,
      "loss": 1.6085,
      "step": 1848
    },
    {
      "epoch": 1.2196569920844327,
      "grad_norm": 1.933776617050171,
      "learning_rate": 5.936675461741426e-05,
      "loss": 0.0679,
      "step": 1849
    },
    {
      "epoch": 1.220316622691293,
      "grad_norm": 1.8802573680877686,
      "learning_rate": 5.9344766930518915e-05,
      "loss": 0.0585,
      "step": 1850
    },
    {
      "epoch": 1.220976253298153,
      "grad_norm": 0.6583164930343628,
      "learning_rate": 5.932277924362357e-05,
      "loss": 0.0459,
      "step": 1851
    },
    {
      "epoch": 1.2216358839050132,
      "grad_norm": 2.0937795639038086,
      "learning_rate": 5.930079155672823e-05,
      "loss": 0.0821,
      "step": 1852
    },
    {
      "epoch": 1.2222955145118735,
      "grad_norm": 14.386303901672363,
      "learning_rate": 5.92788038698329e-05,
      "loss": 0.33,
      "step": 1853
    },
    {
      "epoch": 1.2229551451187335,
      "grad_norm": 5.687691688537598,
      "learning_rate": 5.9256816182937557e-05,
      "loss": 0.147,
      "step": 1854
    },
    {
      "epoch": 1.2236147757255937,
      "grad_norm": 1.1963298320770264,
      "learning_rate": 5.9234828496042214e-05,
      "loss": 0.0883,
      "step": 1855
    },
    {
      "epoch": 1.2242744063324538,
      "grad_norm": 0.9673880338668823,
      "learning_rate": 5.9212840809146884e-05,
      "loss": 0.0924,
      "step": 1856
    },
    {
      "epoch": 1.224934036939314,
      "grad_norm": 1.860761046409607,
      "learning_rate": 5.919085312225154e-05,
      "loss": 0.0724,
      "step": 1857
    },
    {
      "epoch": 1.225593667546174,
      "grad_norm": 5.303929328918457,
      "learning_rate": 5.9168865435356205e-05,
      "loss": 0.2752,
      "step": 1858
    },
    {
      "epoch": 1.2262532981530343,
      "grad_norm": 1.4309420585632324,
      "learning_rate": 5.914687774846086e-05,
      "loss": 0.1341,
      "step": 1859
    },
    {
      "epoch": 1.2269129287598945,
      "grad_norm": 8.91585922241211,
      "learning_rate": 5.912489006156553e-05,
      "loss": 1.0453,
      "step": 1860
    },
    {
      "epoch": 1.2275725593667546,
      "grad_norm": 2.1215810775756836,
      "learning_rate": 5.910290237467019e-05,
      "loss": 0.1664,
      "step": 1861
    },
    {
      "epoch": 1.2282321899736148,
      "grad_norm": 4.359218120574951,
      "learning_rate": 5.9080914687774846e-05,
      "loss": 0.1428,
      "step": 1862
    },
    {
      "epoch": 1.2288918205804749,
      "grad_norm": 17.497922897338867,
      "learning_rate": 5.90589270008795e-05,
      "loss": 0.4911,
      "step": 1863
    },
    {
      "epoch": 1.229551451187335,
      "grad_norm": 11.15786361694336,
      "learning_rate": 5.9036939313984174e-05,
      "loss": 1.3058,
      "step": 1864
    },
    {
      "epoch": 1.2302110817941951,
      "grad_norm": 2.7558112144470215,
      "learning_rate": 5.901495162708883e-05,
      "loss": 0.2067,
      "step": 1865
    },
    {
      "epoch": 1.2308707124010554,
      "grad_norm": 4.391777515411377,
      "learning_rate": 5.899296394019349e-05,
      "loss": 0.1906,
      "step": 1866
    },
    {
      "epoch": 1.2315303430079156,
      "grad_norm": 1.5857800245285034,
      "learning_rate": 5.897097625329816e-05,
      "loss": 0.1592,
      "step": 1867
    },
    {
      "epoch": 1.2321899736147757,
      "grad_norm": 3.307253837585449,
      "learning_rate": 5.8948988566402815e-05,
      "loss": 0.2861,
      "step": 1868
    },
    {
      "epoch": 1.232849604221636,
      "grad_norm": 5.306753635406494,
      "learning_rate": 5.892700087950748e-05,
      "loss": 0.2607,
      "step": 1869
    },
    {
      "epoch": 1.233509234828496,
      "grad_norm": 1.1830133199691772,
      "learning_rate": 5.8905013192612136e-05,
      "loss": 0.1086,
      "step": 1870
    },
    {
      "epoch": 1.2341688654353562,
      "grad_norm": 12.015447616577148,
      "learning_rate": 5.8883025505716807e-05,
      "loss": 0.4563,
      "step": 1871
    },
    {
      "epoch": 1.2348284960422165,
      "grad_norm": 1.1604276895523071,
      "learning_rate": 5.8861037818821464e-05,
      "loss": 0.1051,
      "step": 1872
    },
    {
      "epoch": 1.2354881266490765,
      "grad_norm": 2.6143858432769775,
      "learning_rate": 5.883905013192612e-05,
      "loss": 0.2042,
      "step": 1873
    },
    {
      "epoch": 1.2361477572559367,
      "grad_norm": 4.7760796546936035,
      "learning_rate": 5.881706244503079e-05,
      "loss": 0.3207,
      "step": 1874
    },
    {
      "epoch": 1.2368073878627968,
      "grad_norm": 1.1066913604736328,
      "learning_rate": 5.879507475813545e-05,
      "loss": 0.1099,
      "step": 1875
    },
    {
      "epoch": 1.237467018469657,
      "grad_norm": 3.1548047065734863,
      "learning_rate": 5.8773087071240105e-05,
      "loss": 0.1957,
      "step": 1876
    },
    {
      "epoch": 1.2381266490765173,
      "grad_norm": 2.2602577209472656,
      "learning_rate": 5.875109938434477e-05,
      "loss": 0.0895,
      "step": 1877
    },
    {
      "epoch": 1.2387862796833773,
      "grad_norm": 3.8367364406585693,
      "learning_rate": 5.872911169744943e-05,
      "loss": 0.1765,
      "step": 1878
    },
    {
      "epoch": 1.2394459102902375,
      "grad_norm": 1.4072130918502808,
      "learning_rate": 5.8707124010554096e-05,
      "loss": 0.0969,
      "step": 1879
    },
    {
      "epoch": 1.2401055408970976,
      "grad_norm": 6.007734298706055,
      "learning_rate": 5.868513632365875e-05,
      "loss": 0.3101,
      "step": 1880
    },
    {
      "epoch": 1.2407651715039578,
      "grad_norm": 4.718652248382568,
      "learning_rate": 5.866314863676341e-05,
      "loss": 0.2671,
      "step": 1881
    },
    {
      "epoch": 1.2414248021108178,
      "grad_norm": 8.178104400634766,
      "learning_rate": 5.864116094986808e-05,
      "loss": 0.2939,
      "step": 1882
    },
    {
      "epoch": 1.242084432717678,
      "grad_norm": 0.47340309619903564,
      "learning_rate": 5.861917326297274e-05,
      "loss": 0.0404,
      "step": 1883
    },
    {
      "epoch": 1.2427440633245384,
      "grad_norm": 0.968582808971405,
      "learning_rate": 5.8597185576077395e-05,
      "loss": 0.1353,
      "step": 1884
    },
    {
      "epoch": 1.2434036939313984,
      "grad_norm": 0.9262071847915649,
      "learning_rate": 5.8575197889182065e-05,
      "loss": 0.0864,
      "step": 1885
    },
    {
      "epoch": 1.2440633245382586,
      "grad_norm": 10.2748384475708,
      "learning_rate": 5.855321020228672e-05,
      "loss": 0.3899,
      "step": 1886
    },
    {
      "epoch": 1.2447229551451187,
      "grad_norm": 1.2002607583999634,
      "learning_rate": 5.853122251539138e-05,
      "loss": 0.125,
      "step": 1887
    },
    {
      "epoch": 1.245382585751979,
      "grad_norm": 6.219783782958984,
      "learning_rate": 5.850923482849604e-05,
      "loss": 0.4503,
      "step": 1888
    },
    {
      "epoch": 1.246042216358839,
      "grad_norm": 6.699404239654541,
      "learning_rate": 5.848724714160071e-05,
      "loss": 0.1821,
      "step": 1889
    },
    {
      "epoch": 1.2467018469656992,
      "grad_norm": 2.4274117946624756,
      "learning_rate": 5.846525945470537e-05,
      "loss": 0.1402,
      "step": 1890
    },
    {
      "epoch": 1.2473614775725594,
      "grad_norm": 11.013687133789062,
      "learning_rate": 5.844327176781003e-05,
      "loss": 0.424,
      "step": 1891
    },
    {
      "epoch": 1.2480211081794195,
      "grad_norm": 1.9551093578338623,
      "learning_rate": 5.84212840809147e-05,
      "loss": 0.1312,
      "step": 1892
    },
    {
      "epoch": 1.2486807387862797,
      "grad_norm": 2.9605019092559814,
      "learning_rate": 5.8399296394019355e-05,
      "loss": 0.1996,
      "step": 1893
    },
    {
      "epoch": 1.2493403693931397,
      "grad_norm": 2.2524354457855225,
      "learning_rate": 5.837730870712401e-05,
      "loss": 0.1764,
      "step": 1894
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.9829190373420715,
      "learning_rate": 5.835532102022867e-05,
      "loss": 0.0908,
      "step": 1895
    },
    {
      "epoch": 1.2506596306068603,
      "grad_norm": 2.1855878829956055,
      "learning_rate": 5.833333333333334e-05,
      "loss": 0.1211,
      "step": 1896
    },
    {
      "epoch": 1.2513192612137203,
      "grad_norm": 8.62226390838623,
      "learning_rate": 5.8311345646437996e-05,
      "loss": 0.247,
      "step": 1897
    },
    {
      "epoch": 1.2519788918205805,
      "grad_norm": 23.388208389282227,
      "learning_rate": 5.8289357959542653e-05,
      "loss": 0.637,
      "step": 1898
    },
    {
      "epoch": 1.2526385224274406,
      "grad_norm": 1.5830657482147217,
      "learning_rate": 5.8267370272647324e-05,
      "loss": 0.1094,
      "step": 1899
    },
    {
      "epoch": 1.2532981530343008,
      "grad_norm": 1.7602207660675049,
      "learning_rate": 5.824538258575198e-05,
      "loss": 0.0916,
      "step": 1900
    },
    {
      "epoch": 1.253957783641161,
      "grad_norm": 1.004194974899292,
      "learning_rate": 5.8223394898856645e-05,
      "loss": 0.0828,
      "step": 1901
    },
    {
      "epoch": 1.254617414248021,
      "grad_norm": 7.572329998016357,
      "learning_rate": 5.82014072119613e-05,
      "loss": 0.7304,
      "step": 1902
    },
    {
      "epoch": 1.2552770448548813,
      "grad_norm": 7.617547988891602,
      "learning_rate": 5.817941952506597e-05,
      "loss": 0.2606,
      "step": 1903
    },
    {
      "epoch": 1.2559366754617414,
      "grad_norm": 2.918778657913208,
      "learning_rate": 5.815743183817063e-05,
      "loss": 0.1354,
      "step": 1904
    },
    {
      "epoch": 1.2565963060686016,
      "grad_norm": 7.303542137145996,
      "learning_rate": 5.8135444151275286e-05,
      "loss": 0.2492,
      "step": 1905
    },
    {
      "epoch": 1.2572559366754619,
      "grad_norm": 5.421501636505127,
      "learning_rate": 5.811345646437994e-05,
      "loss": 0.2585,
      "step": 1906
    },
    {
      "epoch": 1.257915567282322,
      "grad_norm": 8.515108108520508,
      "learning_rate": 5.8091468777484614e-05,
      "loss": 0.3762,
      "step": 1907
    },
    {
      "epoch": 1.258575197889182,
      "grad_norm": 5.702062606811523,
      "learning_rate": 5.806948109058927e-05,
      "loss": 0.2376,
      "step": 1908
    },
    {
      "epoch": 1.2592348284960422,
      "grad_norm": 9.215221405029297,
      "learning_rate": 5.804749340369393e-05,
      "loss": 0.3766,
      "step": 1909
    },
    {
      "epoch": 1.2598944591029024,
      "grad_norm": 0.5945886373519897,
      "learning_rate": 5.80255057167986e-05,
      "loss": 0.056,
      "step": 1910
    },
    {
      "epoch": 1.2605540897097625,
      "grad_norm": 17.625110626220703,
      "learning_rate": 5.800351802990326e-05,
      "loss": 0.9559,
      "step": 1911
    },
    {
      "epoch": 1.2612137203166227,
      "grad_norm": 1.063272476196289,
      "learning_rate": 5.798153034300792e-05,
      "loss": 0.0848,
      "step": 1912
    },
    {
      "epoch": 1.2618733509234827,
      "grad_norm": 12.842607498168945,
      "learning_rate": 5.7959542656112576e-05,
      "loss": 0.6317,
      "step": 1913
    },
    {
      "epoch": 1.262532981530343,
      "grad_norm": 1.292266845703125,
      "learning_rate": 5.7937554969217246e-05,
      "loss": 0.1067,
      "step": 1914
    },
    {
      "epoch": 1.2631926121372032,
      "grad_norm": 1.3404603004455566,
      "learning_rate": 5.7915567282321903e-05,
      "loss": 0.1057,
      "step": 1915
    },
    {
      "epoch": 1.2638522427440633,
      "grad_norm": 14.215994834899902,
      "learning_rate": 5.789357959542656e-05,
      "loss": 1.1472,
      "step": 1916
    },
    {
      "epoch": 1.2645118733509235,
      "grad_norm": 2.324742317199707,
      "learning_rate": 5.787159190853123e-05,
      "loss": 0.1397,
      "step": 1917
    },
    {
      "epoch": 1.2651715039577835,
      "grad_norm": 1.0369840860366821,
      "learning_rate": 5.784960422163589e-05,
      "loss": 0.0917,
      "step": 1918
    },
    {
      "epoch": 1.2658311345646438,
      "grad_norm": 1.49687659740448,
      "learning_rate": 5.7827616534740545e-05,
      "loss": 0.1153,
      "step": 1919
    },
    {
      "epoch": 1.266490765171504,
      "grad_norm": 1.3509761095046997,
      "learning_rate": 5.780562884784521e-05,
      "loss": 0.0944,
      "step": 1920
    },
    {
      "epoch": 1.267150395778364,
      "grad_norm": 0.8429889678955078,
      "learning_rate": 5.778364116094987e-05,
      "loss": 0.0741,
      "step": 1921
    },
    {
      "epoch": 1.2678100263852243,
      "grad_norm": 0.49170923233032227,
      "learning_rate": 5.7761653474054536e-05,
      "loss": 0.0406,
      "step": 1922
    },
    {
      "epoch": 1.2684696569920844,
      "grad_norm": 0.703005313873291,
      "learning_rate": 5.773966578715919e-05,
      "loss": 0.042,
      "step": 1923
    },
    {
      "epoch": 1.2691292875989446,
      "grad_norm": 4.211948871612549,
      "learning_rate": 5.771767810026385e-05,
      "loss": 0.1436,
      "step": 1924
    },
    {
      "epoch": 1.2697889182058049,
      "grad_norm": 0.784902036190033,
      "learning_rate": 5.769569041336852e-05,
      "loss": 0.0543,
      "step": 1925
    },
    {
      "epoch": 1.270448548812665,
      "grad_norm": 17.03797149658203,
      "learning_rate": 5.767370272647318e-05,
      "loss": 1.4017,
      "step": 1926
    },
    {
      "epoch": 1.2711081794195251,
      "grad_norm": 9.711305618286133,
      "learning_rate": 5.7651715039577835e-05,
      "loss": 1.362,
      "step": 1927
    },
    {
      "epoch": 1.2717678100263852,
      "grad_norm": 10.060397148132324,
      "learning_rate": 5.7629727352682505e-05,
      "loss": 0.3672,
      "step": 1928
    },
    {
      "epoch": 1.2724274406332454,
      "grad_norm": 1.2078906297683716,
      "learning_rate": 5.760773966578716e-05,
      "loss": 0.0646,
      "step": 1929
    },
    {
      "epoch": 1.2730870712401057,
      "grad_norm": 8.080316543579102,
      "learning_rate": 5.758575197889182e-05,
      "loss": 0.3937,
      "step": 1930
    },
    {
      "epoch": 1.2737467018469657,
      "grad_norm": 2.4542438983917236,
      "learning_rate": 5.756376429199648e-05,
      "loss": 0.0809,
      "step": 1931
    },
    {
      "epoch": 1.2744063324538257,
      "grad_norm": 6.794799327850342,
      "learning_rate": 5.754177660510115e-05,
      "loss": 0.1792,
      "step": 1932
    },
    {
      "epoch": 1.275065963060686,
      "grad_norm": 11.87364387512207,
      "learning_rate": 5.751978891820581e-05,
      "loss": 0.7813,
      "step": 1933
    },
    {
      "epoch": 1.2757255936675462,
      "grad_norm": 2.6229991912841797,
      "learning_rate": 5.749780123131047e-05,
      "loss": 0.0846,
      "step": 1934
    },
    {
      "epoch": 1.2763852242744063,
      "grad_norm": 8.504871368408203,
      "learning_rate": 5.747581354441514e-05,
      "loss": 0.3391,
      "step": 1935
    },
    {
      "epoch": 1.2770448548812665,
      "grad_norm": 0.5689153671264648,
      "learning_rate": 5.7453825857519795e-05,
      "loss": 0.0389,
      "step": 1936
    },
    {
      "epoch": 1.2777044854881265,
      "grad_norm": 8.844898223876953,
      "learning_rate": 5.743183817062445e-05,
      "loss": 0.2748,
      "step": 1937
    },
    {
      "epoch": 1.2783641160949868,
      "grad_norm": 0.881303071975708,
      "learning_rate": 5.740985048372911e-05,
      "loss": 0.0444,
      "step": 1938
    },
    {
      "epoch": 1.279023746701847,
      "grad_norm": 5.133013725280762,
      "learning_rate": 5.738786279683378e-05,
      "loss": 0.3651,
      "step": 1939
    },
    {
      "epoch": 1.279683377308707,
      "grad_norm": 12.431096076965332,
      "learning_rate": 5.7365875109938436e-05,
      "loss": 0.5138,
      "step": 1940
    },
    {
      "epoch": 1.2803430079155673,
      "grad_norm": 3.9486615657806396,
      "learning_rate": 5.7343887423043093e-05,
      "loss": 0.1746,
      "step": 1941
    },
    {
      "epoch": 1.2810026385224274,
      "grad_norm": 1.06007981300354,
      "learning_rate": 5.732189973614776e-05,
      "loss": 0.1007,
      "step": 1942
    },
    {
      "epoch": 1.2816622691292876,
      "grad_norm": 1.3548941612243652,
      "learning_rate": 5.729991204925243e-05,
      "loss": 0.1244,
      "step": 1943
    },
    {
      "epoch": 1.2823218997361479,
      "grad_norm": 0.7926151156425476,
      "learning_rate": 5.7277924362357085e-05,
      "loss": 0.0795,
      "step": 1944
    },
    {
      "epoch": 1.2829815303430079,
      "grad_norm": 2.4543392658233643,
      "learning_rate": 5.725593667546174e-05,
      "loss": 0.1191,
      "step": 1945
    },
    {
      "epoch": 1.2836411609498681,
      "grad_norm": 9.830083847045898,
      "learning_rate": 5.723394898856641e-05,
      "loss": 0.8562,
      "step": 1946
    },
    {
      "epoch": 1.2843007915567282,
      "grad_norm": 1.0851809978485107,
      "learning_rate": 5.721196130167107e-05,
      "loss": 0.0874,
      "step": 1947
    },
    {
      "epoch": 1.2849604221635884,
      "grad_norm": 6.1900153160095215,
      "learning_rate": 5.7189973614775726e-05,
      "loss": 0.2192,
      "step": 1948
    },
    {
      "epoch": 1.2856200527704487,
      "grad_norm": 2.0552961826324463,
      "learning_rate": 5.716798592788038e-05,
      "loss": 0.0757,
      "step": 1949
    },
    {
      "epoch": 1.2862796833773087,
      "grad_norm": 7.44950008392334,
      "learning_rate": 5.7145998240985054e-05,
      "loss": 0.2557,
      "step": 1950
    },
    {
      "epoch": 1.286939313984169,
      "grad_norm": 0.6374791264533997,
      "learning_rate": 5.712401055408971e-05,
      "loss": 0.062,
      "step": 1951
    },
    {
      "epoch": 1.287598944591029,
      "grad_norm": 1.7939449548721313,
      "learning_rate": 5.7102022867194374e-05,
      "loss": 0.115,
      "step": 1952
    },
    {
      "epoch": 1.2882585751978892,
      "grad_norm": 0.9909217953681946,
      "learning_rate": 5.708003518029904e-05,
      "loss": 0.0935,
      "step": 1953
    },
    {
      "epoch": 1.2889182058047495,
      "grad_norm": 1.0756185054779053,
      "learning_rate": 5.70580474934037e-05,
      "loss": 0.0631,
      "step": 1954
    },
    {
      "epoch": 1.2895778364116095,
      "grad_norm": 2.670598030090332,
      "learning_rate": 5.703605980650836e-05,
      "loss": 0.1094,
      "step": 1955
    },
    {
      "epoch": 1.2902374670184695,
      "grad_norm": 9.463809967041016,
      "learning_rate": 5.7014072119613016e-05,
      "loss": 0.2861,
      "step": 1956
    },
    {
      "epoch": 1.2908970976253298,
      "grad_norm": 1.6900209188461304,
      "learning_rate": 5.6992084432717686e-05,
      "loss": 0.117,
      "step": 1957
    },
    {
      "epoch": 1.29155672823219,
      "grad_norm": 7.772659778594971,
      "learning_rate": 5.6970096745822343e-05,
      "loss": 0.1506,
      "step": 1958
    },
    {
      "epoch": 1.29221635883905,
      "grad_norm": 0.4936380088329315,
      "learning_rate": 5.6948109058927e-05,
      "loss": 0.0384,
      "step": 1959
    },
    {
      "epoch": 1.2928759894459103,
      "grad_norm": 3.3045284748077393,
      "learning_rate": 5.692612137203166e-05,
      "loss": 0.1046,
      "step": 1960
    },
    {
      "epoch": 1.2935356200527703,
      "grad_norm": 7.115468978881836,
      "learning_rate": 5.690413368513633e-05,
      "loss": 0.214,
      "step": 1961
    },
    {
      "epoch": 1.2941952506596306,
      "grad_norm": 1.2034950256347656,
      "learning_rate": 5.6882145998240985e-05,
      "loss": 0.0928,
      "step": 1962
    },
    {
      "epoch": 1.2948548812664908,
      "grad_norm": 0.8519923090934753,
      "learning_rate": 5.686015831134565e-05,
      "loss": 0.0516,
      "step": 1963
    },
    {
      "epoch": 1.2955145118733509,
      "grad_norm": 0.45194873213768005,
      "learning_rate": 5.683817062445031e-05,
      "loss": 0.0446,
      "step": 1964
    },
    {
      "epoch": 1.2961741424802111,
      "grad_norm": 6.155733108520508,
      "learning_rate": 5.6816182937554976e-05,
      "loss": 0.2311,
      "step": 1965
    },
    {
      "epoch": 1.2968337730870712,
      "grad_norm": 0.8741047382354736,
      "learning_rate": 5.679419525065963e-05,
      "loss": 0.0553,
      "step": 1966
    },
    {
      "epoch": 1.2974934036939314,
      "grad_norm": 0.43511509895324707,
      "learning_rate": 5.677220756376429e-05,
      "loss": 0.0334,
      "step": 1967
    },
    {
      "epoch": 1.2981530343007917,
      "grad_norm": 0.6256745457649231,
      "learning_rate": 5.675021987686896e-05,
      "loss": 0.0431,
      "step": 1968
    },
    {
      "epoch": 1.2988126649076517,
      "grad_norm": 23.37110710144043,
      "learning_rate": 5.672823218997362e-05,
      "loss": 1.2278,
      "step": 1969
    },
    {
      "epoch": 1.299472295514512,
      "grad_norm": 3.8133704662323,
      "learning_rate": 5.6706244503078275e-05,
      "loss": 0.0983,
      "step": 1970
    },
    {
      "epoch": 1.300131926121372,
      "grad_norm": 9.32408332824707,
      "learning_rate": 5.6684256816182945e-05,
      "loss": 0.5413,
      "step": 1971
    },
    {
      "epoch": 1.3007915567282322,
      "grad_norm": 5.488032817840576,
      "learning_rate": 5.66622691292876e-05,
      "loss": 0.1201,
      "step": 1972
    },
    {
      "epoch": 1.3014511873350925,
      "grad_norm": 0.806869387626648,
      "learning_rate": 5.664028144239226e-05,
      "loss": 0.0457,
      "step": 1973
    },
    {
      "epoch": 1.3021108179419525,
      "grad_norm": 0.6637636423110962,
      "learning_rate": 5.661829375549692e-05,
      "loss": 0.0408,
      "step": 1974
    },
    {
      "epoch": 1.3027704485488127,
      "grad_norm": 4.859460353851318,
      "learning_rate": 5.659630606860159e-05,
      "loss": 0.1144,
      "step": 1975
    },
    {
      "epoch": 1.3034300791556728,
      "grad_norm": 0.48390787839889526,
      "learning_rate": 5.657431838170625e-05,
      "loss": 0.0338,
      "step": 1976
    },
    {
      "epoch": 1.304089709762533,
      "grad_norm": 0.4653940498828888,
      "learning_rate": 5.655233069481091e-05,
      "loss": 0.0327,
      "step": 1977
    },
    {
      "epoch": 1.3047493403693933,
      "grad_norm": 14.373221397399902,
      "learning_rate": 5.6530343007915564e-05,
      "loss": 0.3011,
      "step": 1978
    },
    {
      "epoch": 1.3054089709762533,
      "grad_norm": 10.034330368041992,
      "learning_rate": 5.6508355321020235e-05,
      "loss": 0.8286,
      "step": 1979
    },
    {
      "epoch": 1.3060686015831133,
      "grad_norm": 7.7222771644592285,
      "learning_rate": 5.648636763412489e-05,
      "loss": 0.1893,
      "step": 1980
    },
    {
      "epoch": 1.3067282321899736,
      "grad_norm": 4.236759662628174,
      "learning_rate": 5.646437994722955e-05,
      "loss": 0.1183,
      "step": 1981
    },
    {
      "epoch": 1.3073878627968338,
      "grad_norm": 4.288431644439697,
      "learning_rate": 5.644239226033422e-05,
      "loss": 0.1599,
      "step": 1982
    },
    {
      "epoch": 1.3080474934036939,
      "grad_norm": 1.0330828428268433,
      "learning_rate": 5.6420404573438876e-05,
      "loss": 0.0687,
      "step": 1983
    },
    {
      "epoch": 1.3087071240105541,
      "grad_norm": 1.7363989353179932,
      "learning_rate": 5.639841688654354e-05,
      "loss": 0.1227,
      "step": 1984
    },
    {
      "epoch": 1.3093667546174141,
      "grad_norm": 13.0339994430542,
      "learning_rate": 5.63764291996482e-05,
      "loss": 0.3179,
      "step": 1985
    },
    {
      "epoch": 1.3100263852242744,
      "grad_norm": 0.9860156178474426,
      "learning_rate": 5.635444151275287e-05,
      "loss": 0.0793,
      "step": 1986
    },
    {
      "epoch": 1.3106860158311346,
      "grad_norm": 0.6557572484016418,
      "learning_rate": 5.6332453825857525e-05,
      "loss": 0.0774,
      "step": 1987
    },
    {
      "epoch": 1.3113456464379947,
      "grad_norm": 11.217148780822754,
      "learning_rate": 5.631046613896218e-05,
      "loss": 0.729,
      "step": 1988
    },
    {
      "epoch": 1.312005277044855,
      "grad_norm": 18.870014190673828,
      "learning_rate": 5.628847845206685e-05,
      "loss": 1.036,
      "step": 1989
    },
    {
      "epoch": 1.312664907651715,
      "grad_norm": 1.64946711063385,
      "learning_rate": 5.626649076517151e-05,
      "loss": 0.1534,
      "step": 1990
    },
    {
      "epoch": 1.3133245382585752,
      "grad_norm": 2.3353092670440674,
      "learning_rate": 5.6244503078276166e-05,
      "loss": 0.1151,
      "step": 1991
    },
    {
      "epoch": 1.3139841688654355,
      "grad_norm": 1.246176838874817,
      "learning_rate": 5.622251539138082e-05,
      "loss": 0.07,
      "step": 1992
    },
    {
      "epoch": 1.3146437994722955,
      "grad_norm": 1.2655524015426636,
      "learning_rate": 5.6200527704485494e-05,
      "loss": 0.0434,
      "step": 1993
    },
    {
      "epoch": 1.3153034300791557,
      "grad_norm": 1.0257751941680908,
      "learning_rate": 5.617854001759015e-05,
      "loss": 0.0688,
      "step": 1994
    },
    {
      "epoch": 1.3159630606860158,
      "grad_norm": 11.99604320526123,
      "learning_rate": 5.6156552330694814e-05,
      "loss": 0.347,
      "step": 1995
    },
    {
      "epoch": 1.316622691292876,
      "grad_norm": 0.5677840709686279,
      "learning_rate": 5.613456464379947e-05,
      "loss": 0.0403,
      "step": 1996
    },
    {
      "epoch": 1.3172823218997363,
      "grad_norm": 3.739380359649658,
      "learning_rate": 5.611257695690414e-05,
      "loss": 0.1385,
      "step": 1997
    },
    {
      "epoch": 1.3179419525065963,
      "grad_norm": 14.208539962768555,
      "learning_rate": 5.60905892700088e-05,
      "loss": 0.807,
      "step": 1998
    },
    {
      "epoch": 1.3186015831134565,
      "grad_norm": 0.6628262996673584,
      "learning_rate": 5.6068601583113456e-05,
      "loss": 0.0242,
      "step": 1999
    },
    {
      "epoch": 1.3192612137203166,
      "grad_norm": 8.441838264465332,
      "learning_rate": 5.6046613896218126e-05,
      "loss": 0.5341,
      "step": 2000
    },
    {
      "epoch": 1.3199208443271768,
      "grad_norm": 0.7454337477684021,
      "learning_rate": 5.602462620932278e-05,
      "loss": 0.0408,
      "step": 2001
    },
    {
      "epoch": 1.320580474934037,
      "grad_norm": 22.048736572265625,
      "learning_rate": 5.600263852242744e-05,
      "loss": 0.8712,
      "step": 2002
    },
    {
      "epoch": 1.321240105540897,
      "grad_norm": 0.9840042591094971,
      "learning_rate": 5.59806508355321e-05,
      "loss": 0.0549,
      "step": 2003
    },
    {
      "epoch": 1.3218997361477571,
      "grad_norm": 0.48689284920692444,
      "learning_rate": 5.595866314863677e-05,
      "loss": 0.0296,
      "step": 2004
    },
    {
      "epoch": 1.3225593667546174,
      "grad_norm": 15.55418586730957,
      "learning_rate": 5.5936675461741425e-05,
      "loss": 0.4538,
      "step": 2005
    },
    {
      "epoch": 1.3232189973614776,
      "grad_norm": 0.46788087487220764,
      "learning_rate": 5.591468777484609e-05,
      "loss": 0.0306,
      "step": 2006
    },
    {
      "epoch": 1.3238786279683377,
      "grad_norm": 9.918280601501465,
      "learning_rate": 5.589270008795075e-05,
      "loss": 0.4991,
      "step": 2007
    },
    {
      "epoch": 1.324538258575198,
      "grad_norm": 1.1017956733703613,
      "learning_rate": 5.5870712401055416e-05,
      "loss": 0.0523,
      "step": 2008
    },
    {
      "epoch": 1.325197889182058,
      "grad_norm": 6.645262241363525,
      "learning_rate": 5.584872471416007e-05,
      "loss": 0.2168,
      "step": 2009
    },
    {
      "epoch": 1.3258575197889182,
      "grad_norm": 11.43660831451416,
      "learning_rate": 5.582673702726473e-05,
      "loss": 1.6362,
      "step": 2010
    },
    {
      "epoch": 1.3265171503957784,
      "grad_norm": 12.800613403320312,
      "learning_rate": 5.58047493403694e-05,
      "loss": 1.1984,
      "step": 2011
    },
    {
      "epoch": 1.3271767810026385,
      "grad_norm": 0.905345618724823,
      "learning_rate": 5.578276165347406e-05,
      "loss": 0.0615,
      "step": 2012
    },
    {
      "epoch": 1.3278364116094987,
      "grad_norm": 4.847630500793457,
      "learning_rate": 5.5760773966578715e-05,
      "loss": 0.0901,
      "step": 2013
    },
    {
      "epoch": 1.3284960422163588,
      "grad_norm": 4.611608982086182,
      "learning_rate": 5.573878627968337e-05,
      "loss": 0.1584,
      "step": 2014
    },
    {
      "epoch": 1.329155672823219,
      "grad_norm": 1.74677574634552,
      "learning_rate": 5.571679859278804e-05,
      "loss": 0.0977,
      "step": 2015
    },
    {
      "epoch": 1.3298153034300793,
      "grad_norm": 6.935401439666748,
      "learning_rate": 5.5694810905892706e-05,
      "loss": 0.1595,
      "step": 2016
    },
    {
      "epoch": 1.3304749340369393,
      "grad_norm": 6.987046718597412,
      "learning_rate": 5.567282321899736e-05,
      "loss": 0.6089,
      "step": 2017
    },
    {
      "epoch": 1.3311345646437995,
      "grad_norm": 6.562175273895264,
      "learning_rate": 5.565083553210203e-05,
      "loss": 0.2955,
      "step": 2018
    },
    {
      "epoch": 1.3317941952506596,
      "grad_norm": 1.7369163036346436,
      "learning_rate": 5.562884784520669e-05,
      "loss": 0.1261,
      "step": 2019
    },
    {
      "epoch": 1.3324538258575198,
      "grad_norm": 0.455451637506485,
      "learning_rate": 5.560686015831135e-05,
      "loss": 0.0269,
      "step": 2020
    },
    {
      "epoch": 1.33311345646438,
      "grad_norm": 4.039403438568115,
      "learning_rate": 5.5584872471416004e-05,
      "loss": 0.2261,
      "step": 2021
    },
    {
      "epoch": 1.33377308707124,
      "grad_norm": 0.6256276369094849,
      "learning_rate": 5.5562884784520675e-05,
      "loss": 0.0674,
      "step": 2022
    },
    {
      "epoch": 1.3344327176781003,
      "grad_norm": 0.7198823094367981,
      "learning_rate": 5.554089709762533e-05,
      "loss": 0.0708,
      "step": 2023
    },
    {
      "epoch": 1.3350923482849604,
      "grad_norm": 1.3368096351623535,
      "learning_rate": 5.551890941072999e-05,
      "loss": 0.0814,
      "step": 2024
    },
    {
      "epoch": 1.3357519788918206,
      "grad_norm": 1.6798741817474365,
      "learning_rate": 5.549692172383466e-05,
      "loss": 0.1015,
      "step": 2025
    },
    {
      "epoch": 1.3364116094986809,
      "grad_norm": 6.059301853179932,
      "learning_rate": 5.5474934036939316e-05,
      "loss": 0.2159,
      "step": 2026
    },
    {
      "epoch": 1.337071240105541,
      "grad_norm": 2.2345926761627197,
      "learning_rate": 5.545294635004398e-05,
      "loss": 0.1494,
      "step": 2027
    },
    {
      "epoch": 1.337730870712401,
      "grad_norm": 1.01796293258667,
      "learning_rate": 5.543095866314864e-05,
      "loss": 0.0554,
      "step": 2028
    },
    {
      "epoch": 1.3383905013192612,
      "grad_norm": 1.3031089305877686,
      "learning_rate": 5.540897097625331e-05,
      "loss": 0.0886,
      "step": 2029
    },
    {
      "epoch": 1.3390501319261214,
      "grad_norm": 6.598382472991943,
      "learning_rate": 5.5386983289357965e-05,
      "loss": 0.1958,
      "step": 2030
    },
    {
      "epoch": 1.3397097625329815,
      "grad_norm": 6.520974159240723,
      "learning_rate": 5.536499560246262e-05,
      "loss": 0.1733,
      "step": 2031
    },
    {
      "epoch": 1.3403693931398417,
      "grad_norm": 1.1346898078918457,
      "learning_rate": 5.534300791556728e-05,
      "loss": 0.065,
      "step": 2032
    },
    {
      "epoch": 1.3410290237467017,
      "grad_norm": 2.2967123985290527,
      "learning_rate": 5.532102022867195e-05,
      "loss": 0.0965,
      "step": 2033
    },
    {
      "epoch": 1.341688654353562,
      "grad_norm": 8.689644813537598,
      "learning_rate": 5.5299032541776606e-05,
      "loss": 0.2683,
      "step": 2034
    },
    {
      "epoch": 1.3423482849604222,
      "grad_norm": 8.896468162536621,
      "learning_rate": 5.527704485488126e-05,
      "loss": 0.4594,
      "step": 2035
    },
    {
      "epoch": 1.3430079155672823,
      "grad_norm": 0.8327431082725525,
      "learning_rate": 5.5255057167985934e-05,
      "loss": 0.0851,
      "step": 2036
    },
    {
      "epoch": 1.3436675461741425,
      "grad_norm": 9.574774742126465,
      "learning_rate": 5.523306948109059e-05,
      "loss": 1.1315,
      "step": 2037
    },
    {
      "epoch": 1.3443271767810026,
      "grad_norm": 10.526412963867188,
      "learning_rate": 5.5211081794195254e-05,
      "loss": 0.3252,
      "step": 2038
    },
    {
      "epoch": 1.3449868073878628,
      "grad_norm": 9.448507308959961,
      "learning_rate": 5.518909410729991e-05,
      "loss": 1.2943,
      "step": 2039
    },
    {
      "epoch": 1.345646437994723,
      "grad_norm": 8.008097648620605,
      "learning_rate": 5.516710642040458e-05,
      "loss": 0.201,
      "step": 2040
    },
    {
      "epoch": 1.346306068601583,
      "grad_norm": 36.21068572998047,
      "learning_rate": 5.514511873350924e-05,
      "loss": 0.589,
      "step": 2041
    },
    {
      "epoch": 1.3469656992084433,
      "grad_norm": 1.537940502166748,
      "learning_rate": 5.5123131046613896e-05,
      "loss": 0.0875,
      "step": 2042
    },
    {
      "epoch": 1.3476253298153034,
      "grad_norm": 4.86649751663208,
      "learning_rate": 5.5101143359718566e-05,
      "loss": 0.1211,
      "step": 2043
    },
    {
      "epoch": 1.3482849604221636,
      "grad_norm": 0.8911041617393494,
      "learning_rate": 5.507915567282322e-05,
      "loss": 0.0651,
      "step": 2044
    },
    {
      "epoch": 1.3489445910290239,
      "grad_norm": 0.6828237175941467,
      "learning_rate": 5.505716798592788e-05,
      "loss": 0.0571,
      "step": 2045
    },
    {
      "epoch": 1.349604221635884,
      "grad_norm": 5.914731502532959,
      "learning_rate": 5.503518029903254e-05,
      "loss": 0.146,
      "step": 2046
    },
    {
      "epoch": 1.3502638522427441,
      "grad_norm": 0.9967190027236938,
      "learning_rate": 5.501319261213721e-05,
      "loss": 0.0792,
      "step": 2047
    },
    {
      "epoch": 1.3509234828496042,
      "grad_norm": 0.9090275168418884,
      "learning_rate": 5.499120492524187e-05,
      "loss": 0.0793,
      "step": 2048
    },
    {
      "epoch": 1.3515831134564644,
      "grad_norm": 1.2990080118179321,
      "learning_rate": 5.496921723834653e-05,
      "loss": 0.0932,
      "step": 2049
    },
    {
      "epoch": 1.3522427440633247,
      "grad_norm": 6.193009853363037,
      "learning_rate": 5.4947229551451185e-05,
      "loss": 0.3898,
      "step": 2050
    },
    {
      "epoch": 1.3529023746701847,
      "grad_norm": 7.712370872497559,
      "learning_rate": 5.4925241864555856e-05,
      "loss": 0.6228,
      "step": 2051
    },
    {
      "epoch": 1.3535620052770447,
      "grad_norm": 5.644726753234863,
      "learning_rate": 5.490325417766051e-05,
      "loss": 0.1739,
      "step": 2052
    },
    {
      "epoch": 1.354221635883905,
      "grad_norm": 1.0377428531646729,
      "learning_rate": 5.488126649076517e-05,
      "loss": 0.0733,
      "step": 2053
    },
    {
      "epoch": 1.3548812664907652,
      "grad_norm": 6.847658157348633,
      "learning_rate": 5.485927880386984e-05,
      "loss": 0.1971,
      "step": 2054
    },
    {
      "epoch": 1.3555408970976253,
      "grad_norm": 0.8816655278205872,
      "learning_rate": 5.48372911169745e-05,
      "loss": 0.0573,
      "step": 2055
    },
    {
      "epoch": 1.3562005277044855,
      "grad_norm": 8.457959175109863,
      "learning_rate": 5.4815303430079154e-05,
      "loss": 0.3108,
      "step": 2056
    },
    {
      "epoch": 1.3568601583113455,
      "grad_norm": 1.9177353382110596,
      "learning_rate": 5.479331574318382e-05,
      "loss": 0.1269,
      "step": 2057
    },
    {
      "epoch": 1.3575197889182058,
      "grad_norm": 5.982708930969238,
      "learning_rate": 5.477132805628848e-05,
      "loss": 0.1953,
      "step": 2058
    },
    {
      "epoch": 1.358179419525066,
      "grad_norm": 0.7615460157394409,
      "learning_rate": 5.4749340369393146e-05,
      "loss": 0.0477,
      "step": 2059
    },
    {
      "epoch": 1.358839050131926,
      "grad_norm": 1.0134493112564087,
      "learning_rate": 5.47273526824978e-05,
      "loss": 0.0582,
      "step": 2060
    },
    {
      "epoch": 1.3594986807387863,
      "grad_norm": 8.54569149017334,
      "learning_rate": 5.470536499560247e-05,
      "loss": 0.4167,
      "step": 2061
    },
    {
      "epoch": 1.3601583113456464,
      "grad_norm": 5.329674243927002,
      "learning_rate": 5.468337730870713e-05,
      "loss": 0.2687,
      "step": 2062
    },
    {
      "epoch": 1.3608179419525066,
      "grad_norm": 14.234148025512695,
      "learning_rate": 5.466138962181179e-05,
      "loss": 0.8368,
      "step": 2063
    },
    {
      "epoch": 1.3614775725593669,
      "grad_norm": 0.6533421874046326,
      "learning_rate": 5.4639401934916444e-05,
      "loss": 0.0452,
      "step": 2064
    },
    {
      "epoch": 1.3621372031662269,
      "grad_norm": 10.996390342712402,
      "learning_rate": 5.4617414248021115e-05,
      "loss": 1.0232,
      "step": 2065
    },
    {
      "epoch": 1.3627968337730871,
      "grad_norm": 2.1787900924682617,
      "learning_rate": 5.459542656112577e-05,
      "loss": 0.119,
      "step": 2066
    },
    {
      "epoch": 1.3634564643799472,
      "grad_norm": 0.9233559370040894,
      "learning_rate": 5.457343887423043e-05,
      "loss": 0.0752,
      "step": 2067
    },
    {
      "epoch": 1.3641160949868074,
      "grad_norm": 0.6474093198776245,
      "learning_rate": 5.455145118733509e-05,
      "loss": 0.059,
      "step": 2068
    },
    {
      "epoch": 1.3647757255936677,
      "grad_norm": 1.151060700416565,
      "learning_rate": 5.4529463500439756e-05,
      "loss": 0.0698,
      "step": 2069
    },
    {
      "epoch": 1.3654353562005277,
      "grad_norm": 0.6126752495765686,
      "learning_rate": 5.450747581354442e-05,
      "loss": 0.051,
      "step": 2070
    },
    {
      "epoch": 1.366094986807388,
      "grad_norm": 8.006103515625,
      "learning_rate": 5.448548812664908e-05,
      "loss": 0.2366,
      "step": 2071
    },
    {
      "epoch": 1.366754617414248,
      "grad_norm": 1.2907257080078125,
      "learning_rate": 5.446350043975375e-05,
      "loss": 0.0562,
      "step": 2072
    },
    {
      "epoch": 1.3674142480211082,
      "grad_norm": 1.4408141374588013,
      "learning_rate": 5.4441512752858404e-05,
      "loss": 0.0784,
      "step": 2073
    },
    {
      "epoch": 1.3680738786279685,
      "grad_norm": 0.869418203830719,
      "learning_rate": 5.441952506596306e-05,
      "loss": 0.0628,
      "step": 2074
    },
    {
      "epoch": 1.3687335092348285,
      "grad_norm": 9.818674087524414,
      "learning_rate": 5.439753737906772e-05,
      "loss": 0.3432,
      "step": 2075
    },
    {
      "epoch": 1.3693931398416885,
      "grad_norm": 1.7343385219573975,
      "learning_rate": 5.437554969217239e-05,
      "loss": 0.108,
      "step": 2076
    },
    {
      "epoch": 1.3700527704485488,
      "grad_norm": 1.442100167274475,
      "learning_rate": 5.4353562005277046e-05,
      "loss": 0.0886,
      "step": 2077
    },
    {
      "epoch": 1.370712401055409,
      "grad_norm": 9.825277328491211,
      "learning_rate": 5.43315743183817e-05,
      "loss": 0.3092,
      "step": 2078
    },
    {
      "epoch": 1.371372031662269,
      "grad_norm": 1.7160714864730835,
      "learning_rate": 5.4309586631486373e-05,
      "loss": 0.1357,
      "step": 2079
    },
    {
      "epoch": 1.3720316622691293,
      "grad_norm": 2.4858758449554443,
      "learning_rate": 5.428759894459103e-05,
      "loss": 0.151,
      "step": 2080
    },
    {
      "epoch": 1.3726912928759893,
      "grad_norm": 7.655183792114258,
      "learning_rate": 5.4265611257695694e-05,
      "loss": 0.118,
      "step": 2081
    },
    {
      "epoch": 1.3733509234828496,
      "grad_norm": 1.7604330778121948,
      "learning_rate": 5.424362357080035e-05,
      "loss": 0.0976,
      "step": 2082
    },
    {
      "epoch": 1.3740105540897098,
      "grad_norm": 0.38166147470474243,
      "learning_rate": 5.422163588390502e-05,
      "loss": 0.0327,
      "step": 2083
    },
    {
      "epoch": 1.3746701846965699,
      "grad_norm": 0.7099274396896362,
      "learning_rate": 5.419964819700968e-05,
      "loss": 0.0655,
      "step": 2084
    },
    {
      "epoch": 1.3753298153034301,
      "grad_norm": 5.516084671020508,
      "learning_rate": 5.4177660510114336e-05,
      "loss": 0.1938,
      "step": 2085
    },
    {
      "epoch": 1.3759894459102902,
      "grad_norm": 1.078015685081482,
      "learning_rate": 5.415567282321899e-05,
      "loss": 0.1069,
      "step": 2086
    },
    {
      "epoch": 1.3766490765171504,
      "grad_norm": 9.50398063659668,
      "learning_rate": 5.413368513632366e-05,
      "loss": 0.2061,
      "step": 2087
    },
    {
      "epoch": 1.3773087071240107,
      "grad_norm": 11.271227836608887,
      "learning_rate": 5.411169744942832e-05,
      "loss": 0.842,
      "step": 2088
    },
    {
      "epoch": 1.3779683377308707,
      "grad_norm": 0.694756805896759,
      "learning_rate": 5.4089709762532984e-05,
      "loss": 0.0684,
      "step": 2089
    },
    {
      "epoch": 1.378627968337731,
      "grad_norm": 1.0290828943252563,
      "learning_rate": 5.406772207563765e-05,
      "loss": 0.0556,
      "step": 2090
    },
    {
      "epoch": 1.379287598944591,
      "grad_norm": 19.12519073486328,
      "learning_rate": 5.404573438874231e-05,
      "loss": 0.4156,
      "step": 2091
    },
    {
      "epoch": 1.3799472295514512,
      "grad_norm": 7.355551719665527,
      "learning_rate": 5.402374670184697e-05,
      "loss": 0.3693,
      "step": 2092
    },
    {
      "epoch": 1.3806068601583115,
      "grad_norm": 1.5299460887908936,
      "learning_rate": 5.4001759014951625e-05,
      "loss": 0.0621,
      "step": 2093
    },
    {
      "epoch": 1.3812664907651715,
      "grad_norm": 0.46991246938705444,
      "learning_rate": 5.3979771328056296e-05,
      "loss": 0.0425,
      "step": 2094
    },
    {
      "epoch": 1.3819261213720315,
      "grad_norm": 1.2269121408462524,
      "learning_rate": 5.395778364116095e-05,
      "loss": 0.0853,
      "step": 2095
    },
    {
      "epoch": 1.3825857519788918,
      "grad_norm": 3.440751075744629,
      "learning_rate": 5.393579595426561e-05,
      "loss": 0.1332,
      "step": 2096
    },
    {
      "epoch": 1.383245382585752,
      "grad_norm": 1.8425869941711426,
      "learning_rate": 5.391380826737028e-05,
      "loss": 0.0719,
      "step": 2097
    },
    {
      "epoch": 1.383905013192612,
      "grad_norm": 5.119327545166016,
      "learning_rate": 5.389182058047494e-05,
      "loss": 0.2289,
      "step": 2098
    },
    {
      "epoch": 1.3845646437994723,
      "grad_norm": 2.218888759613037,
      "learning_rate": 5.3869832893579594e-05,
      "loss": 0.0963,
      "step": 2099
    },
    {
      "epoch": 1.3852242744063323,
      "grad_norm": 0.937728762626648,
      "learning_rate": 5.384784520668426e-05,
      "loss": 0.0445,
      "step": 2100
    },
    {
      "epoch": 1.3858839050131926,
      "grad_norm": 1.1567271947860718,
      "learning_rate": 5.382585751978892e-05,
      "loss": 0.0674,
      "step": 2101
    },
    {
      "epoch": 1.3865435356200528,
      "grad_norm": 0.8596214652061462,
      "learning_rate": 5.3803869832893586e-05,
      "loss": 0.0768,
      "step": 2102
    },
    {
      "epoch": 1.3872031662269129,
      "grad_norm": 2.3400964736938477,
      "learning_rate": 5.378188214599824e-05,
      "loss": 0.1588,
      "step": 2103
    },
    {
      "epoch": 1.3878627968337731,
      "grad_norm": 2.50358510017395,
      "learning_rate": 5.37598944591029e-05,
      "loss": 0.075,
      "step": 2104
    },
    {
      "epoch": 1.3885224274406331,
      "grad_norm": 7.287003993988037,
      "learning_rate": 5.373790677220757e-05,
      "loss": 0.1514,
      "step": 2105
    },
    {
      "epoch": 1.3891820580474934,
      "grad_norm": 1.1993408203125,
      "learning_rate": 5.371591908531223e-05,
      "loss": 0.0822,
      "step": 2106
    },
    {
      "epoch": 1.3898416886543536,
      "grad_norm": 1.1252671480178833,
      "learning_rate": 5.3693931398416884e-05,
      "loss": 0.0769,
      "step": 2107
    },
    {
      "epoch": 1.3905013192612137,
      "grad_norm": 7.747257232666016,
      "learning_rate": 5.3671943711521555e-05,
      "loss": 0.2393,
      "step": 2108
    },
    {
      "epoch": 1.391160949868074,
      "grad_norm": 8.538031578063965,
      "learning_rate": 5.364995602462621e-05,
      "loss": 0.2126,
      "step": 2109
    },
    {
      "epoch": 1.391820580474934,
      "grad_norm": 1.7602459192276,
      "learning_rate": 5.362796833773087e-05,
      "loss": 0.1063,
      "step": 2110
    },
    {
      "epoch": 1.3924802110817942,
      "grad_norm": 1.1556073427200317,
      "learning_rate": 5.360598065083553e-05,
      "loss": 0.0676,
      "step": 2111
    },
    {
      "epoch": 1.3931398416886545,
      "grad_norm": 15.2964448928833,
      "learning_rate": 5.3583992963940196e-05,
      "loss": 0.3237,
      "step": 2112
    },
    {
      "epoch": 1.3937994722955145,
      "grad_norm": 0.6710866689682007,
      "learning_rate": 5.356200527704486e-05,
      "loss": 0.0344,
      "step": 2113
    },
    {
      "epoch": 1.3944591029023747,
      "grad_norm": 1.1280661821365356,
      "learning_rate": 5.354001759014952e-05,
      "loss": 0.0445,
      "step": 2114
    },
    {
      "epoch": 1.3951187335092348,
      "grad_norm": 4.028470993041992,
      "learning_rate": 5.351802990325419e-05,
      "loss": 0.1067,
      "step": 2115
    },
    {
      "epoch": 1.395778364116095,
      "grad_norm": 7.761411190032959,
      "learning_rate": 5.3496042216358844e-05,
      "loss": 0.2369,
      "step": 2116
    },
    {
      "epoch": 1.3964379947229553,
      "grad_norm": 8.918205261230469,
      "learning_rate": 5.34740545294635e-05,
      "loss": 0.4931,
      "step": 2117
    },
    {
      "epoch": 1.3970976253298153,
      "grad_norm": 2.202838182449341,
      "learning_rate": 5.345206684256816e-05,
      "loss": 0.0788,
      "step": 2118
    },
    {
      "epoch": 1.3977572559366753,
      "grad_norm": 1.3508102893829346,
      "learning_rate": 5.343007915567283e-05,
      "loss": 0.0844,
      "step": 2119
    },
    {
      "epoch": 1.3984168865435356,
      "grad_norm": 0.8830294609069824,
      "learning_rate": 5.3408091468777486e-05,
      "loss": 0.0776,
      "step": 2120
    },
    {
      "epoch": 1.3990765171503958,
      "grad_norm": 1.7543123960494995,
      "learning_rate": 5.338610378188215e-05,
      "loss": 0.1026,
      "step": 2121
    },
    {
      "epoch": 1.3997361477572559,
      "grad_norm": 4.162267684936523,
      "learning_rate": 5.336411609498681e-05,
      "loss": 0.1014,
      "step": 2122
    },
    {
      "epoch": 1.400395778364116,
      "grad_norm": 10.286917686462402,
      "learning_rate": 5.334212840809148e-05,
      "loss": 0.3338,
      "step": 2123
    },
    {
      "epoch": 1.4010554089709761,
      "grad_norm": 0.6280083060264587,
      "learning_rate": 5.3320140721196134e-05,
      "loss": 0.0299,
      "step": 2124
    },
    {
      "epoch": 1.4017150395778364,
      "grad_norm": 0.563992977142334,
      "learning_rate": 5.329815303430079e-05,
      "loss": 0.0305,
      "step": 2125
    },
    {
      "epoch": 1.4023746701846966,
      "grad_norm": 15.894791603088379,
      "learning_rate": 5.327616534740546e-05,
      "loss": 0.6026,
      "step": 2126
    },
    {
      "epoch": 1.4030343007915567,
      "grad_norm": 14.029048919677734,
      "learning_rate": 5.325417766051012e-05,
      "loss": 1.3152,
      "step": 2127
    },
    {
      "epoch": 1.403693931398417,
      "grad_norm": 12.714269638061523,
      "learning_rate": 5.3232189973614776e-05,
      "loss": 0.4944,
      "step": 2128
    },
    {
      "epoch": 1.404353562005277,
      "grad_norm": 11.263008117675781,
      "learning_rate": 5.321020228671943e-05,
      "loss": 0.1566,
      "step": 2129
    },
    {
      "epoch": 1.4050131926121372,
      "grad_norm": 10.409331321716309,
      "learning_rate": 5.31882145998241e-05,
      "loss": 0.3681,
      "step": 2130
    },
    {
      "epoch": 1.4056728232189974,
      "grad_norm": 9.46976375579834,
      "learning_rate": 5.316622691292876e-05,
      "loss": 0.8607,
      "step": 2131
    },
    {
      "epoch": 1.4063324538258575,
      "grad_norm": 9.98912525177002,
      "learning_rate": 5.3144239226033424e-05,
      "loss": 0.5852,
      "step": 2132
    },
    {
      "epoch": 1.4069920844327177,
      "grad_norm": 5.596481800079346,
      "learning_rate": 5.312225153913809e-05,
      "loss": 0.1777,
      "step": 2133
    },
    {
      "epoch": 1.4076517150395778,
      "grad_norm": 7.8538970947265625,
      "learning_rate": 5.310026385224275e-05,
      "loss": 0.2104,
      "step": 2134
    },
    {
      "epoch": 1.408311345646438,
      "grad_norm": 0.6708179116249084,
      "learning_rate": 5.307827616534741e-05,
      "loss": 0.0813,
      "step": 2135
    },
    {
      "epoch": 1.4089709762532983,
      "grad_norm": 1.1961911916732788,
      "learning_rate": 5.3056288478452065e-05,
      "loss": 0.0864,
      "step": 2136
    },
    {
      "epoch": 1.4096306068601583,
      "grad_norm": 20.25520896911621,
      "learning_rate": 5.3034300791556736e-05,
      "loss": 0.8302,
      "step": 2137
    },
    {
      "epoch": 1.4102902374670185,
      "grad_norm": 2.5890121459960938,
      "learning_rate": 5.301231310466139e-05,
      "loss": 0.1379,
      "step": 2138
    },
    {
      "epoch": 1.4109498680738786,
      "grad_norm": 2.751370429992676,
      "learning_rate": 5.299032541776605e-05,
      "loss": 0.142,
      "step": 2139
    },
    {
      "epoch": 1.4116094986807388,
      "grad_norm": 6.452097415924072,
      "learning_rate": 5.296833773087071e-05,
      "loss": 0.216,
      "step": 2140
    },
    {
      "epoch": 1.412269129287599,
      "grad_norm": 0.8887770175933838,
      "learning_rate": 5.294635004397538e-05,
      "loss": 0.0752,
      "step": 2141
    },
    {
      "epoch": 1.412928759894459,
      "grad_norm": 8.561152458190918,
      "learning_rate": 5.2924362357080034e-05,
      "loss": 0.3825,
      "step": 2142
    },
    {
      "epoch": 1.4135883905013191,
      "grad_norm": 1.102010726928711,
      "learning_rate": 5.29023746701847e-05,
      "loss": 0.1216,
      "step": 2143
    },
    {
      "epoch": 1.4142480211081794,
      "grad_norm": 2.4029674530029297,
      "learning_rate": 5.288038698328936e-05,
      "loss": 0.1502,
      "step": 2144
    },
    {
      "epoch": 1.4149076517150396,
      "grad_norm": 1.5595459938049316,
      "learning_rate": 5.2858399296394026e-05,
      "loss": 0.1121,
      "step": 2145
    },
    {
      "epoch": 1.4155672823218997,
      "grad_norm": 1.1827348470687866,
      "learning_rate": 5.283641160949868e-05,
      "loss": 0.0915,
      "step": 2146
    },
    {
      "epoch": 1.41622691292876,
      "grad_norm": 7.885112762451172,
      "learning_rate": 5.281442392260334e-05,
      "loss": 0.2115,
      "step": 2147
    },
    {
      "epoch": 1.41688654353562,
      "grad_norm": 12.11255168914795,
      "learning_rate": 5.279243623570801e-05,
      "loss": 1.3154,
      "step": 2148
    },
    {
      "epoch": 1.4175461741424802,
      "grad_norm": 0.520863950252533,
      "learning_rate": 5.277044854881267e-05,
      "loss": 0.0546,
      "step": 2149
    },
    {
      "epoch": 1.4182058047493404,
      "grad_norm": 1.9622747898101807,
      "learning_rate": 5.2748460861917324e-05,
      "loss": 0.1295,
      "step": 2150
    },
    {
      "epoch": 1.4188654353562005,
      "grad_norm": 2.4015684127807617,
      "learning_rate": 5.2726473175021995e-05,
      "loss": 0.158,
      "step": 2151
    },
    {
      "epoch": 1.4195250659630607,
      "grad_norm": 6.140277862548828,
      "learning_rate": 5.270448548812665e-05,
      "loss": 0.764,
      "step": 2152
    },
    {
      "epoch": 1.4201846965699207,
      "grad_norm": 2.661505699157715,
      "learning_rate": 5.268249780123131e-05,
      "loss": 0.1145,
      "step": 2153
    },
    {
      "epoch": 1.420844327176781,
      "grad_norm": 1.4617425203323364,
      "learning_rate": 5.266051011433597e-05,
      "loss": 0.0844,
      "step": 2154
    },
    {
      "epoch": 1.4215039577836412,
      "grad_norm": 11.52781867980957,
      "learning_rate": 5.263852242744064e-05,
      "loss": 0.4249,
      "step": 2155
    },
    {
      "epoch": 1.4221635883905013,
      "grad_norm": 10.105535507202148,
      "learning_rate": 5.26165347405453e-05,
      "loss": 0.2292,
      "step": 2156
    },
    {
      "epoch": 1.4228232189973615,
      "grad_norm": 1.6067144870758057,
      "learning_rate": 5.259454705364996e-05,
      "loss": 0.0769,
      "step": 2157
    },
    {
      "epoch": 1.4234828496042216,
      "grad_norm": 11.190357208251953,
      "learning_rate": 5.2572559366754614e-05,
      "loss": 0.4405,
      "step": 2158
    },
    {
      "epoch": 1.4241424802110818,
      "grad_norm": 14.636306762695312,
      "learning_rate": 5.2550571679859284e-05,
      "loss": 0.3608,
      "step": 2159
    },
    {
      "epoch": 1.424802110817942,
      "grad_norm": 4.849570274353027,
      "learning_rate": 5.252858399296394e-05,
      "loss": 0.2081,
      "step": 2160
    },
    {
      "epoch": 1.425461741424802,
      "grad_norm": 1.9842095375061035,
      "learning_rate": 5.25065963060686e-05,
      "loss": 0.172,
      "step": 2161
    },
    {
      "epoch": 1.4261213720316623,
      "grad_norm": 1.9079328775405884,
      "learning_rate": 5.248460861917327e-05,
      "loss": 0.0849,
      "step": 2162
    },
    {
      "epoch": 1.4267810026385224,
      "grad_norm": 1.254634141921997,
      "learning_rate": 5.2462620932277926e-05,
      "loss": 0.077,
      "step": 2163
    },
    {
      "epoch": 1.4274406332453826,
      "grad_norm": 0.41173821687698364,
      "learning_rate": 5.244063324538259e-05,
      "loss": 0.0546,
      "step": 2164
    },
    {
      "epoch": 1.4281002638522429,
      "grad_norm": 1.105255365371704,
      "learning_rate": 5.2418645558487247e-05,
      "loss": 0.1025,
      "step": 2165
    },
    {
      "epoch": 1.428759894459103,
      "grad_norm": 9.474762916564941,
      "learning_rate": 5.239665787159192e-05,
      "loss": 0.4754,
      "step": 2166
    },
    {
      "epoch": 1.429419525065963,
      "grad_norm": 2.2263286113739014,
      "learning_rate": 5.2374670184696574e-05,
      "loss": 0.1415,
      "step": 2167
    },
    {
      "epoch": 1.4300791556728232,
      "grad_norm": 1.806537389755249,
      "learning_rate": 5.235268249780123e-05,
      "loss": 0.1324,
      "step": 2168
    },
    {
      "epoch": 1.4307387862796834,
      "grad_norm": 3.603795051574707,
      "learning_rate": 5.23306948109059e-05,
      "loss": 0.1584,
      "step": 2169
    },
    {
      "epoch": 1.4313984168865435,
      "grad_norm": 0.6599985361099243,
      "learning_rate": 5.230870712401056e-05,
      "loss": 0.0599,
      "step": 2170
    },
    {
      "epoch": 1.4320580474934037,
      "grad_norm": 1.9257155656814575,
      "learning_rate": 5.2286719437115216e-05,
      "loss": 0.1421,
      "step": 2171
    },
    {
      "epoch": 1.4327176781002637,
      "grad_norm": 14.5894136428833,
      "learning_rate": 5.226473175021987e-05,
      "loss": 0.6107,
      "step": 2172
    },
    {
      "epoch": 1.433377308707124,
      "grad_norm": 1.3982967138290405,
      "learning_rate": 5.224274406332454e-05,
      "loss": 0.1145,
      "step": 2173
    },
    {
      "epoch": 1.4340369393139842,
      "grad_norm": 1.6877540349960327,
      "learning_rate": 5.22207563764292e-05,
      "loss": 0.144,
      "step": 2174
    },
    {
      "epoch": 1.4346965699208443,
      "grad_norm": 1.3612040281295776,
      "learning_rate": 5.2198768689533864e-05,
      "loss": 0.0815,
      "step": 2175
    },
    {
      "epoch": 1.4353562005277045,
      "grad_norm": 4.380431652069092,
      "learning_rate": 5.217678100263852e-05,
      "loss": 0.1846,
      "step": 2176
    },
    {
      "epoch": 1.4360158311345645,
      "grad_norm": 19.60184669494629,
      "learning_rate": 5.215479331574319e-05,
      "loss": 1.0869,
      "step": 2177
    },
    {
      "epoch": 1.4366754617414248,
      "grad_norm": 1.4588956832885742,
      "learning_rate": 5.213280562884785e-05,
      "loss": 0.0872,
      "step": 2178
    },
    {
      "epoch": 1.437335092348285,
      "grad_norm": 7.049965858459473,
      "learning_rate": 5.2110817941952505e-05,
      "loss": 0.4303,
      "step": 2179
    },
    {
      "epoch": 1.437994722955145,
      "grad_norm": 0.5254892110824585,
      "learning_rate": 5.2088830255057176e-05,
      "loss": 0.0473,
      "step": 2180
    },
    {
      "epoch": 1.4386543535620053,
      "grad_norm": 1.3236372470855713,
      "learning_rate": 5.206684256816183e-05,
      "loss": 0.0824,
      "step": 2181
    },
    {
      "epoch": 1.4393139841688654,
      "grad_norm": 1.3579524755477905,
      "learning_rate": 5.204485488126649e-05,
      "loss": 0.1069,
      "step": 2182
    },
    {
      "epoch": 1.4399736147757256,
      "grad_norm": 9.444108009338379,
      "learning_rate": 5.202286719437115e-05,
      "loss": 0.4774,
      "step": 2183
    },
    {
      "epoch": 1.4406332453825859,
      "grad_norm": 17.40918731689453,
      "learning_rate": 5.200087950747582e-05,
      "loss": 0.4918,
      "step": 2184
    },
    {
      "epoch": 1.4412928759894459,
      "grad_norm": 4.666824817657471,
      "learning_rate": 5.1978891820580474e-05,
      "loss": 0.1402,
      "step": 2185
    },
    {
      "epoch": 1.4419525065963061,
      "grad_norm": 5.49526309967041,
      "learning_rate": 5.195690413368514e-05,
      "loss": 0.3373,
      "step": 2186
    },
    {
      "epoch": 1.4426121372031662,
      "grad_norm": 5.268027305603027,
      "learning_rate": 5.193491644678981e-05,
      "loss": 0.1369,
      "step": 2187
    },
    {
      "epoch": 1.4432717678100264,
      "grad_norm": 3.5571775436401367,
      "learning_rate": 5.1912928759894466e-05,
      "loss": 0.1575,
      "step": 2188
    },
    {
      "epoch": 1.4439313984168867,
      "grad_norm": 0.814298152923584,
      "learning_rate": 5.189094107299912e-05,
      "loss": 0.0573,
      "step": 2189
    },
    {
      "epoch": 1.4445910290237467,
      "grad_norm": 1.3905375003814697,
      "learning_rate": 5.186895338610378e-05,
      "loss": 0.1382,
      "step": 2190
    },
    {
      "epoch": 1.4452506596306067,
      "grad_norm": 1.1195919513702393,
      "learning_rate": 5.184696569920845e-05,
      "loss": 0.0942,
      "step": 2191
    },
    {
      "epoch": 1.445910290237467,
      "grad_norm": 0.9385898113250732,
      "learning_rate": 5.182497801231311e-05,
      "loss": 0.0721,
      "step": 2192
    },
    {
      "epoch": 1.4465699208443272,
      "grad_norm": 16.765317916870117,
      "learning_rate": 5.1802990325417764e-05,
      "loss": 0.9727,
      "step": 2193
    },
    {
      "epoch": 1.4472295514511873,
      "grad_norm": 0.71454918384552,
      "learning_rate": 5.178100263852243e-05,
      "loss": 0.077,
      "step": 2194
    },
    {
      "epoch": 1.4478891820580475,
      "grad_norm": 16.013837814331055,
      "learning_rate": 5.175901495162709e-05,
      "loss": 0.5118,
      "step": 2195
    },
    {
      "epoch": 1.4485488126649075,
      "grad_norm": 11.044709205627441,
      "learning_rate": 5.1737027264731755e-05,
      "loss": 0.6014,
      "step": 2196
    },
    {
      "epoch": 1.4492084432717678,
      "grad_norm": 0.5086321830749512,
      "learning_rate": 5.171503957783641e-05,
      "loss": 0.0562,
      "step": 2197
    },
    {
      "epoch": 1.449868073878628,
      "grad_norm": 0.6019864082336426,
      "learning_rate": 5.169305189094108e-05,
      "loss": 0.0689,
      "step": 2198
    },
    {
      "epoch": 1.450527704485488,
      "grad_norm": 1.020114779472351,
      "learning_rate": 5.167106420404574e-05,
      "loss": 0.0881,
      "step": 2199
    },
    {
      "epoch": 1.4511873350923483,
      "grad_norm": 12.588130950927734,
      "learning_rate": 5.16490765171504e-05,
      "loss": 0.4224,
      "step": 2200
    },
    {
      "epoch": 1.4518469656992083,
      "grad_norm": 0.6028808355331421,
      "learning_rate": 5.1627088830255054e-05,
      "loss": 0.0745,
      "step": 2201
    },
    {
      "epoch": 1.4525065963060686,
      "grad_norm": 1.4868069887161255,
      "learning_rate": 5.1605101143359724e-05,
      "loss": 0.0711,
      "step": 2202
    },
    {
      "epoch": 1.4531662269129288,
      "grad_norm": 10.714326858520508,
      "learning_rate": 5.158311345646438e-05,
      "loss": 0.4661,
      "step": 2203
    },
    {
      "epoch": 1.4538258575197889,
      "grad_norm": 8.104083061218262,
      "learning_rate": 5.156112576956904e-05,
      "loss": 0.4814,
      "step": 2204
    },
    {
      "epoch": 1.4544854881266491,
      "grad_norm": 6.824552059173584,
      "learning_rate": 5.153913808267371e-05,
      "loss": 0.253,
      "step": 2205
    },
    {
      "epoch": 1.4551451187335092,
      "grad_norm": 13.220370292663574,
      "learning_rate": 5.1517150395778366e-05,
      "loss": 0.5996,
      "step": 2206
    },
    {
      "epoch": 1.4558047493403694,
      "grad_norm": 1.7900720834732056,
      "learning_rate": 5.149516270888303e-05,
      "loss": 0.126,
      "step": 2207
    },
    {
      "epoch": 1.4564643799472297,
      "grad_norm": 0.7354932427406311,
      "learning_rate": 5.1473175021987686e-05,
      "loss": 0.0807,
      "step": 2208
    },
    {
      "epoch": 1.4571240105540897,
      "grad_norm": 5.373973846435547,
      "learning_rate": 5.145118733509236e-05,
      "loss": 0.95,
      "step": 2209
    },
    {
      "epoch": 1.45778364116095,
      "grad_norm": 1.1437575817108154,
      "learning_rate": 5.1429199648197014e-05,
      "loss": 0.0784,
      "step": 2210
    },
    {
      "epoch": 1.45844327176781,
      "grad_norm": 13.201166152954102,
      "learning_rate": 5.140721196130167e-05,
      "loss": 0.414,
      "step": 2211
    },
    {
      "epoch": 1.4591029023746702,
      "grad_norm": 3.3301210403442383,
      "learning_rate": 5.138522427440633e-05,
      "loss": 0.1354,
      "step": 2212
    },
    {
      "epoch": 1.4597625329815305,
      "grad_norm": 1.1695626974105835,
      "learning_rate": 5.1363236587511e-05,
      "loss": 0.0713,
      "step": 2213
    },
    {
      "epoch": 1.4604221635883905,
      "grad_norm": 2.3978583812713623,
      "learning_rate": 5.1341248900615655e-05,
      "loss": 0.1207,
      "step": 2214
    },
    {
      "epoch": 1.4610817941952505,
      "grad_norm": 1.0483057498931885,
      "learning_rate": 5.131926121372031e-05,
      "loss": 0.0974,
      "step": 2215
    },
    {
      "epoch": 1.4617414248021108,
      "grad_norm": 1.2899307012557983,
      "learning_rate": 5.129727352682498e-05,
      "loss": 0.0888,
      "step": 2216
    },
    {
      "epoch": 1.462401055408971,
      "grad_norm": 7.460480690002441,
      "learning_rate": 5.127528583992964e-05,
      "loss": 0.5878,
      "step": 2217
    },
    {
      "epoch": 1.463060686015831,
      "grad_norm": 0.8565948605537415,
      "learning_rate": 5.1253298153034304e-05,
      "loss": 0.072,
      "step": 2218
    },
    {
      "epoch": 1.4637203166226913,
      "grad_norm": 15.223691940307617,
      "learning_rate": 5.123131046613896e-05,
      "loss": 0.4354,
      "step": 2219
    },
    {
      "epoch": 1.4643799472295513,
      "grad_norm": 1.7161868810653687,
      "learning_rate": 5.120932277924363e-05,
      "loss": 0.1071,
      "step": 2220
    },
    {
      "epoch": 1.4650395778364116,
      "grad_norm": 1.713097333908081,
      "learning_rate": 5.118733509234829e-05,
      "loss": 0.1246,
      "step": 2221
    },
    {
      "epoch": 1.4656992084432718,
      "grad_norm": 9.816577911376953,
      "learning_rate": 5.1165347405452945e-05,
      "loss": 1.178,
      "step": 2222
    },
    {
      "epoch": 1.4663588390501319,
      "grad_norm": 13.152215957641602,
      "learning_rate": 5.1143359718557616e-05,
      "loss": 0.505,
      "step": 2223
    },
    {
      "epoch": 1.4670184696569921,
      "grad_norm": 6.486224174499512,
      "learning_rate": 5.112137203166227e-05,
      "loss": 0.2837,
      "step": 2224
    },
    {
      "epoch": 1.4676781002638521,
      "grad_norm": 4.04146671295166,
      "learning_rate": 5.109938434476693e-05,
      "loss": 0.2157,
      "step": 2225
    },
    {
      "epoch": 1.4683377308707124,
      "grad_norm": 1.1332401037216187,
      "learning_rate": 5.1077396657871593e-05,
      "loss": 0.0738,
      "step": 2226
    },
    {
      "epoch": 1.4689973614775726,
      "grad_norm": 1.2677913904190063,
      "learning_rate": 5.105540897097626e-05,
      "loss": 0.1262,
      "step": 2227
    },
    {
      "epoch": 1.4696569920844327,
      "grad_norm": 1.458612084388733,
      "learning_rate": 5.103342128408092e-05,
      "loss": 0.0903,
      "step": 2228
    },
    {
      "epoch": 1.470316622691293,
      "grad_norm": 1.2764856815338135,
      "learning_rate": 5.101143359718558e-05,
      "loss": 0.0863,
      "step": 2229
    },
    {
      "epoch": 1.470976253298153,
      "grad_norm": 5.035417079925537,
      "learning_rate": 5.0989445910290235e-05,
      "loss": 0.2101,
      "step": 2230
    },
    {
      "epoch": 1.4716358839050132,
      "grad_norm": 1.1046745777130127,
      "learning_rate": 5.0967458223394905e-05,
      "loss": 0.0848,
      "step": 2231
    },
    {
      "epoch": 1.4722955145118735,
      "grad_norm": 0.8963395953178406,
      "learning_rate": 5.094547053649956e-05,
      "loss": 0.0884,
      "step": 2232
    },
    {
      "epoch": 1.4729551451187335,
      "grad_norm": 1.3445461988449097,
      "learning_rate": 5.092348284960422e-05,
      "loss": 0.1127,
      "step": 2233
    },
    {
      "epoch": 1.4736147757255937,
      "grad_norm": 17.055971145629883,
      "learning_rate": 5.090149516270889e-05,
      "loss": 0.7873,
      "step": 2234
    },
    {
      "epoch": 1.4742744063324538,
      "grad_norm": 9.446414947509766,
      "learning_rate": 5.087950747581355e-05,
      "loss": 0.4114,
      "step": 2235
    },
    {
      "epoch": 1.474934036939314,
      "grad_norm": 1.36439847946167,
      "learning_rate": 5.0857519788918204e-05,
      "loss": 0.1439,
      "step": 2236
    },
    {
      "epoch": 1.4755936675461743,
      "grad_norm": 2.0637874603271484,
      "learning_rate": 5.083553210202287e-05,
      "loss": 0.1038,
      "step": 2237
    },
    {
      "epoch": 1.4762532981530343,
      "grad_norm": 1.4897042512893677,
      "learning_rate": 5.081354441512753e-05,
      "loss": 0.0788,
      "step": 2238
    },
    {
      "epoch": 1.4769129287598943,
      "grad_norm": 6.824935436248779,
      "learning_rate": 5.0791556728232195e-05,
      "loss": 0.2312,
      "step": 2239
    },
    {
      "epoch": 1.4775725593667546,
      "grad_norm": 0.5915984511375427,
      "learning_rate": 5.076956904133685e-05,
      "loss": 0.0435,
      "step": 2240
    },
    {
      "epoch": 1.4782321899736148,
      "grad_norm": 0.9386722445487976,
      "learning_rate": 5.074758135444152e-05,
      "loss": 0.0436,
      "step": 2241
    },
    {
      "epoch": 1.4788918205804749,
      "grad_norm": 13.323664665222168,
      "learning_rate": 5.072559366754618e-05,
      "loss": 1.2186,
      "step": 2242
    },
    {
      "epoch": 1.479551451187335,
      "grad_norm": 5.213552474975586,
      "learning_rate": 5.070360598065084e-05,
      "loss": 0.2065,
      "step": 2243
    },
    {
      "epoch": 1.4802110817941951,
      "grad_norm": 8.66846752166748,
      "learning_rate": 5.0681618293755494e-05,
      "loss": 0.3055,
      "step": 2244
    },
    {
      "epoch": 1.4808707124010554,
      "grad_norm": 1.598101019859314,
      "learning_rate": 5.0659630606860164e-05,
      "loss": 0.0585,
      "step": 2245
    },
    {
      "epoch": 1.4815303430079156,
      "grad_norm": 5.329833030700684,
      "learning_rate": 5.063764291996482e-05,
      "loss": 0.236,
      "step": 2246
    },
    {
      "epoch": 1.4821899736147757,
      "grad_norm": 5.241227626800537,
      "learning_rate": 5.061565523306948e-05,
      "loss": 0.1638,
      "step": 2247
    },
    {
      "epoch": 1.482849604221636,
      "grad_norm": 0.8096141219139099,
      "learning_rate": 5.059366754617414e-05,
      "loss": 0.0534,
      "step": 2248
    },
    {
      "epoch": 1.483509234828496,
      "grad_norm": 1.5236668586730957,
      "learning_rate": 5.0571679859278806e-05,
      "loss": 0.0906,
      "step": 2249
    },
    {
      "epoch": 1.4841688654353562,
      "grad_norm": 0.6306918859481812,
      "learning_rate": 5.054969217238347e-05,
      "loss": 0.051,
      "step": 2250
    },
    {
      "epoch": 1.4848284960422165,
      "grad_norm": 18.476749420166016,
      "learning_rate": 5.0527704485488126e-05,
      "loss": 0.9344,
      "step": 2251
    },
    {
      "epoch": 1.4854881266490765,
      "grad_norm": 9.107068061828613,
      "learning_rate": 5.05057167985928e-05,
      "loss": 0.4404,
      "step": 2252
    },
    {
      "epoch": 1.4861477572559367,
      "grad_norm": 0.9966137409210205,
      "learning_rate": 5.0483729111697454e-05,
      "loss": 0.0646,
      "step": 2253
    },
    {
      "epoch": 1.4868073878627968,
      "grad_norm": 5.148456573486328,
      "learning_rate": 5.046174142480211e-05,
      "loss": 0.162,
      "step": 2254
    },
    {
      "epoch": 1.487467018469657,
      "grad_norm": 1.2055217027664185,
      "learning_rate": 5.043975373790677e-05,
      "loss": 0.069,
      "step": 2255
    },
    {
      "epoch": 1.4881266490765173,
      "grad_norm": 0.9915781617164612,
      "learning_rate": 5.041776605101144e-05,
      "loss": 0.0866,
      "step": 2256
    },
    {
      "epoch": 1.4887862796833773,
      "grad_norm": 2.5594370365142822,
      "learning_rate": 5.0395778364116095e-05,
      "loss": 0.1426,
      "step": 2257
    },
    {
      "epoch": 1.4894459102902375,
      "grad_norm": 7.026337146759033,
      "learning_rate": 5.037379067722075e-05,
      "loss": 0.2761,
      "step": 2258
    },
    {
      "epoch": 1.4901055408970976,
      "grad_norm": 14.090832710266113,
      "learning_rate": 5.035180299032542e-05,
      "loss": 0.6434,
      "step": 2259
    },
    {
      "epoch": 1.4907651715039578,
      "grad_norm": 0.5823644399642944,
      "learning_rate": 5.032981530343009e-05,
      "loss": 0.0424,
      "step": 2260
    },
    {
      "epoch": 1.491424802110818,
      "grad_norm": 10.685811996459961,
      "learning_rate": 5.0307827616534744e-05,
      "loss": 0.382,
      "step": 2261
    },
    {
      "epoch": 1.492084432717678,
      "grad_norm": 16.20750617980957,
      "learning_rate": 5.02858399296394e-05,
      "loss": 0.9659,
      "step": 2262
    },
    {
      "epoch": 1.4927440633245381,
      "grad_norm": 15.08320140838623,
      "learning_rate": 5.026385224274407e-05,
      "loss": 0.5418,
      "step": 2263
    },
    {
      "epoch": 1.4934036939313984,
      "grad_norm": 1.5154505968093872,
      "learning_rate": 5.024186455584873e-05,
      "loss": 0.0711,
      "step": 2264
    },
    {
      "epoch": 1.4940633245382586,
      "grad_norm": 1.038133978843689,
      "learning_rate": 5.0219876868953385e-05,
      "loss": 0.1055,
      "step": 2265
    },
    {
      "epoch": 1.4947229551451187,
      "grad_norm": 7.848062038421631,
      "learning_rate": 5.019788918205804e-05,
      "loss": 0.281,
      "step": 2266
    },
    {
      "epoch": 1.495382585751979,
      "grad_norm": 6.302994251251221,
      "learning_rate": 5.017590149516271e-05,
      "loss": 0.1807,
      "step": 2267
    },
    {
      "epoch": 1.496042216358839,
      "grad_norm": 2.4925520420074463,
      "learning_rate": 5.015391380826737e-05,
      "loss": 0.1092,
      "step": 2268
    },
    {
      "epoch": 1.4967018469656992,
      "grad_norm": 1.0522068738937378,
      "learning_rate": 5.0131926121372033e-05,
      "loss": 0.0733,
      "step": 2269
    },
    {
      "epoch": 1.4973614775725594,
      "grad_norm": 1.9293102025985718,
      "learning_rate": 5.01099384344767e-05,
      "loss": 0.1207,
      "step": 2270
    },
    {
      "epoch": 1.4980211081794195,
      "grad_norm": 1.243827223777771,
      "learning_rate": 5.008795074758136e-05,
      "loss": 0.0706,
      "step": 2271
    },
    {
      "epoch": 1.4986807387862797,
      "grad_norm": 15.3422269821167,
      "learning_rate": 5.006596306068602e-05,
      "loss": 0.9275,
      "step": 2272
    },
    {
      "epoch": 1.4993403693931397,
      "grad_norm": 5.910858631134033,
      "learning_rate": 5.0043975373790675e-05,
      "loss": 0.1537,
      "step": 2273
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.547295331954956,
      "learning_rate": 5.0021987686895345e-05,
      "loss": 0.0704,
      "step": 2274
    },
    {
      "epoch": 1.5006596306068603,
      "grad_norm": 0.908210039138794,
      "learning_rate": 5e-05,
      "loss": 0.0652,
      "step": 2275
    },
    {
      "epoch": 1.5013192612137203,
      "grad_norm": 10.100924491882324,
      "learning_rate": 4.9978012313104666e-05,
      "loss": 0.4367,
      "step": 2276
    },
    {
      "epoch": 1.5019788918205803,
      "grad_norm": 6.0360846519470215,
      "learning_rate": 4.995602462620932e-05,
      "loss": 0.5533,
      "step": 2277
    },
    {
      "epoch": 1.5026385224274406,
      "grad_norm": 1.8995440006256104,
      "learning_rate": 4.993403693931399e-05,
      "loss": 0.1271,
      "step": 2278
    },
    {
      "epoch": 1.5032981530343008,
      "grad_norm": 3.009972095489502,
      "learning_rate": 4.9912049252418644e-05,
      "loss": 0.0873,
      "step": 2279
    },
    {
      "epoch": 1.503957783641161,
      "grad_norm": 1.7106515169143677,
      "learning_rate": 4.989006156552331e-05,
      "loss": 0.1046,
      "step": 2280
    },
    {
      "epoch": 1.504617414248021,
      "grad_norm": 0.5636730194091797,
      "learning_rate": 4.986807387862797e-05,
      "loss": 0.0371,
      "step": 2281
    },
    {
      "epoch": 1.5052770448548811,
      "grad_norm": 4.8663482666015625,
      "learning_rate": 4.9846086191732635e-05,
      "loss": 0.1767,
      "step": 2282
    },
    {
      "epoch": 1.5059366754617414,
      "grad_norm": 6.253130912780762,
      "learning_rate": 4.982409850483729e-05,
      "loss": 0.1775,
      "step": 2283
    },
    {
      "epoch": 1.5065963060686016,
      "grad_norm": 6.682820796966553,
      "learning_rate": 4.9802110817941956e-05,
      "loss": 0.1685,
      "step": 2284
    },
    {
      "epoch": 1.5072559366754619,
      "grad_norm": 1.247003197669983,
      "learning_rate": 4.978012313104662e-05,
      "loss": 0.0779,
      "step": 2285
    },
    {
      "epoch": 1.507915567282322,
      "grad_norm": 0.8762010931968689,
      "learning_rate": 4.975813544415128e-05,
      "loss": 0.0708,
      "step": 2286
    },
    {
      "epoch": 1.508575197889182,
      "grad_norm": 0.8424665927886963,
      "learning_rate": 4.973614775725594e-05,
      "loss": 0.0717,
      "step": 2287
    },
    {
      "epoch": 1.5092348284960422,
      "grad_norm": 0.996578574180603,
      "learning_rate": 4.97141600703606e-05,
      "loss": 0.0825,
      "step": 2288
    },
    {
      "epoch": 1.5098944591029024,
      "grad_norm": 10.229948043823242,
      "learning_rate": 4.969217238346526e-05,
      "loss": 1.1203,
      "step": 2289
    },
    {
      "epoch": 1.5105540897097627,
      "grad_norm": 1.8072839975357056,
      "learning_rate": 4.967018469656992e-05,
      "loss": 0.0299,
      "step": 2290
    },
    {
      "epoch": 1.5112137203166227,
      "grad_norm": 1.0149160623550415,
      "learning_rate": 4.964819700967458e-05,
      "loss": 0.0728,
      "step": 2291
    },
    {
      "epoch": 1.5118733509234827,
      "grad_norm": 12.384805679321289,
      "learning_rate": 4.9626209322779246e-05,
      "loss": 1.0322,
      "step": 2292
    },
    {
      "epoch": 1.512532981530343,
      "grad_norm": 1.1665928363800049,
      "learning_rate": 4.960422163588391e-05,
      "loss": 0.0725,
      "step": 2293
    },
    {
      "epoch": 1.5131926121372032,
      "grad_norm": 1.3038430213928223,
      "learning_rate": 4.958223394898857e-05,
      "loss": 0.0636,
      "step": 2294
    },
    {
      "epoch": 1.5138522427440633,
      "grad_norm": 3.598289966583252,
      "learning_rate": 4.956024626209323e-05,
      "loss": 0.1332,
      "step": 2295
    },
    {
      "epoch": 1.5145118733509235,
      "grad_norm": 0.8251930475234985,
      "learning_rate": 4.9538258575197894e-05,
      "loss": 0.0519,
      "step": 2296
    },
    {
      "epoch": 1.5151715039577835,
      "grad_norm": 3.8275418281555176,
      "learning_rate": 4.951627088830255e-05,
      "loss": 0.092,
      "step": 2297
    },
    {
      "epoch": 1.5158311345646438,
      "grad_norm": 21.922765731811523,
      "learning_rate": 4.9494283201407215e-05,
      "loss": 0.8784,
      "step": 2298
    },
    {
      "epoch": 1.516490765171504,
      "grad_norm": 1.0264354944229126,
      "learning_rate": 4.947229551451187e-05,
      "loss": 0.0539,
      "step": 2299
    },
    {
      "epoch": 1.517150395778364,
      "grad_norm": 12.042882919311523,
      "learning_rate": 4.9450307827616535e-05,
      "loss": 0.9202,
      "step": 2300
    },
    {
      "epoch": 1.517810026385224,
      "grad_norm": 18.161388397216797,
      "learning_rate": 4.94283201407212e-05,
      "loss": 1.4738,
      "step": 2301
    },
    {
      "epoch": 1.5184696569920844,
      "grad_norm": 8.4812593460083,
      "learning_rate": 4.940633245382586e-05,
      "loss": 0.1869,
      "step": 2302
    },
    {
      "epoch": 1.5191292875989446,
      "grad_norm": 13.269718170166016,
      "learning_rate": 4.938434476693053e-05,
      "loss": 0.8502,
      "step": 2303
    },
    {
      "epoch": 1.5197889182058049,
      "grad_norm": 13.629351615905762,
      "learning_rate": 4.9362357080035184e-05,
      "loss": 0.4244,
      "step": 2304
    },
    {
      "epoch": 1.520448548812665,
      "grad_norm": 0.7041639089584351,
      "learning_rate": 4.934036939313985e-05,
      "loss": 0.0316,
      "step": 2305
    },
    {
      "epoch": 1.521108179419525,
      "grad_norm": 0.5138291120529175,
      "learning_rate": 4.9318381706244504e-05,
      "loss": 0.0268,
      "step": 2306
    },
    {
      "epoch": 1.5217678100263852,
      "grad_norm": 2.9869213104248047,
      "learning_rate": 4.929639401934917e-05,
      "loss": 0.0851,
      "step": 2307
    },
    {
      "epoch": 1.5224274406332454,
      "grad_norm": 0.5393944978713989,
      "learning_rate": 4.9274406332453825e-05,
      "loss": 0.0362,
      "step": 2308
    },
    {
      "epoch": 1.5230870712401057,
      "grad_norm": 0.9931888580322266,
      "learning_rate": 4.925241864555849e-05,
      "loss": 0.0541,
      "step": 2309
    },
    {
      "epoch": 1.5237467018469657,
      "grad_norm": 0.6008099913597107,
      "learning_rate": 4.9230430958663146e-05,
      "loss": 0.0591,
      "step": 2310
    },
    {
      "epoch": 1.5244063324538257,
      "grad_norm": 4.429568290710449,
      "learning_rate": 4.920844327176781e-05,
      "loss": 0.1222,
      "step": 2311
    },
    {
      "epoch": 1.525065963060686,
      "grad_norm": 9.771464347839355,
      "learning_rate": 4.918645558487247e-05,
      "loss": 0.3003,
      "step": 2312
    },
    {
      "epoch": 1.5257255936675462,
      "grad_norm": 12.000060081481934,
      "learning_rate": 4.916446789797714e-05,
      "loss": 0.986,
      "step": 2313
    },
    {
      "epoch": 1.5263852242744065,
      "grad_norm": 5.716439723968506,
      "learning_rate": 4.91424802110818e-05,
      "loss": 0.2033,
      "step": 2314
    },
    {
      "epoch": 1.5270448548812665,
      "grad_norm": 5.917596817016602,
      "learning_rate": 4.912049252418646e-05,
      "loss": 0.2107,
      "step": 2315
    },
    {
      "epoch": 1.5277044854881265,
      "grad_norm": 0.8304612040519714,
      "learning_rate": 4.909850483729112e-05,
      "loss": 0.0713,
      "step": 2316
    },
    {
      "epoch": 1.5283641160949868,
      "grad_norm": 4.885088920593262,
      "learning_rate": 4.907651715039578e-05,
      "loss": 0.2453,
      "step": 2317
    },
    {
      "epoch": 1.529023746701847,
      "grad_norm": 3.5173697471618652,
      "learning_rate": 4.905452946350044e-05,
      "loss": 0.0834,
      "step": 2318
    },
    {
      "epoch": 1.529683377308707,
      "grad_norm": 7.150053024291992,
      "learning_rate": 4.90325417766051e-05,
      "loss": 0.2668,
      "step": 2319
    },
    {
      "epoch": 1.5303430079155673,
      "grad_norm": 6.1769514083862305,
      "learning_rate": 4.901055408970976e-05,
      "loss": 0.2062,
      "step": 2320
    },
    {
      "epoch": 1.5310026385224274,
      "grad_norm": 1.2158010005950928,
      "learning_rate": 4.898856640281443e-05,
      "loss": 0.0679,
      "step": 2321
    },
    {
      "epoch": 1.5316622691292876,
      "grad_norm": 13.299714088439941,
      "learning_rate": 4.8966578715919084e-05,
      "loss": 0.3021,
      "step": 2322
    },
    {
      "epoch": 1.5323218997361479,
      "grad_norm": 7.494235515594482,
      "learning_rate": 4.894459102902375e-05,
      "loss": 0.3224,
      "step": 2323
    },
    {
      "epoch": 1.5329815303430079,
      "grad_norm": 1.310422420501709,
      "learning_rate": 4.892260334212841e-05,
      "loss": 0.0709,
      "step": 2324
    },
    {
      "epoch": 1.533641160949868,
      "grad_norm": 4.600574016571045,
      "learning_rate": 4.8900615655233075e-05,
      "loss": 0.2141,
      "step": 2325
    },
    {
      "epoch": 1.5343007915567282,
      "grad_norm": 5.604648590087891,
      "learning_rate": 4.887862796833773e-05,
      "loss": 0.5489,
      "step": 2326
    },
    {
      "epoch": 1.5349604221635884,
      "grad_norm": 10.8132963180542,
      "learning_rate": 4.8856640281442396e-05,
      "loss": 0.6199,
      "step": 2327
    },
    {
      "epoch": 1.5356200527704487,
      "grad_norm": 0.7417625188827515,
      "learning_rate": 4.883465259454705e-05,
      "loss": 0.0725,
      "step": 2328
    },
    {
      "epoch": 1.5362796833773087,
      "grad_norm": 1.4941174983978271,
      "learning_rate": 4.8812664907651717e-05,
      "loss": 0.1162,
      "step": 2329
    },
    {
      "epoch": 1.5369393139841687,
      "grad_norm": 6.561717987060547,
      "learning_rate": 4.879067722075638e-05,
      "loss": 0.6918,
      "step": 2330
    },
    {
      "epoch": 1.537598944591029,
      "grad_norm": 7.875882625579834,
      "learning_rate": 4.876868953386104e-05,
      "loss": 0.329,
      "step": 2331
    },
    {
      "epoch": 1.5382585751978892,
      "grad_norm": 8.833364486694336,
      "learning_rate": 4.87467018469657e-05,
      "loss": 0.3891,
      "step": 2332
    },
    {
      "epoch": 1.5389182058047495,
      "grad_norm": 1.9404109716415405,
      "learning_rate": 4.8724714160070365e-05,
      "loss": 0.1622,
      "step": 2333
    },
    {
      "epoch": 1.5395778364116095,
      "grad_norm": 1.9199810028076172,
      "learning_rate": 4.870272647317503e-05,
      "loss": 0.1651,
      "step": 2334
    },
    {
      "epoch": 1.5402374670184695,
      "grad_norm": 9.738041877746582,
      "learning_rate": 4.8680738786279686e-05,
      "loss": 0.3992,
      "step": 2335
    },
    {
      "epoch": 1.5408970976253298,
      "grad_norm": 1.6896867752075195,
      "learning_rate": 4.865875109938435e-05,
      "loss": 0.1004,
      "step": 2336
    },
    {
      "epoch": 1.54155672823219,
      "grad_norm": 1.4532808065414429,
      "learning_rate": 4.8636763412489006e-05,
      "loss": 0.1312,
      "step": 2337
    },
    {
      "epoch": 1.5422163588390503,
      "grad_norm": 2.1008903980255127,
      "learning_rate": 4.861477572559367e-05,
      "loss": 0.1826,
      "step": 2338
    },
    {
      "epoch": 1.5428759894459103,
      "grad_norm": 4.001367092132568,
      "learning_rate": 4.8592788038698334e-05,
      "loss": 0.3294,
      "step": 2339
    },
    {
      "epoch": 1.5435356200527703,
      "grad_norm": 0.700102686882019,
      "learning_rate": 4.857080035180299e-05,
      "loss": 0.0652,
      "step": 2340
    },
    {
      "epoch": 1.5441952506596306,
      "grad_norm": 1.9334663152694702,
      "learning_rate": 4.8548812664907655e-05,
      "loss": 0.1388,
      "step": 2341
    },
    {
      "epoch": 1.5448548812664908,
      "grad_norm": 8.054636001586914,
      "learning_rate": 4.852682497801231e-05,
      "loss": 0.2518,
      "step": 2342
    },
    {
      "epoch": 1.5455145118733509,
      "grad_norm": 2.2946255207061768,
      "learning_rate": 4.8504837291116975e-05,
      "loss": 0.1492,
      "step": 2343
    },
    {
      "epoch": 1.5461741424802111,
      "grad_norm": 8.234186172485352,
      "learning_rate": 4.848284960422164e-05,
      "loss": 0.9131,
      "step": 2344
    },
    {
      "epoch": 1.5468337730870712,
      "grad_norm": 1.8100707530975342,
      "learning_rate": 4.84608619173263e-05,
      "loss": 0.1059,
      "step": 2345
    },
    {
      "epoch": 1.5474934036939314,
      "grad_norm": 8.73625659942627,
      "learning_rate": 4.843887423043096e-05,
      "loss": 0.3016,
      "step": 2346
    },
    {
      "epoch": 1.5481530343007917,
      "grad_norm": 5.8648881912231445,
      "learning_rate": 4.8416886543535624e-05,
      "loss": 0.7749,
      "step": 2347
    },
    {
      "epoch": 1.5488126649076517,
      "grad_norm": 0.8962982892990112,
      "learning_rate": 4.839489885664029e-05,
      "loss": 0.064,
      "step": 2348
    },
    {
      "epoch": 1.5494722955145117,
      "grad_norm": 9.00979232788086,
      "learning_rate": 4.8372911169744944e-05,
      "loss": 0.9181,
      "step": 2349
    },
    {
      "epoch": 1.550131926121372,
      "grad_norm": 1.4561200141906738,
      "learning_rate": 4.835092348284961e-05,
      "loss": 0.0765,
      "step": 2350
    },
    {
      "epoch": 1.5507915567282322,
      "grad_norm": 6.837806224822998,
      "learning_rate": 4.8328935795954265e-05,
      "loss": 0.608,
      "step": 2351
    },
    {
      "epoch": 1.5514511873350925,
      "grad_norm": 3.1646480560302734,
      "learning_rate": 4.830694810905893e-05,
      "loss": 0.1796,
      "step": 2352
    },
    {
      "epoch": 1.5521108179419525,
      "grad_norm": 5.68800163269043,
      "learning_rate": 4.8284960422163586e-05,
      "loss": 0.1983,
      "step": 2353
    },
    {
      "epoch": 1.5527704485488125,
      "grad_norm": 0.8527751564979553,
      "learning_rate": 4.826297273526825e-05,
      "loss": 0.0683,
      "step": 2354
    },
    {
      "epoch": 1.5534300791556728,
      "grad_norm": 1.2626349925994873,
      "learning_rate": 4.824098504837291e-05,
      "loss": 0.0637,
      "step": 2355
    },
    {
      "epoch": 1.554089709762533,
      "grad_norm": 1.6644564867019653,
      "learning_rate": 4.821899736147758e-05,
      "loss": 0.1101,
      "step": 2356
    },
    {
      "epoch": 1.5547493403693933,
      "grad_norm": 5.553350448608398,
      "learning_rate": 4.819700967458224e-05,
      "loss": 0.2483,
      "step": 2357
    },
    {
      "epoch": 1.5554089709762533,
      "grad_norm": 4.447991847991943,
      "learning_rate": 4.81750219876869e-05,
      "loss": 0.2049,
      "step": 2358
    },
    {
      "epoch": 1.5560686015831133,
      "grad_norm": 1.708503007888794,
      "learning_rate": 4.815303430079156e-05,
      "loss": 0.1106,
      "step": 2359
    },
    {
      "epoch": 1.5567282321899736,
      "grad_norm": 6.935280799865723,
      "learning_rate": 4.813104661389622e-05,
      "loss": 0.1541,
      "step": 2360
    },
    {
      "epoch": 1.5573878627968338,
      "grad_norm": 0.6193588972091675,
      "learning_rate": 4.810905892700088e-05,
      "loss": 0.0622,
      "step": 2361
    },
    {
      "epoch": 1.558047493403694,
      "grad_norm": 7.193621635437012,
      "learning_rate": 4.808707124010554e-05,
      "loss": 0.464,
      "step": 2362
    },
    {
      "epoch": 1.5587071240105541,
      "grad_norm": 0.7448492646217346,
      "learning_rate": 4.80650835532102e-05,
      "loss": 0.0692,
      "step": 2363
    },
    {
      "epoch": 1.5593667546174141,
      "grad_norm": 1.8653287887573242,
      "learning_rate": 4.804309586631486e-05,
      "loss": 0.0762,
      "step": 2364
    },
    {
      "epoch": 1.5600263852242744,
      "grad_norm": 5.371467590332031,
      "learning_rate": 4.802110817941953e-05,
      "loss": 0.2148,
      "step": 2365
    },
    {
      "epoch": 1.5606860158311346,
      "grad_norm": 6.117524147033691,
      "learning_rate": 4.7999120492524194e-05,
      "loss": 0.2416,
      "step": 2366
    },
    {
      "epoch": 1.5613456464379947,
      "grad_norm": 3.5568108558654785,
      "learning_rate": 4.797713280562885e-05,
      "loss": 0.158,
      "step": 2367
    },
    {
      "epoch": 1.562005277044855,
      "grad_norm": 1.21016263961792,
      "learning_rate": 4.7955145118733515e-05,
      "loss": 0.0967,
      "step": 2368
    },
    {
      "epoch": 1.562664907651715,
      "grad_norm": 1.319257378578186,
      "learning_rate": 4.793315743183817e-05,
      "loss": 0.1146,
      "step": 2369
    },
    {
      "epoch": 1.5633245382585752,
      "grad_norm": 3.671391725540161,
      "learning_rate": 4.7911169744942836e-05,
      "loss": 0.1455,
      "step": 2370
    },
    {
      "epoch": 1.5639841688654355,
      "grad_norm": 2.608637809753418,
      "learning_rate": 4.788918205804749e-05,
      "loss": 0.1426,
      "step": 2371
    },
    {
      "epoch": 1.5646437994722955,
      "grad_norm": 1.0113335847854614,
      "learning_rate": 4.7867194371152156e-05,
      "loss": 0.0935,
      "step": 2372
    },
    {
      "epoch": 1.5653034300791555,
      "grad_norm": 2.371694803237915,
      "learning_rate": 4.7845206684256813e-05,
      "loss": 0.1236,
      "step": 2373
    },
    {
      "epoch": 1.5659630606860158,
      "grad_norm": 3.4602298736572266,
      "learning_rate": 4.782321899736148e-05,
      "loss": 0.1028,
      "step": 2374
    },
    {
      "epoch": 1.566622691292876,
      "grad_norm": 0.8590801954269409,
      "learning_rate": 4.780123131046614e-05,
      "loss": 0.1269,
      "step": 2375
    },
    {
      "epoch": 1.5672823218997363,
      "grad_norm": 6.079279899597168,
      "learning_rate": 4.7779243623570805e-05,
      "loss": 0.2368,
      "step": 2376
    },
    {
      "epoch": 1.5679419525065963,
      "grad_norm": 0.9716987609863281,
      "learning_rate": 4.775725593667547e-05,
      "loss": 0.0789,
      "step": 2377
    },
    {
      "epoch": 1.5686015831134563,
      "grad_norm": 0.7441926002502441,
      "learning_rate": 4.7735268249780125e-05,
      "loss": 0.081,
      "step": 2378
    },
    {
      "epoch": 1.5692612137203166,
      "grad_norm": 11.203653335571289,
      "learning_rate": 4.771328056288479e-05,
      "loss": 0.9629,
      "step": 2379
    },
    {
      "epoch": 1.5699208443271768,
      "grad_norm": 1.2170792818069458,
      "learning_rate": 4.7691292875989446e-05,
      "loss": 0.0855,
      "step": 2380
    },
    {
      "epoch": 1.570580474934037,
      "grad_norm": 15.877745628356934,
      "learning_rate": 4.766930518909411e-05,
      "loss": 0.4259,
      "step": 2381
    },
    {
      "epoch": 1.571240105540897,
      "grad_norm": 1.043540596961975,
      "learning_rate": 4.764731750219877e-05,
      "loss": 0.1027,
      "step": 2382
    },
    {
      "epoch": 1.5718997361477571,
      "grad_norm": 1.046480417251587,
      "learning_rate": 4.762532981530343e-05,
      "loss": 0.0863,
      "step": 2383
    },
    {
      "epoch": 1.5725593667546174,
      "grad_norm": 19.399158477783203,
      "learning_rate": 4.7603342128408094e-05,
      "loss": 0.5259,
      "step": 2384
    },
    {
      "epoch": 1.5732189973614776,
      "grad_norm": 0.9327455759048462,
      "learning_rate": 4.758135444151275e-05,
      "loss": 0.0679,
      "step": 2385
    },
    {
      "epoch": 1.5738786279683379,
      "grad_norm": 16.457746505737305,
      "learning_rate": 4.7559366754617415e-05,
      "loss": 0.5322,
      "step": 2386
    },
    {
      "epoch": 1.574538258575198,
      "grad_norm": 7.026054859161377,
      "learning_rate": 4.753737906772208e-05,
      "loss": 0.2488,
      "step": 2387
    },
    {
      "epoch": 1.575197889182058,
      "grad_norm": 9.611860275268555,
      "learning_rate": 4.751539138082674e-05,
      "loss": 0.2553,
      "step": 2388
    },
    {
      "epoch": 1.5758575197889182,
      "grad_norm": 0.7667828798294067,
      "learning_rate": 4.74934036939314e-05,
      "loss": 0.0482,
      "step": 2389
    },
    {
      "epoch": 1.5765171503957784,
      "grad_norm": 6.3420281410217285,
      "learning_rate": 4.7471416007036063e-05,
      "loss": 0.1766,
      "step": 2390
    },
    {
      "epoch": 1.5771767810026385,
      "grad_norm": 16.73732566833496,
      "learning_rate": 4.744942832014072e-05,
      "loss": 1.103,
      "step": 2391
    },
    {
      "epoch": 1.5778364116094987,
      "grad_norm": 0.795627236366272,
      "learning_rate": 4.7427440633245384e-05,
      "loss": 0.06,
      "step": 2392
    },
    {
      "epoch": 1.5784960422163588,
      "grad_norm": 15.732117652893066,
      "learning_rate": 4.740545294635005e-05,
      "loss": 0.6212,
      "step": 2393
    },
    {
      "epoch": 1.579155672823219,
      "grad_norm": 11.383668899536133,
      "learning_rate": 4.7383465259454705e-05,
      "loss": 0.5445,
      "step": 2394
    },
    {
      "epoch": 1.5798153034300793,
      "grad_norm": 5.329684734344482,
      "learning_rate": 4.736147757255937e-05,
      "loss": 0.1373,
      "step": 2395
    },
    {
      "epoch": 1.5804749340369393,
      "grad_norm": 7.661953449249268,
      "learning_rate": 4.7339489885664026e-05,
      "loss": 0.2213,
      "step": 2396
    },
    {
      "epoch": 1.5811345646437993,
      "grad_norm": 0.5498751997947693,
      "learning_rate": 4.7317502198768696e-05,
      "loss": 0.0422,
      "step": 2397
    },
    {
      "epoch": 1.5817941952506596,
      "grad_norm": 2.3425798416137695,
      "learning_rate": 4.729551451187335e-05,
      "loss": 0.1225,
      "step": 2398
    },
    {
      "epoch": 1.5824538258575198,
      "grad_norm": 0.7248629927635193,
      "learning_rate": 4.727352682497802e-05,
      "loss": 0.0985,
      "step": 2399
    },
    {
      "epoch": 1.58311345646438,
      "grad_norm": 1.887866735458374,
      "learning_rate": 4.7251539138082674e-05,
      "loss": 0.091,
      "step": 2400
    },
    {
      "epoch": 1.58377308707124,
      "grad_norm": 1.1934514045715332,
      "learning_rate": 4.722955145118734e-05,
      "loss": 0.1018,
      "step": 2401
    },
    {
      "epoch": 1.5844327176781001,
      "grad_norm": 11.370494842529297,
      "learning_rate": 4.7207563764292e-05,
      "loss": 0.4332,
      "step": 2402
    },
    {
      "epoch": 1.5850923482849604,
      "grad_norm": 0.5069339871406555,
      "learning_rate": 4.718557607739666e-05,
      "loss": 0.0475,
      "step": 2403
    },
    {
      "epoch": 1.5857519788918206,
      "grad_norm": 1.5977786779403687,
      "learning_rate": 4.716358839050132e-05,
      "loss": 0.0868,
      "step": 2404
    },
    {
      "epoch": 1.5864116094986809,
      "grad_norm": 1.3781077861785889,
      "learning_rate": 4.714160070360598e-05,
      "loss": 0.0917,
      "step": 2405
    },
    {
      "epoch": 1.587071240105541,
      "grad_norm": 1.441066026687622,
      "learning_rate": 4.711961301671064e-05,
      "loss": 0.0884,
      "step": 2406
    },
    {
      "epoch": 1.587730870712401,
      "grad_norm": 7.833385467529297,
      "learning_rate": 4.709762532981531e-05,
      "loss": 0.1715,
      "step": 2407
    },
    {
      "epoch": 1.5883905013192612,
      "grad_norm": 4.453969955444336,
      "learning_rate": 4.707563764291997e-05,
      "loss": 0.1341,
      "step": 2408
    },
    {
      "epoch": 1.5890501319261214,
      "grad_norm": 17.020578384399414,
      "learning_rate": 4.705364995602463e-05,
      "loss": 1.8041,
      "step": 2409
    },
    {
      "epoch": 1.5897097625329817,
      "grad_norm": 9.82032299041748,
      "learning_rate": 4.703166226912929e-05,
      "loss": 0.3287,
      "step": 2410
    },
    {
      "epoch": 1.5903693931398417,
      "grad_norm": 0.8361287713050842,
      "learning_rate": 4.7009674582233955e-05,
      "loss": 0.0632,
      "step": 2411
    },
    {
      "epoch": 1.5910290237467017,
      "grad_norm": 17.239593505859375,
      "learning_rate": 4.698768689533861e-05,
      "loss": 0.8042,
      "step": 2412
    },
    {
      "epoch": 1.591688654353562,
      "grad_norm": 12.220970153808594,
      "learning_rate": 4.6965699208443276e-05,
      "loss": 0.3138,
      "step": 2413
    },
    {
      "epoch": 1.5923482849604222,
      "grad_norm": 3.9336888790130615,
      "learning_rate": 4.694371152154793e-05,
      "loss": 0.1216,
      "step": 2414
    },
    {
      "epoch": 1.5930079155672823,
      "grad_norm": 0.5662781000137329,
      "learning_rate": 4.6921723834652596e-05,
      "loss": 0.0384,
      "step": 2415
    },
    {
      "epoch": 1.5936675461741425,
      "grad_norm": 2.317413568496704,
      "learning_rate": 4.6899736147757253e-05,
      "loss": 0.1341,
      "step": 2416
    },
    {
      "epoch": 1.5943271767810026,
      "grad_norm": 2.182670831680298,
      "learning_rate": 4.687774846086192e-05,
      "loss": 0.0985,
      "step": 2417
    },
    {
      "epoch": 1.5949868073878628,
      "grad_norm": 1.6856735944747925,
      "learning_rate": 4.685576077396658e-05,
      "loss": 0.1111,
      "step": 2418
    },
    {
      "epoch": 1.595646437994723,
      "grad_norm": 12.614726066589355,
      "learning_rate": 4.6833773087071245e-05,
      "loss": 0.7662,
      "step": 2419
    },
    {
      "epoch": 1.596306068601583,
      "grad_norm": 3.158236026763916,
      "learning_rate": 4.681178540017591e-05,
      "loss": 0.1059,
      "step": 2420
    },
    {
      "epoch": 1.5969656992084431,
      "grad_norm": 0.7413445115089417,
      "learning_rate": 4.6789797713280565e-05,
      "loss": 0.051,
      "step": 2421
    },
    {
      "epoch": 1.5976253298153034,
      "grad_norm": 11.017072677612305,
      "learning_rate": 4.676781002638523e-05,
      "loss": 0.1453,
      "step": 2422
    },
    {
      "epoch": 1.5982849604221636,
      "grad_norm": 0.9139531850814819,
      "learning_rate": 4.6745822339489886e-05,
      "loss": 0.0682,
      "step": 2423
    },
    {
      "epoch": 1.5989445910290239,
      "grad_norm": 15.8884916305542,
      "learning_rate": 4.672383465259455e-05,
      "loss": 0.4226,
      "step": 2424
    },
    {
      "epoch": 1.599604221635884,
      "grad_norm": 1.3591653108596802,
      "learning_rate": 4.670184696569921e-05,
      "loss": 0.1077,
      "step": 2425
    },
    {
      "epoch": 1.600263852242744,
      "grad_norm": 1.2374836206436157,
      "learning_rate": 4.667985927880387e-05,
      "loss": 0.0763,
      "step": 2426
    },
    {
      "epoch": 1.6009234828496042,
      "grad_norm": 2.0196332931518555,
      "learning_rate": 4.665787159190853e-05,
      "loss": 0.0906,
      "step": 2427
    },
    {
      "epoch": 1.6015831134564644,
      "grad_norm": 15.30390739440918,
      "learning_rate": 4.663588390501319e-05,
      "loss": 0.5126,
      "step": 2428
    },
    {
      "epoch": 1.6022427440633247,
      "grad_norm": 5.596741676330566,
      "learning_rate": 4.6613896218117855e-05,
      "loss": 0.2035,
      "step": 2429
    },
    {
      "epoch": 1.6029023746701847,
      "grad_norm": 5.554468631744385,
      "learning_rate": 4.659190853122252e-05,
      "loss": 0.1678,
      "step": 2430
    },
    {
      "epoch": 1.6035620052770447,
      "grad_norm": 1.3135195970535278,
      "learning_rate": 4.656992084432718e-05,
      "loss": 0.0676,
      "step": 2431
    },
    {
      "epoch": 1.604221635883905,
      "grad_norm": 1.4349361658096313,
      "learning_rate": 4.654793315743184e-05,
      "loss": 0.1083,
      "step": 2432
    },
    {
      "epoch": 1.6048812664907652,
      "grad_norm": 9.486292839050293,
      "learning_rate": 4.6525945470536503e-05,
      "loss": 1.1996,
      "step": 2433
    },
    {
      "epoch": 1.6055408970976255,
      "grad_norm": 0.9310441613197327,
      "learning_rate": 4.650395778364116e-05,
      "loss": 0.0751,
      "step": 2434
    },
    {
      "epoch": 1.6062005277044855,
      "grad_norm": 3.400177240371704,
      "learning_rate": 4.6481970096745824e-05,
      "loss": 0.132,
      "step": 2435
    },
    {
      "epoch": 1.6068601583113455,
      "grad_norm": 1.8704352378845215,
      "learning_rate": 4.645998240985048e-05,
      "loss": 0.1109,
      "step": 2436
    },
    {
      "epoch": 1.6075197889182058,
      "grad_norm": 6.349108695983887,
      "learning_rate": 4.6437994722955145e-05,
      "loss": 0.2509,
      "step": 2437
    },
    {
      "epoch": 1.608179419525066,
      "grad_norm": 15.116804122924805,
      "learning_rate": 4.641600703605981e-05,
      "loss": 0.4622,
      "step": 2438
    },
    {
      "epoch": 1.608839050131926,
      "grad_norm": 0.8939570784568787,
      "learning_rate": 4.639401934916447e-05,
      "loss": 0.0676,
      "step": 2439
    },
    {
      "epoch": 1.6094986807387863,
      "grad_norm": 1.1453279256820679,
      "learning_rate": 4.6372031662269136e-05,
      "loss": 0.0421,
      "step": 2440
    },
    {
      "epoch": 1.6101583113456464,
      "grad_norm": 12.673534393310547,
      "learning_rate": 4.635004397537379e-05,
      "loss": 1.3551,
      "step": 2441
    },
    {
      "epoch": 1.6108179419525066,
      "grad_norm": 0.6883092522621155,
      "learning_rate": 4.632805628847846e-05,
      "loss": 0.065,
      "step": 2442
    },
    {
      "epoch": 1.6114775725593669,
      "grad_norm": 0.3926541209220886,
      "learning_rate": 4.6306068601583114e-05,
      "loss": 0.0346,
      "step": 2443
    },
    {
      "epoch": 1.6121372031662269,
      "grad_norm": 15.700809478759766,
      "learning_rate": 4.628408091468778e-05,
      "loss": 0.3139,
      "step": 2444
    },
    {
      "epoch": 1.612796833773087,
      "grad_norm": 2.122819662094116,
      "learning_rate": 4.6262093227792435e-05,
      "loss": 0.0733,
      "step": 2445
    },
    {
      "epoch": 1.6134564643799472,
      "grad_norm": 0.46782439947128296,
      "learning_rate": 4.62401055408971e-05,
      "loss": 0.0506,
      "step": 2446
    },
    {
      "epoch": 1.6141160949868074,
      "grad_norm": 12.98425006866455,
      "learning_rate": 4.621811785400176e-05,
      "loss": 0.9903,
      "step": 2447
    },
    {
      "epoch": 1.6147757255936677,
      "grad_norm": 0.5767037272453308,
      "learning_rate": 4.619613016710642e-05,
      "loss": 0.0488,
      "step": 2448
    },
    {
      "epoch": 1.6154353562005277,
      "grad_norm": 9.86338996887207,
      "learning_rate": 4.617414248021108e-05,
      "loss": 0.672,
      "step": 2449
    },
    {
      "epoch": 1.6160949868073877,
      "grad_norm": 2.091639757156372,
      "learning_rate": 4.615215479331575e-05,
      "loss": 0.0683,
      "step": 2450
    },
    {
      "epoch": 1.616754617414248,
      "grad_norm": 15.141703605651855,
      "learning_rate": 4.613016710642041e-05,
      "loss": 1.4339,
      "step": 2451
    },
    {
      "epoch": 1.6174142480211082,
      "grad_norm": 8.286322593688965,
      "learning_rate": 4.610817941952507e-05,
      "loss": 0.2516,
      "step": 2452
    },
    {
      "epoch": 1.6180738786279685,
      "grad_norm": 2.372063159942627,
      "learning_rate": 4.608619173262973e-05,
      "loss": 0.1117,
      "step": 2453
    },
    {
      "epoch": 1.6187335092348285,
      "grad_norm": 1.3297529220581055,
      "learning_rate": 4.606420404573439e-05,
      "loss": 0.069,
      "step": 2454
    },
    {
      "epoch": 1.6193931398416885,
      "grad_norm": 0.9648951888084412,
      "learning_rate": 4.604221635883905e-05,
      "loss": 0.0755,
      "step": 2455
    },
    {
      "epoch": 1.6200527704485488,
      "grad_norm": 2.031540632247925,
      "learning_rate": 4.6020228671943716e-05,
      "loss": 0.1155,
      "step": 2456
    },
    {
      "epoch": 1.620712401055409,
      "grad_norm": 3.3007516860961914,
      "learning_rate": 4.599824098504837e-05,
      "loss": 0.1357,
      "step": 2457
    },
    {
      "epoch": 1.6213720316622693,
      "grad_norm": 1.342828631401062,
      "learning_rate": 4.5976253298153036e-05,
      "loss": 0.0855,
      "step": 2458
    },
    {
      "epoch": 1.6220316622691293,
      "grad_norm": 2.3132920265197754,
      "learning_rate": 4.595426561125769e-05,
      "loss": 0.1401,
      "step": 2459
    },
    {
      "epoch": 1.6226912928759893,
      "grad_norm": 0.8880963921546936,
      "learning_rate": 4.593227792436236e-05,
      "loss": 0.0829,
      "step": 2460
    },
    {
      "epoch": 1.6233509234828496,
      "grad_norm": 7.954193592071533,
      "learning_rate": 4.591029023746702e-05,
      "loss": 0.2547,
      "step": 2461
    },
    {
      "epoch": 1.6240105540897098,
      "grad_norm": 0.7589948177337646,
      "learning_rate": 4.5888302550571685e-05,
      "loss": 0.0468,
      "step": 2462
    },
    {
      "epoch": 1.6246701846965699,
      "grad_norm": 2.243619441986084,
      "learning_rate": 4.586631486367634e-05,
      "loss": 0.1236,
      "step": 2463
    },
    {
      "epoch": 1.6253298153034301,
      "grad_norm": 4.158143520355225,
      "learning_rate": 4.5844327176781005e-05,
      "loss": 0.2295,
      "step": 2464
    },
    {
      "epoch": 1.6259894459102902,
      "grad_norm": 1.1601693630218506,
      "learning_rate": 4.582233948988567e-05,
      "loss": 0.0936,
      "step": 2465
    },
    {
      "epoch": 1.6266490765171504,
      "grad_norm": 1.92287278175354,
      "learning_rate": 4.5800351802990326e-05,
      "loss": 0.1434,
      "step": 2466
    },
    {
      "epoch": 1.6273087071240107,
      "grad_norm": 1.6370118856430054,
      "learning_rate": 4.577836411609499e-05,
      "loss": 0.1159,
      "step": 2467
    },
    {
      "epoch": 1.6279683377308707,
      "grad_norm": 1.9354690313339233,
      "learning_rate": 4.575637642919965e-05,
      "loss": 0.1338,
      "step": 2468
    },
    {
      "epoch": 1.6286279683377307,
      "grad_norm": 8.47028923034668,
      "learning_rate": 4.573438874230431e-05,
      "loss": 0.8684,
      "step": 2469
    },
    {
      "epoch": 1.629287598944591,
      "grad_norm": 3.444937229156494,
      "learning_rate": 4.5712401055408974e-05,
      "loss": 0.2302,
      "step": 2470
    },
    {
      "epoch": 1.6299472295514512,
      "grad_norm": 10.461103439331055,
      "learning_rate": 4.569041336851364e-05,
      "loss": 0.7475,
      "step": 2471
    },
    {
      "epoch": 1.6306068601583115,
      "grad_norm": 1.4040899276733398,
      "learning_rate": 4.56684256816183e-05,
      "loss": 0.1348,
      "step": 2472
    },
    {
      "epoch": 1.6312664907651715,
      "grad_norm": 0.6596490740776062,
      "learning_rate": 4.564643799472296e-05,
      "loss": 0.0404,
      "step": 2473
    },
    {
      "epoch": 1.6319261213720315,
      "grad_norm": 2.2003304958343506,
      "learning_rate": 4.562445030782762e-05,
      "loss": 0.1268,
      "step": 2474
    },
    {
      "epoch": 1.6325857519788918,
      "grad_norm": 1.1175638437271118,
      "learning_rate": 4.560246262093228e-05,
      "loss": 0.0783,
      "step": 2475
    },
    {
      "epoch": 1.633245382585752,
      "grad_norm": 4.304882526397705,
      "learning_rate": 4.558047493403694e-05,
      "loss": 0.1407,
      "step": 2476
    },
    {
      "epoch": 1.6339050131926123,
      "grad_norm": 1.272014856338501,
      "learning_rate": 4.55584872471416e-05,
      "loss": 0.0664,
      "step": 2477
    },
    {
      "epoch": 1.6345646437994723,
      "grad_norm": 2.2483527660369873,
      "learning_rate": 4.5536499560246264e-05,
      "loss": 0.1189,
      "step": 2478
    },
    {
      "epoch": 1.6352242744063323,
      "grad_norm": 16.88109016418457,
      "learning_rate": 4.551451187335092e-05,
      "loss": 1.3284,
      "step": 2479
    },
    {
      "epoch": 1.6358839050131926,
      "grad_norm": 1.431603193283081,
      "learning_rate": 4.5492524186455585e-05,
      "loss": 0.1131,
      "step": 2480
    },
    {
      "epoch": 1.6365435356200528,
      "grad_norm": 0.7879180908203125,
      "learning_rate": 4.547053649956025e-05,
      "loss": 0.0543,
      "step": 2481
    },
    {
      "epoch": 1.637203166226913,
      "grad_norm": 3.591834545135498,
      "learning_rate": 4.544854881266491e-05,
      "loss": 0.1786,
      "step": 2482
    },
    {
      "epoch": 1.6378627968337731,
      "grad_norm": 1.0467252731323242,
      "learning_rate": 4.5426561125769576e-05,
      "loss": 0.0702,
      "step": 2483
    },
    {
      "epoch": 1.6385224274406331,
      "grad_norm": 13.697596549987793,
      "learning_rate": 4.540457343887423e-05,
      "loss": 0.4478,
      "step": 2484
    },
    {
      "epoch": 1.6391820580474934,
      "grad_norm": 31.986555099487305,
      "learning_rate": 4.53825857519789e-05,
      "loss": 0.9753,
      "step": 2485
    },
    {
      "epoch": 1.6398416886543536,
      "grad_norm": 5.867708683013916,
      "learning_rate": 4.5360598065083554e-05,
      "loss": 0.1338,
      "step": 2486
    },
    {
      "epoch": 1.6405013192612137,
      "grad_norm": 14.87554931640625,
      "learning_rate": 4.533861037818822e-05,
      "loss": 0.4179,
      "step": 2487
    },
    {
      "epoch": 1.641160949868074,
      "grad_norm": 4.234880447387695,
      "learning_rate": 4.5316622691292875e-05,
      "loss": 0.1153,
      "step": 2488
    },
    {
      "epoch": 1.641820580474934,
      "grad_norm": 13.115401268005371,
      "learning_rate": 4.529463500439754e-05,
      "loss": 0.4186,
      "step": 2489
    },
    {
      "epoch": 1.6424802110817942,
      "grad_norm": 9.861604690551758,
      "learning_rate": 4.52726473175022e-05,
      "loss": 0.4485,
      "step": 2490
    },
    {
      "epoch": 1.6431398416886545,
      "grad_norm": 11.82478141784668,
      "learning_rate": 4.525065963060686e-05,
      "loss": 1.186,
      "step": 2491
    },
    {
      "epoch": 1.6437994722955145,
      "grad_norm": 12.258428573608398,
      "learning_rate": 4.522867194371152e-05,
      "loss": 0.8017,
      "step": 2492
    },
    {
      "epoch": 1.6444591029023745,
      "grad_norm": 2.1318745613098145,
      "learning_rate": 4.5206684256816187e-05,
      "loss": 0.1288,
      "step": 2493
    },
    {
      "epoch": 1.6451187335092348,
      "grad_norm": 1.3315001726150513,
      "learning_rate": 4.518469656992085e-05,
      "loss": 0.0768,
      "step": 2494
    },
    {
      "epoch": 1.645778364116095,
      "grad_norm": 2.0943400859832764,
      "learning_rate": 4.516270888302551e-05,
      "loss": 0.156,
      "step": 2495
    },
    {
      "epoch": 1.6464379947229553,
      "grad_norm": 7.827015399932861,
      "learning_rate": 4.514072119613017e-05,
      "loss": 0.2777,
      "step": 2496
    },
    {
      "epoch": 1.6470976253298153,
      "grad_norm": 12.72603702545166,
      "learning_rate": 4.511873350923483e-05,
      "loss": 0.303,
      "step": 2497
    },
    {
      "epoch": 1.6477572559366753,
      "grad_norm": 1.7918448448181152,
      "learning_rate": 4.509674582233949e-05,
      "loss": 0.1418,
      "step": 2498
    },
    {
      "epoch": 1.6484168865435356,
      "grad_norm": 1.1718218326568604,
      "learning_rate": 4.5074758135444156e-05,
      "loss": 0.1162,
      "step": 2499
    },
    {
      "epoch": 1.6490765171503958,
      "grad_norm": 0.7050497531890869,
      "learning_rate": 4.505277044854881e-05,
      "loss": 0.099,
      "step": 2500
    },
    {
      "epoch": 1.649736147757256,
      "grad_norm": 5.631005764007568,
      "learning_rate": 4.5030782761653476e-05,
      "loss": 0.3012,
      "step": 2501
    },
    {
      "epoch": 1.650395778364116,
      "grad_norm": 1.281540870666504,
      "learning_rate": 4.500879507475813e-05,
      "loss": 0.0846,
      "step": 2502
    },
    {
      "epoch": 1.6510554089709761,
      "grad_norm": 3.084803819656372,
      "learning_rate": 4.4986807387862804e-05,
      "loss": 0.1238,
      "step": 2503
    },
    {
      "epoch": 1.6517150395778364,
      "grad_norm": 0.8374939560890198,
      "learning_rate": 4.496481970096746e-05,
      "loss": 0.0961,
      "step": 2504
    },
    {
      "epoch": 1.6523746701846966,
      "grad_norm": 2.0144264698028564,
      "learning_rate": 4.4942832014072125e-05,
      "loss": 0.131,
      "step": 2505
    },
    {
      "epoch": 1.6530343007915569,
      "grad_norm": 0.7574396133422852,
      "learning_rate": 4.492084432717678e-05,
      "loss": 0.0416,
      "step": 2506
    },
    {
      "epoch": 1.653693931398417,
      "grad_norm": 0.7736021876335144,
      "learning_rate": 4.4898856640281445e-05,
      "loss": 0.0627,
      "step": 2507
    },
    {
      "epoch": 1.654353562005277,
      "grad_norm": 0.7616987228393555,
      "learning_rate": 4.487686895338611e-05,
      "loss": 0.0915,
      "step": 2508
    },
    {
      "epoch": 1.6550131926121372,
      "grad_norm": 1.281001329421997,
      "learning_rate": 4.4854881266490766e-05,
      "loss": 0.0643,
      "step": 2509
    },
    {
      "epoch": 1.6556728232189974,
      "grad_norm": 0.5740297436714172,
      "learning_rate": 4.483289357959543e-05,
      "loss": 0.0764,
      "step": 2510
    },
    {
      "epoch": 1.6563324538258575,
      "grad_norm": 14.294822692871094,
      "learning_rate": 4.481090589270009e-05,
      "loss": 0.6087,
      "step": 2511
    },
    {
      "epoch": 1.6569920844327177,
      "grad_norm": 10.168578147888184,
      "learning_rate": 4.478891820580475e-05,
      "loss": 0.3623,
      "step": 2512
    },
    {
      "epoch": 1.6576517150395778,
      "grad_norm": 8.827664375305176,
      "learning_rate": 4.4766930518909414e-05,
      "loss": 0.6618,
      "step": 2513
    },
    {
      "epoch": 1.658311345646438,
      "grad_norm": 14.709450721740723,
      "learning_rate": 4.474494283201408e-05,
      "loss": 1.3313,
      "step": 2514
    },
    {
      "epoch": 1.6589709762532983,
      "grad_norm": 13.349114418029785,
      "learning_rate": 4.4722955145118735e-05,
      "loss": 0.7271,
      "step": 2515
    },
    {
      "epoch": 1.6596306068601583,
      "grad_norm": 2.1566946506500244,
      "learning_rate": 4.47009674582234e-05,
      "loss": 0.1011,
      "step": 2516
    },
    {
      "epoch": 1.6602902374670183,
      "grad_norm": 8.929227828979492,
      "learning_rate": 4.467897977132806e-05,
      "loss": 0.2846,
      "step": 2517
    },
    {
      "epoch": 1.6609498680738786,
      "grad_norm": 10.82198715209961,
      "learning_rate": 4.465699208443272e-05,
      "loss": 1.0943,
      "step": 2518
    },
    {
      "epoch": 1.6616094986807388,
      "grad_norm": 5.5926032066345215,
      "learning_rate": 4.463500439753738e-05,
      "loss": 0.1754,
      "step": 2519
    },
    {
      "epoch": 1.662269129287599,
      "grad_norm": 11.6847562789917,
      "learning_rate": 4.461301671064204e-05,
      "loss": 0.7629,
      "step": 2520
    },
    {
      "epoch": 1.662928759894459,
      "grad_norm": 0.7477695941925049,
      "learning_rate": 4.4591029023746704e-05,
      "loss": 0.0813,
      "step": 2521
    },
    {
      "epoch": 1.6635883905013191,
      "grad_norm": 1.3815072774887085,
      "learning_rate": 4.456904133685136e-05,
      "loss": 0.0941,
      "step": 2522
    },
    {
      "epoch": 1.6642480211081794,
      "grad_norm": 11.296996116638184,
      "learning_rate": 4.4547053649956025e-05,
      "loss": 0.4628,
      "step": 2523
    },
    {
      "epoch": 1.6649076517150396,
      "grad_norm": 0.6983452439308167,
      "learning_rate": 4.452506596306069e-05,
      "loss": 0.0415,
      "step": 2524
    },
    {
      "epoch": 1.6655672823218999,
      "grad_norm": 12.893380165100098,
      "learning_rate": 4.450307827616535e-05,
      "loss": 1.3342,
      "step": 2525
    },
    {
      "epoch": 1.66622691292876,
      "grad_norm": 7.707539081573486,
      "learning_rate": 4.4481090589270016e-05,
      "loss": 0.2009,
      "step": 2526
    },
    {
      "epoch": 1.66688654353562,
      "grad_norm": 0.989337682723999,
      "learning_rate": 4.445910290237467e-05,
      "loss": 0.0777,
      "step": 2527
    },
    {
      "epoch": 1.6675461741424802,
      "grad_norm": 0.6786738634109497,
      "learning_rate": 4.443711521547934e-05,
      "loss": 0.0504,
      "step": 2528
    },
    {
      "epoch": 1.6682058047493404,
      "grad_norm": 2.7458913326263428,
      "learning_rate": 4.4415127528583994e-05,
      "loss": 0.1407,
      "step": 2529
    },
    {
      "epoch": 1.6688654353562007,
      "grad_norm": 24.44976806640625,
      "learning_rate": 4.439313984168866e-05,
      "loss": 1.1125,
      "step": 2530
    },
    {
      "epoch": 1.6695250659630607,
      "grad_norm": 1.369417428970337,
      "learning_rate": 4.4371152154793314e-05,
      "loss": 0.0791,
      "step": 2531
    },
    {
      "epoch": 1.6701846965699207,
      "grad_norm": 0.7973348498344421,
      "learning_rate": 4.434916446789798e-05,
      "loss": 0.0664,
      "step": 2532
    },
    {
      "epoch": 1.670844327176781,
      "grad_norm": 1.2940335273742676,
      "learning_rate": 4.4327176781002635e-05,
      "loss": 0.1024,
      "step": 2533
    },
    {
      "epoch": 1.6715039577836412,
      "grad_norm": 6.768095970153809,
      "learning_rate": 4.43051890941073e-05,
      "loss": 0.1703,
      "step": 2534
    },
    {
      "epoch": 1.6721635883905013,
      "grad_norm": 8.239306449890137,
      "learning_rate": 4.428320140721196e-05,
      "loss": 0.3575,
      "step": 2535
    },
    {
      "epoch": 1.6728232189973615,
      "grad_norm": 1.1949739456176758,
      "learning_rate": 4.4261213720316626e-05,
      "loss": 0.0867,
      "step": 2536
    },
    {
      "epoch": 1.6734828496042216,
      "grad_norm": 0.9975473880767822,
      "learning_rate": 4.423922603342129e-05,
      "loss": 0.0857,
      "step": 2537
    },
    {
      "epoch": 1.6741424802110818,
      "grad_norm": 1.5669373273849487,
      "learning_rate": 4.421723834652595e-05,
      "loss": 0.1155,
      "step": 2538
    },
    {
      "epoch": 1.674802110817942,
      "grad_norm": 8.666065216064453,
      "learning_rate": 4.419525065963061e-05,
      "loss": 1.1945,
      "step": 2539
    },
    {
      "epoch": 1.675461741424802,
      "grad_norm": 2.4138267040252686,
      "learning_rate": 4.417326297273527e-05,
      "loss": 0.0663,
      "step": 2540
    },
    {
      "epoch": 1.6761213720316621,
      "grad_norm": 1.2192667722702026,
      "learning_rate": 4.415127528583993e-05,
      "loss": 0.0572,
      "step": 2541
    },
    {
      "epoch": 1.6767810026385224,
      "grad_norm": 8.603761672973633,
      "learning_rate": 4.412928759894459e-05,
      "loss": 0.2746,
      "step": 2542
    },
    {
      "epoch": 1.6774406332453826,
      "grad_norm": 5.971922874450684,
      "learning_rate": 4.410729991204925e-05,
      "loss": 0.1504,
      "step": 2543
    },
    {
      "epoch": 1.6781002638522429,
      "grad_norm": 14.08525276184082,
      "learning_rate": 4.4085312225153916e-05,
      "loss": 0.2742,
      "step": 2544
    },
    {
      "epoch": 1.678759894459103,
      "grad_norm": 0.7583642601966858,
      "learning_rate": 4.406332453825858e-05,
      "loss": 0.0376,
      "step": 2545
    },
    {
      "epoch": 1.679419525065963,
      "grad_norm": 3.718419313430786,
      "learning_rate": 4.4041336851363244e-05,
      "loss": 0.1398,
      "step": 2546
    },
    {
      "epoch": 1.6800791556728232,
      "grad_norm": 1.249062180519104,
      "learning_rate": 4.40193491644679e-05,
      "loss": 0.0833,
      "step": 2547
    },
    {
      "epoch": 1.6807387862796834,
      "grad_norm": 1.2441600561141968,
      "learning_rate": 4.3997361477572564e-05,
      "loss": 0.067,
      "step": 2548
    },
    {
      "epoch": 1.6813984168865437,
      "grad_norm": 7.6579813957214355,
      "learning_rate": 4.397537379067722e-05,
      "loss": 0.4156,
      "step": 2549
    },
    {
      "epoch": 1.6820580474934037,
      "grad_norm": 18.106679916381836,
      "learning_rate": 4.3953386103781885e-05,
      "loss": 1.094,
      "step": 2550
    },
    {
      "epoch": 1.6827176781002637,
      "grad_norm": 4.400484085083008,
      "learning_rate": 4.393139841688654e-05,
      "loss": 0.1671,
      "step": 2551
    },
    {
      "epoch": 1.683377308707124,
      "grad_norm": 1.7536531686782837,
      "learning_rate": 4.3909410729991206e-05,
      "loss": 0.1178,
      "step": 2552
    },
    {
      "epoch": 1.6840369393139842,
      "grad_norm": 5.286768436431885,
      "learning_rate": 4.388742304309587e-05,
      "loss": 0.1839,
      "step": 2553
    },
    {
      "epoch": 1.6846965699208445,
      "grad_norm": 2.2363579273223877,
      "learning_rate": 4.386543535620053e-05,
      "loss": 0.1056,
      "step": 2554
    },
    {
      "epoch": 1.6853562005277045,
      "grad_norm": 0.7781772613525391,
      "learning_rate": 4.384344766930519e-05,
      "loss": 0.0595,
      "step": 2555
    },
    {
      "epoch": 1.6860158311345645,
      "grad_norm": 0.4802110195159912,
      "learning_rate": 4.3821459982409854e-05,
      "loss": 0.041,
      "step": 2556
    },
    {
      "epoch": 1.6866754617414248,
      "grad_norm": 6.761916637420654,
      "learning_rate": 4.379947229551452e-05,
      "loss": 0.2056,
      "step": 2557
    },
    {
      "epoch": 1.687335092348285,
      "grad_norm": 6.507123947143555,
      "learning_rate": 4.3777484608619175e-05,
      "loss": 0.2396,
      "step": 2558
    },
    {
      "epoch": 1.687994722955145,
      "grad_norm": 7.311703205108643,
      "learning_rate": 4.375549692172384e-05,
      "loss": 0.3689,
      "step": 2559
    },
    {
      "epoch": 1.6886543535620053,
      "grad_norm": 6.309328556060791,
      "learning_rate": 4.3733509234828496e-05,
      "loss": 0.1772,
      "step": 2560
    },
    {
      "epoch": 1.6893139841688654,
      "grad_norm": 12.586374282836914,
      "learning_rate": 4.371152154793316e-05,
      "loss": 0.3921,
      "step": 2561
    },
    {
      "epoch": 1.6899736147757256,
      "grad_norm": 8.215847969055176,
      "learning_rate": 4.368953386103782e-05,
      "loss": 0.2267,
      "step": 2562
    },
    {
      "epoch": 1.6906332453825859,
      "grad_norm": 13.917643547058105,
      "learning_rate": 4.366754617414248e-05,
      "loss": 0.3149,
      "step": 2563
    },
    {
      "epoch": 1.6912928759894459,
      "grad_norm": 8.018832206726074,
      "learning_rate": 4.3645558487247144e-05,
      "loss": 0.2171,
      "step": 2564
    },
    {
      "epoch": 1.691952506596306,
      "grad_norm": 6.46229362487793,
      "learning_rate": 4.36235708003518e-05,
      "loss": 0.4635,
      "step": 2565
    },
    {
      "epoch": 1.6926121372031662,
      "grad_norm": 5.36085319519043,
      "learning_rate": 4.3601583113456465e-05,
      "loss": 0.2815,
      "step": 2566
    },
    {
      "epoch": 1.6932717678100264,
      "grad_norm": 8.75671672821045,
      "learning_rate": 4.357959542656113e-05,
      "loss": 0.4178,
      "step": 2567
    },
    {
      "epoch": 1.6939313984168867,
      "grad_norm": 1.7740161418914795,
      "learning_rate": 4.355760773966579e-05,
      "loss": 0.1435,
      "step": 2568
    },
    {
      "epoch": 1.6945910290237467,
      "grad_norm": 2.103099822998047,
      "learning_rate": 4.353562005277045e-05,
      "loss": 0.1712,
      "step": 2569
    },
    {
      "epoch": 1.6952506596306067,
      "grad_norm": 1.4882510900497437,
      "learning_rate": 4.351363236587511e-05,
      "loss": 0.1073,
      "step": 2570
    },
    {
      "epoch": 1.695910290237467,
      "grad_norm": 1.655738115310669,
      "learning_rate": 4.349164467897978e-05,
      "loss": 0.1499,
      "step": 2571
    },
    {
      "epoch": 1.6965699208443272,
      "grad_norm": 1.6608147621154785,
      "learning_rate": 4.3469656992084434e-05,
      "loss": 0.1331,
      "step": 2572
    },
    {
      "epoch": 1.6972295514511875,
      "grad_norm": 1.9330220222473145,
      "learning_rate": 4.34476693051891e-05,
      "loss": 0.1551,
      "step": 2573
    },
    {
      "epoch": 1.6978891820580475,
      "grad_norm": 2.6266419887542725,
      "learning_rate": 4.3425681618293754e-05,
      "loss": 0.2541,
      "step": 2574
    },
    {
      "epoch": 1.6985488126649075,
      "grad_norm": 0.9198398590087891,
      "learning_rate": 4.340369393139842e-05,
      "loss": 0.0929,
      "step": 2575
    },
    {
      "epoch": 1.6992084432717678,
      "grad_norm": 1.119309663772583,
      "learning_rate": 4.338170624450308e-05,
      "loss": 0.096,
      "step": 2576
    },
    {
      "epoch": 1.699868073878628,
      "grad_norm": 5.702362537384033,
      "learning_rate": 4.3359718557607746e-05,
      "loss": 0.2937,
      "step": 2577
    },
    {
      "epoch": 1.7005277044854883,
      "grad_norm": 1.73167884349823,
      "learning_rate": 4.33377308707124e-05,
      "loss": 0.1126,
      "step": 2578
    },
    {
      "epoch": 1.7011873350923483,
      "grad_norm": 2.289527654647827,
      "learning_rate": 4.3315743183817066e-05,
      "loss": 0.1232,
      "step": 2579
    },
    {
      "epoch": 1.7018469656992083,
      "grad_norm": 0.8983360528945923,
      "learning_rate": 4.329375549692173e-05,
      "loss": 0.1072,
      "step": 2580
    },
    {
      "epoch": 1.7025065963060686,
      "grad_norm": 2.420640707015991,
      "learning_rate": 4.327176781002639e-05,
      "loss": 0.1327,
      "step": 2581
    },
    {
      "epoch": 1.7031662269129288,
      "grad_norm": 1.376210331916809,
      "learning_rate": 4.324978012313105e-05,
      "loss": 0.093,
      "step": 2582
    },
    {
      "epoch": 1.7038258575197889,
      "grad_norm": 10.805610656738281,
      "learning_rate": 4.322779243623571e-05,
      "loss": 0.4421,
      "step": 2583
    },
    {
      "epoch": 1.7044854881266491,
      "grad_norm": 7.485750675201416,
      "learning_rate": 4.320580474934037e-05,
      "loss": 0.3015,
      "step": 2584
    },
    {
      "epoch": 1.7051451187335092,
      "grad_norm": 0.6805218458175659,
      "learning_rate": 4.318381706244503e-05,
      "loss": 0.0482,
      "step": 2585
    },
    {
      "epoch": 1.7058047493403694,
      "grad_norm": 2.0943331718444824,
      "learning_rate": 4.316182937554969e-05,
      "loss": 0.0946,
      "step": 2586
    },
    {
      "epoch": 1.7064643799472297,
      "grad_norm": 1.6998693943023682,
      "learning_rate": 4.3139841688654356e-05,
      "loss": 0.1153,
      "step": 2587
    },
    {
      "epoch": 1.7071240105540897,
      "grad_norm": 12.101621627807617,
      "learning_rate": 4.311785400175902e-05,
      "loss": 1.0399,
      "step": 2588
    },
    {
      "epoch": 1.7077836411609497,
      "grad_norm": 7.172886371612549,
      "learning_rate": 4.3095866314863684e-05,
      "loss": 0.2844,
      "step": 2589
    },
    {
      "epoch": 1.70844327176781,
      "grad_norm": 8.904382705688477,
      "learning_rate": 4.307387862796834e-05,
      "loss": 0.5426,
      "step": 2590
    },
    {
      "epoch": 1.7091029023746702,
      "grad_norm": 0.7490732669830322,
      "learning_rate": 4.3051890941073004e-05,
      "loss": 0.0519,
      "step": 2591
    },
    {
      "epoch": 1.7097625329815305,
      "grad_norm": 2.1690187454223633,
      "learning_rate": 4.302990325417766e-05,
      "loss": 0.0808,
      "step": 2592
    },
    {
      "epoch": 1.7104221635883905,
      "grad_norm": 10.876364707946777,
      "learning_rate": 4.3007915567282325e-05,
      "loss": 0.6099,
      "step": 2593
    },
    {
      "epoch": 1.7110817941952505,
      "grad_norm": 5.596094608306885,
      "learning_rate": 4.298592788038698e-05,
      "loss": 0.2251,
      "step": 2594
    },
    {
      "epoch": 1.7117414248021108,
      "grad_norm": 14.49308967590332,
      "learning_rate": 4.2963940193491646e-05,
      "loss": 0.4568,
      "step": 2595
    },
    {
      "epoch": 1.712401055408971,
      "grad_norm": 10.943249702453613,
      "learning_rate": 4.29419525065963e-05,
      "loss": 0.4279,
      "step": 2596
    },
    {
      "epoch": 1.7130606860158313,
      "grad_norm": 0.5918543338775635,
      "learning_rate": 4.291996481970097e-05,
      "loss": 0.044,
      "step": 2597
    },
    {
      "epoch": 1.7137203166226913,
      "grad_norm": 0.9395241737365723,
      "learning_rate": 4.289797713280563e-05,
      "loss": 0.0894,
      "step": 2598
    },
    {
      "epoch": 1.7143799472295513,
      "grad_norm": 1.1875436305999756,
      "learning_rate": 4.2875989445910294e-05,
      "loss": 0.066,
      "step": 2599
    },
    {
      "epoch": 1.7150395778364116,
      "grad_norm": 0.9769327640533447,
      "learning_rate": 4.285400175901496e-05,
      "loss": 0.056,
      "step": 2600
    },
    {
      "epoch": 1.7156992084432718,
      "grad_norm": 0.6471913456916809,
      "learning_rate": 4.2832014072119615e-05,
      "loss": 0.0676,
      "step": 2601
    },
    {
      "epoch": 1.716358839050132,
      "grad_norm": 2.711090326309204,
      "learning_rate": 4.281002638522428e-05,
      "loss": 0.1444,
      "step": 2602
    },
    {
      "epoch": 1.7170184696569921,
      "grad_norm": 1.316232442855835,
      "learning_rate": 4.2788038698328936e-05,
      "loss": 0.111,
      "step": 2603
    },
    {
      "epoch": 1.7176781002638521,
      "grad_norm": 3.1348865032196045,
      "learning_rate": 4.27660510114336e-05,
      "loss": 0.1432,
      "step": 2604
    },
    {
      "epoch": 1.7183377308707124,
      "grad_norm": 1.233940601348877,
      "learning_rate": 4.2744063324538256e-05,
      "loss": 0.0691,
      "step": 2605
    },
    {
      "epoch": 1.7189973614775726,
      "grad_norm": 1.6612694263458252,
      "learning_rate": 4.272207563764292e-05,
      "loss": 0.1046,
      "step": 2606
    },
    {
      "epoch": 1.7196569920844327,
      "grad_norm": 22.14520263671875,
      "learning_rate": 4.2700087950747584e-05,
      "loss": 1.0058,
      "step": 2607
    },
    {
      "epoch": 1.720316622691293,
      "grad_norm": 10.273443222045898,
      "learning_rate": 4.267810026385225e-05,
      "loss": 0.3992,
      "step": 2608
    },
    {
      "epoch": 1.720976253298153,
      "grad_norm": 4.0461745262146,
      "learning_rate": 4.265611257695691e-05,
      "loss": 0.1594,
      "step": 2609
    },
    {
      "epoch": 1.7216358839050132,
      "grad_norm": 0.9839915037155151,
      "learning_rate": 4.263412489006157e-05,
      "loss": 0.0771,
      "step": 2610
    },
    {
      "epoch": 1.7222955145118735,
      "grad_norm": 5.2120490074157715,
      "learning_rate": 4.261213720316623e-05,
      "loss": 0.1504,
      "step": 2611
    },
    {
      "epoch": 1.7229551451187335,
      "grad_norm": 1.05793035030365,
      "learning_rate": 4.259014951627089e-05,
      "loss": 0.0902,
      "step": 2612
    },
    {
      "epoch": 1.7236147757255935,
      "grad_norm": 11.49316692352295,
      "learning_rate": 4.256816182937555e-05,
      "loss": 0.4489,
      "step": 2613
    },
    {
      "epoch": 1.7242744063324538,
      "grad_norm": 0.6073595881462097,
      "learning_rate": 4.254617414248021e-05,
      "loss": 0.052,
      "step": 2614
    },
    {
      "epoch": 1.724934036939314,
      "grad_norm": 0.5042135715484619,
      "learning_rate": 4.2524186455584874e-05,
      "loss": 0.0507,
      "step": 2615
    },
    {
      "epoch": 1.7255936675461743,
      "grad_norm": 2.2810239791870117,
      "learning_rate": 4.250219876868954e-05,
      "loss": 0.1297,
      "step": 2616
    },
    {
      "epoch": 1.7262532981530343,
      "grad_norm": 1.2620130777359009,
      "learning_rate": 4.2480211081794194e-05,
      "loss": 0.0847,
      "step": 2617
    },
    {
      "epoch": 1.7269129287598943,
      "grad_norm": 0.8417465090751648,
      "learning_rate": 4.245822339489886e-05,
      "loss": 0.0603,
      "step": 2618
    },
    {
      "epoch": 1.7275725593667546,
      "grad_norm": 1.7699830532073975,
      "learning_rate": 4.243623570800352e-05,
      "loss": 0.0915,
      "step": 2619
    },
    {
      "epoch": 1.7282321899736148,
      "grad_norm": 3.066230535507202,
      "learning_rate": 4.2414248021108186e-05,
      "loss": 0.0936,
      "step": 2620
    },
    {
      "epoch": 1.728891820580475,
      "grad_norm": 0.6381198167800903,
      "learning_rate": 4.239226033421284e-05,
      "loss": 0.0622,
      "step": 2621
    },
    {
      "epoch": 1.729551451187335,
      "grad_norm": 3.4676930904388428,
      "learning_rate": 4.2370272647317506e-05,
      "loss": 0.1053,
      "step": 2622
    },
    {
      "epoch": 1.7302110817941951,
      "grad_norm": 10.607741355895996,
      "learning_rate": 4.234828496042216e-05,
      "loss": 0.5847,
      "step": 2623
    },
    {
      "epoch": 1.7308707124010554,
      "grad_norm": 0.9850299954414368,
      "learning_rate": 4.232629727352683e-05,
      "loss": 0.0956,
      "step": 2624
    },
    {
      "epoch": 1.7315303430079156,
      "grad_norm": 0.8423095345497131,
      "learning_rate": 4.230430958663149e-05,
      "loss": 0.0511,
      "step": 2625
    },
    {
      "epoch": 1.732189973614776,
      "grad_norm": 0.5409525632858276,
      "learning_rate": 4.228232189973615e-05,
      "loss": 0.0392,
      "step": 2626
    },
    {
      "epoch": 1.732849604221636,
      "grad_norm": 1.0424985885620117,
      "learning_rate": 4.226033421284081e-05,
      "loss": 0.0591,
      "step": 2627
    },
    {
      "epoch": 1.733509234828496,
      "grad_norm": 4.210433483123779,
      "learning_rate": 4.223834652594547e-05,
      "loss": 0.1088,
      "step": 2628
    },
    {
      "epoch": 1.7341688654353562,
      "grad_norm": 4.1235151290893555,
      "learning_rate": 4.221635883905013e-05,
      "loss": 0.1059,
      "step": 2629
    },
    {
      "epoch": 1.7348284960422165,
      "grad_norm": 5.043927192687988,
      "learning_rate": 4.2194371152154796e-05,
      "loss": 0.1517,
      "step": 2630
    },
    {
      "epoch": 1.7354881266490765,
      "grad_norm": 10.626886367797852,
      "learning_rate": 4.217238346525946e-05,
      "loss": 0.3868,
      "step": 2631
    },
    {
      "epoch": 1.7361477572559367,
      "grad_norm": 23.443758010864258,
      "learning_rate": 4.215039577836412e-05,
      "loss": 0.2868,
      "step": 2632
    },
    {
      "epoch": 1.7368073878627968,
      "grad_norm": 10.134275436401367,
      "learning_rate": 4.212840809146878e-05,
      "loss": 0.5872,
      "step": 2633
    },
    {
      "epoch": 1.737467018469657,
      "grad_norm": 0.322197288274765,
      "learning_rate": 4.2106420404573444e-05,
      "loss": 0.0358,
      "step": 2634
    },
    {
      "epoch": 1.7381266490765173,
      "grad_norm": 7.565582275390625,
      "learning_rate": 4.20844327176781e-05,
      "loss": 0.2144,
      "step": 2635
    },
    {
      "epoch": 1.7387862796833773,
      "grad_norm": 1.4642237424850464,
      "learning_rate": 4.2062445030782765e-05,
      "loss": 0.0869,
      "step": 2636
    },
    {
      "epoch": 1.7394459102902373,
      "grad_norm": 8.72396469116211,
      "learning_rate": 4.204045734388742e-05,
      "loss": 0.1779,
      "step": 2637
    },
    {
      "epoch": 1.7401055408970976,
      "grad_norm": 0.9683916568756104,
      "learning_rate": 4.2018469656992086e-05,
      "loss": 0.0948,
      "step": 2638
    },
    {
      "epoch": 1.7407651715039578,
      "grad_norm": 17.150806427001953,
      "learning_rate": 4.199648197009674e-05,
      "loss": 0.5844,
      "step": 2639
    },
    {
      "epoch": 1.741424802110818,
      "grad_norm": 3.8970534801483154,
      "learning_rate": 4.1974494283201407e-05,
      "loss": 0.1176,
      "step": 2640
    },
    {
      "epoch": 1.742084432717678,
      "grad_norm": 0.9980224370956421,
      "learning_rate": 4.195250659630607e-05,
      "loss": 0.0572,
      "step": 2641
    },
    {
      "epoch": 1.7427440633245381,
      "grad_norm": 1.3540644645690918,
      "learning_rate": 4.1930518909410734e-05,
      "loss": 0.0997,
      "step": 2642
    },
    {
      "epoch": 1.7434036939313984,
      "grad_norm": 5.575183391571045,
      "learning_rate": 4.19085312225154e-05,
      "loss": 0.1827,
      "step": 2643
    },
    {
      "epoch": 1.7440633245382586,
      "grad_norm": 2.903717279434204,
      "learning_rate": 4.1886543535620055e-05,
      "loss": 0.1214,
      "step": 2644
    },
    {
      "epoch": 1.7447229551451189,
      "grad_norm": 0.6129449605941772,
      "learning_rate": 4.186455584872472e-05,
      "loss": 0.0477,
      "step": 2645
    },
    {
      "epoch": 1.745382585751979,
      "grad_norm": 1.222195029258728,
      "learning_rate": 4.1842568161829376e-05,
      "loss": 0.0594,
      "step": 2646
    },
    {
      "epoch": 1.746042216358839,
      "grad_norm": 12.704477310180664,
      "learning_rate": 4.182058047493404e-05,
      "loss": 0.5973,
      "step": 2647
    },
    {
      "epoch": 1.7467018469656992,
      "grad_norm": 0.7826929092407227,
      "learning_rate": 4.1798592788038696e-05,
      "loss": 0.0552,
      "step": 2648
    },
    {
      "epoch": 1.7473614775725594,
      "grad_norm": 0.5937402844429016,
      "learning_rate": 4.177660510114336e-05,
      "loss": 0.058,
      "step": 2649
    },
    {
      "epoch": 1.7480211081794197,
      "grad_norm": 1.953153371810913,
      "learning_rate": 4.1754617414248024e-05,
      "loss": 0.1485,
      "step": 2650
    },
    {
      "epoch": 1.7486807387862797,
      "grad_norm": 14.84700870513916,
      "learning_rate": 4.173262972735269e-05,
      "loss": 0.1752,
      "step": 2651
    },
    {
      "epoch": 1.7493403693931397,
      "grad_norm": 7.770595550537109,
      "learning_rate": 4.171064204045735e-05,
      "loss": 0.2276,
      "step": 2652
    },
    {
      "epoch": 1.75,
      "grad_norm": 13.301835060119629,
      "learning_rate": 4.168865435356201e-05,
      "loss": 0.2941,
      "step": 2653
    },
    {
      "epoch": 1.7506596306068603,
      "grad_norm": 2.5046613216400146,
      "learning_rate": 4.166666666666667e-05,
      "loss": 0.0824,
      "step": 2654
    },
    {
      "epoch": 1.7513192612137203,
      "grad_norm": 1.4520095586776733,
      "learning_rate": 4.164467897977133e-05,
      "loss": 0.0969,
      "step": 2655
    },
    {
      "epoch": 1.7519788918205803,
      "grad_norm": 2.019237995147705,
      "learning_rate": 4.162269129287599e-05,
      "loss": 0.0709,
      "step": 2656
    },
    {
      "epoch": 1.7526385224274406,
      "grad_norm": 0.826947808265686,
      "learning_rate": 4.160070360598065e-05,
      "loss": 0.0351,
      "step": 2657
    },
    {
      "epoch": 1.7532981530343008,
      "grad_norm": 0.7639120817184448,
      "learning_rate": 4.1578715919085314e-05,
      "loss": 0.0624,
      "step": 2658
    },
    {
      "epoch": 1.753957783641161,
      "grad_norm": 11.749227523803711,
      "learning_rate": 4.155672823218997e-05,
      "loss": 0.7643,
      "step": 2659
    },
    {
      "epoch": 1.754617414248021,
      "grad_norm": 14.344632148742676,
      "learning_rate": 4.1534740545294634e-05,
      "loss": 0.7307,
      "step": 2660
    },
    {
      "epoch": 1.7552770448548811,
      "grad_norm": 7.36958122253418,
      "learning_rate": 4.15127528583993e-05,
      "loss": 0.3499,
      "step": 2661
    },
    {
      "epoch": 1.7559366754617414,
      "grad_norm": 0.6645495891571045,
      "learning_rate": 4.149076517150396e-05,
      "loss": 0.0458,
      "step": 2662
    },
    {
      "epoch": 1.7565963060686016,
      "grad_norm": 1.7559754848480225,
      "learning_rate": 4.1468777484608626e-05,
      "loss": 0.058,
      "step": 2663
    },
    {
      "epoch": 1.7572559366754619,
      "grad_norm": 1.5741196870803833,
      "learning_rate": 4.144678979771328e-05,
      "loss": 0.0707,
      "step": 2664
    },
    {
      "epoch": 1.757915567282322,
      "grad_norm": 0.6535843014717102,
      "learning_rate": 4.1424802110817946e-05,
      "loss": 0.0488,
      "step": 2665
    },
    {
      "epoch": 1.758575197889182,
      "grad_norm": 12.11031436920166,
      "learning_rate": 4.14028144239226e-05,
      "loss": 0.8039,
      "step": 2666
    },
    {
      "epoch": 1.7592348284960422,
      "grad_norm": 0.43712887167930603,
      "learning_rate": 4.138082673702727e-05,
      "loss": 0.0344,
      "step": 2667
    },
    {
      "epoch": 1.7598944591029024,
      "grad_norm": 14.891005516052246,
      "learning_rate": 4.1358839050131924e-05,
      "loss": 0.4763,
      "step": 2668
    },
    {
      "epoch": 1.7605540897097627,
      "grad_norm": 3.480243682861328,
      "learning_rate": 4.133685136323659e-05,
      "loss": 0.1027,
      "step": 2669
    },
    {
      "epoch": 1.7612137203166227,
      "grad_norm": 4.303412914276123,
      "learning_rate": 4.131486367634125e-05,
      "loss": 0.1389,
      "step": 2670
    },
    {
      "epoch": 1.7618733509234827,
      "grad_norm": 2.0221896171569824,
      "learning_rate": 4.129287598944591e-05,
      "loss": 0.1025,
      "step": 2671
    },
    {
      "epoch": 1.762532981530343,
      "grad_norm": 1.70376718044281,
      "learning_rate": 4.127088830255057e-05,
      "loss": 0.0838,
      "step": 2672
    },
    {
      "epoch": 1.7631926121372032,
      "grad_norm": 1.0718097686767578,
      "learning_rate": 4.1248900615655236e-05,
      "loss": 0.0454,
      "step": 2673
    },
    {
      "epoch": 1.7638522427440633,
      "grad_norm": 0.8708710074424744,
      "learning_rate": 4.12269129287599e-05,
      "loss": 0.0708,
      "step": 2674
    },
    {
      "epoch": 1.7645118733509235,
      "grad_norm": 4.225086688995361,
      "learning_rate": 4.120492524186456e-05,
      "loss": 0.1386,
      "step": 2675
    },
    {
      "epoch": 1.7651715039577835,
      "grad_norm": 1.529801845550537,
      "learning_rate": 4.118293755496922e-05,
      "loss": 0.1029,
      "step": 2676
    },
    {
      "epoch": 1.7658311345646438,
      "grad_norm": 1.8821417093276978,
      "learning_rate": 4.116094986807388e-05,
      "loss": 0.0589,
      "step": 2677
    },
    {
      "epoch": 1.766490765171504,
      "grad_norm": 8.311356544494629,
      "learning_rate": 4.113896218117854e-05,
      "loss": 0.3498,
      "step": 2678
    },
    {
      "epoch": 1.767150395778364,
      "grad_norm": 12.343616485595703,
      "learning_rate": 4.1116974494283205e-05,
      "loss": 0.859,
      "step": 2679
    },
    {
      "epoch": 1.767810026385224,
      "grad_norm": 3.928556203842163,
      "learning_rate": 4.109498680738786e-05,
      "loss": 0.1162,
      "step": 2680
    },
    {
      "epoch": 1.7684696569920844,
      "grad_norm": 7.296600818634033,
      "learning_rate": 4.1072999120492526e-05,
      "loss": 0.0497,
      "step": 2681
    },
    {
      "epoch": 1.7691292875989446,
      "grad_norm": 1.8459622859954834,
      "learning_rate": 4.105101143359719e-05,
      "loss": 0.1055,
      "step": 2682
    },
    {
      "epoch": 1.7697889182058049,
      "grad_norm": 11.91458511352539,
      "learning_rate": 4.102902374670185e-05,
      "loss": 0.433,
      "step": 2683
    },
    {
      "epoch": 1.770448548812665,
      "grad_norm": 10.347160339355469,
      "learning_rate": 4.100703605980651e-05,
      "loss": 0.5077,
      "step": 2684
    },
    {
      "epoch": 1.771108179419525,
      "grad_norm": 8.954668998718262,
      "learning_rate": 4.0985048372911174e-05,
      "loss": 0.2513,
      "step": 2685
    },
    {
      "epoch": 1.7717678100263852,
      "grad_norm": 1.3730127811431885,
      "learning_rate": 4.096306068601583e-05,
      "loss": 0.0769,
      "step": 2686
    },
    {
      "epoch": 1.7724274406332454,
      "grad_norm": 0.6332892179489136,
      "learning_rate": 4.0941072999120495e-05,
      "loss": 0.0587,
      "step": 2687
    },
    {
      "epoch": 1.7730870712401057,
      "grad_norm": 1.0095101594924927,
      "learning_rate": 4.091908531222516e-05,
      "loss": 0.0385,
      "step": 2688
    },
    {
      "epoch": 1.7737467018469657,
      "grad_norm": 7.625988483428955,
      "learning_rate": 4.0897097625329815e-05,
      "loss": 0.3219,
      "step": 2689
    },
    {
      "epoch": 1.7744063324538257,
      "grad_norm": 15.486045837402344,
      "learning_rate": 4.087510993843448e-05,
      "loss": 0.4585,
      "step": 2690
    },
    {
      "epoch": 1.775065963060686,
      "grad_norm": 14.214691162109375,
      "learning_rate": 4.0853122251539136e-05,
      "loss": 0.539,
      "step": 2691
    },
    {
      "epoch": 1.7757255936675462,
      "grad_norm": 8.977054595947266,
      "learning_rate": 4.08311345646438e-05,
      "loss": 0.3472,
      "step": 2692
    },
    {
      "epoch": 1.7763852242744065,
      "grad_norm": 2.4838643074035645,
      "learning_rate": 4.0809146877748464e-05,
      "loss": 0.1108,
      "step": 2693
    },
    {
      "epoch": 1.7770448548812665,
      "grad_norm": 10.72998046875,
      "learning_rate": 4.078715919085313e-05,
      "loss": 0.5113,
      "step": 2694
    },
    {
      "epoch": 1.7777044854881265,
      "grad_norm": 1.9618779420852661,
      "learning_rate": 4.0765171503957784e-05,
      "loss": 0.093,
      "step": 2695
    },
    {
      "epoch": 1.7783641160949868,
      "grad_norm": 0.8092622756958008,
      "learning_rate": 4.074318381706245e-05,
      "loss": 0.0497,
      "step": 2696
    },
    {
      "epoch": 1.779023746701847,
      "grad_norm": 2.0356948375701904,
      "learning_rate": 4.072119613016711e-05,
      "loss": 0.1245,
      "step": 2697
    },
    {
      "epoch": 1.779683377308707,
      "grad_norm": 18.324329376220703,
      "learning_rate": 4.069920844327177e-05,
      "loss": 1.6003,
      "step": 2698
    },
    {
      "epoch": 1.7803430079155673,
      "grad_norm": 8.82694149017334,
      "learning_rate": 4.067722075637643e-05,
      "loss": 0.4078,
      "step": 2699
    },
    {
      "epoch": 1.7810026385224274,
      "grad_norm": 15.276712417602539,
      "learning_rate": 4.065523306948109e-05,
      "loss": 0.9911,
      "step": 2700
    },
    {
      "epoch": 1.7816622691292876,
      "grad_norm": 1.8712741136550903,
      "learning_rate": 4.0633245382585753e-05,
      "loss": 0.1095,
      "step": 2701
    },
    {
      "epoch": 1.7823218997361479,
      "grad_norm": 5.810438632965088,
      "learning_rate": 4.061125769569041e-05,
      "loss": 0.4227,
      "step": 2702
    },
    {
      "epoch": 1.7829815303430079,
      "grad_norm": 11.286758422851562,
      "learning_rate": 4.0589270008795074e-05,
      "loss": 0.5758,
      "step": 2703
    },
    {
      "epoch": 1.783641160949868,
      "grad_norm": 2.6106183528900146,
      "learning_rate": 4.056728232189974e-05,
      "loss": 0.1841,
      "step": 2704
    },
    {
      "epoch": 1.7843007915567282,
      "grad_norm": 1.252832055091858,
      "learning_rate": 4.05452946350044e-05,
      "loss": 0.0808,
      "step": 2705
    },
    {
      "epoch": 1.7849604221635884,
      "grad_norm": 1.8582630157470703,
      "learning_rate": 4.0523306948109065e-05,
      "loss": 0.1563,
      "step": 2706
    },
    {
      "epoch": 1.7856200527704487,
      "grad_norm": 4.402214050292969,
      "learning_rate": 4.050131926121372e-05,
      "loss": 0.1196,
      "step": 2707
    },
    {
      "epoch": 1.7862796833773087,
      "grad_norm": 6.718860149383545,
      "learning_rate": 4.0479331574318386e-05,
      "loss": 0.2883,
      "step": 2708
    },
    {
      "epoch": 1.7869393139841687,
      "grad_norm": 1.9483007192611694,
      "learning_rate": 4.045734388742304e-05,
      "loss": 0.1692,
      "step": 2709
    },
    {
      "epoch": 1.787598944591029,
      "grad_norm": 2.0792160034179688,
      "learning_rate": 4.043535620052771e-05,
      "loss": 0.1147,
      "step": 2710
    },
    {
      "epoch": 1.7882585751978892,
      "grad_norm": 8.038678169250488,
      "learning_rate": 4.0413368513632364e-05,
      "loss": 0.2598,
      "step": 2711
    },
    {
      "epoch": 1.7889182058047495,
      "grad_norm": 1.3093785047531128,
      "learning_rate": 4.039138082673703e-05,
      "loss": 0.1348,
      "step": 2712
    },
    {
      "epoch": 1.7895778364116095,
      "grad_norm": 1.2610673904418945,
      "learning_rate": 4.0369393139841685e-05,
      "loss": 0.1214,
      "step": 2713
    },
    {
      "epoch": 1.7902374670184695,
      "grad_norm": 2.775336742401123,
      "learning_rate": 4.0347405452946355e-05,
      "loss": 0.1535,
      "step": 2714
    },
    {
      "epoch": 1.7908970976253298,
      "grad_norm": 6.453156471252441,
      "learning_rate": 4.032541776605102e-05,
      "loss": 0.232,
      "step": 2715
    },
    {
      "epoch": 1.79155672823219,
      "grad_norm": 1.894430160522461,
      "learning_rate": 4.0303430079155676e-05,
      "loss": 0.1241,
      "step": 2716
    },
    {
      "epoch": 1.7922163588390503,
      "grad_norm": 0.7948489785194397,
      "learning_rate": 4.028144239226034e-05,
      "loss": 0.0709,
      "step": 2717
    },
    {
      "epoch": 1.7928759894459103,
      "grad_norm": 1.0218489170074463,
      "learning_rate": 4.0259454705365e-05,
      "loss": 0.0968,
      "step": 2718
    },
    {
      "epoch": 1.7935356200527703,
      "grad_norm": 1.7101454734802246,
      "learning_rate": 4.023746701846966e-05,
      "loss": 0.0956,
      "step": 2719
    },
    {
      "epoch": 1.7941952506596306,
      "grad_norm": 24.80246353149414,
      "learning_rate": 4.021547933157432e-05,
      "loss": 1.2549,
      "step": 2720
    },
    {
      "epoch": 1.7948548812664908,
      "grad_norm": 0.9449682831764221,
      "learning_rate": 4.019349164467898e-05,
      "loss": 0.073,
      "step": 2721
    },
    {
      "epoch": 1.7955145118733509,
      "grad_norm": 10.85494613647461,
      "learning_rate": 4.017150395778364e-05,
      "loss": 0.6871,
      "step": 2722
    },
    {
      "epoch": 1.7961741424802111,
      "grad_norm": 0.6278874278068542,
      "learning_rate": 4.01495162708883e-05,
      "loss": 0.0666,
      "step": 2723
    },
    {
      "epoch": 1.7968337730870712,
      "grad_norm": 0.8150255680084229,
      "learning_rate": 4.0127528583992966e-05,
      "loss": 0.0513,
      "step": 2724
    },
    {
      "epoch": 1.7974934036939314,
      "grad_norm": 6.580297470092773,
      "learning_rate": 4.010554089709763e-05,
      "loss": 0.2343,
      "step": 2725
    },
    {
      "epoch": 1.7981530343007917,
      "grad_norm": 1.5280125141143799,
      "learning_rate": 4.008355321020229e-05,
      "loss": 0.0719,
      "step": 2726
    },
    {
      "epoch": 1.7988126649076517,
      "grad_norm": 9.314962387084961,
      "learning_rate": 4.006156552330695e-05,
      "loss": 0.5904,
      "step": 2727
    },
    {
      "epoch": 1.7994722955145117,
      "grad_norm": 1.7081114053726196,
      "learning_rate": 4.0039577836411614e-05,
      "loss": 0.1128,
      "step": 2728
    },
    {
      "epoch": 1.800131926121372,
      "grad_norm": 22.62056541442871,
      "learning_rate": 4.001759014951627e-05,
      "loss": 0.3745,
      "step": 2729
    },
    {
      "epoch": 1.8007915567282322,
      "grad_norm": 9.769092559814453,
      "learning_rate": 3.9995602462620935e-05,
      "loss": 0.6937,
      "step": 2730
    },
    {
      "epoch": 1.8014511873350925,
      "grad_norm": 0.470443457365036,
      "learning_rate": 3.997361477572559e-05,
      "loss": 0.0477,
      "step": 2731
    },
    {
      "epoch": 1.8021108179419525,
      "grad_norm": 0.41145554184913635,
      "learning_rate": 3.9951627088830255e-05,
      "loss": 0.0389,
      "step": 2732
    },
    {
      "epoch": 1.8027704485488125,
      "grad_norm": 9.345503807067871,
      "learning_rate": 3.992963940193492e-05,
      "loss": 0.9956,
      "step": 2733
    },
    {
      "epoch": 1.8034300791556728,
      "grad_norm": 1.8520647287368774,
      "learning_rate": 3.9907651715039576e-05,
      "loss": 0.1136,
      "step": 2734
    },
    {
      "epoch": 1.804089709762533,
      "grad_norm": 3.432701349258423,
      "learning_rate": 3.988566402814424e-05,
      "loss": 0.1303,
      "step": 2735
    },
    {
      "epoch": 1.8047493403693933,
      "grad_norm": 0.9695805311203003,
      "learning_rate": 3.9863676341248904e-05,
      "loss": 0.0525,
      "step": 2736
    },
    {
      "epoch": 1.8054089709762533,
      "grad_norm": 18.288570404052734,
      "learning_rate": 3.984168865435357e-05,
      "loss": 0.6798,
      "step": 2737
    },
    {
      "epoch": 1.8060686015831133,
      "grad_norm": 15.490406036376953,
      "learning_rate": 3.9819700967458224e-05,
      "loss": 0.9822,
      "step": 2738
    },
    {
      "epoch": 1.8067282321899736,
      "grad_norm": 4.547871112823486,
      "learning_rate": 3.979771328056289e-05,
      "loss": 0.1283,
      "step": 2739
    },
    {
      "epoch": 1.8073878627968338,
      "grad_norm": 0.9620028138160706,
      "learning_rate": 3.9775725593667545e-05,
      "loss": 0.0601,
      "step": 2740
    },
    {
      "epoch": 1.808047493403694,
      "grad_norm": 4.439675807952881,
      "learning_rate": 3.975373790677221e-05,
      "loss": 0.2483,
      "step": 2741
    },
    {
      "epoch": 1.8087071240105541,
      "grad_norm": 15.093034744262695,
      "learning_rate": 3.973175021987687e-05,
      "loss": 0.4898,
      "step": 2742
    },
    {
      "epoch": 1.8093667546174141,
      "grad_norm": 16.332134246826172,
      "learning_rate": 3.970976253298153e-05,
      "loss": 0.2622,
      "step": 2743
    },
    {
      "epoch": 1.8100263852242744,
      "grad_norm": 7.076671123504639,
      "learning_rate": 3.9687774846086193e-05,
      "loss": 0.2522,
      "step": 2744
    },
    {
      "epoch": 1.8106860158311346,
      "grad_norm": 1.7328377962112427,
      "learning_rate": 3.966578715919085e-05,
      "loss": 0.0668,
      "step": 2745
    },
    {
      "epoch": 1.8113456464379947,
      "grad_norm": 17.446500778198242,
      "learning_rate": 3.9643799472295514e-05,
      "loss": 1.3082,
      "step": 2746
    },
    {
      "epoch": 1.812005277044855,
      "grad_norm": 9.518306732177734,
      "learning_rate": 3.962181178540018e-05,
      "loss": 0.4208,
      "step": 2747
    },
    {
      "epoch": 1.812664907651715,
      "grad_norm": 5.72781229019165,
      "learning_rate": 3.959982409850484e-05,
      "loss": 0.1731,
      "step": 2748
    },
    {
      "epoch": 1.8133245382585752,
      "grad_norm": 10.638669967651367,
      "learning_rate": 3.95778364116095e-05,
      "loss": 1.0532,
      "step": 2749
    },
    {
      "epoch": 1.8139841688654355,
      "grad_norm": 1.634246587753296,
      "learning_rate": 3.955584872471416e-05,
      "loss": 0.1394,
      "step": 2750
    },
    {
      "epoch": 1.8146437994722955,
      "grad_norm": 1.1144294738769531,
      "learning_rate": 3.9533861037818826e-05,
      "loss": 0.1,
      "step": 2751
    },
    {
      "epoch": 1.8153034300791555,
      "grad_norm": 0.8832687735557556,
      "learning_rate": 3.951187335092348e-05,
      "loss": 0.0593,
      "step": 2752
    },
    {
      "epoch": 1.8159630606860158,
      "grad_norm": 1.2561180591583252,
      "learning_rate": 3.948988566402815e-05,
      "loss": 0.0836,
      "step": 2753
    },
    {
      "epoch": 1.816622691292876,
      "grad_norm": 0.7963053584098816,
      "learning_rate": 3.9467897977132804e-05,
      "loss": 0.0564,
      "step": 2754
    },
    {
      "epoch": 1.8172823218997363,
      "grad_norm": 1.948866367340088,
      "learning_rate": 3.944591029023747e-05,
      "loss": 0.1347,
      "step": 2755
    },
    {
      "epoch": 1.8179419525065963,
      "grad_norm": 0.9204444289207458,
      "learning_rate": 3.942392260334213e-05,
      "loss": 0.0831,
      "step": 2756
    },
    {
      "epoch": 1.8186015831134563,
      "grad_norm": 0.9754191637039185,
      "learning_rate": 3.9401934916446795e-05,
      "loss": 0.0714,
      "step": 2757
    },
    {
      "epoch": 1.8192612137203166,
      "grad_norm": 0.9442179799079895,
      "learning_rate": 3.937994722955145e-05,
      "loss": 0.0683,
      "step": 2758
    },
    {
      "epoch": 1.8199208443271768,
      "grad_norm": 2.1028640270233154,
      "learning_rate": 3.9357959542656116e-05,
      "loss": 0.134,
      "step": 2759
    },
    {
      "epoch": 1.820580474934037,
      "grad_norm": 4.131069183349609,
      "learning_rate": 3.933597185576078e-05,
      "loss": 0.1321,
      "step": 2760
    },
    {
      "epoch": 1.821240105540897,
      "grad_norm": 2.8523519039154053,
      "learning_rate": 3.931398416886544e-05,
      "loss": 0.1449,
      "step": 2761
    },
    {
      "epoch": 1.8218997361477571,
      "grad_norm": 4.237049579620361,
      "learning_rate": 3.92919964819701e-05,
      "loss": 0.1546,
      "step": 2762
    },
    {
      "epoch": 1.8225593667546174,
      "grad_norm": 7.659719944000244,
      "learning_rate": 3.927000879507476e-05,
      "loss": 0.1945,
      "step": 2763
    },
    {
      "epoch": 1.8232189973614776,
      "grad_norm": 18.524112701416016,
      "learning_rate": 3.924802110817942e-05,
      "loss": 0.3248,
      "step": 2764
    },
    {
      "epoch": 1.8238786279683379,
      "grad_norm": 2.7952163219451904,
      "learning_rate": 3.922603342128408e-05,
      "loss": 0.1241,
      "step": 2765
    },
    {
      "epoch": 1.824538258575198,
      "grad_norm": 10.298161506652832,
      "learning_rate": 3.920404573438874e-05,
      "loss": 0.6505,
      "step": 2766
    },
    {
      "epoch": 1.825197889182058,
      "grad_norm": 1.8772655725479126,
      "learning_rate": 3.9182058047493406e-05,
      "loss": 0.1145,
      "step": 2767
    },
    {
      "epoch": 1.8258575197889182,
      "grad_norm": 2.3562333583831787,
      "learning_rate": 3.916007036059807e-05,
      "loss": 0.1009,
      "step": 2768
    },
    {
      "epoch": 1.8265171503957784,
      "grad_norm": 25.11233139038086,
      "learning_rate": 3.913808267370273e-05,
      "loss": 0.1467,
      "step": 2769
    },
    {
      "epoch": 1.8271767810026385,
      "grad_norm": 2.193321943283081,
      "learning_rate": 3.911609498680739e-05,
      "loss": 0.0866,
      "step": 2770
    },
    {
      "epoch": 1.8278364116094987,
      "grad_norm": 9.320406913757324,
      "learning_rate": 3.9094107299912054e-05,
      "loss": 0.7941,
      "step": 2771
    },
    {
      "epoch": 1.8284960422163588,
      "grad_norm": 1.3960821628570557,
      "learning_rate": 3.907211961301671e-05,
      "loss": 0.121,
      "step": 2772
    },
    {
      "epoch": 1.829155672823219,
      "grad_norm": 15.320442199707031,
      "learning_rate": 3.9050131926121375e-05,
      "loss": 1.5091,
      "step": 2773
    },
    {
      "epoch": 1.8298153034300793,
      "grad_norm": 3.515763521194458,
      "learning_rate": 3.902814423922603e-05,
      "loss": 0.1717,
      "step": 2774
    },
    {
      "epoch": 1.8304749340369393,
      "grad_norm": 0.940666139125824,
      "learning_rate": 3.9006156552330695e-05,
      "loss": 0.0621,
      "step": 2775
    },
    {
      "epoch": 1.8311345646437993,
      "grad_norm": 1.4814043045043945,
      "learning_rate": 3.898416886543535e-05,
      "loss": 0.082,
      "step": 2776
    },
    {
      "epoch": 1.8317941952506596,
      "grad_norm": 1.2032349109649658,
      "learning_rate": 3.8962181178540016e-05,
      "loss": 0.0963,
      "step": 2777
    },
    {
      "epoch": 1.8324538258575198,
      "grad_norm": 1.0897525548934937,
      "learning_rate": 3.894019349164468e-05,
      "loss": 0.1245,
      "step": 2778
    },
    {
      "epoch": 1.83311345646438,
      "grad_norm": 10.052776336669922,
      "learning_rate": 3.8918205804749344e-05,
      "loss": 0.3049,
      "step": 2779
    },
    {
      "epoch": 1.83377308707124,
      "grad_norm": 1.3200932741165161,
      "learning_rate": 3.889621811785401e-05,
      "loss": 0.1286,
      "step": 2780
    },
    {
      "epoch": 1.8344327176781001,
      "grad_norm": 2.7365686893463135,
      "learning_rate": 3.8874230430958664e-05,
      "loss": 0.1311,
      "step": 2781
    },
    {
      "epoch": 1.8350923482849604,
      "grad_norm": 1.4437118768692017,
      "learning_rate": 3.885224274406333e-05,
      "loss": 0.0964,
      "step": 2782
    },
    {
      "epoch": 1.8357519788918206,
      "grad_norm": 9.726602554321289,
      "learning_rate": 3.8830255057167985e-05,
      "loss": 0.4803,
      "step": 2783
    },
    {
      "epoch": 1.8364116094986809,
      "grad_norm": 1.8903170824050903,
      "learning_rate": 3.880826737027265e-05,
      "loss": 0.0538,
      "step": 2784
    },
    {
      "epoch": 1.837071240105541,
      "grad_norm": 5.289468765258789,
      "learning_rate": 3.8786279683377306e-05,
      "loss": 0.1734,
      "step": 2785
    },
    {
      "epoch": 1.837730870712401,
      "grad_norm": 17.401195526123047,
      "learning_rate": 3.876429199648197e-05,
      "loss": 0.8069,
      "step": 2786
    },
    {
      "epoch": 1.8383905013192612,
      "grad_norm": 0.7805021405220032,
      "learning_rate": 3.874230430958663e-05,
      "loss": 0.0634,
      "step": 2787
    },
    {
      "epoch": 1.8390501319261214,
      "grad_norm": 5.661125659942627,
      "learning_rate": 3.87203166226913e-05,
      "loss": 0.119,
      "step": 2788
    },
    {
      "epoch": 1.8397097625329817,
      "grad_norm": 1.9721375703811646,
      "learning_rate": 3.869832893579596e-05,
      "loss": 0.1111,
      "step": 2789
    },
    {
      "epoch": 1.8403693931398417,
      "grad_norm": 11.362344741821289,
      "learning_rate": 3.867634124890062e-05,
      "loss": 0.4308,
      "step": 2790
    },
    {
      "epoch": 1.8410290237467017,
      "grad_norm": 1.522278904914856,
      "learning_rate": 3.865435356200528e-05,
      "loss": 0.0496,
      "step": 2791
    },
    {
      "epoch": 1.841688654353562,
      "grad_norm": 3.5293469429016113,
      "learning_rate": 3.863236587510994e-05,
      "loss": 0.1034,
      "step": 2792
    },
    {
      "epoch": 1.8423482849604222,
      "grad_norm": 6.0397257804870605,
      "learning_rate": 3.86103781882146e-05,
      "loss": 0.1672,
      "step": 2793
    },
    {
      "epoch": 1.8430079155672823,
      "grad_norm": 15.81653118133545,
      "learning_rate": 3.858839050131926e-05,
      "loss": 1.2246,
      "step": 2794
    },
    {
      "epoch": 1.8436675461741425,
      "grad_norm": 1.043747067451477,
      "learning_rate": 3.856640281442392e-05,
      "loss": 0.074,
      "step": 2795
    },
    {
      "epoch": 1.8443271767810026,
      "grad_norm": 0.7642236351966858,
      "learning_rate": 3.854441512752859e-05,
      "loss": 0.0615,
      "step": 2796
    },
    {
      "epoch": 1.8449868073878628,
      "grad_norm": 5.2990946769714355,
      "learning_rate": 3.8522427440633244e-05,
      "loss": 0.2005,
      "step": 2797
    },
    {
      "epoch": 1.845646437994723,
      "grad_norm": 5.867966175079346,
      "learning_rate": 3.850043975373791e-05,
      "loss": 0.1727,
      "step": 2798
    },
    {
      "epoch": 1.846306068601583,
      "grad_norm": 0.8447623252868652,
      "learning_rate": 3.847845206684257e-05,
      "loss": 0.0574,
      "step": 2799
    },
    {
      "epoch": 1.8469656992084431,
      "grad_norm": 0.9833104014396667,
      "learning_rate": 3.8456464379947235e-05,
      "loss": 0.0647,
      "step": 2800
    },
    {
      "epoch": 1.8476253298153034,
      "grad_norm": 1.6773213148117065,
      "learning_rate": 3.843447669305189e-05,
      "loss": 0.1033,
      "step": 2801
    },
    {
      "epoch": 1.8482849604221636,
      "grad_norm": 1.1504756212234497,
      "learning_rate": 3.8412489006156556e-05,
      "loss": 0.0655,
      "step": 2802
    },
    {
      "epoch": 1.8489445910290239,
      "grad_norm": 0.771164059638977,
      "learning_rate": 3.839050131926121e-05,
      "loss": 0.0577,
      "step": 2803
    },
    {
      "epoch": 1.849604221635884,
      "grad_norm": 8.120492935180664,
      "learning_rate": 3.8368513632365877e-05,
      "loss": 0.3215,
      "step": 2804
    },
    {
      "epoch": 1.850263852242744,
      "grad_norm": 0.8412371277809143,
      "learning_rate": 3.834652594547054e-05,
      "loss": 0.0336,
      "step": 2805
    },
    {
      "epoch": 1.8509234828496042,
      "grad_norm": 6.797659873962402,
      "learning_rate": 3.83245382585752e-05,
      "loss": 0.2074,
      "step": 2806
    },
    {
      "epoch": 1.8515831134564644,
      "grad_norm": 0.821050763130188,
      "learning_rate": 3.830255057167986e-05,
      "loss": 0.0709,
      "step": 2807
    },
    {
      "epoch": 1.8522427440633247,
      "grad_norm": 1.6077440977096558,
      "learning_rate": 3.828056288478452e-05,
      "loss": 0.0685,
      "step": 2808
    },
    {
      "epoch": 1.8529023746701847,
      "grad_norm": 5.663525581359863,
      "learning_rate": 3.825857519788918e-05,
      "loss": 0.2927,
      "step": 2809
    },
    {
      "epoch": 1.8535620052770447,
      "grad_norm": 25.17902946472168,
      "learning_rate": 3.8236587510993846e-05,
      "loss": 0.6398,
      "step": 2810
    },
    {
      "epoch": 1.854221635883905,
      "grad_norm": 1.7434402704238892,
      "learning_rate": 3.821459982409851e-05,
      "loss": 0.1064,
      "step": 2811
    },
    {
      "epoch": 1.8548812664907652,
      "grad_norm": 2.5578129291534424,
      "learning_rate": 3.8192612137203166e-05,
      "loss": 0.0991,
      "step": 2812
    },
    {
      "epoch": 1.8555408970976255,
      "grad_norm": 6.7151288986206055,
      "learning_rate": 3.817062445030783e-05,
      "loss": 0.5652,
      "step": 2813
    },
    {
      "epoch": 1.8562005277044855,
      "grad_norm": 0.5874227285385132,
      "learning_rate": 3.8148636763412494e-05,
      "loss": 0.0428,
      "step": 2814
    },
    {
      "epoch": 1.8568601583113455,
      "grad_norm": 0.9283482432365417,
      "learning_rate": 3.812664907651715e-05,
      "loss": 0.0564,
      "step": 2815
    },
    {
      "epoch": 1.8575197889182058,
      "grad_norm": 3.938062906265259,
      "learning_rate": 3.8104661389621815e-05,
      "loss": 0.089,
      "step": 2816
    },
    {
      "epoch": 1.858179419525066,
      "grad_norm": 0.892266571521759,
      "learning_rate": 3.808267370272647e-05,
      "loss": 0.0477,
      "step": 2817
    },
    {
      "epoch": 1.858839050131926,
      "grad_norm": 14.377206802368164,
      "learning_rate": 3.8060686015831135e-05,
      "loss": 0.4785,
      "step": 2818
    },
    {
      "epoch": 1.8594986807387863,
      "grad_norm": 2.7931790351867676,
      "learning_rate": 3.80386983289358e-05,
      "loss": 0.0797,
      "step": 2819
    },
    {
      "epoch": 1.8601583113456464,
      "grad_norm": 0.5100439786911011,
      "learning_rate": 3.801671064204046e-05,
      "loss": 0.0545,
      "step": 2820
    },
    {
      "epoch": 1.8608179419525066,
      "grad_norm": 8.391435623168945,
      "learning_rate": 3.799472295514512e-05,
      "loss": 0.6253,
      "step": 2821
    },
    {
      "epoch": 1.8614775725593669,
      "grad_norm": 0.47416549921035767,
      "learning_rate": 3.7972735268249784e-05,
      "loss": 0.0259,
      "step": 2822
    },
    {
      "epoch": 1.8621372031662269,
      "grad_norm": 4.955886363983154,
      "learning_rate": 3.795074758135445e-05,
      "loss": 0.1145,
      "step": 2823
    },
    {
      "epoch": 1.862796833773087,
      "grad_norm": 2.1490352153778076,
      "learning_rate": 3.7928759894459104e-05,
      "loss": 0.0783,
      "step": 2824
    },
    {
      "epoch": 1.8634564643799472,
      "grad_norm": 10.613341331481934,
      "learning_rate": 3.790677220756377e-05,
      "loss": 0.5909,
      "step": 2825
    },
    {
      "epoch": 1.8641160949868074,
      "grad_norm": 1.244255542755127,
      "learning_rate": 3.7884784520668425e-05,
      "loss": 0.0716,
      "step": 2826
    },
    {
      "epoch": 1.8647757255936677,
      "grad_norm": 27.907499313354492,
      "learning_rate": 3.786279683377309e-05,
      "loss": 0.7026,
      "step": 2827
    },
    {
      "epoch": 1.8654353562005277,
      "grad_norm": 1.5688331127166748,
      "learning_rate": 3.7840809146877746e-05,
      "loss": 0.0922,
      "step": 2828
    },
    {
      "epoch": 1.8660949868073877,
      "grad_norm": 1.9439022541046143,
      "learning_rate": 3.781882145998241e-05,
      "loss": 0.1067,
      "step": 2829
    },
    {
      "epoch": 1.866754617414248,
      "grad_norm": 8.58437728881836,
      "learning_rate": 3.779683377308707e-05,
      "loss": 0.7512,
      "step": 2830
    },
    {
      "epoch": 1.8674142480211082,
      "grad_norm": 1.7048536539077759,
      "learning_rate": 3.777484608619174e-05,
      "loss": 0.1113,
      "step": 2831
    },
    {
      "epoch": 1.8680738786279685,
      "grad_norm": 1.4635794162750244,
      "learning_rate": 3.77528583992964e-05,
      "loss": 0.1112,
      "step": 2832
    },
    {
      "epoch": 1.8687335092348285,
      "grad_norm": 1.1096723079681396,
      "learning_rate": 3.773087071240106e-05,
      "loss": 0.0625,
      "step": 2833
    },
    {
      "epoch": 1.8693931398416885,
      "grad_norm": 3.0040998458862305,
      "learning_rate": 3.770888302550572e-05,
      "loss": 0.0992,
      "step": 2834
    },
    {
      "epoch": 1.8700527704485488,
      "grad_norm": 1.1884454488754272,
      "learning_rate": 3.768689533861038e-05,
      "loss": 0.0741,
      "step": 2835
    },
    {
      "epoch": 1.870712401055409,
      "grad_norm": 12.066390037536621,
      "learning_rate": 3.766490765171504e-05,
      "loss": 0.4735,
      "step": 2836
    },
    {
      "epoch": 1.8713720316622693,
      "grad_norm": 10.140275001525879,
      "learning_rate": 3.76429199648197e-05,
      "loss": 1.5616,
      "step": 2837
    },
    {
      "epoch": 1.8720316622691293,
      "grad_norm": 11.72966194152832,
      "learning_rate": 3.762093227792436e-05,
      "loss": 0.1517,
      "step": 2838
    },
    {
      "epoch": 1.8726912928759893,
      "grad_norm": 7.068862438201904,
      "learning_rate": 3.759894459102902e-05,
      "loss": 0.4135,
      "step": 2839
    },
    {
      "epoch": 1.8733509234828496,
      "grad_norm": 0.9574666023254395,
      "learning_rate": 3.7576956904133684e-05,
      "loss": 0.0498,
      "step": 2840
    },
    {
      "epoch": 1.8740105540897098,
      "grad_norm": 0.614205539226532,
      "learning_rate": 3.755496921723835e-05,
      "loss": 0.0323,
      "step": 2841
    },
    {
      "epoch": 1.8746701846965699,
      "grad_norm": 11.720158576965332,
      "learning_rate": 3.753298153034301e-05,
      "loss": 0.7472,
      "step": 2842
    },
    {
      "epoch": 1.8753298153034301,
      "grad_norm": 8.725957870483398,
      "learning_rate": 3.7510993843447675e-05,
      "loss": 0.3173,
      "step": 2843
    },
    {
      "epoch": 1.8759894459102902,
      "grad_norm": 2.929297924041748,
      "learning_rate": 3.748900615655233e-05,
      "loss": 0.0663,
      "step": 2844
    },
    {
      "epoch": 1.8766490765171504,
      "grad_norm": 5.233532428741455,
      "learning_rate": 3.7467018469656996e-05,
      "loss": 0.1625,
      "step": 2845
    },
    {
      "epoch": 1.8773087071240107,
      "grad_norm": 1.0640367269515991,
      "learning_rate": 3.744503078276165e-05,
      "loss": 0.0379,
      "step": 2846
    },
    {
      "epoch": 1.8779683377308707,
      "grad_norm": 2.653115749359131,
      "learning_rate": 3.7423043095866316e-05,
      "loss": 0.0805,
      "step": 2847
    },
    {
      "epoch": 1.8786279683377307,
      "grad_norm": 5.990235805511475,
      "learning_rate": 3.740105540897098e-05,
      "loss": 0.2381,
      "step": 2848
    },
    {
      "epoch": 1.879287598944591,
      "grad_norm": 0.49139168858528137,
      "learning_rate": 3.737906772207564e-05,
      "loss": 0.0282,
      "step": 2849
    },
    {
      "epoch": 1.8799472295514512,
      "grad_norm": 7.738452434539795,
      "learning_rate": 3.73570800351803e-05,
      "loss": 0.1315,
      "step": 2850
    },
    {
      "epoch": 1.8806068601583115,
      "grad_norm": 7.190683841705322,
      "learning_rate": 3.733509234828496e-05,
      "loss": 0.1997,
      "step": 2851
    },
    {
      "epoch": 1.8812664907651715,
      "grad_norm": 1.0927183628082275,
      "learning_rate": 3.731310466138963e-05,
      "loss": 0.0655,
      "step": 2852
    },
    {
      "epoch": 1.8819261213720315,
      "grad_norm": 0.9762004017829895,
      "learning_rate": 3.7291116974494285e-05,
      "loss": 0.0737,
      "step": 2853
    },
    {
      "epoch": 1.8825857519788918,
      "grad_norm": 5.549389839172363,
      "learning_rate": 3.726912928759895e-05,
      "loss": 0.2164,
      "step": 2854
    },
    {
      "epoch": 1.883245382585752,
      "grad_norm": 2.013854742050171,
      "learning_rate": 3.7247141600703606e-05,
      "loss": 0.0716,
      "step": 2855
    },
    {
      "epoch": 1.8839050131926123,
      "grad_norm": 9.26718807220459,
      "learning_rate": 3.722515391380827e-05,
      "loss": 0.2725,
      "step": 2856
    },
    {
      "epoch": 1.8845646437994723,
      "grad_norm": 21.323280334472656,
      "learning_rate": 3.7203166226912934e-05,
      "loss": 0.4953,
      "step": 2857
    },
    {
      "epoch": 1.8852242744063323,
      "grad_norm": 0.6233179569244385,
      "learning_rate": 3.718117854001759e-05,
      "loss": 0.0628,
      "step": 2858
    },
    {
      "epoch": 1.8858839050131926,
      "grad_norm": 1.2881653308868408,
      "learning_rate": 3.7159190853122254e-05,
      "loss": 0.0743,
      "step": 2859
    },
    {
      "epoch": 1.8865435356200528,
      "grad_norm": 2.455498695373535,
      "learning_rate": 3.713720316622691e-05,
      "loss": 0.1023,
      "step": 2860
    },
    {
      "epoch": 1.887203166226913,
      "grad_norm": 1.942043662071228,
      "learning_rate": 3.7115215479331575e-05,
      "loss": 0.1062,
      "step": 2861
    },
    {
      "epoch": 1.8878627968337731,
      "grad_norm": 1.0490851402282715,
      "learning_rate": 3.709322779243624e-05,
      "loss": 0.0686,
      "step": 2862
    },
    {
      "epoch": 1.8885224274406331,
      "grad_norm": 10.723387718200684,
      "learning_rate": 3.70712401055409e-05,
      "loss": 0.5304,
      "step": 2863
    },
    {
      "epoch": 1.8891820580474934,
      "grad_norm": 0.9649240374565125,
      "learning_rate": 3.704925241864556e-05,
      "loss": 0.0573,
      "step": 2864
    },
    {
      "epoch": 1.8898416886543536,
      "grad_norm": 6.4469194412231445,
      "learning_rate": 3.7027264731750223e-05,
      "loss": 0.1472,
      "step": 2865
    },
    {
      "epoch": 1.8905013192612137,
      "grad_norm": 2.564866065979004,
      "learning_rate": 3.700527704485489e-05,
      "loss": 0.1788,
      "step": 2866
    },
    {
      "epoch": 1.891160949868074,
      "grad_norm": 2.350644826889038,
      "learning_rate": 3.6983289357959544e-05,
      "loss": 0.107,
      "step": 2867
    },
    {
      "epoch": 1.891820580474934,
      "grad_norm": 8.428892135620117,
      "learning_rate": 3.696130167106421e-05,
      "loss": 0.1532,
      "step": 2868
    },
    {
      "epoch": 1.8924802110817942,
      "grad_norm": 5.139846324920654,
      "learning_rate": 3.6939313984168865e-05,
      "loss": 0.1692,
      "step": 2869
    },
    {
      "epoch": 1.8931398416886545,
      "grad_norm": 1.846639633178711,
      "learning_rate": 3.691732629727353e-05,
      "loss": 0.1058,
      "step": 2870
    },
    {
      "epoch": 1.8937994722955145,
      "grad_norm": 5.615802764892578,
      "learning_rate": 3.6895338610378186e-05,
      "loss": 0.5552,
      "step": 2871
    },
    {
      "epoch": 1.8944591029023745,
      "grad_norm": 18.677268981933594,
      "learning_rate": 3.687335092348285e-05,
      "loss": 1.0036,
      "step": 2872
    },
    {
      "epoch": 1.8951187335092348,
      "grad_norm": 0.9965826869010925,
      "learning_rate": 3.685136323658751e-05,
      "loss": 0.0586,
      "step": 2873
    },
    {
      "epoch": 1.895778364116095,
      "grad_norm": 2.7996366024017334,
      "learning_rate": 3.682937554969218e-05,
      "loss": 0.1198,
      "step": 2874
    },
    {
      "epoch": 1.8964379947229553,
      "grad_norm": 1.072350025177002,
      "learning_rate": 3.680738786279684e-05,
      "loss": 0.0926,
      "step": 2875
    },
    {
      "epoch": 1.8970976253298153,
      "grad_norm": 3.3649730682373047,
      "learning_rate": 3.67854001759015e-05,
      "loss": 0.0964,
      "step": 2876
    },
    {
      "epoch": 1.8977572559366753,
      "grad_norm": 12.979736328125,
      "learning_rate": 3.676341248900616e-05,
      "loss": 0.6442,
      "step": 2877
    },
    {
      "epoch": 1.8984168865435356,
      "grad_norm": 0.8282926678657532,
      "learning_rate": 3.674142480211082e-05,
      "loss": 0.0559,
      "step": 2878
    },
    {
      "epoch": 1.8990765171503958,
      "grad_norm": 2.126847743988037,
      "learning_rate": 3.671943711521548e-05,
      "loss": 0.1185,
      "step": 2879
    },
    {
      "epoch": 1.899736147757256,
      "grad_norm": 0.9773503541946411,
      "learning_rate": 3.669744942832014e-05,
      "loss": 0.0509,
      "step": 2880
    },
    {
      "epoch": 1.900395778364116,
      "grad_norm": 10.230596542358398,
      "learning_rate": 3.66754617414248e-05,
      "loss": 0.7771,
      "step": 2881
    },
    {
      "epoch": 1.9010554089709761,
      "grad_norm": 2.035508155822754,
      "learning_rate": 3.665347405452946e-05,
      "loss": 0.0647,
      "step": 2882
    },
    {
      "epoch": 1.9017150395778364,
      "grad_norm": 0.7948359251022339,
      "learning_rate": 3.6631486367634124e-05,
      "loss": 0.0568,
      "step": 2883
    },
    {
      "epoch": 1.9023746701846966,
      "grad_norm": 1.0439268350601196,
      "learning_rate": 3.660949868073879e-05,
      "loss": 0.0715,
      "step": 2884
    },
    {
      "epoch": 1.9030343007915569,
      "grad_norm": 0.6073690056800842,
      "learning_rate": 3.658751099384345e-05,
      "loss": 0.0328,
      "step": 2885
    },
    {
      "epoch": 1.903693931398417,
      "grad_norm": 4.844982147216797,
      "learning_rate": 3.6565523306948115e-05,
      "loss": 0.1888,
      "step": 2886
    },
    {
      "epoch": 1.904353562005277,
      "grad_norm": 14.205489158630371,
      "learning_rate": 3.654353562005277e-05,
      "loss": 1.0664,
      "step": 2887
    },
    {
      "epoch": 1.9050131926121372,
      "grad_norm": 0.46313923597335815,
      "learning_rate": 3.6521547933157436e-05,
      "loss": 0.0297,
      "step": 2888
    },
    {
      "epoch": 1.9056728232189974,
      "grad_norm": 11.376221656799316,
      "learning_rate": 3.649956024626209e-05,
      "loss": 0.3862,
      "step": 2889
    },
    {
      "epoch": 1.9063324538258575,
      "grad_norm": 0.7779521942138672,
      "learning_rate": 3.6477572559366756e-05,
      "loss": 0.0307,
      "step": 2890
    },
    {
      "epoch": 1.9069920844327177,
      "grad_norm": 6.217970371246338,
      "learning_rate": 3.6455584872471413e-05,
      "loss": 0.1782,
      "step": 2891
    },
    {
      "epoch": 1.9076517150395778,
      "grad_norm": 16.24116325378418,
      "learning_rate": 3.643359718557608e-05,
      "loss": 0.4507,
      "step": 2892
    },
    {
      "epoch": 1.908311345646438,
      "grad_norm": 15.839468955993652,
      "learning_rate": 3.641160949868074e-05,
      "loss": 0.4164,
      "step": 2893
    },
    {
      "epoch": 1.9089709762532983,
      "grad_norm": 1.0082722902297974,
      "learning_rate": 3.6389621811785405e-05,
      "loss": 0.0668,
      "step": 2894
    },
    {
      "epoch": 1.9096306068601583,
      "grad_norm": 11.245617866516113,
      "learning_rate": 3.636763412489007e-05,
      "loss": 0.1234,
      "step": 2895
    },
    {
      "epoch": 1.9102902374670183,
      "grad_norm": 2.911930561065674,
      "learning_rate": 3.6345646437994725e-05,
      "loss": 0.0727,
      "step": 2896
    },
    {
      "epoch": 1.9109498680738786,
      "grad_norm": 15.847209930419922,
      "learning_rate": 3.632365875109939e-05,
      "loss": 0.8418,
      "step": 2897
    },
    {
      "epoch": 1.9116094986807388,
      "grad_norm": 9.330622673034668,
      "learning_rate": 3.6301671064204046e-05,
      "loss": 1.1943,
      "step": 2898
    },
    {
      "epoch": 1.912269129287599,
      "grad_norm": 11.696744918823242,
      "learning_rate": 3.627968337730871e-05,
      "loss": 1.1184,
      "step": 2899
    },
    {
      "epoch": 1.912928759894459,
      "grad_norm": 8.71939754486084,
      "learning_rate": 3.625769569041337e-05,
      "loss": 0.1564,
      "step": 2900
    },
    {
      "epoch": 1.9135883905013191,
      "grad_norm": 1.1467825174331665,
      "learning_rate": 3.623570800351803e-05,
      "loss": 0.0923,
      "step": 2901
    },
    {
      "epoch": 1.9142480211081794,
      "grad_norm": 12.995711326599121,
      "learning_rate": 3.6213720316622694e-05,
      "loss": 0.3316,
      "step": 2902
    },
    {
      "epoch": 1.9149076517150396,
      "grad_norm": 1.1021960973739624,
      "learning_rate": 3.619173262972735e-05,
      "loss": 0.0619,
      "step": 2903
    },
    {
      "epoch": 1.9155672823218999,
      "grad_norm": 5.735710144042969,
      "learning_rate": 3.6169744942832015e-05,
      "loss": 0.1909,
      "step": 2904
    },
    {
      "epoch": 1.91622691292876,
      "grad_norm": 0.7181317806243896,
      "learning_rate": 3.614775725593668e-05,
      "loss": 0.058,
      "step": 2905
    },
    {
      "epoch": 1.91688654353562,
      "grad_norm": 7.478020668029785,
      "learning_rate": 3.612576956904134e-05,
      "loss": 0.2714,
      "step": 2906
    },
    {
      "epoch": 1.9175461741424802,
      "grad_norm": 6.261769771575928,
      "learning_rate": 3.6103781882146e-05,
      "loss": 0.1817,
      "step": 2907
    },
    {
      "epoch": 1.9182058047493404,
      "grad_norm": 1.060592532157898,
      "learning_rate": 3.6081794195250663e-05,
      "loss": 0.0715,
      "step": 2908
    },
    {
      "epoch": 1.9188654353562007,
      "grad_norm": 6.767747402191162,
      "learning_rate": 3.605980650835532e-05,
      "loss": 0.382,
      "step": 2909
    },
    {
      "epoch": 1.9195250659630607,
      "grad_norm": 1.2626310586929321,
      "learning_rate": 3.6037818821459984e-05,
      "loss": 0.0986,
      "step": 2910
    },
    {
      "epoch": 1.9201846965699207,
      "grad_norm": 1.8469511270523071,
      "learning_rate": 3.601583113456465e-05,
      "loss": 0.1585,
      "step": 2911
    },
    {
      "epoch": 1.920844327176781,
      "grad_norm": 1.2710442543029785,
      "learning_rate": 3.5993843447669305e-05,
      "loss": 0.0923,
      "step": 2912
    },
    {
      "epoch": 1.9215039577836412,
      "grad_norm": 1.8324769735336304,
      "learning_rate": 3.597185576077397e-05,
      "loss": 0.1159,
      "step": 2913
    },
    {
      "epoch": 1.9221635883905013,
      "grad_norm": 1.187881350517273,
      "learning_rate": 3.5949868073878626e-05,
      "loss": 0.1056,
      "step": 2914
    },
    {
      "epoch": 1.9228232189973615,
      "grad_norm": 1.371658205986023,
      "learning_rate": 3.592788038698329e-05,
      "loss": 0.0764,
      "step": 2915
    },
    {
      "epoch": 1.9234828496042216,
      "grad_norm": 2.0136256217956543,
      "learning_rate": 3.590589270008795e-05,
      "loss": 0.1279,
      "step": 2916
    },
    {
      "epoch": 1.9241424802110818,
      "grad_norm": 13.724093437194824,
      "learning_rate": 3.588390501319262e-05,
      "loss": 1.2727,
      "step": 2917
    },
    {
      "epoch": 1.924802110817942,
      "grad_norm": 7.274348258972168,
      "learning_rate": 3.5861917326297274e-05,
      "loss": 0.1793,
      "step": 2918
    },
    {
      "epoch": 1.925461741424802,
      "grad_norm": 8.36838150024414,
      "learning_rate": 3.583992963940194e-05,
      "loss": 0.5074,
      "step": 2919
    },
    {
      "epoch": 1.9261213720316621,
      "grad_norm": 0.5568092465400696,
      "learning_rate": 3.58179419525066e-05,
      "loss": 0.0354,
      "step": 2920
    },
    {
      "epoch": 1.9267810026385224,
      "grad_norm": 1.170344591140747,
      "learning_rate": 3.579595426561126e-05,
      "loss": 0.0728,
      "step": 2921
    },
    {
      "epoch": 1.9274406332453826,
      "grad_norm": 11.64330768585205,
      "learning_rate": 3.577396657871592e-05,
      "loss": 0.7976,
      "step": 2922
    },
    {
      "epoch": 1.9281002638522429,
      "grad_norm": 1.4141225814819336,
      "learning_rate": 3.575197889182058e-05,
      "loss": 0.1045,
      "step": 2923
    },
    {
      "epoch": 1.928759894459103,
      "grad_norm": 1.8715450763702393,
      "learning_rate": 3.572999120492524e-05,
      "loss": 0.131,
      "step": 2924
    },
    {
      "epoch": 1.929419525065963,
      "grad_norm": 0.9587645530700684,
      "learning_rate": 3.5708003518029907e-05,
      "loss": 0.0414,
      "step": 2925
    },
    {
      "epoch": 1.9300791556728232,
      "grad_norm": 7.7711873054504395,
      "learning_rate": 3.568601583113457e-05,
      "loss": 0.6217,
      "step": 2926
    },
    {
      "epoch": 1.9307387862796834,
      "grad_norm": 0.7610584497451782,
      "learning_rate": 3.566402814423923e-05,
      "loss": 0.0361,
      "step": 2927
    },
    {
      "epoch": 1.9313984168865437,
      "grad_norm": 15.839669227600098,
      "learning_rate": 3.564204045734389e-05,
      "loss": 0.8267,
      "step": 2928
    },
    {
      "epoch": 1.9320580474934037,
      "grad_norm": 1.856011986732483,
      "learning_rate": 3.5620052770448555e-05,
      "loss": 0.0649,
      "step": 2929
    },
    {
      "epoch": 1.9327176781002637,
      "grad_norm": 3.3238558769226074,
      "learning_rate": 3.559806508355321e-05,
      "loss": 0.1311,
      "step": 2930
    },
    {
      "epoch": 1.933377308707124,
      "grad_norm": 1.2551182508468628,
      "learning_rate": 3.5576077396657876e-05,
      "loss": 0.0692,
      "step": 2931
    },
    {
      "epoch": 1.9340369393139842,
      "grad_norm": 1.0661067962646484,
      "learning_rate": 3.555408970976253e-05,
      "loss": 0.0855,
      "step": 2932
    },
    {
      "epoch": 1.9346965699208445,
      "grad_norm": 1.6676347255706787,
      "learning_rate": 3.5532102022867196e-05,
      "loss": 0.0597,
      "step": 2933
    },
    {
      "epoch": 1.9353562005277045,
      "grad_norm": 8.963807106018066,
      "learning_rate": 3.551011433597185e-05,
      "loss": 0.3519,
      "step": 2934
    },
    {
      "epoch": 1.9360158311345645,
      "grad_norm": 9.03726863861084,
      "learning_rate": 3.548812664907652e-05,
      "loss": 1.4262,
      "step": 2935
    },
    {
      "epoch": 1.9366754617414248,
      "grad_norm": 2.2526097297668457,
      "learning_rate": 3.546613896218118e-05,
      "loss": 0.1052,
      "step": 2936
    },
    {
      "epoch": 1.937335092348285,
      "grad_norm": 3.2573890686035156,
      "learning_rate": 3.5444151275285845e-05,
      "loss": 0.1045,
      "step": 2937
    },
    {
      "epoch": 1.937994722955145,
      "grad_norm": 9.613512992858887,
      "learning_rate": 3.542216358839051e-05,
      "loss": 0.7511,
      "step": 2938
    },
    {
      "epoch": 1.9386543535620053,
      "grad_norm": 5.011046409606934,
      "learning_rate": 3.5400175901495165e-05,
      "loss": 0.1115,
      "step": 2939
    },
    {
      "epoch": 1.9393139841688654,
      "grad_norm": 0.9323960542678833,
      "learning_rate": 3.537818821459983e-05,
      "loss": 0.0688,
      "step": 2940
    },
    {
      "epoch": 1.9399736147757256,
      "grad_norm": 3.926384449005127,
      "learning_rate": 3.5356200527704486e-05,
      "loss": 0.1178,
      "step": 2941
    },
    {
      "epoch": 1.9406332453825859,
      "grad_norm": 14.340497016906738,
      "learning_rate": 3.533421284080915e-05,
      "loss": 0.7973,
      "step": 2942
    },
    {
      "epoch": 1.9412928759894459,
      "grad_norm": 2.306748151779175,
      "learning_rate": 3.531222515391381e-05,
      "loss": 0.1232,
      "step": 2943
    },
    {
      "epoch": 1.941952506596306,
      "grad_norm": 17.576663970947266,
      "learning_rate": 3.529023746701847e-05,
      "loss": 0.8247,
      "step": 2944
    },
    {
      "epoch": 1.9426121372031662,
      "grad_norm": 0.8320393562316895,
      "learning_rate": 3.526824978012313e-05,
      "loss": 0.1099,
      "step": 2945
    },
    {
      "epoch": 1.9432717678100264,
      "grad_norm": 2.455742359161377,
      "learning_rate": 3.524626209322779e-05,
      "loss": 0.1649,
      "step": 2946
    },
    {
      "epoch": 1.9439313984168867,
      "grad_norm": 11.571332931518555,
      "learning_rate": 3.5224274406332455e-05,
      "loss": 0.4205,
      "step": 2947
    },
    {
      "epoch": 1.9445910290237467,
      "grad_norm": 6.576430797576904,
      "learning_rate": 3.520228671943712e-05,
      "loss": 0.2777,
      "step": 2948
    },
    {
      "epoch": 1.9452506596306067,
      "grad_norm": 3.0234713554382324,
      "learning_rate": 3.518029903254178e-05,
      "loss": 0.2221,
      "step": 2949
    },
    {
      "epoch": 1.945910290237467,
      "grad_norm": 0.9714457988739014,
      "learning_rate": 3.515831134564644e-05,
      "loss": 0.0912,
      "step": 2950
    },
    {
      "epoch": 1.9465699208443272,
      "grad_norm": 1.3010207414627075,
      "learning_rate": 3.51363236587511e-05,
      "loss": 0.0871,
      "step": 2951
    },
    {
      "epoch": 1.9472295514511875,
      "grad_norm": 5.5883636474609375,
      "learning_rate": 3.511433597185576e-05,
      "loss": 0.1715,
      "step": 2952
    },
    {
      "epoch": 1.9478891820580475,
      "grad_norm": 0.8524300456047058,
      "learning_rate": 3.5092348284960424e-05,
      "loss": 0.0558,
      "step": 2953
    },
    {
      "epoch": 1.9485488126649075,
      "grad_norm": 8.570045471191406,
      "learning_rate": 3.507036059806508e-05,
      "loss": 0.7375,
      "step": 2954
    },
    {
      "epoch": 1.9492084432717678,
      "grad_norm": 1.6858423948287964,
      "learning_rate": 3.5048372911169745e-05,
      "loss": 0.0981,
      "step": 2955
    },
    {
      "epoch": 1.949868073878628,
      "grad_norm": 10.19929313659668,
      "learning_rate": 3.502638522427441e-05,
      "loss": 0.4796,
      "step": 2956
    },
    {
      "epoch": 1.9505277044854883,
      "grad_norm": 5.076327323913574,
      "learning_rate": 3.5004397537379066e-05,
      "loss": 0.2155,
      "step": 2957
    },
    {
      "epoch": 1.9511873350923483,
      "grad_norm": 2.8822410106658936,
      "learning_rate": 3.4982409850483736e-05,
      "loss": 0.1648,
      "step": 2958
    },
    {
      "epoch": 1.9518469656992083,
      "grad_norm": 1.6663142442703247,
      "learning_rate": 3.496042216358839e-05,
      "loss": 0.1233,
      "step": 2959
    },
    {
      "epoch": 1.9525065963060686,
      "grad_norm": 2.405735492706299,
      "learning_rate": 3.493843447669306e-05,
      "loss": 0.0976,
      "step": 2960
    },
    {
      "epoch": 1.9531662269129288,
      "grad_norm": 8.249631881713867,
      "learning_rate": 3.4916446789797714e-05,
      "loss": 0.8067,
      "step": 2961
    },
    {
      "epoch": 1.9538258575197889,
      "grad_norm": 0.9834304451942444,
      "learning_rate": 3.489445910290238e-05,
      "loss": 0.0397,
      "step": 2962
    },
    {
      "epoch": 1.9544854881266491,
      "grad_norm": 0.505728006362915,
      "learning_rate": 3.4872471416007035e-05,
      "loss": 0.0468,
      "step": 2963
    },
    {
      "epoch": 1.9551451187335092,
      "grad_norm": 0.8477656841278076,
      "learning_rate": 3.48504837291117e-05,
      "loss": 0.0749,
      "step": 2964
    },
    {
      "epoch": 1.9558047493403694,
      "grad_norm": 7.105260372161865,
      "learning_rate": 3.482849604221636e-05,
      "loss": 0.4263,
      "step": 2965
    },
    {
      "epoch": 1.9564643799472297,
      "grad_norm": 1.2477670907974243,
      "learning_rate": 3.480650835532102e-05,
      "loss": 0.0657,
      "step": 2966
    },
    {
      "epoch": 1.9571240105540897,
      "grad_norm": 8.250288009643555,
      "learning_rate": 3.478452066842568e-05,
      "loss": 0.41,
      "step": 2967
    },
    {
      "epoch": 1.9577836411609497,
      "grad_norm": 1.1121339797973633,
      "learning_rate": 3.4762532981530347e-05,
      "loss": 0.0858,
      "step": 2968
    },
    {
      "epoch": 1.95844327176781,
      "grad_norm": 0.8540405631065369,
      "learning_rate": 3.474054529463501e-05,
      "loss": 0.0377,
      "step": 2969
    },
    {
      "epoch": 1.9591029023746702,
      "grad_norm": 3.2170886993408203,
      "learning_rate": 3.471855760773967e-05,
      "loss": 0.1212,
      "step": 2970
    },
    {
      "epoch": 1.9597625329815305,
      "grad_norm": 0.884159505367279,
      "learning_rate": 3.469656992084433e-05,
      "loss": 0.0397,
      "step": 2971
    },
    {
      "epoch": 1.9604221635883905,
      "grad_norm": 5.412890434265137,
      "learning_rate": 3.467458223394899e-05,
      "loss": 0.1934,
      "step": 2972
    },
    {
      "epoch": 1.9610817941952505,
      "grad_norm": 13.317875862121582,
      "learning_rate": 3.465259454705365e-05,
      "loss": 0.446,
      "step": 2973
    },
    {
      "epoch": 1.9617414248021108,
      "grad_norm": 2.2322371006011963,
      "learning_rate": 3.4630606860158316e-05,
      "loss": 0.0894,
      "step": 2974
    },
    {
      "epoch": 1.962401055408971,
      "grad_norm": 0.986884593963623,
      "learning_rate": 3.460861917326297e-05,
      "loss": 0.0532,
      "step": 2975
    },
    {
      "epoch": 1.9630606860158313,
      "grad_norm": 12.761839866638184,
      "learning_rate": 3.4586631486367636e-05,
      "loss": 0.2958,
      "step": 2976
    },
    {
      "epoch": 1.9637203166226913,
      "grad_norm": 11.959341049194336,
      "learning_rate": 3.456464379947229e-05,
      "loss": 0.626,
      "step": 2977
    },
    {
      "epoch": 1.9643799472295513,
      "grad_norm": 5.191666603088379,
      "learning_rate": 3.454265611257696e-05,
      "loss": 0.1397,
      "step": 2978
    },
    {
      "epoch": 1.9650395778364116,
      "grad_norm": 6.141293048858643,
      "learning_rate": 3.452066842568162e-05,
      "loss": 0.2058,
      "step": 2979
    },
    {
      "epoch": 1.9656992084432718,
      "grad_norm": 3.703934669494629,
      "learning_rate": 3.4498680738786285e-05,
      "loss": 0.1153,
      "step": 2980
    },
    {
      "epoch": 1.966358839050132,
      "grad_norm": 10.932943344116211,
      "learning_rate": 3.447669305189094e-05,
      "loss": 0.8112,
      "step": 2981
    },
    {
      "epoch": 1.9670184696569921,
      "grad_norm": 11.169614791870117,
      "learning_rate": 3.4454705364995605e-05,
      "loss": 0.3124,
      "step": 2982
    },
    {
      "epoch": 1.9676781002638521,
      "grad_norm": 0.9942231774330139,
      "learning_rate": 3.443271767810027e-05,
      "loss": 0.0698,
      "step": 2983
    },
    {
      "epoch": 1.9683377308707124,
      "grad_norm": 1.7616654634475708,
      "learning_rate": 3.4410729991204926e-05,
      "loss": 0.0598,
      "step": 2984
    },
    {
      "epoch": 1.9689973614775726,
      "grad_norm": 2.050506353378296,
      "learning_rate": 3.438874230430959e-05,
      "loss": 0.1181,
      "step": 2985
    },
    {
      "epoch": 1.9696569920844327,
      "grad_norm": 1.264846920967102,
      "learning_rate": 3.436675461741425e-05,
      "loss": 0.1195,
      "step": 2986
    },
    {
      "epoch": 1.970316622691293,
      "grad_norm": 17.196147918701172,
      "learning_rate": 3.434476693051891e-05,
      "loss": 0.8932,
      "step": 2987
    },
    {
      "epoch": 1.970976253298153,
      "grad_norm": 0.9493686556816101,
      "learning_rate": 3.432277924362357e-05,
      "loss": 0.0879,
      "step": 2988
    },
    {
      "epoch": 1.9716358839050132,
      "grad_norm": 1.258237600326538,
      "learning_rate": 3.430079155672823e-05,
      "loss": 0.0853,
      "step": 2989
    },
    {
      "epoch": 1.9722955145118735,
      "grad_norm": 7.725961685180664,
      "learning_rate": 3.4278803869832895e-05,
      "loss": 0.1947,
      "step": 2990
    },
    {
      "epoch": 1.9729551451187335,
      "grad_norm": 1.8998188972473145,
      "learning_rate": 3.425681618293756e-05,
      "loss": 0.1264,
      "step": 2991
    },
    {
      "epoch": 1.9736147757255935,
      "grad_norm": 0.5609713792800903,
      "learning_rate": 3.423482849604222e-05,
      "loss": 0.0445,
      "step": 2992
    },
    {
      "epoch": 1.9742744063324538,
      "grad_norm": 20.972837448120117,
      "learning_rate": 3.421284080914688e-05,
      "loss": 2.0251,
      "step": 2993
    },
    {
      "epoch": 1.974934036939314,
      "grad_norm": 1.068658709526062,
      "learning_rate": 3.419085312225154e-05,
      "loss": 0.0648,
      "step": 2994
    },
    {
      "epoch": 1.9755936675461743,
      "grad_norm": 8.498435020446777,
      "learning_rate": 3.41688654353562e-05,
      "loss": 0.5306,
      "step": 2995
    },
    {
      "epoch": 1.9762532981530343,
      "grad_norm": 0.9066844582557678,
      "learning_rate": 3.4146877748460864e-05,
      "loss": 0.0544,
      "step": 2996
    },
    {
      "epoch": 1.9769129287598943,
      "grad_norm": 8.829212188720703,
      "learning_rate": 3.412489006156552e-05,
      "loss": 0.5899,
      "step": 2997
    },
    {
      "epoch": 1.9775725593667546,
      "grad_norm": 0.8718112707138062,
      "learning_rate": 3.4102902374670185e-05,
      "loss": 0.0836,
      "step": 2998
    },
    {
      "epoch": 1.9782321899736148,
      "grad_norm": 1.0586539506912231,
      "learning_rate": 3.408091468777485e-05,
      "loss": 0.0602,
      "step": 2999
    },
    {
      "epoch": 1.978891820580475,
      "grad_norm": 1.0163357257843018,
      "learning_rate": 3.405892700087951e-05,
      "loss": 0.0614,
      "step": 3000
    },
    {
      "epoch": 1.979551451187335,
      "grad_norm": 1.107218861579895,
      "learning_rate": 3.4036939313984176e-05,
      "loss": 0.0717,
      "step": 3001
    },
    {
      "epoch": 1.9802110817941951,
      "grad_norm": 0.44779443740844727,
      "learning_rate": 3.401495162708883e-05,
      "loss": 0.033,
      "step": 3002
    },
    {
      "epoch": 1.9808707124010554,
      "grad_norm": 0.4618084728717804,
      "learning_rate": 3.39929639401935e-05,
      "loss": 0.0282,
      "step": 3003
    },
    {
      "epoch": 1.9815303430079156,
      "grad_norm": 9.155279159545898,
      "learning_rate": 3.3970976253298154e-05,
      "loss": 0.292,
      "step": 3004
    },
    {
      "epoch": 1.982189973614776,
      "grad_norm": 2.3809261322021484,
      "learning_rate": 3.394898856640282e-05,
      "loss": 0.0413,
      "step": 3005
    },
    {
      "epoch": 1.982849604221636,
      "grad_norm": 17.932737350463867,
      "learning_rate": 3.3927000879507474e-05,
      "loss": 1.1481,
      "step": 3006
    },
    {
      "epoch": 1.983509234828496,
      "grad_norm": 14.928410530090332,
      "learning_rate": 3.390501319261214e-05,
      "loss": 0.9289,
      "step": 3007
    },
    {
      "epoch": 1.9841688654353562,
      "grad_norm": 41.03345489501953,
      "learning_rate": 3.3883025505716795e-05,
      "loss": 0.6527,
      "step": 3008
    },
    {
      "epoch": 1.9848284960422165,
      "grad_norm": 1.1078979969024658,
      "learning_rate": 3.386103781882146e-05,
      "loss": 0.0573,
      "step": 3009
    },
    {
      "epoch": 1.9854881266490765,
      "grad_norm": 2.9681761264801025,
      "learning_rate": 3.383905013192612e-05,
      "loss": 0.0751,
      "step": 3010
    },
    {
      "epoch": 1.9861477572559367,
      "grad_norm": 0.901096761226654,
      "learning_rate": 3.3817062445030786e-05,
      "loss": 0.0418,
      "step": 3011
    },
    {
      "epoch": 1.9868073878627968,
      "grad_norm": 0.9402137398719788,
      "learning_rate": 3.379507475813545e-05,
      "loss": 0.0388,
      "step": 3012
    },
    {
      "epoch": 1.987467018469657,
      "grad_norm": 5.2464070320129395,
      "learning_rate": 3.377308707124011e-05,
      "loss": 0.1741,
      "step": 3013
    },
    {
      "epoch": 1.9881266490765173,
      "grad_norm": 0.47092974185943604,
      "learning_rate": 3.375109938434477e-05,
      "loss": 0.0267,
      "step": 3014
    },
    {
      "epoch": 1.9887862796833773,
      "grad_norm": 26.763635635375977,
      "learning_rate": 3.372911169744943e-05,
      "loss": 2.4898,
      "step": 3015
    },
    {
      "epoch": 1.9894459102902373,
      "grad_norm": 0.3939574956893921,
      "learning_rate": 3.370712401055409e-05,
      "loss": 0.0206,
      "step": 3016
    },
    {
      "epoch": 1.9901055408970976,
      "grad_norm": 10.06045150756836,
      "learning_rate": 3.368513632365875e-05,
      "loss": 0.2505,
      "step": 3017
    },
    {
      "epoch": 1.9907651715039578,
      "grad_norm": 11.083850860595703,
      "learning_rate": 3.366314863676341e-05,
      "loss": 0.922,
      "step": 3018
    },
    {
      "epoch": 1.991424802110818,
      "grad_norm": 1.692238211631775,
      "learning_rate": 3.3641160949868076e-05,
      "loss": 0.0579,
      "step": 3019
    },
    {
      "epoch": 1.992084432717678,
      "grad_norm": 5.85322380065918,
      "learning_rate": 3.361917326297273e-05,
      "loss": 0.1613,
      "step": 3020
    },
    {
      "epoch": 1.9927440633245381,
      "grad_norm": 8.484664916992188,
      "learning_rate": 3.35971855760774e-05,
      "loss": 0.315,
      "step": 3021
    },
    {
      "epoch": 1.9934036939313984,
      "grad_norm": 2.7808597087860107,
      "learning_rate": 3.357519788918206e-05,
      "loss": 0.0774,
      "step": 3022
    },
    {
      "epoch": 1.9940633245382586,
      "grad_norm": 20.738656997680664,
      "learning_rate": 3.3553210202286724e-05,
      "loss": 0.5354,
      "step": 3023
    },
    {
      "epoch": 1.9947229551451189,
      "grad_norm": 4.652158260345459,
      "learning_rate": 3.353122251539138e-05,
      "loss": 0.1036,
      "step": 3024
    },
    {
      "epoch": 1.995382585751979,
      "grad_norm": 0.5750129222869873,
      "learning_rate": 3.3509234828496045e-05,
      "loss": 0.0411,
      "step": 3025
    },
    {
      "epoch": 1.996042216358839,
      "grad_norm": 3.7409443855285645,
      "learning_rate": 3.34872471416007e-05,
      "loss": 0.1096,
      "step": 3026
    },
    {
      "epoch": 1.9967018469656992,
      "grad_norm": 13.352298736572266,
      "learning_rate": 3.3465259454705366e-05,
      "loss": 0.1627,
      "step": 3027
    },
    {
      "epoch": 1.9973614775725594,
      "grad_norm": 1.3301396369934082,
      "learning_rate": 3.344327176781003e-05,
      "loss": 0.061,
      "step": 3028
    },
    {
      "epoch": 1.9980211081794197,
      "grad_norm": 4.739861965179443,
      "learning_rate": 3.342128408091469e-05,
      "loss": 0.1838,
      "step": 3029
    },
    {
      "epoch": 1.9986807387862797,
      "grad_norm": 10.833325386047363,
      "learning_rate": 3.339929639401935e-05,
      "loss": 0.3764,
      "step": 3030
    },
    {
      "epoch": 1.9993403693931397,
      "grad_norm": 1.8411093950271606,
      "learning_rate": 3.3377308707124014e-05,
      "loss": 0.1153,
      "step": 3031
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.647897720336914,
      "learning_rate": 3.335532102022868e-05,
      "loss": 0.0868,
      "step": 3032
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8643410852713178,
      "eval_f1": 0.8486803519061583,
      "eval_keras_BCE": 0.4324982464313507,
      "eval_loss": 0.5317972302436829,
      "eval_precision": 0.8619254851488151,
      "eval_recall": 0.7954545454545454,
      "eval_runtime": 1.7219,
      "eval_samples_per_second": 149.834,
      "eval_steps_per_second": 19.165,
      "eval_weighted BCE": 28.360483169555664,
      "step": 3032
    },
    {
      "epoch": 2.0006596306068603,
      "grad_norm": 0.7540773153305054,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.0586,
      "step": 3033
    },
    {
      "epoch": 2.0013192612137205,
      "grad_norm": 3.4529709815979004,
      "learning_rate": 3.3311345646438e-05,
      "loss": 0.1835,
      "step": 3034
    },
    {
      "epoch": 2.0019788918205803,
      "grad_norm": 1.2837804555892944,
      "learning_rate": 3.3289357959542656e-05,
      "loss": 0.0861,
      "step": 3035
    },
    {
      "epoch": 2.0026385224274406,
      "grad_norm": 1.1106539964675903,
      "learning_rate": 3.326737027264732e-05,
      "loss": 0.0743,
      "step": 3036
    },
    {
      "epoch": 2.003298153034301,
      "grad_norm": 3.93690824508667,
      "learning_rate": 3.324538258575198e-05,
      "loss": 0.2017,
      "step": 3037
    },
    {
      "epoch": 2.003957783641161,
      "grad_norm": 1.0817999839782715,
      "learning_rate": 3.322339489885664e-05,
      "loss": 0.0778,
      "step": 3038
    },
    {
      "epoch": 2.0046174142480213,
      "grad_norm": 0.7433074712753296,
      "learning_rate": 3.3201407211961304e-05,
      "loss": 0.0623,
      "step": 3039
    },
    {
      "epoch": 2.005277044854881,
      "grad_norm": 0.7057398557662964,
      "learning_rate": 3.317941952506596e-05,
      "loss": 0.0771,
      "step": 3040
    },
    {
      "epoch": 2.0059366754617414,
      "grad_norm": 2.6527276039123535,
      "learning_rate": 3.3157431838170625e-05,
      "loss": 0.0612,
      "step": 3041
    },
    {
      "epoch": 2.0065963060686016,
      "grad_norm": 1.0089834928512573,
      "learning_rate": 3.313544415127529e-05,
      "loss": 0.0981,
      "step": 3042
    },
    {
      "epoch": 2.007255936675462,
      "grad_norm": 1.5794481039047241,
      "learning_rate": 3.311345646437995e-05,
      "loss": 0.1394,
      "step": 3043
    },
    {
      "epoch": 2.007915567282322,
      "grad_norm": 2.520601511001587,
      "learning_rate": 3.309146877748461e-05,
      "loss": 0.1691,
      "step": 3044
    },
    {
      "epoch": 2.008575197889182,
      "grad_norm": 6.098848342895508,
      "learning_rate": 3.306948109058927e-05,
      "loss": 0.1903,
      "step": 3045
    },
    {
      "epoch": 2.009234828496042,
      "grad_norm": 2.687018632888794,
      "learning_rate": 3.304749340369394e-05,
      "loss": 0.0754,
      "step": 3046
    },
    {
      "epoch": 2.0098944591029024,
      "grad_norm": 1.0984874963760376,
      "learning_rate": 3.3025505716798594e-05,
      "loss": 0.073,
      "step": 3047
    },
    {
      "epoch": 2.0105540897097627,
      "grad_norm": 0.6888885498046875,
      "learning_rate": 3.300351802990326e-05,
      "loss": 0.0276,
      "step": 3048
    },
    {
      "epoch": 2.0112137203166225,
      "grad_norm": 5.6984543800354,
      "learning_rate": 3.2981530343007914e-05,
      "loss": 0.3891,
      "step": 3049
    },
    {
      "epoch": 2.0118733509234827,
      "grad_norm": 2.438937187194824,
      "learning_rate": 3.295954265611258e-05,
      "loss": 0.0584,
      "step": 3050
    },
    {
      "epoch": 2.012532981530343,
      "grad_norm": 0.7813346982002258,
      "learning_rate": 3.2937554969217235e-05,
      "loss": 0.037,
      "step": 3051
    },
    {
      "epoch": 2.0131926121372032,
      "grad_norm": 0.441339910030365,
      "learning_rate": 3.29155672823219e-05,
      "loss": 0.0198,
      "step": 3052
    },
    {
      "epoch": 2.0138522427440635,
      "grad_norm": 11.778685569763184,
      "learning_rate": 3.289357959542656e-05,
      "loss": 0.3224,
      "step": 3053
    },
    {
      "epoch": 2.0145118733509233,
      "grad_norm": 0.6006363034248352,
      "learning_rate": 3.2871591908531226e-05,
      "loss": 0.0399,
      "step": 3054
    },
    {
      "epoch": 2.0151715039577835,
      "grad_norm": 0.5055035352706909,
      "learning_rate": 3.284960422163589e-05,
      "loss": 0.0463,
      "step": 3055
    },
    {
      "epoch": 2.015831134564644,
      "grad_norm": 8.813067436218262,
      "learning_rate": 3.282761653474055e-05,
      "loss": 0.2853,
      "step": 3056
    },
    {
      "epoch": 2.016490765171504,
      "grad_norm": 0.475287526845932,
      "learning_rate": 3.280562884784521e-05,
      "loss": 0.0346,
      "step": 3057
    },
    {
      "epoch": 2.0171503957783643,
      "grad_norm": 0.9146106243133545,
      "learning_rate": 3.278364116094987e-05,
      "loss": 0.0609,
      "step": 3058
    },
    {
      "epoch": 2.017810026385224,
      "grad_norm": 11.642191886901855,
      "learning_rate": 3.276165347405453e-05,
      "loss": 0.473,
      "step": 3059
    },
    {
      "epoch": 2.0184696569920844,
      "grad_norm": 0.6354109644889832,
      "learning_rate": 3.273966578715919e-05,
      "loss": 0.0248,
      "step": 3060
    },
    {
      "epoch": 2.0191292875989446,
      "grad_norm": 10.945228576660156,
      "learning_rate": 3.271767810026385e-05,
      "loss": 0.6177,
      "step": 3061
    },
    {
      "epoch": 2.019788918205805,
      "grad_norm": 19.947830200195312,
      "learning_rate": 3.269569041336851e-05,
      "loss": 0.7798,
      "step": 3062
    },
    {
      "epoch": 2.020448548812665,
      "grad_norm": 0.6915160417556763,
      "learning_rate": 3.267370272647318e-05,
      "loss": 0.0194,
      "step": 3063
    },
    {
      "epoch": 2.021108179419525,
      "grad_norm": 11.50429916381836,
      "learning_rate": 3.2651715039577844e-05,
      "loss": 0.3778,
      "step": 3064
    },
    {
      "epoch": 2.021767810026385,
      "grad_norm": 6.453028202056885,
      "learning_rate": 3.26297273526825e-05,
      "loss": 0.5267,
      "step": 3065
    },
    {
      "epoch": 2.0224274406332454,
      "grad_norm": 12.875081062316895,
      "learning_rate": 3.2607739665787164e-05,
      "loss": 0.3786,
      "step": 3066
    },
    {
      "epoch": 2.0230870712401057,
      "grad_norm": 4.117362022399902,
      "learning_rate": 3.258575197889182e-05,
      "loss": 0.1048,
      "step": 3067
    },
    {
      "epoch": 2.0237467018469655,
      "grad_norm": 10.780228614807129,
      "learning_rate": 3.2563764291996485e-05,
      "loss": 0.5916,
      "step": 3068
    },
    {
      "epoch": 2.0244063324538257,
      "grad_norm": 0.7514308094978333,
      "learning_rate": 3.254177660510114e-05,
      "loss": 0.0406,
      "step": 3069
    },
    {
      "epoch": 2.025065963060686,
      "grad_norm": 1.5923452377319336,
      "learning_rate": 3.2519788918205806e-05,
      "loss": 0.0825,
      "step": 3070
    },
    {
      "epoch": 2.0257255936675462,
      "grad_norm": 0.5833922028541565,
      "learning_rate": 3.249780123131046e-05,
      "loss": 0.0373,
      "step": 3071
    },
    {
      "epoch": 2.0263852242744065,
      "grad_norm": 9.13593578338623,
      "learning_rate": 3.2475813544415127e-05,
      "loss": 0.2971,
      "step": 3072
    },
    {
      "epoch": 2.0270448548812663,
      "grad_norm": 0.654247522354126,
      "learning_rate": 3.245382585751979e-05,
      "loss": 0.0378,
      "step": 3073
    },
    {
      "epoch": 2.0277044854881265,
      "grad_norm": 1.6847630739212036,
      "learning_rate": 3.2431838170624454e-05,
      "loss": 0.0905,
      "step": 3074
    },
    {
      "epoch": 2.028364116094987,
      "grad_norm": 0.6768624782562256,
      "learning_rate": 3.240985048372912e-05,
      "loss": 0.0324,
      "step": 3075
    },
    {
      "epoch": 2.029023746701847,
      "grad_norm": 0.7627129554748535,
      "learning_rate": 3.2387862796833775e-05,
      "loss": 0.0487,
      "step": 3076
    },
    {
      "epoch": 2.0296833773087073,
      "grad_norm": 1.101747989654541,
      "learning_rate": 3.236587510993844e-05,
      "loss": 0.0667,
      "step": 3077
    },
    {
      "epoch": 2.030343007915567,
      "grad_norm": 4.60896635055542,
      "learning_rate": 3.2343887423043096e-05,
      "loss": 0.1984,
      "step": 3078
    },
    {
      "epoch": 2.0310026385224274,
      "grad_norm": 0.7763599157333374,
      "learning_rate": 3.232189973614776e-05,
      "loss": 0.0407,
      "step": 3079
    },
    {
      "epoch": 2.0316622691292876,
      "grad_norm": 0.7071242332458496,
      "learning_rate": 3.2299912049252416e-05,
      "loss": 0.0464,
      "step": 3080
    },
    {
      "epoch": 2.032321899736148,
      "grad_norm": 2.5099868774414062,
      "learning_rate": 3.227792436235708e-05,
      "loss": 0.1056,
      "step": 3081
    },
    {
      "epoch": 2.032981530343008,
      "grad_norm": 3.0834076404571533,
      "learning_rate": 3.2255936675461744e-05,
      "loss": 0.0935,
      "step": 3082
    },
    {
      "epoch": 2.033641160949868,
      "grad_norm": 15.984217643737793,
      "learning_rate": 3.22339489885664e-05,
      "loss": 0.7073,
      "step": 3083
    },
    {
      "epoch": 2.034300791556728,
      "grad_norm": 5.343896389007568,
      "learning_rate": 3.2211961301671065e-05,
      "loss": 0.0931,
      "step": 3084
    },
    {
      "epoch": 2.0349604221635884,
      "grad_norm": 5.913207054138184,
      "learning_rate": 3.218997361477573e-05,
      "loss": 0.1687,
      "step": 3085
    },
    {
      "epoch": 2.0356200527704487,
      "grad_norm": 1.215762734413147,
      "learning_rate": 3.216798592788039e-05,
      "loss": 0.047,
      "step": 3086
    },
    {
      "epoch": 2.036279683377309,
      "grad_norm": 7.027212619781494,
      "learning_rate": 3.214599824098505e-05,
      "loss": 0.1971,
      "step": 3087
    },
    {
      "epoch": 2.0369393139841687,
      "grad_norm": 12.463284492492676,
      "learning_rate": 3.212401055408971e-05,
      "loss": 0.3604,
      "step": 3088
    },
    {
      "epoch": 2.037598944591029,
      "grad_norm": 1.139869213104248,
      "learning_rate": 3.210202286719437e-05,
      "loss": 0.0557,
      "step": 3089
    },
    {
      "epoch": 2.038258575197889,
      "grad_norm": 3.163121461868286,
      "learning_rate": 3.2080035180299034e-05,
      "loss": 0.0678,
      "step": 3090
    },
    {
      "epoch": 2.0389182058047495,
      "grad_norm": 0.5772021412849426,
      "learning_rate": 3.20580474934037e-05,
      "loss": 0.0388,
      "step": 3091
    },
    {
      "epoch": 2.0395778364116097,
      "grad_norm": 1.4076259136199951,
      "learning_rate": 3.2036059806508354e-05,
      "loss": 0.078,
      "step": 3092
    },
    {
      "epoch": 2.0402374670184695,
      "grad_norm": 0.6475071907043457,
      "learning_rate": 3.201407211961302e-05,
      "loss": 0.0251,
      "step": 3093
    },
    {
      "epoch": 2.04089709762533,
      "grad_norm": 0.744011402130127,
      "learning_rate": 3.1992084432717675e-05,
      "loss": 0.0714,
      "step": 3094
    },
    {
      "epoch": 2.04155672823219,
      "grad_norm": 0.7952858805656433,
      "learning_rate": 3.197009674582234e-05,
      "loss": 0.0362,
      "step": 3095
    },
    {
      "epoch": 2.0422163588390503,
      "grad_norm": 10.577223777770996,
      "learning_rate": 3.1948109058927e-05,
      "loss": 0.4524,
      "step": 3096
    },
    {
      "epoch": 2.04287598944591,
      "grad_norm": 2.0854852199554443,
      "learning_rate": 3.1926121372031666e-05,
      "loss": 0.0566,
      "step": 3097
    },
    {
      "epoch": 2.0435356200527703,
      "grad_norm": 10.911230087280273,
      "learning_rate": 3.190413368513632e-05,
      "loss": 0.8919,
      "step": 3098
    },
    {
      "epoch": 2.0441952506596306,
      "grad_norm": 9.142818450927734,
      "learning_rate": 3.188214599824099e-05,
      "loss": 0.3139,
      "step": 3099
    },
    {
      "epoch": 2.044854881266491,
      "grad_norm": 1.9124691486358643,
      "learning_rate": 3.186015831134565e-05,
      "loss": 0.1003,
      "step": 3100
    },
    {
      "epoch": 2.045514511873351,
      "grad_norm": 8.642616271972656,
      "learning_rate": 3.183817062445031e-05,
      "loss": 0.4632,
      "step": 3101
    },
    {
      "epoch": 2.046174142480211,
      "grad_norm": 0.6221799850463867,
      "learning_rate": 3.181618293755497e-05,
      "loss": 0.0353,
      "step": 3102
    },
    {
      "epoch": 2.046833773087071,
      "grad_norm": 1.007107138633728,
      "learning_rate": 3.179419525065963e-05,
      "loss": 0.069,
      "step": 3103
    },
    {
      "epoch": 2.0474934036939314,
      "grad_norm": 0.9103096723556519,
      "learning_rate": 3.177220756376429e-05,
      "loss": 0.0522,
      "step": 3104
    },
    {
      "epoch": 2.0481530343007917,
      "grad_norm": 0.8061222434043884,
      "learning_rate": 3.1750219876868956e-05,
      "loss": 0.0522,
      "step": 3105
    },
    {
      "epoch": 2.048812664907652,
      "grad_norm": 0.5413869023323059,
      "learning_rate": 3.172823218997362e-05,
      "loss": 0.0511,
      "step": 3106
    },
    {
      "epoch": 2.0494722955145117,
      "grad_norm": 3.987154245376587,
      "learning_rate": 3.170624450307828e-05,
      "loss": 0.0823,
      "step": 3107
    },
    {
      "epoch": 2.050131926121372,
      "grad_norm": 10.510212898254395,
      "learning_rate": 3.168425681618294e-05,
      "loss": 0.1648,
      "step": 3108
    },
    {
      "epoch": 2.050791556728232,
      "grad_norm": 0.992958128452301,
      "learning_rate": 3.1662269129287604e-05,
      "loss": 0.0656,
      "step": 3109
    },
    {
      "epoch": 2.0514511873350925,
      "grad_norm": 4.525798797607422,
      "learning_rate": 3.164028144239226e-05,
      "loss": 0.1195,
      "step": 3110
    },
    {
      "epoch": 2.0521108179419527,
      "grad_norm": 3.060504913330078,
      "learning_rate": 3.1618293755496925e-05,
      "loss": 0.1148,
      "step": 3111
    },
    {
      "epoch": 2.0527704485488125,
      "grad_norm": 3.6861178874969482,
      "learning_rate": 3.159630606860158e-05,
      "loss": 0.0976,
      "step": 3112
    },
    {
      "epoch": 2.0534300791556728,
      "grad_norm": 8.407943725585938,
      "learning_rate": 3.1574318381706246e-05,
      "loss": 0.2324,
      "step": 3113
    },
    {
      "epoch": 2.054089709762533,
      "grad_norm": 1.4775937795639038,
      "learning_rate": 3.15523306948109e-05,
      "loss": 0.1097,
      "step": 3114
    },
    {
      "epoch": 2.0547493403693933,
      "grad_norm": 1.4836397171020508,
      "learning_rate": 3.1530343007915567e-05,
      "loss": 0.0968,
      "step": 3115
    },
    {
      "epoch": 2.055408970976253,
      "grad_norm": 0.8146687150001526,
      "learning_rate": 3.150835532102023e-05,
      "loss": 0.0555,
      "step": 3116
    },
    {
      "epoch": 2.0560686015831133,
      "grad_norm": 0.7065957188606262,
      "learning_rate": 3.1486367634124894e-05,
      "loss": 0.0543,
      "step": 3117
    },
    {
      "epoch": 2.0567282321899736,
      "grad_norm": 10.26325798034668,
      "learning_rate": 3.146437994722956e-05,
      "loss": 0.1784,
      "step": 3118
    },
    {
      "epoch": 2.057387862796834,
      "grad_norm": 0.3705529272556305,
      "learning_rate": 3.1442392260334215e-05,
      "loss": 0.0206,
      "step": 3119
    },
    {
      "epoch": 2.058047493403694,
      "grad_norm": 1.1086456775665283,
      "learning_rate": 3.142040457343888e-05,
      "loss": 0.0763,
      "step": 3120
    },
    {
      "epoch": 2.058707124010554,
      "grad_norm": 9.341499328613281,
      "learning_rate": 3.1398416886543536e-05,
      "loss": 0.972,
      "step": 3121
    },
    {
      "epoch": 2.059366754617414,
      "grad_norm": 1.9179795980453491,
      "learning_rate": 3.13764291996482e-05,
      "loss": 0.0451,
      "step": 3122
    },
    {
      "epoch": 2.0600263852242744,
      "grad_norm": 19.864961624145508,
      "learning_rate": 3.1354441512752856e-05,
      "loss": 0.6196,
      "step": 3123
    },
    {
      "epoch": 2.0606860158311346,
      "grad_norm": 5.405309200286865,
      "learning_rate": 3.133245382585752e-05,
      "loss": 0.2277,
      "step": 3124
    },
    {
      "epoch": 2.061345646437995,
      "grad_norm": 0.5970047116279602,
      "learning_rate": 3.131046613896218e-05,
      "loss": 0.041,
      "step": 3125
    },
    {
      "epoch": 2.0620052770448547,
      "grad_norm": 0.641924262046814,
      "learning_rate": 3.128847845206684e-05,
      "loss": 0.0579,
      "step": 3126
    },
    {
      "epoch": 2.062664907651715,
      "grad_norm": 1.4562891721725464,
      "learning_rate": 3.1266490765171505e-05,
      "loss": 0.0512,
      "step": 3127
    },
    {
      "epoch": 2.063324538258575,
      "grad_norm": 9.130791664123535,
      "learning_rate": 3.124450307827617e-05,
      "loss": 0.618,
      "step": 3128
    },
    {
      "epoch": 2.0639841688654355,
      "grad_norm": 3.0615360736846924,
      "learning_rate": 3.122251539138083e-05,
      "loss": 0.0805,
      "step": 3129
    },
    {
      "epoch": 2.0646437994722957,
      "grad_norm": 15.004697799682617,
      "learning_rate": 3.120052770448549e-05,
      "loss": 0.4932,
      "step": 3130
    },
    {
      "epoch": 2.0653034300791555,
      "grad_norm": 0.8384197950363159,
      "learning_rate": 3.117854001759015e-05,
      "loss": 0.0328,
      "step": 3131
    },
    {
      "epoch": 2.0659630606860158,
      "grad_norm": 1.1215218305587769,
      "learning_rate": 3.115655233069481e-05,
      "loss": 0.0589,
      "step": 3132
    },
    {
      "epoch": 2.066622691292876,
      "grad_norm": 11.94599723815918,
      "learning_rate": 3.1134564643799474e-05,
      "loss": 0.4604,
      "step": 3133
    },
    {
      "epoch": 2.0672823218997363,
      "grad_norm": 0.7507777810096741,
      "learning_rate": 3.111257695690413e-05,
      "loss": 0.0377,
      "step": 3134
    },
    {
      "epoch": 2.0679419525065965,
      "grad_norm": 1.0444308519363403,
      "learning_rate": 3.1090589270008794e-05,
      "loss": 0.0657,
      "step": 3135
    },
    {
      "epoch": 2.0686015831134563,
      "grad_norm": 1.45290207862854,
      "learning_rate": 3.106860158311346e-05,
      "loss": 0.0662,
      "step": 3136
    },
    {
      "epoch": 2.0692612137203166,
      "grad_norm": 7.795694351196289,
      "learning_rate": 3.104661389621812e-05,
      "loss": 0.4847,
      "step": 3137
    },
    {
      "epoch": 2.069920844327177,
      "grad_norm": 1.2495535612106323,
      "learning_rate": 3.1024626209322786e-05,
      "loss": 0.0854,
      "step": 3138
    },
    {
      "epoch": 2.070580474934037,
      "grad_norm": 16.752260208129883,
      "learning_rate": 3.100263852242744e-05,
      "loss": 1.0193,
      "step": 3139
    },
    {
      "epoch": 2.0712401055408973,
      "grad_norm": 0.8040373921394348,
      "learning_rate": 3.0980650835532106e-05,
      "loss": 0.043,
      "step": 3140
    },
    {
      "epoch": 2.071899736147757,
      "grad_norm": 17.33055305480957,
      "learning_rate": 3.095866314863676e-05,
      "loss": 0.2494,
      "step": 3141
    },
    {
      "epoch": 2.0725593667546174,
      "grad_norm": 1.3954871892929077,
      "learning_rate": 3.093667546174143e-05,
      "loss": 0.0796,
      "step": 3142
    },
    {
      "epoch": 2.0732189973614776,
      "grad_norm": 0.9486428499221802,
      "learning_rate": 3.0914687774846084e-05,
      "loss": 0.0648,
      "step": 3143
    },
    {
      "epoch": 2.073878627968338,
      "grad_norm": 0.6144033670425415,
      "learning_rate": 3.089270008795075e-05,
      "loss": 0.0518,
      "step": 3144
    },
    {
      "epoch": 2.0745382585751977,
      "grad_norm": 14.637557983398438,
      "learning_rate": 3.087071240105541e-05,
      "loss": 0.3443,
      "step": 3145
    },
    {
      "epoch": 2.075197889182058,
      "grad_norm": 1.5885100364685059,
      "learning_rate": 3.084872471416007e-05,
      "loss": 0.047,
      "step": 3146
    },
    {
      "epoch": 2.075857519788918,
      "grad_norm": 0.6960494518280029,
      "learning_rate": 3.082673702726473e-05,
      "loss": 0.0309,
      "step": 3147
    },
    {
      "epoch": 2.0765171503957784,
      "grad_norm": 8.765717506408691,
      "learning_rate": 3.0804749340369396e-05,
      "loss": 0.7326,
      "step": 3148
    },
    {
      "epoch": 2.0771767810026387,
      "grad_norm": 1.9436572790145874,
      "learning_rate": 3.078276165347406e-05,
      "loss": 0.0777,
      "step": 3149
    },
    {
      "epoch": 2.0778364116094985,
      "grad_norm": 1.842895746231079,
      "learning_rate": 3.076077396657872e-05,
      "loss": 0.0756,
      "step": 3150
    },
    {
      "epoch": 2.0784960422163588,
      "grad_norm": 1.9343900680541992,
      "learning_rate": 3.073878627968338e-05,
      "loss": 0.1074,
      "step": 3151
    },
    {
      "epoch": 2.079155672823219,
      "grad_norm": 0.8224346041679382,
      "learning_rate": 3.071679859278804e-05,
      "loss": 0.0307,
      "step": 3152
    },
    {
      "epoch": 2.0798153034300793,
      "grad_norm": 2.270772933959961,
      "learning_rate": 3.06948109058927e-05,
      "loss": 0.1164,
      "step": 3153
    },
    {
      "epoch": 2.0804749340369395,
      "grad_norm": 0.710258960723877,
      "learning_rate": 3.0672823218997365e-05,
      "loss": 0.04,
      "step": 3154
    },
    {
      "epoch": 2.0811345646437993,
      "grad_norm": 1.786169409751892,
      "learning_rate": 3.065083553210202e-05,
      "loss": 0.0471,
      "step": 3155
    },
    {
      "epoch": 2.0817941952506596,
      "grad_norm": 18.55746078491211,
      "learning_rate": 3.0628847845206686e-05,
      "loss": 0.4059,
      "step": 3156
    },
    {
      "epoch": 2.08245382585752,
      "grad_norm": 4.492051124572754,
      "learning_rate": 3.060686015831134e-05,
      "loss": 0.0976,
      "step": 3157
    },
    {
      "epoch": 2.08311345646438,
      "grad_norm": 16.6358699798584,
      "learning_rate": 3.0584872471416006e-05,
      "loss": 0.778,
      "step": 3158
    },
    {
      "epoch": 2.0837730870712403,
      "grad_norm": 0.6070688366889954,
      "learning_rate": 3.056288478452067e-05,
      "loss": 0.0436,
      "step": 3159
    },
    {
      "epoch": 2.0844327176781,
      "grad_norm": 20.508163452148438,
      "learning_rate": 3.0540897097625334e-05,
      "loss": 0.2445,
      "step": 3160
    },
    {
      "epoch": 2.0850923482849604,
      "grad_norm": 0.5467491745948792,
      "learning_rate": 3.051890941072999e-05,
      "loss": 0.034,
      "step": 3161
    },
    {
      "epoch": 2.0857519788918206,
      "grad_norm": 8.310242652893066,
      "learning_rate": 3.0496921723834655e-05,
      "loss": 0.1556,
      "step": 3162
    },
    {
      "epoch": 2.086411609498681,
      "grad_norm": 1.0983059406280518,
      "learning_rate": 3.047493403693932e-05,
      "loss": 0.0451,
      "step": 3163
    },
    {
      "epoch": 2.0870712401055407,
      "grad_norm": 20.932085037231445,
      "learning_rate": 3.0452946350043975e-05,
      "loss": 0.5549,
      "step": 3164
    },
    {
      "epoch": 2.087730870712401,
      "grad_norm": 20.89798355102539,
      "learning_rate": 3.043095866314864e-05,
      "loss": 0.6337,
      "step": 3165
    },
    {
      "epoch": 2.088390501319261,
      "grad_norm": 0.3077421188354492,
      "learning_rate": 3.04089709762533e-05,
      "loss": 0.043,
      "step": 3166
    },
    {
      "epoch": 2.0890501319261214,
      "grad_norm": 1.292850136756897,
      "learning_rate": 3.0386983289357963e-05,
      "loss": 0.0698,
      "step": 3167
    },
    {
      "epoch": 2.0897097625329817,
      "grad_norm": 28.06365394592285,
      "learning_rate": 3.036499560246262e-05,
      "loss": 0.7631,
      "step": 3168
    },
    {
      "epoch": 2.0903693931398415,
      "grad_norm": 0.36434081196784973,
      "learning_rate": 3.0343007915567284e-05,
      "loss": 0.0112,
      "step": 3169
    },
    {
      "epoch": 2.0910290237467017,
      "grad_norm": 10.047077178955078,
      "learning_rate": 3.032102022867194e-05,
      "loss": 0.5146,
      "step": 3170
    },
    {
      "epoch": 2.091688654353562,
      "grad_norm": 3.1167266368865967,
      "learning_rate": 3.0299032541776605e-05,
      "loss": 0.0696,
      "step": 3171
    },
    {
      "epoch": 2.0923482849604222,
      "grad_norm": 11.456847190856934,
      "learning_rate": 3.027704485488127e-05,
      "loss": 0.5128,
      "step": 3172
    },
    {
      "epoch": 2.0930079155672825,
      "grad_norm": 0.4569462239742279,
      "learning_rate": 3.025505716798593e-05,
      "loss": 0.0161,
      "step": 3173
    },
    {
      "epoch": 2.0936675461741423,
      "grad_norm": 0.32714709639549255,
      "learning_rate": 3.0233069481090593e-05,
      "loss": 0.0299,
      "step": 3174
    },
    {
      "epoch": 2.0943271767810026,
      "grad_norm": 6.220303535461426,
      "learning_rate": 3.021108179419525e-05,
      "loss": 0.1511,
      "step": 3175
    },
    {
      "epoch": 2.094986807387863,
      "grad_norm": 5.861506938934326,
      "learning_rate": 3.0189094107299913e-05,
      "loss": 0.6658,
      "step": 3176
    },
    {
      "epoch": 2.095646437994723,
      "grad_norm": 22.162813186645508,
      "learning_rate": 3.0167106420404574e-05,
      "loss": 0.9188,
      "step": 3177
    },
    {
      "epoch": 2.0963060686015833,
      "grad_norm": 3.38419771194458,
      "learning_rate": 3.0145118733509238e-05,
      "loss": 0.0673,
      "step": 3178
    },
    {
      "epoch": 2.096965699208443,
      "grad_norm": 0.35009580850601196,
      "learning_rate": 3.0123131046613895e-05,
      "loss": 0.0262,
      "step": 3179
    },
    {
      "epoch": 2.0976253298153034,
      "grad_norm": 9.07069206237793,
      "learning_rate": 3.010114335971856e-05,
      "loss": 0.2304,
      "step": 3180
    },
    {
      "epoch": 2.0982849604221636,
      "grad_norm": 0.9903148412704468,
      "learning_rate": 3.0079155672823222e-05,
      "loss": 0.0817,
      "step": 3181
    },
    {
      "epoch": 2.098944591029024,
      "grad_norm": 1.3074496984481812,
      "learning_rate": 3.0057167985927882e-05,
      "loss": 0.0468,
      "step": 3182
    },
    {
      "epoch": 2.099604221635884,
      "grad_norm": 15.974542617797852,
      "learning_rate": 3.0035180299032546e-05,
      "loss": 1.0955,
      "step": 3183
    },
    {
      "epoch": 2.100263852242744,
      "grad_norm": 0.7358358502388,
      "learning_rate": 3.0013192612137203e-05,
      "loss": 0.0397,
      "step": 3184
    },
    {
      "epoch": 2.100923482849604,
      "grad_norm": 10.947888374328613,
      "learning_rate": 2.9991204925241867e-05,
      "loss": 0.2633,
      "step": 3185
    },
    {
      "epoch": 2.1015831134564644,
      "grad_norm": 0.5685797929763794,
      "learning_rate": 2.9969217238346524e-05,
      "loss": 0.0435,
      "step": 3186
    },
    {
      "epoch": 2.1022427440633247,
      "grad_norm": 0.7834675312042236,
      "learning_rate": 2.9947229551451188e-05,
      "loss": 0.0714,
      "step": 3187
    },
    {
      "epoch": 2.1029023746701845,
      "grad_norm": 4.070855140686035,
      "learning_rate": 2.9925241864555848e-05,
      "loss": 0.1082,
      "step": 3188
    },
    {
      "epoch": 2.1035620052770447,
      "grad_norm": 26.060279846191406,
      "learning_rate": 2.9903254177660512e-05,
      "loss": 0.6494,
      "step": 3189
    },
    {
      "epoch": 2.104221635883905,
      "grad_norm": 1.657235026359558,
      "learning_rate": 2.9881266490765176e-05,
      "loss": 0.0714,
      "step": 3190
    },
    {
      "epoch": 2.1048812664907652,
      "grad_norm": 1.5209026336669922,
      "learning_rate": 2.9859278803869833e-05,
      "loss": 0.1126,
      "step": 3191
    },
    {
      "epoch": 2.1055408970976255,
      "grad_norm": 0.715057373046875,
      "learning_rate": 2.9837291116974496e-05,
      "loss": 0.0525,
      "step": 3192
    },
    {
      "epoch": 2.1062005277044853,
      "grad_norm": 1.6302436590194702,
      "learning_rate": 2.9815303430079157e-05,
      "loss": 0.1117,
      "step": 3193
    },
    {
      "epoch": 2.1068601583113455,
      "grad_norm": 1.890800952911377,
      "learning_rate": 2.979331574318382e-05,
      "loss": 0.0602,
      "step": 3194
    },
    {
      "epoch": 2.107519788918206,
      "grad_norm": 1.6088576316833496,
      "learning_rate": 2.9771328056288477e-05,
      "loss": 0.0778,
      "step": 3195
    },
    {
      "epoch": 2.108179419525066,
      "grad_norm": 14.75988483428955,
      "learning_rate": 2.974934036939314e-05,
      "loss": 0.2652,
      "step": 3196
    },
    {
      "epoch": 2.1088390501319263,
      "grad_norm": 9.313362121582031,
      "learning_rate": 2.97273526824978e-05,
      "loss": 0.1837,
      "step": 3197
    },
    {
      "epoch": 2.109498680738786,
      "grad_norm": 6.212154865264893,
      "learning_rate": 2.9705364995602465e-05,
      "loss": 0.1397,
      "step": 3198
    },
    {
      "epoch": 2.1101583113456464,
      "grad_norm": 0.4583760201931,
      "learning_rate": 2.968337730870713e-05,
      "loss": 0.0298,
      "step": 3199
    },
    {
      "epoch": 2.1108179419525066,
      "grad_norm": 5.8427734375,
      "learning_rate": 2.9661389621811786e-05,
      "loss": 0.1795,
      "step": 3200
    },
    {
      "epoch": 2.111477572559367,
      "grad_norm": 2.7068862915039062,
      "learning_rate": 2.963940193491645e-05,
      "loss": 0.0966,
      "step": 3201
    },
    {
      "epoch": 2.112137203166227,
      "grad_norm": 0.9044328927993774,
      "learning_rate": 2.9617414248021107e-05,
      "loss": 0.0291,
      "step": 3202
    },
    {
      "epoch": 2.112796833773087,
      "grad_norm": 0.6712000966072083,
      "learning_rate": 2.959542656112577e-05,
      "loss": 0.0532,
      "step": 3203
    },
    {
      "epoch": 2.113456464379947,
      "grad_norm": 1.2208653688430786,
      "learning_rate": 2.957343887423043e-05,
      "loss": 0.0808,
      "step": 3204
    },
    {
      "epoch": 2.1141160949868074,
      "grad_norm": 15.160415649414062,
      "learning_rate": 2.9551451187335095e-05,
      "loss": 0.2633,
      "step": 3205
    },
    {
      "epoch": 2.1147757255936677,
      "grad_norm": 9.090276718139648,
      "learning_rate": 2.952946350043975e-05,
      "loss": 0.3167,
      "step": 3206
    },
    {
      "epoch": 2.115435356200528,
      "grad_norm": 6.550048828125,
      "learning_rate": 2.9507475813544415e-05,
      "loss": 0.2045,
      "step": 3207
    },
    {
      "epoch": 2.1160949868073877,
      "grad_norm": 3.8917899131774902,
      "learning_rate": 2.948548812664908e-05,
      "loss": 0.0851,
      "step": 3208
    },
    {
      "epoch": 2.116754617414248,
      "grad_norm": 0.9403622150421143,
      "learning_rate": 2.946350043975374e-05,
      "loss": 0.0532,
      "step": 3209
    },
    {
      "epoch": 2.1174142480211082,
      "grad_norm": 0.5986633896827698,
      "learning_rate": 2.9441512752858403e-05,
      "loss": 0.0761,
      "step": 3210
    },
    {
      "epoch": 2.1180738786279685,
      "grad_norm": 1.2389934062957764,
      "learning_rate": 2.941952506596306e-05,
      "loss": 0.0516,
      "step": 3211
    },
    {
      "epoch": 2.1187335092348283,
      "grad_norm": 11.850642204284668,
      "learning_rate": 2.9397537379067724e-05,
      "loss": 0.3983,
      "step": 3212
    },
    {
      "epoch": 2.1193931398416885,
      "grad_norm": 1.2588139772415161,
      "learning_rate": 2.9375549692172384e-05,
      "loss": 0.0528,
      "step": 3213
    },
    {
      "epoch": 2.120052770448549,
      "grad_norm": 1.1455461978912354,
      "learning_rate": 2.9353562005277048e-05,
      "loss": 0.0561,
      "step": 3214
    },
    {
      "epoch": 2.120712401055409,
      "grad_norm": 0.8172860145568848,
      "learning_rate": 2.9331574318381705e-05,
      "loss": 0.0439,
      "step": 3215
    },
    {
      "epoch": 2.1213720316622693,
      "grad_norm": 1.7696716785430908,
      "learning_rate": 2.930958663148637e-05,
      "loss": 0.0648,
      "step": 3216
    },
    {
      "epoch": 2.122031662269129,
      "grad_norm": 10.183551788330078,
      "learning_rate": 2.9287598944591033e-05,
      "loss": 0.4154,
      "step": 3217
    },
    {
      "epoch": 2.1226912928759893,
      "grad_norm": 2.249114513397217,
      "learning_rate": 2.926561125769569e-05,
      "loss": 0.0858,
      "step": 3218
    },
    {
      "epoch": 2.1233509234828496,
      "grad_norm": 1.07145094871521,
      "learning_rate": 2.9243623570800353e-05,
      "loss": 0.0502,
      "step": 3219
    },
    {
      "epoch": 2.12401055408971,
      "grad_norm": 1.878928303718567,
      "learning_rate": 2.9221635883905014e-05,
      "loss": 0.0462,
      "step": 3220
    },
    {
      "epoch": 2.12467018469657,
      "grad_norm": 1.2843265533447266,
      "learning_rate": 2.9199648197009678e-05,
      "loss": 0.0526,
      "step": 3221
    },
    {
      "epoch": 2.12532981530343,
      "grad_norm": 1.8395776748657227,
      "learning_rate": 2.9177660510114334e-05,
      "loss": 0.0611,
      "step": 3222
    },
    {
      "epoch": 2.12598944591029,
      "grad_norm": 7.170215129852295,
      "learning_rate": 2.9155672823218998e-05,
      "loss": 0.1095,
      "step": 3223
    },
    {
      "epoch": 2.1266490765171504,
      "grad_norm": 0.5002281069755554,
      "learning_rate": 2.9133685136323662e-05,
      "loss": 0.0335,
      "step": 3224
    },
    {
      "epoch": 2.1273087071240107,
      "grad_norm": 0.9137330055236816,
      "learning_rate": 2.9111697449428322e-05,
      "loss": 0.055,
      "step": 3225
    },
    {
      "epoch": 2.127968337730871,
      "grad_norm": 6.035983562469482,
      "learning_rate": 2.9089709762532986e-05,
      "loss": 0.0957,
      "step": 3226
    },
    {
      "epoch": 2.1286279683377307,
      "grad_norm": 0.645781934261322,
      "learning_rate": 2.9067722075637643e-05,
      "loss": 0.038,
      "step": 3227
    },
    {
      "epoch": 2.129287598944591,
      "grad_norm": 17.826791763305664,
      "learning_rate": 2.9045734388742307e-05,
      "loss": 0.4224,
      "step": 3228
    },
    {
      "epoch": 2.129947229551451,
      "grad_norm": 14.865950584411621,
      "learning_rate": 2.9023746701846964e-05,
      "loss": 1.2381,
      "step": 3229
    },
    {
      "epoch": 2.1306068601583115,
      "grad_norm": 12.906439781188965,
      "learning_rate": 2.900175901495163e-05,
      "loss": 0.3821,
      "step": 3230
    },
    {
      "epoch": 2.1312664907651717,
      "grad_norm": 0.3704400360584259,
      "learning_rate": 2.8979771328056288e-05,
      "loss": 0.0189,
      "step": 3231
    },
    {
      "epoch": 2.1319261213720315,
      "grad_norm": 0.5630897283554077,
      "learning_rate": 2.8957783641160952e-05,
      "loss": 0.0309,
      "step": 3232
    },
    {
      "epoch": 2.1325857519788918,
      "grad_norm": 2.9174275398254395,
      "learning_rate": 2.8935795954265615e-05,
      "loss": 0.0813,
      "step": 3233
    },
    {
      "epoch": 2.133245382585752,
      "grad_norm": 2.7126944065093994,
      "learning_rate": 2.8913808267370272e-05,
      "loss": 0.0711,
      "step": 3234
    },
    {
      "epoch": 2.1339050131926123,
      "grad_norm": 22.886404037475586,
      "learning_rate": 2.8891820580474936e-05,
      "loss": 1.2819,
      "step": 3235
    },
    {
      "epoch": 2.1345646437994725,
      "grad_norm": 3.9800450801849365,
      "learning_rate": 2.8869832893579597e-05,
      "loss": 0.0328,
      "step": 3236
    },
    {
      "epoch": 2.1352242744063323,
      "grad_norm": 10.543715476989746,
      "learning_rate": 2.884784520668426e-05,
      "loss": 1.1352,
      "step": 3237
    },
    {
      "epoch": 2.1358839050131926,
      "grad_norm": 0.9097532629966736,
      "learning_rate": 2.8825857519788917e-05,
      "loss": 0.0572,
      "step": 3238
    },
    {
      "epoch": 2.136543535620053,
      "grad_norm": 14.446822166442871,
      "learning_rate": 2.880386983289358e-05,
      "loss": 0.3083,
      "step": 3239
    },
    {
      "epoch": 2.137203166226913,
      "grad_norm": 4.08879280090332,
      "learning_rate": 2.878188214599824e-05,
      "loss": 0.1028,
      "step": 3240
    },
    {
      "epoch": 2.137862796833773,
      "grad_norm": 5.2545952796936035,
      "learning_rate": 2.8759894459102905e-05,
      "loss": 0.0782,
      "step": 3241
    },
    {
      "epoch": 2.138522427440633,
      "grad_norm": 0.7375786900520325,
      "learning_rate": 2.873790677220757e-05,
      "loss": 0.0451,
      "step": 3242
    },
    {
      "epoch": 2.1391820580474934,
      "grad_norm": 7.94489860534668,
      "learning_rate": 2.8715919085312226e-05,
      "loss": 0.1896,
      "step": 3243
    },
    {
      "epoch": 2.1398416886543536,
      "grad_norm": 4.605831146240234,
      "learning_rate": 2.869393139841689e-05,
      "loss": 0.1231,
      "step": 3244
    },
    {
      "epoch": 2.140501319261214,
      "grad_norm": 3.8416481018066406,
      "learning_rate": 2.8671943711521547e-05,
      "loss": 0.0712,
      "step": 3245
    },
    {
      "epoch": 2.1411609498680737,
      "grad_norm": 5.940474510192871,
      "learning_rate": 2.8649956024626214e-05,
      "loss": 0.1193,
      "step": 3246
    },
    {
      "epoch": 2.141820580474934,
      "grad_norm": 0.541843831539154,
      "learning_rate": 2.862796833773087e-05,
      "loss": 0.0472,
      "step": 3247
    },
    {
      "epoch": 2.142480211081794,
      "grad_norm": 0.8928499221801758,
      "learning_rate": 2.8605980650835535e-05,
      "loss": 0.0561,
      "step": 3248
    },
    {
      "epoch": 2.1431398416886545,
      "grad_norm": 2.3735790252685547,
      "learning_rate": 2.858399296394019e-05,
      "loss": 0.0791,
      "step": 3249
    },
    {
      "epoch": 2.1437994722955147,
      "grad_norm": 7.998978614807129,
      "learning_rate": 2.8562005277044855e-05,
      "loss": 0.1668,
      "step": 3250
    },
    {
      "epoch": 2.1444591029023745,
      "grad_norm": 1.403856635093689,
      "learning_rate": 2.854001759014952e-05,
      "loss": 0.0771,
      "step": 3251
    },
    {
      "epoch": 2.1451187335092348,
      "grad_norm": 0.7244544625282288,
      "learning_rate": 2.851802990325418e-05,
      "loss": 0.041,
      "step": 3252
    },
    {
      "epoch": 2.145778364116095,
      "grad_norm": 14.120641708374023,
      "learning_rate": 2.8496042216358843e-05,
      "loss": 0.2609,
      "step": 3253
    },
    {
      "epoch": 2.1464379947229553,
      "grad_norm": 11.544681549072266,
      "learning_rate": 2.84740545294635e-05,
      "loss": 0.9836,
      "step": 3254
    },
    {
      "epoch": 2.147097625329815,
      "grad_norm": 0.6785870790481567,
      "learning_rate": 2.8452066842568164e-05,
      "loss": 0.0449,
      "step": 3255
    },
    {
      "epoch": 2.1477572559366753,
      "grad_norm": 2.0237622261047363,
      "learning_rate": 2.8430079155672824e-05,
      "loss": 0.1091,
      "step": 3256
    },
    {
      "epoch": 2.1484168865435356,
      "grad_norm": 1.8185465335845947,
      "learning_rate": 2.8408091468777488e-05,
      "loss": 0.1362,
      "step": 3257
    },
    {
      "epoch": 2.149076517150396,
      "grad_norm": 1.6696914434432983,
      "learning_rate": 2.8386103781882145e-05,
      "loss": 0.1257,
      "step": 3258
    },
    {
      "epoch": 2.149736147757256,
      "grad_norm": 1.5131856203079224,
      "learning_rate": 2.836411609498681e-05,
      "loss": 0.1254,
      "step": 3259
    },
    {
      "epoch": 2.150395778364116,
      "grad_norm": 1.1181039810180664,
      "learning_rate": 2.8342128408091473e-05,
      "loss": 0.0637,
      "step": 3260
    },
    {
      "epoch": 2.151055408970976,
      "grad_norm": 8.013410568237305,
      "learning_rate": 2.832014072119613e-05,
      "loss": 0.3296,
      "step": 3261
    },
    {
      "epoch": 2.1517150395778364,
      "grad_norm": 0.5591049790382385,
      "learning_rate": 2.8298153034300793e-05,
      "loss": 0.0478,
      "step": 3262
    },
    {
      "epoch": 2.1523746701846966,
      "grad_norm": 0.4956219494342804,
      "learning_rate": 2.8276165347405454e-05,
      "loss": 0.0285,
      "step": 3263
    },
    {
      "epoch": 2.153034300791557,
      "grad_norm": 23.816068649291992,
      "learning_rate": 2.8254177660510117e-05,
      "loss": 0.9402,
      "step": 3264
    },
    {
      "epoch": 2.1536939313984167,
      "grad_norm": 1.3431309461593628,
      "learning_rate": 2.8232189973614774e-05,
      "loss": 0.0674,
      "step": 3265
    },
    {
      "epoch": 2.154353562005277,
      "grad_norm": 0.41940784454345703,
      "learning_rate": 2.8210202286719438e-05,
      "loss": 0.0469,
      "step": 3266
    },
    {
      "epoch": 2.155013192612137,
      "grad_norm": 0.7307187914848328,
      "learning_rate": 2.81882145998241e-05,
      "loss": 0.0528,
      "step": 3267
    },
    {
      "epoch": 2.1556728232189974,
      "grad_norm": 3.1824450492858887,
      "learning_rate": 2.8166226912928762e-05,
      "loss": 0.1039,
      "step": 3268
    },
    {
      "epoch": 2.1563324538258577,
      "grad_norm": 9.37890911102295,
      "learning_rate": 2.8144239226033426e-05,
      "loss": 0.7885,
      "step": 3269
    },
    {
      "epoch": 2.1569920844327175,
      "grad_norm": 1.1285489797592163,
      "learning_rate": 2.8122251539138083e-05,
      "loss": 0.0616,
      "step": 3270
    },
    {
      "epoch": 2.1576517150395778,
      "grad_norm": 0.8551886081695557,
      "learning_rate": 2.8100263852242747e-05,
      "loss": 0.0479,
      "step": 3271
    },
    {
      "epoch": 2.158311345646438,
      "grad_norm": 0.46471545100212097,
      "learning_rate": 2.8078276165347407e-05,
      "loss": 0.0492,
      "step": 3272
    },
    {
      "epoch": 2.1589709762532983,
      "grad_norm": 0.9753238558769226,
      "learning_rate": 2.805628847845207e-05,
      "loss": 0.0496,
      "step": 3273
    },
    {
      "epoch": 2.1596306068601585,
      "grad_norm": 6.17434024810791,
      "learning_rate": 2.8034300791556728e-05,
      "loss": 0.145,
      "step": 3274
    },
    {
      "epoch": 2.1602902374670183,
      "grad_norm": 7.615835666656494,
      "learning_rate": 2.801231310466139e-05,
      "loss": 0.3044,
      "step": 3275
    },
    {
      "epoch": 2.1609498680738786,
      "grad_norm": 0.5181309580802917,
      "learning_rate": 2.799032541776605e-05,
      "loss": 0.0204,
      "step": 3276
    },
    {
      "epoch": 2.161609498680739,
      "grad_norm": 4.485494613647461,
      "learning_rate": 2.7968337730870712e-05,
      "loss": 0.1054,
      "step": 3277
    },
    {
      "epoch": 2.162269129287599,
      "grad_norm": 0.8087089657783508,
      "learning_rate": 2.7946350043975376e-05,
      "loss": 0.046,
      "step": 3278
    },
    {
      "epoch": 2.1629287598944593,
      "grad_norm": 0.5021963715553284,
      "learning_rate": 2.7924362357080037e-05,
      "loss": 0.0152,
      "step": 3279
    },
    {
      "epoch": 2.163588390501319,
      "grad_norm": 0.38844239711761475,
      "learning_rate": 2.79023746701847e-05,
      "loss": 0.0273,
      "step": 3280
    },
    {
      "epoch": 2.1642480211081794,
      "grad_norm": 7.370091915130615,
      "learning_rate": 2.7880386983289357e-05,
      "loss": 0.1646,
      "step": 3281
    },
    {
      "epoch": 2.1649076517150396,
      "grad_norm": 6.166935920715332,
      "learning_rate": 2.785839929639402e-05,
      "loss": 0.1469,
      "step": 3282
    },
    {
      "epoch": 2.1655672823219,
      "grad_norm": 16.48670196533203,
      "learning_rate": 2.783641160949868e-05,
      "loss": 0.3641,
      "step": 3283
    },
    {
      "epoch": 2.16622691292876,
      "grad_norm": 4.361679553985596,
      "learning_rate": 2.7814423922603345e-05,
      "loss": 0.0987,
      "step": 3284
    },
    {
      "epoch": 2.16688654353562,
      "grad_norm": 6.155269145965576,
      "learning_rate": 2.7792436235708002e-05,
      "loss": 0.2802,
      "step": 3285
    },
    {
      "epoch": 2.16754617414248,
      "grad_norm": 26.888708114624023,
      "learning_rate": 2.7770448548812666e-05,
      "loss": 0.8297,
      "step": 3286
    },
    {
      "epoch": 2.1682058047493404,
      "grad_norm": 9.619927406311035,
      "learning_rate": 2.774846086191733e-05,
      "loss": 0.3038,
      "step": 3287
    },
    {
      "epoch": 2.1688654353562007,
      "grad_norm": 6.274105072021484,
      "learning_rate": 2.772647317502199e-05,
      "loss": 0.0948,
      "step": 3288
    },
    {
      "epoch": 2.1695250659630605,
      "grad_norm": 6.186221122741699,
      "learning_rate": 2.7704485488126654e-05,
      "loss": 0.2334,
      "step": 3289
    },
    {
      "epoch": 2.1701846965699207,
      "grad_norm": 2.049598455429077,
      "learning_rate": 2.768249780123131e-05,
      "loss": 0.1123,
      "step": 3290
    },
    {
      "epoch": 2.170844327176781,
      "grad_norm": 7.74523401260376,
      "learning_rate": 2.7660510114335975e-05,
      "loss": 0.3694,
      "step": 3291
    },
    {
      "epoch": 2.1715039577836412,
      "grad_norm": 0.4933379888534546,
      "learning_rate": 2.763852242744063e-05,
      "loss": 0.0273,
      "step": 3292
    },
    {
      "epoch": 2.1721635883905015,
      "grad_norm": 4.592428207397461,
      "learning_rate": 2.7616534740545295e-05,
      "loss": 0.1532,
      "step": 3293
    },
    {
      "epoch": 2.1728232189973613,
      "grad_norm": 0.8671839833259583,
      "learning_rate": 2.7594547053649956e-05,
      "loss": 0.0438,
      "step": 3294
    },
    {
      "epoch": 2.1734828496042216,
      "grad_norm": 0.8493661284446716,
      "learning_rate": 2.757255936675462e-05,
      "loss": 0.0469,
      "step": 3295
    },
    {
      "epoch": 2.174142480211082,
      "grad_norm": 0.4879322052001953,
      "learning_rate": 2.7550571679859283e-05,
      "loss": 0.0416,
      "step": 3296
    },
    {
      "epoch": 2.174802110817942,
      "grad_norm": 1.0926660299301147,
      "learning_rate": 2.752858399296394e-05,
      "loss": 0.0607,
      "step": 3297
    },
    {
      "epoch": 2.1754617414248023,
      "grad_norm": 3.1429898738861084,
      "learning_rate": 2.7506596306068604e-05,
      "loss": 0.131,
      "step": 3298
    },
    {
      "epoch": 2.176121372031662,
      "grad_norm": 0.9156787395477295,
      "learning_rate": 2.7484608619173264e-05,
      "loss": 0.0651,
      "step": 3299
    },
    {
      "epoch": 2.1767810026385224,
      "grad_norm": 16.851194381713867,
      "learning_rate": 2.7462620932277928e-05,
      "loss": 0.6037,
      "step": 3300
    },
    {
      "epoch": 2.1774406332453826,
      "grad_norm": 1.9116253852844238,
      "learning_rate": 2.7440633245382585e-05,
      "loss": 0.1151,
      "step": 3301
    },
    {
      "epoch": 2.178100263852243,
      "grad_norm": 1.5561261177062988,
      "learning_rate": 2.741864555848725e-05,
      "loss": 0.0796,
      "step": 3302
    },
    {
      "epoch": 2.1787598944591027,
      "grad_norm": 1.338244915008545,
      "learning_rate": 2.739665787159191e-05,
      "loss": 0.1075,
      "step": 3303
    },
    {
      "epoch": 2.179419525065963,
      "grad_norm": 6.934335231781006,
      "learning_rate": 2.7374670184696573e-05,
      "loss": 0.2797,
      "step": 3304
    },
    {
      "epoch": 2.180079155672823,
      "grad_norm": 1.1918179988861084,
      "learning_rate": 2.7352682497801237e-05,
      "loss": 0.0708,
      "step": 3305
    },
    {
      "epoch": 2.1807387862796834,
      "grad_norm": 1.2274988889694214,
      "learning_rate": 2.7330694810905894e-05,
      "loss": 0.0559,
      "step": 3306
    },
    {
      "epoch": 2.1813984168865437,
      "grad_norm": 0.7588169574737549,
      "learning_rate": 2.7308707124010557e-05,
      "loss": 0.0284,
      "step": 3307
    },
    {
      "epoch": 2.1820580474934035,
      "grad_norm": 0.7555409073829651,
      "learning_rate": 2.7286719437115214e-05,
      "loss": 0.0384,
      "step": 3308
    },
    {
      "epoch": 2.1827176781002637,
      "grad_norm": 1.2365840673446655,
      "learning_rate": 2.7264731750219878e-05,
      "loss": 0.0621,
      "step": 3309
    },
    {
      "epoch": 2.183377308707124,
      "grad_norm": 22.882570266723633,
      "learning_rate": 2.724274406332454e-05,
      "loss": 1.3127,
      "step": 3310
    },
    {
      "epoch": 2.1840369393139842,
      "grad_norm": 0.3487923741340637,
      "learning_rate": 2.7220756376429202e-05,
      "loss": 0.0153,
      "step": 3311
    },
    {
      "epoch": 2.1846965699208445,
      "grad_norm": 0.6270293593406677,
      "learning_rate": 2.719876868953386e-05,
      "loss": 0.0486,
      "step": 3312
    },
    {
      "epoch": 2.1853562005277043,
      "grad_norm": 0.7540438175201416,
      "learning_rate": 2.7176781002638523e-05,
      "loss": 0.0386,
      "step": 3313
    },
    {
      "epoch": 2.1860158311345645,
      "grad_norm": 6.0620951652526855,
      "learning_rate": 2.7154793315743187e-05,
      "loss": 0.1965,
      "step": 3314
    },
    {
      "epoch": 2.186675461741425,
      "grad_norm": 8.645303726196289,
      "learning_rate": 2.7132805628847847e-05,
      "loss": 0.3488,
      "step": 3315
    },
    {
      "epoch": 2.187335092348285,
      "grad_norm": 9.602441787719727,
      "learning_rate": 2.711081794195251e-05,
      "loss": 0.1818,
      "step": 3316
    },
    {
      "epoch": 2.1879947229551453,
      "grad_norm": 11.49886417388916,
      "learning_rate": 2.7088830255057168e-05,
      "loss": 0.6831,
      "step": 3317
    },
    {
      "epoch": 2.188654353562005,
      "grad_norm": 10.065017700195312,
      "learning_rate": 2.706684256816183e-05,
      "loss": 0.195,
      "step": 3318
    },
    {
      "epoch": 2.1893139841688654,
      "grad_norm": 5.865511894226074,
      "learning_rate": 2.7044854881266492e-05,
      "loss": 0.1714,
      "step": 3319
    },
    {
      "epoch": 2.1899736147757256,
      "grad_norm": 9.724078178405762,
      "learning_rate": 2.7022867194371156e-05,
      "loss": 0.2238,
      "step": 3320
    },
    {
      "epoch": 2.190633245382586,
      "grad_norm": 0.7353495359420776,
      "learning_rate": 2.7000879507475813e-05,
      "loss": 0.0422,
      "step": 3321
    },
    {
      "epoch": 2.191292875989446,
      "grad_norm": 0.4640115201473236,
      "learning_rate": 2.6978891820580476e-05,
      "loss": 0.0188,
      "step": 3322
    },
    {
      "epoch": 2.191952506596306,
      "grad_norm": 4.1447014808654785,
      "learning_rate": 2.695690413368514e-05,
      "loss": 0.0759,
      "step": 3323
    },
    {
      "epoch": 2.192612137203166,
      "grad_norm": 11.10383129119873,
      "learning_rate": 2.6934916446789797e-05,
      "loss": 0.1786,
      "step": 3324
    },
    {
      "epoch": 2.1932717678100264,
      "grad_norm": 6.842388153076172,
      "learning_rate": 2.691292875989446e-05,
      "loss": 0.1782,
      "step": 3325
    },
    {
      "epoch": 2.1939313984168867,
      "grad_norm": 3.99013090133667,
      "learning_rate": 2.689094107299912e-05,
      "loss": 0.0755,
      "step": 3326
    },
    {
      "epoch": 2.194591029023747,
      "grad_norm": 9.463130950927734,
      "learning_rate": 2.6868953386103785e-05,
      "loss": 0.6316,
      "step": 3327
    },
    {
      "epoch": 2.1952506596306067,
      "grad_norm": 2.5959949493408203,
      "learning_rate": 2.6846965699208442e-05,
      "loss": 0.0578,
      "step": 3328
    },
    {
      "epoch": 2.195910290237467,
      "grad_norm": 13.59235668182373,
      "learning_rate": 2.6824978012313106e-05,
      "loss": 0.5531,
      "step": 3329
    },
    {
      "epoch": 2.1965699208443272,
      "grad_norm": 1.2828460931777954,
      "learning_rate": 2.6802990325417766e-05,
      "loss": 0.034,
      "step": 3330
    },
    {
      "epoch": 2.1972295514511875,
      "grad_norm": 0.5807239413261414,
      "learning_rate": 2.678100263852243e-05,
      "loss": 0.0243,
      "step": 3331
    },
    {
      "epoch": 2.1978891820580473,
      "grad_norm": 6.783080577850342,
      "learning_rate": 2.6759014951627094e-05,
      "loss": 0.1226,
      "step": 3332
    },
    {
      "epoch": 2.1985488126649075,
      "grad_norm": 0.9377039670944214,
      "learning_rate": 2.673702726473175e-05,
      "loss": 0.033,
      "step": 3333
    },
    {
      "epoch": 2.199208443271768,
      "grad_norm": 0.4366622567176819,
      "learning_rate": 2.6715039577836414e-05,
      "loss": 0.0333,
      "step": 3334
    },
    {
      "epoch": 2.199868073878628,
      "grad_norm": 1.123682975769043,
      "learning_rate": 2.6693051890941075e-05,
      "loss": 0.0641,
      "step": 3335
    },
    {
      "epoch": 2.2005277044854883,
      "grad_norm": 1.6019779443740845,
      "learning_rate": 2.667106420404574e-05,
      "loss": 0.0614,
      "step": 3336
    },
    {
      "epoch": 2.201187335092348,
      "grad_norm": 1.377367615699768,
      "learning_rate": 2.6649076517150396e-05,
      "loss": 0.0584,
      "step": 3337
    },
    {
      "epoch": 2.2018469656992083,
      "grad_norm": 2.404628276824951,
      "learning_rate": 2.662708883025506e-05,
      "loss": 0.067,
      "step": 3338
    },
    {
      "epoch": 2.2025065963060686,
      "grad_norm": 11.639364242553711,
      "learning_rate": 2.6605101143359716e-05,
      "loss": 0.662,
      "step": 3339
    },
    {
      "epoch": 2.203166226912929,
      "grad_norm": 3.086627244949341,
      "learning_rate": 2.658311345646438e-05,
      "loss": 0.1003,
      "step": 3340
    },
    {
      "epoch": 2.203825857519789,
      "grad_norm": 1.133302092552185,
      "learning_rate": 2.6561125769569044e-05,
      "loss": 0.0712,
      "step": 3341
    },
    {
      "epoch": 2.204485488126649,
      "grad_norm": 0.6413500308990479,
      "learning_rate": 2.6539138082673704e-05,
      "loss": 0.0563,
      "step": 3342
    },
    {
      "epoch": 2.205145118733509,
      "grad_norm": 1.1091803312301636,
      "learning_rate": 2.6517150395778368e-05,
      "loss": 0.0858,
      "step": 3343
    },
    {
      "epoch": 2.2058047493403694,
      "grad_norm": 4.581571102142334,
      "learning_rate": 2.6495162708883025e-05,
      "loss": 0.1091,
      "step": 3344
    },
    {
      "epoch": 2.2064643799472297,
      "grad_norm": 0.9359944462776184,
      "learning_rate": 2.647317502198769e-05,
      "loss": 0.0491,
      "step": 3345
    },
    {
      "epoch": 2.20712401055409,
      "grad_norm": 1.8976573944091797,
      "learning_rate": 2.645118733509235e-05,
      "loss": 0.0469,
      "step": 3346
    },
    {
      "epoch": 2.2077836411609497,
      "grad_norm": 0.9404888153076172,
      "learning_rate": 2.6429199648197013e-05,
      "loss": 0.0559,
      "step": 3347
    },
    {
      "epoch": 2.20844327176781,
      "grad_norm": 9.737698554992676,
      "learning_rate": 2.640721196130167e-05,
      "loss": 0.2241,
      "step": 3348
    },
    {
      "epoch": 2.20910290237467,
      "grad_norm": 7.286479473114014,
      "learning_rate": 2.6385224274406334e-05,
      "loss": 0.276,
      "step": 3349
    },
    {
      "epoch": 2.2097625329815305,
      "grad_norm": 1.4127520322799683,
      "learning_rate": 2.6363236587510997e-05,
      "loss": 0.0873,
      "step": 3350
    },
    {
      "epoch": 2.2104221635883903,
      "grad_norm": 9.871269226074219,
      "learning_rate": 2.6341248900615654e-05,
      "loss": 0.144,
      "step": 3351
    },
    {
      "epoch": 2.2110817941952505,
      "grad_norm": 0.5954687595367432,
      "learning_rate": 2.631926121372032e-05,
      "loss": 0.0452,
      "step": 3352
    },
    {
      "epoch": 2.211741424802111,
      "grad_norm": 0.7205760478973389,
      "learning_rate": 2.629727352682498e-05,
      "loss": 0.0536,
      "step": 3353
    },
    {
      "epoch": 2.212401055408971,
      "grad_norm": 9.271869659423828,
      "learning_rate": 2.6275285839929642e-05,
      "loss": 0.5116,
      "step": 3354
    },
    {
      "epoch": 2.2130606860158313,
      "grad_norm": 5.559701442718506,
      "learning_rate": 2.62532981530343e-05,
      "loss": 0.1867,
      "step": 3355
    },
    {
      "epoch": 2.213720316622691,
      "grad_norm": 4.136316299438477,
      "learning_rate": 2.6231310466138963e-05,
      "loss": 0.1164,
      "step": 3356
    },
    {
      "epoch": 2.2143799472295513,
      "grad_norm": 21.36515998840332,
      "learning_rate": 2.6209322779243623e-05,
      "loss": 0.4651,
      "step": 3357
    },
    {
      "epoch": 2.2150395778364116,
      "grad_norm": 9.86264419555664,
      "learning_rate": 2.6187335092348287e-05,
      "loss": 0.3818,
      "step": 3358
    },
    {
      "epoch": 2.215699208443272,
      "grad_norm": 0.49925488233566284,
      "learning_rate": 2.616534740545295e-05,
      "loss": 0.0261,
      "step": 3359
    },
    {
      "epoch": 2.216358839050132,
      "grad_norm": 1.584787368774414,
      "learning_rate": 2.6143359718557608e-05,
      "loss": 0.0528,
      "step": 3360
    },
    {
      "epoch": 2.217018469656992,
      "grad_norm": 1.917689561843872,
      "learning_rate": 2.612137203166227e-05,
      "loss": 0.1085,
      "step": 3361
    },
    {
      "epoch": 2.217678100263852,
      "grad_norm": 1.6026822328567505,
      "learning_rate": 2.6099384344766932e-05,
      "loss": 0.1048,
      "step": 3362
    },
    {
      "epoch": 2.2183377308707124,
      "grad_norm": 9.604278564453125,
      "learning_rate": 2.6077396657871596e-05,
      "loss": 0.1289,
      "step": 3363
    },
    {
      "epoch": 2.2189973614775726,
      "grad_norm": 2.472764253616333,
      "learning_rate": 2.6055408970976253e-05,
      "loss": 0.086,
      "step": 3364
    },
    {
      "epoch": 2.219656992084433,
      "grad_norm": 0.6185282468795776,
      "learning_rate": 2.6033421284080916e-05,
      "loss": 0.0439,
      "step": 3365
    },
    {
      "epoch": 2.2203166226912927,
      "grad_norm": 1.2883436679840088,
      "learning_rate": 2.6011433597185573e-05,
      "loss": 0.0721,
      "step": 3366
    },
    {
      "epoch": 2.220976253298153,
      "grad_norm": 1.928185224533081,
      "learning_rate": 2.5989445910290237e-05,
      "loss": 0.0695,
      "step": 3367
    },
    {
      "epoch": 2.221635883905013,
      "grad_norm": 0.7758913040161133,
      "learning_rate": 2.5967458223394904e-05,
      "loss": 0.0517,
      "step": 3368
    },
    {
      "epoch": 2.2222955145118735,
      "grad_norm": 0.3256145715713501,
      "learning_rate": 2.594547053649956e-05,
      "loss": 0.0272,
      "step": 3369
    },
    {
      "epoch": 2.2229551451187337,
      "grad_norm": 0.9240434169769287,
      "learning_rate": 2.5923482849604225e-05,
      "loss": 0.0508,
      "step": 3370
    },
    {
      "epoch": 2.2236147757255935,
      "grad_norm": 17.720552444458008,
      "learning_rate": 2.5901495162708882e-05,
      "loss": 0.2375,
      "step": 3371
    },
    {
      "epoch": 2.2242744063324538,
      "grad_norm": 0.9665393233299255,
      "learning_rate": 2.5879507475813546e-05,
      "loss": 0.049,
      "step": 3372
    },
    {
      "epoch": 2.224934036939314,
      "grad_norm": 1.0855209827423096,
      "learning_rate": 2.5857519788918206e-05,
      "loss": 0.0744,
      "step": 3373
    },
    {
      "epoch": 2.2255936675461743,
      "grad_norm": 3.427938222885132,
      "learning_rate": 2.583553210202287e-05,
      "loss": 0.0568,
      "step": 3374
    },
    {
      "epoch": 2.2262532981530345,
      "grad_norm": 10.70744514465332,
      "learning_rate": 2.5813544415127527e-05,
      "loss": 0.2415,
      "step": 3375
    },
    {
      "epoch": 2.2269129287598943,
      "grad_norm": 12.839402198791504,
      "learning_rate": 2.579155672823219e-05,
      "loss": 0.2326,
      "step": 3376
    },
    {
      "epoch": 2.2275725593667546,
      "grad_norm": 21.44368553161621,
      "learning_rate": 2.5769569041336854e-05,
      "loss": 0.7983,
      "step": 3377
    },
    {
      "epoch": 2.228232189973615,
      "grad_norm": 1.0008782148361206,
      "learning_rate": 2.5747581354441515e-05,
      "loss": 0.0619,
      "step": 3378
    },
    {
      "epoch": 2.228891820580475,
      "grad_norm": 0.6741604208946228,
      "learning_rate": 2.572559366754618e-05,
      "loss": 0.0757,
      "step": 3379
    },
    {
      "epoch": 2.229551451187335,
      "grad_norm": 2.67814564704895,
      "learning_rate": 2.5703605980650835e-05,
      "loss": 0.0791,
      "step": 3380
    },
    {
      "epoch": 2.230211081794195,
      "grad_norm": 0.9418663382530212,
      "learning_rate": 2.56816182937555e-05,
      "loss": 0.0625,
      "step": 3381
    },
    {
      "epoch": 2.2308707124010554,
      "grad_norm": 1.253906488418579,
      "learning_rate": 2.5659630606860156e-05,
      "loss": 0.0526,
      "step": 3382
    },
    {
      "epoch": 2.2315303430079156,
      "grad_norm": 0.6793116927146912,
      "learning_rate": 2.563764291996482e-05,
      "loss": 0.0446,
      "step": 3383
    },
    {
      "epoch": 2.232189973614776,
      "grad_norm": 0.9836718440055847,
      "learning_rate": 2.561565523306948e-05,
      "loss": 0.082,
      "step": 3384
    },
    {
      "epoch": 2.2328496042216357,
      "grad_norm": 3.4759135246276855,
      "learning_rate": 2.5593667546174144e-05,
      "loss": 0.0988,
      "step": 3385
    },
    {
      "epoch": 2.233509234828496,
      "grad_norm": 0.9272021651268005,
      "learning_rate": 2.5571679859278808e-05,
      "loss": 0.0352,
      "step": 3386
    },
    {
      "epoch": 2.234168865435356,
      "grad_norm": 2.5213396549224854,
      "learning_rate": 2.5549692172383465e-05,
      "loss": 0.1587,
      "step": 3387
    },
    {
      "epoch": 2.2348284960422165,
      "grad_norm": 0.62907874584198,
      "learning_rate": 2.552770448548813e-05,
      "loss": 0.0541,
      "step": 3388
    },
    {
      "epoch": 2.2354881266490767,
      "grad_norm": 0.9189714789390564,
      "learning_rate": 2.550571679859279e-05,
      "loss": 0.0318,
      "step": 3389
    },
    {
      "epoch": 2.2361477572559365,
      "grad_norm": 0.6295353174209595,
      "learning_rate": 2.5483729111697453e-05,
      "loss": 0.0476,
      "step": 3390
    },
    {
      "epoch": 2.2368073878627968,
      "grad_norm": 15.732954025268555,
      "learning_rate": 2.546174142480211e-05,
      "loss": 0.1442,
      "step": 3391
    },
    {
      "epoch": 2.237467018469657,
      "grad_norm": 4.7378106117248535,
      "learning_rate": 2.5439753737906773e-05,
      "loss": 0.0981,
      "step": 3392
    },
    {
      "epoch": 2.2381266490765173,
      "grad_norm": 9.787549018859863,
      "learning_rate": 2.5417766051011434e-05,
      "loss": 0.3087,
      "step": 3393
    },
    {
      "epoch": 2.2387862796833775,
      "grad_norm": 7.542594909667969,
      "learning_rate": 2.5395778364116098e-05,
      "loss": 0.155,
      "step": 3394
    },
    {
      "epoch": 2.2394459102902373,
      "grad_norm": 9.684638977050781,
      "learning_rate": 2.537379067722076e-05,
      "loss": 0.7116,
      "step": 3395
    },
    {
      "epoch": 2.2401055408970976,
      "grad_norm": 1.3786017894744873,
      "learning_rate": 2.535180299032542e-05,
      "loss": 0.0441,
      "step": 3396
    },
    {
      "epoch": 2.240765171503958,
      "grad_norm": 6.58101749420166,
      "learning_rate": 2.5329815303430082e-05,
      "loss": 0.1228,
      "step": 3397
    },
    {
      "epoch": 2.241424802110818,
      "grad_norm": 3.054718255996704,
      "learning_rate": 2.530782761653474e-05,
      "loss": 0.0729,
      "step": 3398
    },
    {
      "epoch": 2.242084432717678,
      "grad_norm": 13.95561695098877,
      "learning_rate": 2.5285839929639403e-05,
      "loss": 0.9006,
      "step": 3399
    },
    {
      "epoch": 2.242744063324538,
      "grad_norm": 0.8922064900398254,
      "learning_rate": 2.5263852242744063e-05,
      "loss": 0.0613,
      "step": 3400
    },
    {
      "epoch": 2.2434036939313984,
      "grad_norm": 15.331531524658203,
      "learning_rate": 2.5241864555848727e-05,
      "loss": 0.8076,
      "step": 3401
    },
    {
      "epoch": 2.2440633245382586,
      "grad_norm": 3.8989908695220947,
      "learning_rate": 2.5219876868953384e-05,
      "loss": 0.1073,
      "step": 3402
    },
    {
      "epoch": 2.244722955145119,
      "grad_norm": 0.6814383864402771,
      "learning_rate": 2.5197889182058048e-05,
      "loss": 0.0616,
      "step": 3403
    },
    {
      "epoch": 2.2453825857519787,
      "grad_norm": 2.039355754852295,
      "learning_rate": 2.517590149516271e-05,
      "loss": 0.0789,
      "step": 3404
    },
    {
      "epoch": 2.246042216358839,
      "grad_norm": 7.214920520782471,
      "learning_rate": 2.5153913808267372e-05,
      "loss": 0.154,
      "step": 3405
    },
    {
      "epoch": 2.246701846965699,
      "grad_norm": 1.7720757722854614,
      "learning_rate": 2.5131926121372036e-05,
      "loss": 0.101,
      "step": 3406
    },
    {
      "epoch": 2.2473614775725594,
      "grad_norm": 9.236763954162598,
      "learning_rate": 2.5109938434476693e-05,
      "loss": 0.213,
      "step": 3407
    },
    {
      "epoch": 2.2480211081794197,
      "grad_norm": 0.7716978788375854,
      "learning_rate": 2.5087950747581356e-05,
      "loss": 0.0386,
      "step": 3408
    },
    {
      "epoch": 2.2486807387862795,
      "grad_norm": 20.408199310302734,
      "learning_rate": 2.5065963060686017e-05,
      "loss": 1.1283,
      "step": 3409
    },
    {
      "epoch": 2.2493403693931397,
      "grad_norm": 22.86603546142578,
      "learning_rate": 2.504397537379068e-05,
      "loss": 0.6091,
      "step": 3410
    },
    {
      "epoch": 2.25,
      "grad_norm": 12.44090461730957,
      "learning_rate": 2.5021987686895337e-05,
      "loss": 0.5056,
      "step": 3411
    },
    {
      "epoch": 2.2506596306068603,
      "grad_norm": 0.49512970447540283,
      "learning_rate": 2.5e-05,
      "loss": 0.0347,
      "step": 3412
    },
    {
      "epoch": 2.2513192612137205,
      "grad_norm": 0.8871842622756958,
      "learning_rate": 2.497801231310466e-05,
      "loss": 0.0335,
      "step": 3413
    },
    {
      "epoch": 2.2519788918205803,
      "grad_norm": 1.3284157514572144,
      "learning_rate": 2.4956024626209322e-05,
      "loss": 0.0778,
      "step": 3414
    },
    {
      "epoch": 2.2526385224274406,
      "grad_norm": 12.587508201599121,
      "learning_rate": 2.4934036939313986e-05,
      "loss": 1.1998,
      "step": 3415
    },
    {
      "epoch": 2.253298153034301,
      "grad_norm": 2.706847667694092,
      "learning_rate": 2.4912049252418646e-05,
      "loss": 0.0765,
      "step": 3416
    },
    {
      "epoch": 2.253957783641161,
      "grad_norm": 1.657683253288269,
      "learning_rate": 2.489006156552331e-05,
      "loss": 0.0861,
      "step": 3417
    },
    {
      "epoch": 2.2546174142480213,
      "grad_norm": 1.1910537481307983,
      "learning_rate": 2.486807387862797e-05,
      "loss": 0.0785,
      "step": 3418
    },
    {
      "epoch": 2.255277044854881,
      "grad_norm": 2.6426587104797363,
      "learning_rate": 2.484608619173263e-05,
      "loss": 0.056,
      "step": 3419
    },
    {
      "epoch": 2.2559366754617414,
      "grad_norm": 0.7675925493240356,
      "learning_rate": 2.482409850483729e-05,
      "loss": 0.0581,
      "step": 3420
    },
    {
      "epoch": 2.2565963060686016,
      "grad_norm": 1.0028859376907349,
      "learning_rate": 2.4802110817941955e-05,
      "loss": 0.0657,
      "step": 3421
    },
    {
      "epoch": 2.257255936675462,
      "grad_norm": 0.39661476016044617,
      "learning_rate": 2.4780123131046615e-05,
      "loss": 0.0281,
      "step": 3422
    },
    {
      "epoch": 2.257915567282322,
      "grad_norm": 1.328352928161621,
      "learning_rate": 2.4758135444151275e-05,
      "loss": 0.0726,
      "step": 3423
    },
    {
      "epoch": 2.258575197889182,
      "grad_norm": 9.956829071044922,
      "learning_rate": 2.4736147757255936e-05,
      "loss": 0.8929,
      "step": 3424
    },
    {
      "epoch": 2.259234828496042,
      "grad_norm": 0.39388224482536316,
      "learning_rate": 2.47141600703606e-05,
      "loss": 0.0332,
      "step": 3425
    },
    {
      "epoch": 2.2598944591029024,
      "grad_norm": 0.7566579580307007,
      "learning_rate": 2.4692172383465263e-05,
      "loss": 0.0721,
      "step": 3426
    },
    {
      "epoch": 2.2605540897097627,
      "grad_norm": 0.8854564428329468,
      "learning_rate": 2.4670184696569924e-05,
      "loss": 0.0415,
      "step": 3427
    },
    {
      "epoch": 2.261213720316623,
      "grad_norm": 2.5179028511047363,
      "learning_rate": 2.4648197009674584e-05,
      "loss": 0.0657,
      "step": 3428
    },
    {
      "epoch": 2.2618733509234827,
      "grad_norm": 0.8942860960960388,
      "learning_rate": 2.4626209322779244e-05,
      "loss": 0.0439,
      "step": 3429
    },
    {
      "epoch": 2.262532981530343,
      "grad_norm": 1.7060954570770264,
      "learning_rate": 2.4604221635883905e-05,
      "loss": 0.0459,
      "step": 3430
    },
    {
      "epoch": 2.2631926121372032,
      "grad_norm": 0.578952968120575,
      "learning_rate": 2.458223394898857e-05,
      "loss": 0.0278,
      "step": 3431
    },
    {
      "epoch": 2.2638522427440635,
      "grad_norm": 9.114726066589355,
      "learning_rate": 2.456024626209323e-05,
      "loss": 1.0232,
      "step": 3432
    },
    {
      "epoch": 2.2645118733509233,
      "grad_norm": 0.5460863709449768,
      "learning_rate": 2.453825857519789e-05,
      "loss": 0.0197,
      "step": 3433
    },
    {
      "epoch": 2.2651715039577835,
      "grad_norm": 38.24479293823242,
      "learning_rate": 2.451627088830255e-05,
      "loss": 0.5232,
      "step": 3434
    },
    {
      "epoch": 2.265831134564644,
      "grad_norm": 15.30224895477295,
      "learning_rate": 2.4494283201407213e-05,
      "loss": 0.7763,
      "step": 3435
    },
    {
      "epoch": 2.266490765171504,
      "grad_norm": 23.60541343688965,
      "learning_rate": 2.4472295514511874e-05,
      "loss": 0.7675,
      "step": 3436
    },
    {
      "epoch": 2.2671503957783643,
      "grad_norm": 0.8669680953025818,
      "learning_rate": 2.4450307827616538e-05,
      "loss": 0.0532,
      "step": 3437
    },
    {
      "epoch": 2.267810026385224,
      "grad_norm": 1.9336944818496704,
      "learning_rate": 2.4428320140721198e-05,
      "loss": 0.0484,
      "step": 3438
    },
    {
      "epoch": 2.2684696569920844,
      "grad_norm": 0.6337342262268066,
      "learning_rate": 2.4406332453825858e-05,
      "loss": 0.0245,
      "step": 3439
    },
    {
      "epoch": 2.2691292875989446,
      "grad_norm": 20.786054611206055,
      "learning_rate": 2.438434476693052e-05,
      "loss": 0.3005,
      "step": 3440
    },
    {
      "epoch": 2.269788918205805,
      "grad_norm": 0.5879734754562378,
      "learning_rate": 2.4362357080035182e-05,
      "loss": 0.0295,
      "step": 3441
    },
    {
      "epoch": 2.2704485488126647,
      "grad_norm": 0.7314755320549011,
      "learning_rate": 2.4340369393139843e-05,
      "loss": 0.0378,
      "step": 3442
    },
    {
      "epoch": 2.271108179419525,
      "grad_norm": 30.586172103881836,
      "learning_rate": 2.4318381706244503e-05,
      "loss": 0.2464,
      "step": 3443
    },
    {
      "epoch": 2.271767810026385,
      "grad_norm": 8.032666206359863,
      "learning_rate": 2.4296394019349167e-05,
      "loss": 0.093,
      "step": 3444
    },
    {
      "epoch": 2.2724274406332454,
      "grad_norm": 4.341747283935547,
      "learning_rate": 2.4274406332453827e-05,
      "loss": 0.1165,
      "step": 3445
    },
    {
      "epoch": 2.2730870712401057,
      "grad_norm": 2.273805618286133,
      "learning_rate": 2.4252418645558488e-05,
      "loss": 0.0888,
      "step": 3446
    },
    {
      "epoch": 2.2737467018469655,
      "grad_norm": 0.9632790684700012,
      "learning_rate": 2.423043095866315e-05,
      "loss": 0.0458,
      "step": 3447
    },
    {
      "epoch": 2.2744063324538257,
      "grad_norm": 1.2336509227752686,
      "learning_rate": 2.4208443271767812e-05,
      "loss": 0.0804,
      "step": 3448
    },
    {
      "epoch": 2.275065963060686,
      "grad_norm": 9.017731666564941,
      "learning_rate": 2.4186455584872472e-05,
      "loss": 0.3243,
      "step": 3449
    },
    {
      "epoch": 2.2757255936675462,
      "grad_norm": 1.948161005973816,
      "learning_rate": 2.4164467897977133e-05,
      "loss": 0.0414,
      "step": 3450
    },
    {
      "epoch": 2.2763852242744065,
      "grad_norm": 0.8221204876899719,
      "learning_rate": 2.4142480211081793e-05,
      "loss": 0.0451,
      "step": 3451
    },
    {
      "epoch": 2.2770448548812663,
      "grad_norm": 0.9463464617729187,
      "learning_rate": 2.4120492524186457e-05,
      "loss": 0.0739,
      "step": 3452
    },
    {
      "epoch": 2.2777044854881265,
      "grad_norm": 2.079333543777466,
      "learning_rate": 2.409850483729112e-05,
      "loss": 0.0457,
      "step": 3453
    },
    {
      "epoch": 2.278364116094987,
      "grad_norm": 0.8555225133895874,
      "learning_rate": 2.407651715039578e-05,
      "loss": 0.0394,
      "step": 3454
    },
    {
      "epoch": 2.279023746701847,
      "grad_norm": 2.8047866821289062,
      "learning_rate": 2.405452946350044e-05,
      "loss": 0.098,
      "step": 3455
    },
    {
      "epoch": 2.2796833773087073,
      "grad_norm": 1.9034550189971924,
      "learning_rate": 2.40325417766051e-05,
      "loss": 0.0762,
      "step": 3456
    },
    {
      "epoch": 2.280343007915567,
      "grad_norm": 4.525635719299316,
      "learning_rate": 2.4010554089709765e-05,
      "loss": 0.0857,
      "step": 3457
    },
    {
      "epoch": 2.2810026385224274,
      "grad_norm": 1.7445093393325806,
      "learning_rate": 2.3988566402814426e-05,
      "loss": 0.0469,
      "step": 3458
    },
    {
      "epoch": 2.2816622691292876,
      "grad_norm": 1.0338753461837769,
      "learning_rate": 2.3966578715919086e-05,
      "loss": 0.0696,
      "step": 3459
    },
    {
      "epoch": 2.282321899736148,
      "grad_norm": 0.5760412812232971,
      "learning_rate": 2.3944591029023746e-05,
      "loss": 0.0208,
      "step": 3460
    },
    {
      "epoch": 2.282981530343008,
      "grad_norm": 25.593544006347656,
      "learning_rate": 2.3922603342128407e-05,
      "loss": 0.5645,
      "step": 3461
    },
    {
      "epoch": 2.283641160949868,
      "grad_norm": 3.359386920928955,
      "learning_rate": 2.390061565523307e-05,
      "loss": 0.0866,
      "step": 3462
    },
    {
      "epoch": 2.284300791556728,
      "grad_norm": 0.5669593811035156,
      "learning_rate": 2.3878627968337734e-05,
      "loss": 0.0333,
      "step": 3463
    },
    {
      "epoch": 2.2849604221635884,
      "grad_norm": 4.7251200675964355,
      "learning_rate": 2.3856640281442395e-05,
      "loss": 0.0811,
      "step": 3464
    },
    {
      "epoch": 2.2856200527704487,
      "grad_norm": 7.581276893615723,
      "learning_rate": 2.3834652594547055e-05,
      "loss": 0.097,
      "step": 3465
    },
    {
      "epoch": 2.286279683377309,
      "grad_norm": 8.433096885681152,
      "learning_rate": 2.3812664907651715e-05,
      "loss": 0.0978,
      "step": 3466
    },
    {
      "epoch": 2.2869393139841687,
      "grad_norm": 0.510828971862793,
      "learning_rate": 2.3790677220756376e-05,
      "loss": 0.0167,
      "step": 3467
    },
    {
      "epoch": 2.287598944591029,
      "grad_norm": 0.690184473991394,
      "learning_rate": 2.376868953386104e-05,
      "loss": 0.0315,
      "step": 3468
    },
    {
      "epoch": 2.288258575197889,
      "grad_norm": 16.287212371826172,
      "learning_rate": 2.37467018469657e-05,
      "loss": 0.2358,
      "step": 3469
    },
    {
      "epoch": 2.2889182058047495,
      "grad_norm": 4.724115371704102,
      "learning_rate": 2.372471416007036e-05,
      "loss": 0.0962,
      "step": 3470
    },
    {
      "epoch": 2.2895778364116097,
      "grad_norm": 25.867717742919922,
      "learning_rate": 2.3702726473175024e-05,
      "loss": 0.7924,
      "step": 3471
    },
    {
      "epoch": 2.2902374670184695,
      "grad_norm": 0.8280470967292786,
      "learning_rate": 2.3680738786279684e-05,
      "loss": 0.0446,
      "step": 3472
    },
    {
      "epoch": 2.29089709762533,
      "grad_norm": 3.505439281463623,
      "learning_rate": 2.3658751099384348e-05,
      "loss": 0.1153,
      "step": 3473
    },
    {
      "epoch": 2.29155672823219,
      "grad_norm": 0.9450973868370056,
      "learning_rate": 2.363676341248901e-05,
      "loss": 0.0512,
      "step": 3474
    },
    {
      "epoch": 2.2922163588390503,
      "grad_norm": 0.48695531487464905,
      "learning_rate": 2.361477572559367e-05,
      "loss": 0.0393,
      "step": 3475
    },
    {
      "epoch": 2.2928759894459105,
      "grad_norm": 1.294986605644226,
      "learning_rate": 2.359278803869833e-05,
      "loss": 0.0333,
      "step": 3476
    },
    {
      "epoch": 2.2935356200527703,
      "grad_norm": 0.6298195719718933,
      "learning_rate": 2.357080035180299e-05,
      "loss": 0.0465,
      "step": 3477
    },
    {
      "epoch": 2.2941952506596306,
      "grad_norm": 4.062795162200928,
      "learning_rate": 2.3548812664907653e-05,
      "loss": 0.0625,
      "step": 3478
    },
    {
      "epoch": 2.294854881266491,
      "grad_norm": 1.0127063989639282,
      "learning_rate": 2.3526824978012314e-05,
      "loss": 0.0544,
      "step": 3479
    },
    {
      "epoch": 2.295514511873351,
      "grad_norm": 1.738356590270996,
      "learning_rate": 2.3504837291116977e-05,
      "loss": 0.0453,
      "step": 3480
    },
    {
      "epoch": 2.296174142480211,
      "grad_norm": 0.46479883790016174,
      "learning_rate": 2.3482849604221638e-05,
      "loss": 0.0311,
      "step": 3481
    },
    {
      "epoch": 2.296833773087071,
      "grad_norm": 0.9250425100326538,
      "learning_rate": 2.3460861917326298e-05,
      "loss": 0.0617,
      "step": 3482
    },
    {
      "epoch": 2.2974934036939314,
      "grad_norm": 0.35163208842277527,
      "learning_rate": 2.343887423043096e-05,
      "loss": 0.0172,
      "step": 3483
    },
    {
      "epoch": 2.2981530343007917,
      "grad_norm": 1.5214533805847168,
      "learning_rate": 2.3416886543535622e-05,
      "loss": 0.0929,
      "step": 3484
    },
    {
      "epoch": 2.298812664907652,
      "grad_norm": 1.0214611291885376,
      "learning_rate": 2.3394898856640283e-05,
      "loss": 0.0621,
      "step": 3485
    },
    {
      "epoch": 2.2994722955145117,
      "grad_norm": 13.416620254516602,
      "learning_rate": 2.3372911169744943e-05,
      "loss": 0.457,
      "step": 3486
    },
    {
      "epoch": 2.300131926121372,
      "grad_norm": 1.125225305557251,
      "learning_rate": 2.3350923482849603e-05,
      "loss": 0.0646,
      "step": 3487
    },
    {
      "epoch": 2.300791556728232,
      "grad_norm": 0.7183525562286377,
      "learning_rate": 2.3328935795954264e-05,
      "loss": 0.0481,
      "step": 3488
    },
    {
      "epoch": 2.3014511873350925,
      "grad_norm": 7.575995922088623,
      "learning_rate": 2.3306948109058928e-05,
      "loss": 0.1882,
      "step": 3489
    },
    {
      "epoch": 2.3021108179419523,
      "grad_norm": 14.080412864685059,
      "learning_rate": 2.328496042216359e-05,
      "loss": 0.3664,
      "step": 3490
    },
    {
      "epoch": 2.3027704485488125,
      "grad_norm": 24.007097244262695,
      "learning_rate": 2.3262972735268252e-05,
      "loss": 2.6122,
      "step": 3491
    },
    {
      "epoch": 2.3034300791556728,
      "grad_norm": 7.665621280670166,
      "learning_rate": 2.3240985048372912e-05,
      "loss": 0.303,
      "step": 3492
    },
    {
      "epoch": 2.304089709762533,
      "grad_norm": 0.8589584827423096,
      "learning_rate": 2.3218997361477572e-05,
      "loss": 0.0402,
      "step": 3493
    },
    {
      "epoch": 2.3047493403693933,
      "grad_norm": 11.149571418762207,
      "learning_rate": 2.3197009674582236e-05,
      "loss": 1.5459,
      "step": 3494
    },
    {
      "epoch": 2.305408970976253,
      "grad_norm": 1.0395272970199585,
      "learning_rate": 2.3175021987686897e-05,
      "loss": 0.0251,
      "step": 3495
    },
    {
      "epoch": 2.3060686015831133,
      "grad_norm": 1.237043857574463,
      "learning_rate": 2.3153034300791557e-05,
      "loss": 0.0437,
      "step": 3496
    },
    {
      "epoch": 2.3067282321899736,
      "grad_norm": 1.2829316854476929,
      "learning_rate": 2.3131046613896217e-05,
      "loss": 0.0631,
      "step": 3497
    },
    {
      "epoch": 2.307387862796834,
      "grad_norm": 4.548892498016357,
      "learning_rate": 2.310905892700088e-05,
      "loss": 0.1105,
      "step": 3498
    },
    {
      "epoch": 2.308047493403694,
      "grad_norm": 12.738162994384766,
      "learning_rate": 2.308707124010554e-05,
      "loss": 0.8954,
      "step": 3499
    },
    {
      "epoch": 2.308707124010554,
      "grad_norm": 1.1013245582580566,
      "learning_rate": 2.3065083553210205e-05,
      "loss": 0.0474,
      "step": 3500
    },
    {
      "epoch": 2.309366754617414,
      "grad_norm": 18.74541473388672,
      "learning_rate": 2.3043095866314866e-05,
      "loss": 0.4037,
      "step": 3501
    },
    {
      "epoch": 2.3100263852242744,
      "grad_norm": 26.77266502380371,
      "learning_rate": 2.3021108179419526e-05,
      "loss": 0.5321,
      "step": 3502
    },
    {
      "epoch": 2.3106860158311346,
      "grad_norm": 0.9012561440467834,
      "learning_rate": 2.2999120492524186e-05,
      "loss": 0.0346,
      "step": 3503
    },
    {
      "epoch": 2.311345646437995,
      "grad_norm": 3.3592989444732666,
      "learning_rate": 2.2977132805628847e-05,
      "loss": 0.048,
      "step": 3504
    },
    {
      "epoch": 2.3120052770448547,
      "grad_norm": 14.943220138549805,
      "learning_rate": 2.295514511873351e-05,
      "loss": 0.5471,
      "step": 3505
    },
    {
      "epoch": 2.312664907651715,
      "grad_norm": 0.8025326728820801,
      "learning_rate": 2.293315743183817e-05,
      "loss": 0.0756,
      "step": 3506
    },
    {
      "epoch": 2.313324538258575,
      "grad_norm": 3.129351854324341,
      "learning_rate": 2.2911169744942835e-05,
      "loss": 0.0616,
      "step": 3507
    },
    {
      "epoch": 2.3139841688654355,
      "grad_norm": 0.546769917011261,
      "learning_rate": 2.2889182058047495e-05,
      "loss": 0.0279,
      "step": 3508
    },
    {
      "epoch": 2.3146437994722957,
      "grad_norm": 11.122411727905273,
      "learning_rate": 2.2867194371152155e-05,
      "loss": 0.1349,
      "step": 3509
    },
    {
      "epoch": 2.3153034300791555,
      "grad_norm": 4.805148124694824,
      "learning_rate": 2.284520668425682e-05,
      "loss": 0.1035,
      "step": 3510
    },
    {
      "epoch": 2.3159630606860158,
      "grad_norm": 13.426569938659668,
      "learning_rate": 2.282321899736148e-05,
      "loss": 1.0956,
      "step": 3511
    },
    {
      "epoch": 2.316622691292876,
      "grad_norm": 2.241856813430786,
      "learning_rate": 2.280123131046614e-05,
      "loss": 0.0992,
      "step": 3512
    },
    {
      "epoch": 2.3172823218997363,
      "grad_norm": 20.196651458740234,
      "learning_rate": 2.27792436235708e-05,
      "loss": 0.8913,
      "step": 3513
    },
    {
      "epoch": 2.3179419525065965,
      "grad_norm": 0.6876589059829712,
      "learning_rate": 2.275725593667546e-05,
      "loss": 0.0485,
      "step": 3514
    },
    {
      "epoch": 2.3186015831134563,
      "grad_norm": 96.77165985107422,
      "learning_rate": 2.2735268249780124e-05,
      "loss": 0.7265,
      "step": 3515
    },
    {
      "epoch": 2.3192612137203166,
      "grad_norm": 1.4962332248687744,
      "learning_rate": 2.2713280562884788e-05,
      "loss": 0.0809,
      "step": 3516
    },
    {
      "epoch": 2.319920844327177,
      "grad_norm": 0.8117305636405945,
      "learning_rate": 2.269129287598945e-05,
      "loss": 0.0472,
      "step": 3517
    },
    {
      "epoch": 2.320580474934037,
      "grad_norm": 1.7480453252792358,
      "learning_rate": 2.266930518909411e-05,
      "loss": 0.0548,
      "step": 3518
    },
    {
      "epoch": 2.3212401055408973,
      "grad_norm": 11.834951400756836,
      "learning_rate": 2.264731750219877e-05,
      "loss": 0.2522,
      "step": 3519
    },
    {
      "epoch": 2.321899736147757,
      "grad_norm": 4.883552074432373,
      "learning_rate": 2.262532981530343e-05,
      "loss": 0.1518,
      "step": 3520
    },
    {
      "epoch": 2.3225593667546174,
      "grad_norm": 4.416745662689209,
      "learning_rate": 2.2603342128408093e-05,
      "loss": 0.1154,
      "step": 3521
    },
    {
      "epoch": 2.3232189973614776,
      "grad_norm": 1.6117933988571167,
      "learning_rate": 2.2581354441512754e-05,
      "loss": 0.0679,
      "step": 3522
    },
    {
      "epoch": 2.323878627968338,
      "grad_norm": 0.43928053975105286,
      "learning_rate": 2.2559366754617414e-05,
      "loss": 0.0278,
      "step": 3523
    },
    {
      "epoch": 2.324538258575198,
      "grad_norm": 0.9438401460647583,
      "learning_rate": 2.2537379067722078e-05,
      "loss": 0.0378,
      "step": 3524
    },
    {
      "epoch": 2.325197889182058,
      "grad_norm": 1.0329999923706055,
      "learning_rate": 2.2515391380826738e-05,
      "loss": 0.0709,
      "step": 3525
    },
    {
      "epoch": 2.325857519788918,
      "grad_norm": 0.6945395469665527,
      "learning_rate": 2.2493403693931402e-05,
      "loss": 0.0333,
      "step": 3526
    },
    {
      "epoch": 2.3265171503957784,
      "grad_norm": 3.9734103679656982,
      "learning_rate": 2.2471416007036062e-05,
      "loss": 0.1104,
      "step": 3527
    },
    {
      "epoch": 2.3271767810026387,
      "grad_norm": 0.6940928101539612,
      "learning_rate": 2.2449428320140723e-05,
      "loss": 0.0335,
      "step": 3528
    },
    {
      "epoch": 2.3278364116094985,
      "grad_norm": 0.39759933948516846,
      "learning_rate": 2.2427440633245383e-05,
      "loss": 0.0299,
      "step": 3529
    },
    {
      "epoch": 2.3284960422163588,
      "grad_norm": 1.4411708116531372,
      "learning_rate": 2.2405452946350043e-05,
      "loss": 0.047,
      "step": 3530
    },
    {
      "epoch": 2.329155672823219,
      "grad_norm": 0.6033624410629272,
      "learning_rate": 2.2383465259454707e-05,
      "loss": 0.0383,
      "step": 3531
    },
    {
      "epoch": 2.3298153034300793,
      "grad_norm": 18.252779006958008,
      "learning_rate": 2.2361477572559368e-05,
      "loss": 0.523,
      "step": 3532
    },
    {
      "epoch": 2.3304749340369395,
      "grad_norm": 4.709300994873047,
      "learning_rate": 2.233948988566403e-05,
      "loss": 0.0449,
      "step": 3533
    },
    {
      "epoch": 2.3311345646437993,
      "grad_norm": 0.7902489304542542,
      "learning_rate": 2.231750219876869e-05,
      "loss": 0.0515,
      "step": 3534
    },
    {
      "epoch": 2.3317941952506596,
      "grad_norm": 1.9193286895751953,
      "learning_rate": 2.2295514511873352e-05,
      "loss": 0.0653,
      "step": 3535
    },
    {
      "epoch": 2.33245382585752,
      "grad_norm": 14.028204917907715,
      "learning_rate": 2.2273526824978012e-05,
      "loss": 0.9187,
      "step": 3536
    },
    {
      "epoch": 2.33311345646438,
      "grad_norm": 12.633346557617188,
      "learning_rate": 2.2251539138082676e-05,
      "loss": 0.356,
      "step": 3537
    },
    {
      "epoch": 2.33377308707124,
      "grad_norm": 0.9947036504745483,
      "learning_rate": 2.2229551451187336e-05,
      "loss": 0.0664,
      "step": 3538
    },
    {
      "epoch": 2.3344327176781,
      "grad_norm": 1.0889298915863037,
      "learning_rate": 2.2207563764291997e-05,
      "loss": 0.0451,
      "step": 3539
    },
    {
      "epoch": 2.3350923482849604,
      "grad_norm": 0.7266703248023987,
      "learning_rate": 2.2185576077396657e-05,
      "loss": 0.0506,
      "step": 3540
    },
    {
      "epoch": 2.3357519788918206,
      "grad_norm": 1.372394323348999,
      "learning_rate": 2.2163588390501318e-05,
      "loss": 0.0928,
      "step": 3541
    },
    {
      "epoch": 2.336411609498681,
      "grad_norm": 1.3982362747192383,
      "learning_rate": 2.214160070360598e-05,
      "loss": 0.0993,
      "step": 3542
    },
    {
      "epoch": 2.3370712401055407,
      "grad_norm": 0.7501276731491089,
      "learning_rate": 2.2119613016710645e-05,
      "loss": 0.0491,
      "step": 3543
    },
    {
      "epoch": 2.337730870712401,
      "grad_norm": 7.451093673706055,
      "learning_rate": 2.2097625329815305e-05,
      "loss": 0.1472,
      "step": 3544
    },
    {
      "epoch": 2.338390501319261,
      "grad_norm": 1.2060445547103882,
      "learning_rate": 2.2075637642919966e-05,
      "loss": 0.0576,
      "step": 3545
    },
    {
      "epoch": 2.3390501319261214,
      "grad_norm": 1.5736562013626099,
      "learning_rate": 2.2053649956024626e-05,
      "loss": 0.0301,
      "step": 3546
    },
    {
      "epoch": 2.3397097625329817,
      "grad_norm": 11.021397590637207,
      "learning_rate": 2.203166226912929e-05,
      "loss": 0.8495,
      "step": 3547
    },
    {
      "epoch": 2.3403693931398415,
      "grad_norm": 1.3610388040542603,
      "learning_rate": 2.200967458223395e-05,
      "loss": 0.0557,
      "step": 3548
    },
    {
      "epoch": 2.3410290237467017,
      "grad_norm": 6.066018104553223,
      "learning_rate": 2.198768689533861e-05,
      "loss": 0.0907,
      "step": 3549
    },
    {
      "epoch": 2.341688654353562,
      "grad_norm": 1.1913095712661743,
      "learning_rate": 2.196569920844327e-05,
      "loss": 0.08,
      "step": 3550
    },
    {
      "epoch": 2.3423482849604222,
      "grad_norm": 1.798030972480774,
      "learning_rate": 2.1943711521547935e-05,
      "loss": 0.0547,
      "step": 3551
    },
    {
      "epoch": 2.3430079155672825,
      "grad_norm": 7.6585612297058105,
      "learning_rate": 2.1921723834652595e-05,
      "loss": 0.2197,
      "step": 3552
    },
    {
      "epoch": 2.3436675461741423,
      "grad_norm": 0.7358775734901428,
      "learning_rate": 2.189973614775726e-05,
      "loss": 0.032,
      "step": 3553
    },
    {
      "epoch": 2.3443271767810026,
      "grad_norm": 13.916526794433594,
      "learning_rate": 2.187774846086192e-05,
      "loss": 0.8591,
      "step": 3554
    },
    {
      "epoch": 2.344986807387863,
      "grad_norm": 9.201807022094727,
      "learning_rate": 2.185576077396658e-05,
      "loss": 0.2556,
      "step": 3555
    },
    {
      "epoch": 2.345646437994723,
      "grad_norm": 6.30307149887085,
      "learning_rate": 2.183377308707124e-05,
      "loss": 0.113,
      "step": 3556
    },
    {
      "epoch": 2.3463060686015833,
      "grad_norm": 37.741878509521484,
      "learning_rate": 2.18117854001759e-05,
      "loss": 0.3803,
      "step": 3557
    },
    {
      "epoch": 2.346965699208443,
      "grad_norm": 15.022775650024414,
      "learning_rate": 2.1789797713280564e-05,
      "loss": 0.4949,
      "step": 3558
    },
    {
      "epoch": 2.3476253298153034,
      "grad_norm": 3.3800525665283203,
      "learning_rate": 2.1767810026385225e-05,
      "loss": 0.0633,
      "step": 3559
    },
    {
      "epoch": 2.3482849604221636,
      "grad_norm": 10.339822769165039,
      "learning_rate": 2.174582233948989e-05,
      "loss": 0.8814,
      "step": 3560
    },
    {
      "epoch": 2.348944591029024,
      "grad_norm": 10.85825252532959,
      "learning_rate": 2.172383465259455e-05,
      "loss": 0.1182,
      "step": 3561
    },
    {
      "epoch": 2.349604221635884,
      "grad_norm": 0.649875819683075,
      "learning_rate": 2.170184696569921e-05,
      "loss": 0.0404,
      "step": 3562
    },
    {
      "epoch": 2.350263852242744,
      "grad_norm": 0.9357773661613464,
      "learning_rate": 2.1679859278803873e-05,
      "loss": 0.0307,
      "step": 3563
    },
    {
      "epoch": 2.350923482849604,
      "grad_norm": 1.2144994735717773,
      "learning_rate": 2.1657871591908533e-05,
      "loss": 0.0762,
      "step": 3564
    },
    {
      "epoch": 2.3515831134564644,
      "grad_norm": 7.625617504119873,
      "learning_rate": 2.1635883905013194e-05,
      "loss": 0.2307,
      "step": 3565
    },
    {
      "epoch": 2.3522427440633247,
      "grad_norm": 0.944570779800415,
      "learning_rate": 2.1613896218117854e-05,
      "loss": 0.0355,
      "step": 3566
    },
    {
      "epoch": 2.352902374670185,
      "grad_norm": 4.998468399047852,
      "learning_rate": 2.1591908531222514e-05,
      "loss": 0.095,
      "step": 3567
    },
    {
      "epoch": 2.3535620052770447,
      "grad_norm": 1.1473468542099,
      "learning_rate": 2.1569920844327178e-05,
      "loss": 0.0621,
      "step": 3568
    },
    {
      "epoch": 2.354221635883905,
      "grad_norm": 7.300939559936523,
      "learning_rate": 2.1547933157431842e-05,
      "loss": 0.1961,
      "step": 3569
    },
    {
      "epoch": 2.3548812664907652,
      "grad_norm": 6.261831283569336,
      "learning_rate": 2.1525945470536502e-05,
      "loss": 0.1328,
      "step": 3570
    },
    {
      "epoch": 2.3555408970976255,
      "grad_norm": 15.317777633666992,
      "learning_rate": 2.1503957783641163e-05,
      "loss": 0.7398,
      "step": 3571
    },
    {
      "epoch": 2.3562005277044857,
      "grad_norm": 0.9457412958145142,
      "learning_rate": 2.1481970096745823e-05,
      "loss": 0.0875,
      "step": 3572
    },
    {
      "epoch": 2.3568601583113455,
      "grad_norm": 0.452627569437027,
      "learning_rate": 2.1459982409850483e-05,
      "loss": 0.0293,
      "step": 3573
    },
    {
      "epoch": 2.357519788918206,
      "grad_norm": 0.8565342426300049,
      "learning_rate": 2.1437994722955147e-05,
      "loss": 0.0478,
      "step": 3574
    },
    {
      "epoch": 2.358179419525066,
      "grad_norm": 0.7701941132545471,
      "learning_rate": 2.1416007036059807e-05,
      "loss": 0.0621,
      "step": 3575
    },
    {
      "epoch": 2.3588390501319263,
      "grad_norm": 0.9447770118713379,
      "learning_rate": 2.1394019349164468e-05,
      "loss": 0.0353,
      "step": 3576
    },
    {
      "epoch": 2.359498680738786,
      "grad_norm": 0.8987762331962585,
      "learning_rate": 2.1372031662269128e-05,
      "loss": 0.0323,
      "step": 3577
    },
    {
      "epoch": 2.3601583113456464,
      "grad_norm": 2.167545795440674,
      "learning_rate": 2.1350043975373792e-05,
      "loss": 0.0367,
      "step": 3578
    },
    {
      "epoch": 2.3608179419525066,
      "grad_norm": 9.589308738708496,
      "learning_rate": 2.1328056288478456e-05,
      "loss": 1.1237,
      "step": 3579
    },
    {
      "epoch": 2.361477572559367,
      "grad_norm": 2.1072897911071777,
      "learning_rate": 2.1306068601583116e-05,
      "loss": 0.0752,
      "step": 3580
    },
    {
      "epoch": 2.362137203166227,
      "grad_norm": 13.197362899780273,
      "learning_rate": 2.1284080914687776e-05,
      "loss": 1.6486,
      "step": 3581
    },
    {
      "epoch": 2.362796833773087,
      "grad_norm": 5.498798370361328,
      "learning_rate": 2.1262093227792437e-05,
      "loss": 0.1515,
      "step": 3582
    },
    {
      "epoch": 2.363456464379947,
      "grad_norm": 3.7494876384735107,
      "learning_rate": 2.1240105540897097e-05,
      "loss": 0.0911,
      "step": 3583
    },
    {
      "epoch": 2.3641160949868074,
      "grad_norm": 0.6756532192230225,
      "learning_rate": 2.121811785400176e-05,
      "loss": 0.0277,
      "step": 3584
    },
    {
      "epoch": 2.3647757255936677,
      "grad_norm": 1.0144016742706299,
      "learning_rate": 2.119613016710642e-05,
      "loss": 0.0471,
      "step": 3585
    },
    {
      "epoch": 2.3654353562005275,
      "grad_norm": 0.8525020480155945,
      "learning_rate": 2.117414248021108e-05,
      "loss": 0.0286,
      "step": 3586
    },
    {
      "epoch": 2.3660949868073877,
      "grad_norm": 0.905789315700531,
      "learning_rate": 2.1152154793315745e-05,
      "loss": 0.0405,
      "step": 3587
    },
    {
      "epoch": 2.366754617414248,
      "grad_norm": 27.958560943603516,
      "learning_rate": 2.1130167106420406e-05,
      "loss": 0.2075,
      "step": 3588
    },
    {
      "epoch": 2.3674142480211082,
      "grad_norm": 15.3223876953125,
      "learning_rate": 2.1108179419525066e-05,
      "loss": 0.3202,
      "step": 3589
    },
    {
      "epoch": 2.3680738786279685,
      "grad_norm": 17.388153076171875,
      "learning_rate": 2.108619173262973e-05,
      "loss": 0.5109,
      "step": 3590
    },
    {
      "epoch": 2.3687335092348283,
      "grad_norm": 1.3384745121002197,
      "learning_rate": 2.106420404573439e-05,
      "loss": 0.0431,
      "step": 3591
    },
    {
      "epoch": 2.3693931398416885,
      "grad_norm": 4.078011512756348,
      "learning_rate": 2.104221635883905e-05,
      "loss": 0.0788,
      "step": 3592
    },
    {
      "epoch": 2.370052770448549,
      "grad_norm": 1.177730679512024,
      "learning_rate": 2.102022867194371e-05,
      "loss": 0.0644,
      "step": 3593
    },
    {
      "epoch": 2.370712401055409,
      "grad_norm": 1.6679050922393799,
      "learning_rate": 2.099824098504837e-05,
      "loss": 0.0978,
      "step": 3594
    },
    {
      "epoch": 2.3713720316622693,
      "grad_norm": 2.79337215423584,
      "learning_rate": 2.0976253298153035e-05,
      "loss": 0.1159,
      "step": 3595
    },
    {
      "epoch": 2.372031662269129,
      "grad_norm": 3.4371581077575684,
      "learning_rate": 2.09542656112577e-05,
      "loss": 0.1031,
      "step": 3596
    },
    {
      "epoch": 2.3726912928759893,
      "grad_norm": 8.729751586914062,
      "learning_rate": 2.093227792436236e-05,
      "loss": 0.2087,
      "step": 3597
    },
    {
      "epoch": 2.3733509234828496,
      "grad_norm": 1.070173740386963,
      "learning_rate": 2.091029023746702e-05,
      "loss": 0.0684,
      "step": 3598
    },
    {
      "epoch": 2.37401055408971,
      "grad_norm": 11.30273723602295,
      "learning_rate": 2.088830255057168e-05,
      "loss": 0.2612,
      "step": 3599
    },
    {
      "epoch": 2.37467018469657,
      "grad_norm": 2.0841493606567383,
      "learning_rate": 2.0866314863676344e-05,
      "loss": 0.1162,
      "step": 3600
    },
    {
      "epoch": 2.37532981530343,
      "grad_norm": 6.689169406890869,
      "learning_rate": 2.0844327176781004e-05,
      "loss": 0.0991,
      "step": 3601
    },
    {
      "epoch": 2.37598944591029,
      "grad_norm": 2.115941047668457,
      "learning_rate": 2.0822339489885665e-05,
      "loss": 0.0559,
      "step": 3602
    },
    {
      "epoch": 2.3766490765171504,
      "grad_norm": 0.6013379693031311,
      "learning_rate": 2.0800351802990325e-05,
      "loss": 0.0269,
      "step": 3603
    },
    {
      "epoch": 2.3773087071240107,
      "grad_norm": 7.3705244064331055,
      "learning_rate": 2.0778364116094985e-05,
      "loss": 0.5355,
      "step": 3604
    },
    {
      "epoch": 2.377968337730871,
      "grad_norm": 0.7083461880683899,
      "learning_rate": 2.075637642919965e-05,
      "loss": 0.0462,
      "step": 3605
    },
    {
      "epoch": 2.3786279683377307,
      "grad_norm": 10.04254150390625,
      "learning_rate": 2.0734388742304313e-05,
      "loss": 0.3479,
      "step": 3606
    },
    {
      "epoch": 2.379287598944591,
      "grad_norm": 0.7375495433807373,
      "learning_rate": 2.0712401055408973e-05,
      "loss": 0.0414,
      "step": 3607
    },
    {
      "epoch": 2.379947229551451,
      "grad_norm": 10.024937629699707,
      "learning_rate": 2.0690413368513634e-05,
      "loss": 0.1452,
      "step": 3608
    },
    {
      "epoch": 2.3806068601583115,
      "grad_norm": 8.714983940124512,
      "learning_rate": 2.0668425681618294e-05,
      "loss": 0.1077,
      "step": 3609
    },
    {
      "epoch": 2.3812664907651717,
      "grad_norm": 0.9439612030982971,
      "learning_rate": 2.0646437994722954e-05,
      "loss": 0.0378,
      "step": 3610
    },
    {
      "epoch": 2.3819261213720315,
      "grad_norm": 0.7977020144462585,
      "learning_rate": 2.0624450307827618e-05,
      "loss": 0.0437,
      "step": 3611
    },
    {
      "epoch": 2.3825857519788918,
      "grad_norm": 0.7111902236938477,
      "learning_rate": 2.060246262093228e-05,
      "loss": 0.0285,
      "step": 3612
    },
    {
      "epoch": 2.383245382585752,
      "grad_norm": 1.798984169960022,
      "learning_rate": 2.058047493403694e-05,
      "loss": 0.074,
      "step": 3613
    },
    {
      "epoch": 2.3839050131926123,
      "grad_norm": 13.372064590454102,
      "learning_rate": 2.0558487247141603e-05,
      "loss": 0.1464,
      "step": 3614
    },
    {
      "epoch": 2.3845646437994725,
      "grad_norm": 0.9860356450080872,
      "learning_rate": 2.0536499560246263e-05,
      "loss": 0.0574,
      "step": 3615
    },
    {
      "epoch": 2.3852242744063323,
      "grad_norm": 1.3799062967300415,
      "learning_rate": 2.0514511873350927e-05,
      "loss": 0.0896,
      "step": 3616
    },
    {
      "epoch": 2.3858839050131926,
      "grad_norm": 6.3697590827941895,
      "learning_rate": 2.0492524186455587e-05,
      "loss": 0.1367,
      "step": 3617
    },
    {
      "epoch": 2.386543535620053,
      "grad_norm": 1.1953727006912231,
      "learning_rate": 2.0470536499560247e-05,
      "loss": 0.0615,
      "step": 3618
    },
    {
      "epoch": 2.387203166226913,
      "grad_norm": 15.619365692138672,
      "learning_rate": 2.0448548812664908e-05,
      "loss": 0.7042,
      "step": 3619
    },
    {
      "epoch": 2.387862796833773,
      "grad_norm": 6.276348114013672,
      "learning_rate": 2.0426561125769568e-05,
      "loss": 0.1519,
      "step": 3620
    },
    {
      "epoch": 2.388522427440633,
      "grad_norm": 2.5297324657440186,
      "learning_rate": 2.0404573438874232e-05,
      "loss": 0.0716,
      "step": 3621
    },
    {
      "epoch": 2.3891820580474934,
      "grad_norm": 1.4557734727859497,
      "learning_rate": 2.0382585751978892e-05,
      "loss": 0.0539,
      "step": 3622
    },
    {
      "epoch": 2.3898416886543536,
      "grad_norm": 2.813218832015991,
      "learning_rate": 2.0360598065083556e-05,
      "loss": 0.0471,
      "step": 3623
    },
    {
      "epoch": 2.390501319261214,
      "grad_norm": 14.640636444091797,
      "learning_rate": 2.0338610378188216e-05,
      "loss": 0.3638,
      "step": 3624
    },
    {
      "epoch": 2.3911609498680737,
      "grad_norm": 1.426893949508667,
      "learning_rate": 2.0316622691292877e-05,
      "loss": 0.0371,
      "step": 3625
    },
    {
      "epoch": 2.391820580474934,
      "grad_norm": 0.3933826684951782,
      "learning_rate": 2.0294635004397537e-05,
      "loss": 0.0249,
      "step": 3626
    },
    {
      "epoch": 2.392480211081794,
      "grad_norm": 7.304976940155029,
      "learning_rate": 2.02726473175022e-05,
      "loss": 0.2454,
      "step": 3627
    },
    {
      "epoch": 2.3931398416886545,
      "grad_norm": 2.352154016494751,
      "learning_rate": 2.025065963060686e-05,
      "loss": 0.0863,
      "step": 3628
    },
    {
      "epoch": 2.3937994722955143,
      "grad_norm": 1.0621256828308105,
      "learning_rate": 2.022867194371152e-05,
      "loss": 0.0762,
      "step": 3629
    },
    {
      "epoch": 2.3944591029023745,
      "grad_norm": 19.043397903442383,
      "learning_rate": 2.0206684256816182e-05,
      "loss": 0.3979,
      "step": 3630
    },
    {
      "epoch": 2.3951187335092348,
      "grad_norm": 1.305353045463562,
      "learning_rate": 2.0184696569920842e-05,
      "loss": 0.0511,
      "step": 3631
    },
    {
      "epoch": 2.395778364116095,
      "grad_norm": 1.8240712881088257,
      "learning_rate": 2.016270888302551e-05,
      "loss": 0.0742,
      "step": 3632
    },
    {
      "epoch": 2.3964379947229553,
      "grad_norm": 15.829362869262695,
      "learning_rate": 2.014072119613017e-05,
      "loss": 0.4245,
      "step": 3633
    },
    {
      "epoch": 2.397097625329815,
      "grad_norm": 0.8433305025100708,
      "learning_rate": 2.011873350923483e-05,
      "loss": 0.0402,
      "step": 3634
    },
    {
      "epoch": 2.3977572559366753,
      "grad_norm": 12.06678581237793,
      "learning_rate": 2.009674582233949e-05,
      "loss": 0.2414,
      "step": 3635
    },
    {
      "epoch": 2.3984168865435356,
      "grad_norm": 1.4635822772979736,
      "learning_rate": 2.007475813544415e-05,
      "loss": 0.0448,
      "step": 3636
    },
    {
      "epoch": 2.399076517150396,
      "grad_norm": 0.6871644854545593,
      "learning_rate": 2.0052770448548815e-05,
      "loss": 0.0334,
      "step": 3637
    },
    {
      "epoch": 2.399736147757256,
      "grad_norm": 0.8735228776931763,
      "learning_rate": 2.0030782761653475e-05,
      "loss": 0.054,
      "step": 3638
    },
    {
      "epoch": 2.400395778364116,
      "grad_norm": 12.808320999145508,
      "learning_rate": 2.0008795074758135e-05,
      "loss": 0.528,
      "step": 3639
    },
    {
      "epoch": 2.401055408970976,
      "grad_norm": 1.6934008598327637,
      "learning_rate": 1.9986807387862796e-05,
      "loss": 0.05,
      "step": 3640
    },
    {
      "epoch": 2.4017150395778364,
      "grad_norm": 17.295969009399414,
      "learning_rate": 1.996481970096746e-05,
      "loss": 0.4702,
      "step": 3641
    },
    {
      "epoch": 2.4023746701846966,
      "grad_norm": 1.0618062019348145,
      "learning_rate": 1.994283201407212e-05,
      "loss": 0.0764,
      "step": 3642
    },
    {
      "epoch": 2.403034300791557,
      "grad_norm": 6.380912780761719,
      "learning_rate": 1.9920844327176784e-05,
      "loss": 0.1875,
      "step": 3643
    },
    {
      "epoch": 2.4036939313984167,
      "grad_norm": 13.3623685836792,
      "learning_rate": 1.9898856640281444e-05,
      "loss": 0.5568,
      "step": 3644
    },
    {
      "epoch": 2.404353562005277,
      "grad_norm": 0.9775574803352356,
      "learning_rate": 1.9876868953386104e-05,
      "loss": 0.0796,
      "step": 3645
    },
    {
      "epoch": 2.405013192612137,
      "grad_norm": 1.2294307947158813,
      "learning_rate": 1.9854881266490765e-05,
      "loss": 0.0646,
      "step": 3646
    },
    {
      "epoch": 2.4056728232189974,
      "grad_norm": 8.038613319396973,
      "learning_rate": 1.9832893579595425e-05,
      "loss": 0.2184,
      "step": 3647
    },
    {
      "epoch": 2.4063324538258577,
      "grad_norm": 0.8736444115638733,
      "learning_rate": 1.981090589270009e-05,
      "loss": 0.0609,
      "step": 3648
    },
    {
      "epoch": 2.4069920844327175,
      "grad_norm": 0.9704980850219727,
      "learning_rate": 1.978891820580475e-05,
      "loss": 0.0548,
      "step": 3649
    },
    {
      "epoch": 2.4076517150395778,
      "grad_norm": 1.7502086162567139,
      "learning_rate": 1.9766930518909413e-05,
      "loss": 0.0618,
      "step": 3650
    },
    {
      "epoch": 2.408311345646438,
      "grad_norm": 1.1856629848480225,
      "learning_rate": 1.9744942832014073e-05,
      "loss": 0.0455,
      "step": 3651
    },
    {
      "epoch": 2.4089709762532983,
      "grad_norm": 1.5475248098373413,
      "learning_rate": 1.9722955145118734e-05,
      "loss": 0.0434,
      "step": 3652
    },
    {
      "epoch": 2.4096306068601585,
      "grad_norm": 18.13433074951172,
      "learning_rate": 1.9700967458223398e-05,
      "loss": 0.4168,
      "step": 3653
    },
    {
      "epoch": 2.4102902374670183,
      "grad_norm": 8.782958030700684,
      "learning_rate": 1.9678979771328058e-05,
      "loss": 0.7234,
      "step": 3654
    },
    {
      "epoch": 2.4109498680738786,
      "grad_norm": 0.9260009527206421,
      "learning_rate": 1.965699208443272e-05,
      "loss": 0.0633,
      "step": 3655
    },
    {
      "epoch": 2.411609498680739,
      "grad_norm": 11.152979850769043,
      "learning_rate": 1.963500439753738e-05,
      "loss": 0.4252,
      "step": 3656
    },
    {
      "epoch": 2.412269129287599,
      "grad_norm": 0.5891337990760803,
      "learning_rate": 1.961301671064204e-05,
      "loss": 0.0345,
      "step": 3657
    },
    {
      "epoch": 2.4129287598944593,
      "grad_norm": 6.597647666931152,
      "learning_rate": 1.9591029023746703e-05,
      "loss": 0.1634,
      "step": 3658
    },
    {
      "epoch": 2.413588390501319,
      "grad_norm": 1.252316951751709,
      "learning_rate": 1.9569041336851367e-05,
      "loss": 0.0717,
      "step": 3659
    },
    {
      "epoch": 2.4142480211081794,
      "grad_norm": 2.090137481689453,
      "learning_rate": 1.9547053649956027e-05,
      "loss": 0.0775,
      "step": 3660
    },
    {
      "epoch": 2.4149076517150396,
      "grad_norm": 1.0833332538604736,
      "learning_rate": 1.9525065963060687e-05,
      "loss": 0.0455,
      "step": 3661
    },
    {
      "epoch": 2.4155672823219,
      "grad_norm": 2.6956169605255127,
      "learning_rate": 1.9503078276165348e-05,
      "loss": 0.1879,
      "step": 3662
    },
    {
      "epoch": 2.41622691292876,
      "grad_norm": 0.7299275994300842,
      "learning_rate": 1.9481090589270008e-05,
      "loss": 0.0492,
      "step": 3663
    },
    {
      "epoch": 2.41688654353562,
      "grad_norm": 1.853497862815857,
      "learning_rate": 1.9459102902374672e-05,
      "loss": 0.0692,
      "step": 3664
    },
    {
      "epoch": 2.41754617414248,
      "grad_norm": 10.829242706298828,
      "learning_rate": 1.9437115215479332e-05,
      "loss": 0.3835,
      "step": 3665
    },
    {
      "epoch": 2.4182058047493404,
      "grad_norm": 1.6228179931640625,
      "learning_rate": 1.9415127528583993e-05,
      "loss": 0.058,
      "step": 3666
    },
    {
      "epoch": 2.4188654353562007,
      "grad_norm": 4.984007358551025,
      "learning_rate": 1.9393139841688653e-05,
      "loss": 0.1069,
      "step": 3667
    },
    {
      "epoch": 2.4195250659630605,
      "grad_norm": 0.9112786650657654,
      "learning_rate": 1.9371152154793317e-05,
      "loss": 0.0485,
      "step": 3668
    },
    {
      "epoch": 2.4201846965699207,
      "grad_norm": 1.4859315156936646,
      "learning_rate": 1.934916446789798e-05,
      "loss": 0.0639,
      "step": 3669
    },
    {
      "epoch": 2.420844327176781,
      "grad_norm": 2.0531978607177734,
      "learning_rate": 1.932717678100264e-05,
      "loss": 0.1015,
      "step": 3670
    },
    {
      "epoch": 2.4215039577836412,
      "grad_norm": 0.5670930743217468,
      "learning_rate": 1.93051890941073e-05,
      "loss": 0.0311,
      "step": 3671
    },
    {
      "epoch": 2.4221635883905015,
      "grad_norm": 7.992578506469727,
      "learning_rate": 1.928320140721196e-05,
      "loss": 0.1721,
      "step": 3672
    },
    {
      "epoch": 2.4228232189973613,
      "grad_norm": 1.221855640411377,
      "learning_rate": 1.9261213720316622e-05,
      "loss": 0.0605,
      "step": 3673
    },
    {
      "epoch": 2.4234828496042216,
      "grad_norm": 15.217309951782227,
      "learning_rate": 1.9239226033421286e-05,
      "loss": 0.365,
      "step": 3674
    },
    {
      "epoch": 2.424142480211082,
      "grad_norm": 17.40700912475586,
      "learning_rate": 1.9217238346525946e-05,
      "loss": 0.9496,
      "step": 3675
    },
    {
      "epoch": 2.424802110817942,
      "grad_norm": 1.4119346141815186,
      "learning_rate": 1.9195250659630606e-05,
      "loss": 0.0625,
      "step": 3676
    },
    {
      "epoch": 2.425461741424802,
      "grad_norm": 1.8812576532363892,
      "learning_rate": 1.917326297273527e-05,
      "loss": 0.0445,
      "step": 3677
    },
    {
      "epoch": 2.426121372031662,
      "grad_norm": 2.0823915004730225,
      "learning_rate": 1.915127528583993e-05,
      "loss": 0.0937,
      "step": 3678
    },
    {
      "epoch": 2.4267810026385224,
      "grad_norm": 16.001510620117188,
      "learning_rate": 1.912928759894459e-05,
      "loss": 0.6316,
      "step": 3679
    },
    {
      "epoch": 2.4274406332453826,
      "grad_norm": 11.823726654052734,
      "learning_rate": 1.9107299912049255e-05,
      "loss": 0.7269,
      "step": 3680
    },
    {
      "epoch": 2.428100263852243,
      "grad_norm": 7.640746116638184,
      "learning_rate": 1.9085312225153915e-05,
      "loss": 0.4511,
      "step": 3681
    },
    {
      "epoch": 2.4287598944591027,
      "grad_norm": 7.515884876251221,
      "learning_rate": 1.9063324538258575e-05,
      "loss": 0.2154,
      "step": 3682
    },
    {
      "epoch": 2.429419525065963,
      "grad_norm": 4.81652307510376,
      "learning_rate": 1.9041336851363236e-05,
      "loss": 0.1258,
      "step": 3683
    },
    {
      "epoch": 2.430079155672823,
      "grad_norm": 5.840562343597412,
      "learning_rate": 1.90193491644679e-05,
      "loss": 0.1051,
      "step": 3684
    },
    {
      "epoch": 2.4307387862796834,
      "grad_norm": 6.559758186340332,
      "learning_rate": 1.899736147757256e-05,
      "loss": 0.7646,
      "step": 3685
    },
    {
      "epoch": 2.4313984168865437,
      "grad_norm": 6.396324634552002,
      "learning_rate": 1.8975373790677224e-05,
      "loss": 0.097,
      "step": 3686
    },
    {
      "epoch": 2.4320580474934035,
      "grad_norm": 4.783420085906982,
      "learning_rate": 1.8953386103781884e-05,
      "loss": 0.0882,
      "step": 3687
    },
    {
      "epoch": 2.4327176781002637,
      "grad_norm": 14.588360786437988,
      "learning_rate": 1.8931398416886544e-05,
      "loss": 0.3061,
      "step": 3688
    },
    {
      "epoch": 2.433377308707124,
      "grad_norm": 0.6480216979980469,
      "learning_rate": 1.8909410729991205e-05,
      "loss": 0.032,
      "step": 3689
    },
    {
      "epoch": 2.4340369393139842,
      "grad_norm": 37.11399841308594,
      "learning_rate": 1.888742304309587e-05,
      "loss": 0.8037,
      "step": 3690
    },
    {
      "epoch": 2.4346965699208445,
      "grad_norm": 9.734319686889648,
      "learning_rate": 1.886543535620053e-05,
      "loss": 0.4784,
      "step": 3691
    },
    {
      "epoch": 2.4353562005277043,
      "grad_norm": 1.2074265480041504,
      "learning_rate": 1.884344766930519e-05,
      "loss": 0.0426,
      "step": 3692
    },
    {
      "epoch": 2.4360158311345645,
      "grad_norm": 0.8189626336097717,
      "learning_rate": 1.882145998240985e-05,
      "loss": 0.0348,
      "step": 3693
    },
    {
      "epoch": 2.436675461741425,
      "grad_norm": 2.1426398754119873,
      "learning_rate": 1.879947229551451e-05,
      "loss": 0.0874,
      "step": 3694
    },
    {
      "epoch": 2.437335092348285,
      "grad_norm": 9.383867263793945,
      "learning_rate": 1.8777484608619174e-05,
      "loss": 0.6457,
      "step": 3695
    },
    {
      "epoch": 2.4379947229551453,
      "grad_norm": 8.784375190734863,
      "learning_rate": 1.8755496921723838e-05,
      "loss": 0.5174,
      "step": 3696
    },
    {
      "epoch": 2.438654353562005,
      "grad_norm": 6.020352363586426,
      "learning_rate": 1.8733509234828498e-05,
      "loss": 0.1352,
      "step": 3697
    },
    {
      "epoch": 2.4393139841688654,
      "grad_norm": 2.668316602706909,
      "learning_rate": 1.8711521547933158e-05,
      "loss": 0.1081,
      "step": 3698
    },
    {
      "epoch": 2.4399736147757256,
      "grad_norm": 0.7261943817138672,
      "learning_rate": 1.868953386103782e-05,
      "loss": 0.0458,
      "step": 3699
    },
    {
      "epoch": 2.440633245382586,
      "grad_norm": 1.496626615524292,
      "learning_rate": 1.866754617414248e-05,
      "loss": 0.0742,
      "step": 3700
    },
    {
      "epoch": 2.441292875989446,
      "grad_norm": 1.9717152118682861,
      "learning_rate": 1.8645558487247143e-05,
      "loss": 0.1421,
      "step": 3701
    },
    {
      "epoch": 2.441952506596306,
      "grad_norm": 1.578170657157898,
      "learning_rate": 1.8623570800351803e-05,
      "loss": 0.0775,
      "step": 3702
    },
    {
      "epoch": 2.442612137203166,
      "grad_norm": 2.730470657348633,
      "learning_rate": 1.8601583113456467e-05,
      "loss": 0.0648,
      "step": 3703
    },
    {
      "epoch": 2.4432717678100264,
      "grad_norm": 8.282419204711914,
      "learning_rate": 1.8579595426561127e-05,
      "loss": 0.8282,
      "step": 3704
    },
    {
      "epoch": 2.4439313984168867,
      "grad_norm": 1.526421308517456,
      "learning_rate": 1.8557607739665788e-05,
      "loss": 0.1082,
      "step": 3705
    },
    {
      "epoch": 2.444591029023747,
      "grad_norm": 1.0351957082748413,
      "learning_rate": 1.853562005277045e-05,
      "loss": 0.0449,
      "step": 3706
    },
    {
      "epoch": 2.4452506596306067,
      "grad_norm": 3.7524898052215576,
      "learning_rate": 1.8513632365875112e-05,
      "loss": 0.0913,
      "step": 3707
    },
    {
      "epoch": 2.445910290237467,
      "grad_norm": 2.0982320308685303,
      "learning_rate": 1.8491644678979772e-05,
      "loss": 0.0576,
      "step": 3708
    },
    {
      "epoch": 2.4465699208443272,
      "grad_norm": 4.357437610626221,
      "learning_rate": 1.8469656992084432e-05,
      "loss": 0.1529,
      "step": 3709
    },
    {
      "epoch": 2.4472295514511875,
      "grad_norm": 23.14301109313965,
      "learning_rate": 1.8447669305189093e-05,
      "loss": 0.6263,
      "step": 3710
    },
    {
      "epoch": 2.4478891820580477,
      "grad_norm": 2.3579819202423096,
      "learning_rate": 1.8425681618293757e-05,
      "loss": 0.1018,
      "step": 3711
    },
    {
      "epoch": 2.4485488126649075,
      "grad_norm": 3.3003950119018555,
      "learning_rate": 1.840369393139842e-05,
      "loss": 0.0854,
      "step": 3712
    },
    {
      "epoch": 2.449208443271768,
      "grad_norm": 1.0174081325531006,
      "learning_rate": 1.838170624450308e-05,
      "loss": 0.0596,
      "step": 3713
    },
    {
      "epoch": 2.449868073878628,
      "grad_norm": 4.522638320922852,
      "learning_rate": 1.835971855760774e-05,
      "loss": 0.1254,
      "step": 3714
    },
    {
      "epoch": 2.4505277044854883,
      "grad_norm": 11.311487197875977,
      "learning_rate": 1.83377308707124e-05,
      "loss": 0.7283,
      "step": 3715
    },
    {
      "epoch": 2.451187335092348,
      "grad_norm": 0.8394555449485779,
      "learning_rate": 1.8315743183817062e-05,
      "loss": 0.083,
      "step": 3716
    },
    {
      "epoch": 2.4518469656992083,
      "grad_norm": 5.165856838226318,
      "learning_rate": 1.8293755496921726e-05,
      "loss": 0.1388,
      "step": 3717
    },
    {
      "epoch": 2.4525065963060686,
      "grad_norm": 1.2386244535446167,
      "learning_rate": 1.8271767810026386e-05,
      "loss": 0.055,
      "step": 3718
    },
    {
      "epoch": 2.453166226912929,
      "grad_norm": 10.871417045593262,
      "learning_rate": 1.8249780123131046e-05,
      "loss": 0.2163,
      "step": 3719
    },
    {
      "epoch": 2.453825857519789,
      "grad_norm": 1.1209007501602173,
      "learning_rate": 1.8227792436235707e-05,
      "loss": 0.0528,
      "step": 3720
    },
    {
      "epoch": 2.454485488126649,
      "grad_norm": 18.121824264526367,
      "learning_rate": 1.820580474934037e-05,
      "loss": 0.4259,
      "step": 3721
    },
    {
      "epoch": 2.455145118733509,
      "grad_norm": 0.7035366892814636,
      "learning_rate": 1.8183817062445034e-05,
      "loss": 0.0525,
      "step": 3722
    },
    {
      "epoch": 2.4558047493403694,
      "grad_norm": 2.421344518661499,
      "learning_rate": 1.8161829375549695e-05,
      "loss": 0.0987,
      "step": 3723
    },
    {
      "epoch": 2.4564643799472297,
      "grad_norm": 1.2948837280273438,
      "learning_rate": 1.8139841688654355e-05,
      "loss": 0.1007,
      "step": 3724
    },
    {
      "epoch": 2.4571240105540895,
      "grad_norm": 1.2553619146347046,
      "learning_rate": 1.8117854001759015e-05,
      "loss": 0.0671,
      "step": 3725
    },
    {
      "epoch": 2.4577836411609497,
      "grad_norm": 1.4364094734191895,
      "learning_rate": 1.8095866314863676e-05,
      "loss": 0.0618,
      "step": 3726
    },
    {
      "epoch": 2.45844327176781,
      "grad_norm": 13.342262268066406,
      "learning_rate": 1.807387862796834e-05,
      "loss": 0.4431,
      "step": 3727
    },
    {
      "epoch": 2.45910290237467,
      "grad_norm": 0.485097199678421,
      "learning_rate": 1.8051890941073e-05,
      "loss": 0.0244,
      "step": 3728
    },
    {
      "epoch": 2.4597625329815305,
      "grad_norm": 0.7461362481117249,
      "learning_rate": 1.802990325417766e-05,
      "loss": 0.0354,
      "step": 3729
    },
    {
      "epoch": 2.4604221635883903,
      "grad_norm": 8.240901947021484,
      "learning_rate": 1.8007915567282324e-05,
      "loss": 0.1744,
      "step": 3730
    },
    {
      "epoch": 2.4610817941952505,
      "grad_norm": 7.971334934234619,
      "learning_rate": 1.7985927880386984e-05,
      "loss": 0.2537,
      "step": 3731
    },
    {
      "epoch": 2.461741424802111,
      "grad_norm": 12.914752006530762,
      "learning_rate": 1.7963940193491645e-05,
      "loss": 0.3925,
      "step": 3732
    },
    {
      "epoch": 2.462401055408971,
      "grad_norm": 1.565089464187622,
      "learning_rate": 1.794195250659631e-05,
      "loss": 0.0809,
      "step": 3733
    },
    {
      "epoch": 2.4630606860158313,
      "grad_norm": 0.9973152875900269,
      "learning_rate": 1.791996481970097e-05,
      "loss": 0.068,
      "step": 3734
    },
    {
      "epoch": 2.463720316622691,
      "grad_norm": 1.680809736251831,
      "learning_rate": 1.789797713280563e-05,
      "loss": 0.0759,
      "step": 3735
    },
    {
      "epoch": 2.4643799472295513,
      "grad_norm": 20.003002166748047,
      "learning_rate": 1.787598944591029e-05,
      "loss": 1.0766,
      "step": 3736
    },
    {
      "epoch": 2.4650395778364116,
      "grad_norm": 1.2293202877044678,
      "learning_rate": 1.7854001759014953e-05,
      "loss": 0.0836,
      "step": 3737
    },
    {
      "epoch": 2.465699208443272,
      "grad_norm": 1.1027460098266602,
      "learning_rate": 1.7832014072119614e-05,
      "loss": 0.0546,
      "step": 3738
    },
    {
      "epoch": 2.466358839050132,
      "grad_norm": 15.602781295776367,
      "learning_rate": 1.7810026385224277e-05,
      "loss": 0.2967,
      "step": 3739
    },
    {
      "epoch": 2.467018469656992,
      "grad_norm": 2.2019903659820557,
      "learning_rate": 1.7788038698328938e-05,
      "loss": 0.1374,
      "step": 3740
    },
    {
      "epoch": 2.467678100263852,
      "grad_norm": 6.2724690437316895,
      "learning_rate": 1.7766051011433598e-05,
      "loss": 0.1786,
      "step": 3741
    },
    {
      "epoch": 2.4683377308707124,
      "grad_norm": 3.3163869380950928,
      "learning_rate": 1.774406332453826e-05,
      "loss": 0.0697,
      "step": 3742
    },
    {
      "epoch": 2.4689973614775726,
      "grad_norm": 11.043417930603027,
      "learning_rate": 1.7722075637642922e-05,
      "loss": 0.6675,
      "step": 3743
    },
    {
      "epoch": 2.469656992084433,
      "grad_norm": 14.216634750366211,
      "learning_rate": 1.7700087950747583e-05,
      "loss": 0.7956,
      "step": 3744
    },
    {
      "epoch": 2.4703166226912927,
      "grad_norm": 0.8984125852584839,
      "learning_rate": 1.7678100263852243e-05,
      "loss": 0.0394,
      "step": 3745
    },
    {
      "epoch": 2.470976253298153,
      "grad_norm": 1.012576699256897,
      "learning_rate": 1.7656112576956903e-05,
      "loss": 0.0495,
      "step": 3746
    },
    {
      "epoch": 2.471635883905013,
      "grad_norm": 1.7513302564620972,
      "learning_rate": 1.7634124890061564e-05,
      "loss": 0.1192,
      "step": 3747
    },
    {
      "epoch": 2.4722955145118735,
      "grad_norm": 8.197946548461914,
      "learning_rate": 1.7612137203166228e-05,
      "loss": 0.15,
      "step": 3748
    },
    {
      "epoch": 2.4729551451187337,
      "grad_norm": 0.6581156253814697,
      "learning_rate": 1.759014951627089e-05,
      "loss": 0.0335,
      "step": 3749
    },
    {
      "epoch": 2.4736147757255935,
      "grad_norm": 19.44062614440918,
      "learning_rate": 1.756816182937555e-05,
      "loss": 0.2645,
      "step": 3750
    },
    {
      "epoch": 2.4742744063324538,
      "grad_norm": 1.6490375995635986,
      "learning_rate": 1.7546174142480212e-05,
      "loss": 0.0612,
      "step": 3751
    },
    {
      "epoch": 2.474934036939314,
      "grad_norm": 11.987521171569824,
      "learning_rate": 1.7524186455584872e-05,
      "loss": 0.4091,
      "step": 3752
    },
    {
      "epoch": 2.4755936675461743,
      "grad_norm": 0.5651598572731018,
      "learning_rate": 1.7502198768689533e-05,
      "loss": 0.0373,
      "step": 3753
    },
    {
      "epoch": 2.4762532981530345,
      "grad_norm": 20.348690032958984,
      "learning_rate": 1.7480211081794197e-05,
      "loss": 0.6573,
      "step": 3754
    },
    {
      "epoch": 2.4769129287598943,
      "grad_norm": 5.228353977203369,
      "learning_rate": 1.7458223394898857e-05,
      "loss": 0.0683,
      "step": 3755
    },
    {
      "epoch": 2.4775725593667546,
      "grad_norm": 1.511484980583191,
      "learning_rate": 1.7436235708003517e-05,
      "loss": 0.0604,
      "step": 3756
    },
    {
      "epoch": 2.478232189973615,
      "grad_norm": 2.194594144821167,
      "learning_rate": 1.741424802110818e-05,
      "loss": 0.1021,
      "step": 3757
    },
    {
      "epoch": 2.478891820580475,
      "grad_norm": 1.3008419275283813,
      "learning_rate": 1.739226033421284e-05,
      "loss": 0.096,
      "step": 3758
    },
    {
      "epoch": 2.4795514511873353,
      "grad_norm": 12.99763011932373,
      "learning_rate": 1.7370272647317505e-05,
      "loss": 0.2523,
      "step": 3759
    },
    {
      "epoch": 2.480211081794195,
      "grad_norm": 1.7857015132904053,
      "learning_rate": 1.7348284960422166e-05,
      "loss": 0.0715,
      "step": 3760
    },
    {
      "epoch": 2.4808707124010554,
      "grad_norm": 1.2222164869308472,
      "learning_rate": 1.7326297273526826e-05,
      "loss": 0.0539,
      "step": 3761
    },
    {
      "epoch": 2.4815303430079156,
      "grad_norm": 2.99356746673584,
      "learning_rate": 1.7304309586631486e-05,
      "loss": 0.0663,
      "step": 3762
    },
    {
      "epoch": 2.482189973614776,
      "grad_norm": 0.8564019203186035,
      "learning_rate": 1.7282321899736147e-05,
      "loss": 0.0597,
      "step": 3763
    },
    {
      "epoch": 2.4828496042216357,
      "grad_norm": 1.7053711414337158,
      "learning_rate": 1.726033421284081e-05,
      "loss": 0.0927,
      "step": 3764
    },
    {
      "epoch": 2.483509234828496,
      "grad_norm": 4.104137897491455,
      "learning_rate": 1.723834652594547e-05,
      "loss": 0.106,
      "step": 3765
    },
    {
      "epoch": 2.484168865435356,
      "grad_norm": 4.244579315185547,
      "learning_rate": 1.7216358839050135e-05,
      "loss": 0.0562,
      "step": 3766
    },
    {
      "epoch": 2.4848284960422165,
      "grad_norm": 0.8834826350212097,
      "learning_rate": 1.7194371152154795e-05,
      "loss": 0.0591,
      "step": 3767
    },
    {
      "epoch": 2.4854881266490767,
      "grad_norm": 21.3858585357666,
      "learning_rate": 1.7172383465259455e-05,
      "loss": 0.9013,
      "step": 3768
    },
    {
      "epoch": 2.4861477572559365,
      "grad_norm": 1.6258186101913452,
      "learning_rate": 1.7150395778364116e-05,
      "loss": 0.052,
      "step": 3769
    },
    {
      "epoch": 2.4868073878627968,
      "grad_norm": 1.7561243772506714,
      "learning_rate": 1.712840809146878e-05,
      "loss": 0.0875,
      "step": 3770
    },
    {
      "epoch": 2.487467018469657,
      "grad_norm": 0.6312912702560425,
      "learning_rate": 1.710642040457344e-05,
      "loss": 0.0301,
      "step": 3771
    },
    {
      "epoch": 2.4881266490765173,
      "grad_norm": 1.2492003440856934,
      "learning_rate": 1.70844327176781e-05,
      "loss": 0.0386,
      "step": 3772
    },
    {
      "epoch": 2.488786279683377,
      "grad_norm": 0.3934198319911957,
      "learning_rate": 1.706244503078276e-05,
      "loss": 0.0314,
      "step": 3773
    },
    {
      "epoch": 2.4894459102902373,
      "grad_norm": 8.375900268554688,
      "learning_rate": 1.7040457343887424e-05,
      "loss": 0.1671,
      "step": 3774
    },
    {
      "epoch": 2.4901055408970976,
      "grad_norm": 0.8870134949684143,
      "learning_rate": 1.7018469656992088e-05,
      "loss": 0.0768,
      "step": 3775
    },
    {
      "epoch": 2.490765171503958,
      "grad_norm": 0.5335507392883301,
      "learning_rate": 1.699648197009675e-05,
      "loss": 0.0268,
      "step": 3776
    },
    {
      "epoch": 2.491424802110818,
      "grad_norm": 1.3282201290130615,
      "learning_rate": 1.697449428320141e-05,
      "loss": 0.0384,
      "step": 3777
    },
    {
      "epoch": 2.492084432717678,
      "grad_norm": 11.044709205627441,
      "learning_rate": 1.695250659630607e-05,
      "loss": 0.4398,
      "step": 3778
    },
    {
      "epoch": 2.492744063324538,
      "grad_norm": 0.959211528301239,
      "learning_rate": 1.693051890941073e-05,
      "loss": 0.0497,
      "step": 3779
    },
    {
      "epoch": 2.4934036939313984,
      "grad_norm": 3.5241901874542236,
      "learning_rate": 1.6908531222515393e-05,
      "loss": 0.0873,
      "step": 3780
    },
    {
      "epoch": 2.4940633245382586,
      "grad_norm": 13.095247268676758,
      "learning_rate": 1.6886543535620054e-05,
      "loss": 0.8095,
      "step": 3781
    },
    {
      "epoch": 2.494722955145119,
      "grad_norm": 2.556575059890747,
      "learning_rate": 1.6864555848724714e-05,
      "loss": 0.0559,
      "step": 3782
    },
    {
      "epoch": 2.4953825857519787,
      "grad_norm": 10.839154243469238,
      "learning_rate": 1.6842568161829374e-05,
      "loss": 0.5654,
      "step": 3783
    },
    {
      "epoch": 2.496042216358839,
      "grad_norm": 0.764956533908844,
      "learning_rate": 1.6820580474934038e-05,
      "loss": 0.051,
      "step": 3784
    },
    {
      "epoch": 2.496701846965699,
      "grad_norm": 1.319122552871704,
      "learning_rate": 1.67985927880387e-05,
      "loss": 0.0435,
      "step": 3785
    },
    {
      "epoch": 2.4973614775725594,
      "grad_norm": 0.6431829929351807,
      "learning_rate": 1.6776605101143362e-05,
      "loss": 0.0345,
      "step": 3786
    },
    {
      "epoch": 2.4980211081794197,
      "grad_norm": 0.746581494808197,
      "learning_rate": 1.6754617414248023e-05,
      "loss": 0.0402,
      "step": 3787
    },
    {
      "epoch": 2.4986807387862795,
      "grad_norm": 8.887600898742676,
      "learning_rate": 1.6732629727352683e-05,
      "loss": 0.1926,
      "step": 3788
    },
    {
      "epoch": 2.4993403693931397,
      "grad_norm": 10.0525484085083,
      "learning_rate": 1.6710642040457343e-05,
      "loss": 0.1789,
      "step": 3789
    },
    {
      "epoch": 2.5,
      "grad_norm": 7.768185138702393,
      "learning_rate": 1.6688654353562007e-05,
      "loss": 0.1381,
      "step": 3790
    },
    {
      "epoch": 2.5006596306068603,
      "grad_norm": 4.38260555267334,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.0586,
      "step": 3791
    },
    {
      "epoch": 2.5013192612137205,
      "grad_norm": 1.7561336755752563,
      "learning_rate": 1.6644678979771328e-05,
      "loss": 0.1063,
      "step": 3792
    },
    {
      "epoch": 2.5019788918205803,
      "grad_norm": 0.9146051406860352,
      "learning_rate": 1.662269129287599e-05,
      "loss": 0.0701,
      "step": 3793
    },
    {
      "epoch": 2.5026385224274406,
      "grad_norm": 11.122920989990234,
      "learning_rate": 1.6600703605980652e-05,
      "loss": 0.3246,
      "step": 3794
    },
    {
      "epoch": 2.503298153034301,
      "grad_norm": 0.5619927048683167,
      "learning_rate": 1.6578715919085312e-05,
      "loss": 0.032,
      "step": 3795
    },
    {
      "epoch": 2.503957783641161,
      "grad_norm": 23.679527282714844,
      "learning_rate": 1.6556728232189976e-05,
      "loss": 0.2664,
      "step": 3796
    },
    {
      "epoch": 2.5046174142480213,
      "grad_norm": 3.0884342193603516,
      "learning_rate": 1.6534740545294636e-05,
      "loss": 0.0485,
      "step": 3797
    },
    {
      "epoch": 2.505277044854881,
      "grad_norm": 0.5360884666442871,
      "learning_rate": 1.6512752858399297e-05,
      "loss": 0.0134,
      "step": 3798
    },
    {
      "epoch": 2.5059366754617414,
      "grad_norm": 1.3528718948364258,
      "learning_rate": 1.6490765171503957e-05,
      "loss": 0.0491,
      "step": 3799
    },
    {
      "epoch": 2.5065963060686016,
      "grad_norm": 11.425946235656738,
      "learning_rate": 1.6468777484608618e-05,
      "loss": 0.5906,
      "step": 3800
    },
    {
      "epoch": 2.507255936675462,
      "grad_norm": 0.8356714844703674,
      "learning_rate": 1.644678979771328e-05,
      "loss": 0.0498,
      "step": 3801
    },
    {
      "epoch": 2.507915567282322,
      "grad_norm": 5.392834186553955,
      "learning_rate": 1.6424802110817945e-05,
      "loss": 0.1545,
      "step": 3802
    },
    {
      "epoch": 2.508575197889182,
      "grad_norm": 10.570326805114746,
      "learning_rate": 1.6402814423922605e-05,
      "loss": 0.1997,
      "step": 3803
    },
    {
      "epoch": 2.509234828496042,
      "grad_norm": 14.481283187866211,
      "learning_rate": 1.6380826737027266e-05,
      "loss": 0.2103,
      "step": 3804
    },
    {
      "epoch": 2.5098944591029024,
      "grad_norm": 6.884807586669922,
      "learning_rate": 1.6358839050131926e-05,
      "loss": 0.1284,
      "step": 3805
    },
    {
      "epoch": 2.5105540897097627,
      "grad_norm": 36.58942794799805,
      "learning_rate": 1.633685136323659e-05,
      "loss": 0.7166,
      "step": 3806
    },
    {
      "epoch": 2.511213720316623,
      "grad_norm": 8.6459379196167,
      "learning_rate": 1.631486367634125e-05,
      "loss": 0.1597,
      "step": 3807
    },
    {
      "epoch": 2.5118733509234827,
      "grad_norm": 9.874015808105469,
      "learning_rate": 1.629287598944591e-05,
      "loss": 0.1799,
      "step": 3808
    },
    {
      "epoch": 2.512532981530343,
      "grad_norm": 4.511072635650635,
      "learning_rate": 1.627088830255057e-05,
      "loss": 0.0621,
      "step": 3809
    },
    {
      "epoch": 2.5131926121372032,
      "grad_norm": 0.9848917722702026,
      "learning_rate": 1.624890061565523e-05,
      "loss": 0.039,
      "step": 3810
    },
    {
      "epoch": 2.513852242744063,
      "grad_norm": 0.5788114666938782,
      "learning_rate": 1.6226912928759895e-05,
      "loss": 0.0421,
      "step": 3811
    },
    {
      "epoch": 2.5145118733509237,
      "grad_norm": 1.0260601043701172,
      "learning_rate": 1.620492524186456e-05,
      "loss": 0.0686,
      "step": 3812
    },
    {
      "epoch": 2.5151715039577835,
      "grad_norm": 22.38072967529297,
      "learning_rate": 1.618293755496922e-05,
      "loss": 0.7262,
      "step": 3813
    },
    {
      "epoch": 2.515831134564644,
      "grad_norm": 0.521899938583374,
      "learning_rate": 1.616094986807388e-05,
      "loss": 0.0271,
      "step": 3814
    },
    {
      "epoch": 2.516490765171504,
      "grad_norm": 1.4767794609069824,
      "learning_rate": 1.613896218117854e-05,
      "loss": 0.0889,
      "step": 3815
    },
    {
      "epoch": 2.517150395778364,
      "grad_norm": 0.8375012874603271,
      "learning_rate": 1.61169744942832e-05,
      "loss": 0.0512,
      "step": 3816
    },
    {
      "epoch": 2.517810026385224,
      "grad_norm": 0.4416848421096802,
      "learning_rate": 1.6094986807387864e-05,
      "loss": 0.0246,
      "step": 3817
    },
    {
      "epoch": 2.5184696569920844,
      "grad_norm": 0.8881335258483887,
      "learning_rate": 1.6072999120492525e-05,
      "loss": 0.0672,
      "step": 3818
    },
    {
      "epoch": 2.5191292875989446,
      "grad_norm": 1.047564148902893,
      "learning_rate": 1.6051011433597185e-05,
      "loss": 0.0446,
      "step": 3819
    },
    {
      "epoch": 2.519788918205805,
      "grad_norm": 1.2894784212112427,
      "learning_rate": 1.602902374670185e-05,
      "loss": 0.0976,
      "step": 3820
    },
    {
      "epoch": 2.5204485488126647,
      "grad_norm": 0.8652489185333252,
      "learning_rate": 1.600703605980651e-05,
      "loss": 0.0575,
      "step": 3821
    },
    {
      "epoch": 2.521108179419525,
      "grad_norm": 5.145610809326172,
      "learning_rate": 1.598504837291117e-05,
      "loss": 0.079,
      "step": 3822
    },
    {
      "epoch": 2.521767810026385,
      "grad_norm": 0.6456236243247986,
      "learning_rate": 1.5963060686015833e-05,
      "loss": 0.0439,
      "step": 3823
    },
    {
      "epoch": 2.5224274406332454,
      "grad_norm": 3.3448832035064697,
      "learning_rate": 1.5941072999120494e-05,
      "loss": 0.0886,
      "step": 3824
    },
    {
      "epoch": 2.5230870712401057,
      "grad_norm": 9.21774959564209,
      "learning_rate": 1.5919085312225154e-05,
      "loss": 0.6723,
      "step": 3825
    },
    {
      "epoch": 2.5237467018469655,
      "grad_norm": 12.463798522949219,
      "learning_rate": 1.5897097625329814e-05,
      "loss": 0.6988,
      "step": 3826
    },
    {
      "epoch": 2.5244063324538257,
      "grad_norm": 0.9482011795043945,
      "learning_rate": 1.5875109938434478e-05,
      "loss": 0.0331,
      "step": 3827
    },
    {
      "epoch": 2.525065963060686,
      "grad_norm": 14.0438871383667,
      "learning_rate": 1.585312225153914e-05,
      "loss": 0.4938,
      "step": 3828
    },
    {
      "epoch": 2.5257255936675462,
      "grad_norm": 0.8080067038536072,
      "learning_rate": 1.5831134564643802e-05,
      "loss": 0.0624,
      "step": 3829
    },
    {
      "epoch": 2.5263852242744065,
      "grad_norm": 0.6780864596366882,
      "learning_rate": 1.5809146877748463e-05,
      "loss": 0.0373,
      "step": 3830
    },
    {
      "epoch": 2.5270448548812663,
      "grad_norm": 0.7676246166229248,
      "learning_rate": 1.5787159190853123e-05,
      "loss": 0.0388,
      "step": 3831
    },
    {
      "epoch": 2.5277044854881265,
      "grad_norm": 0.5833998322486877,
      "learning_rate": 1.5765171503957783e-05,
      "loss": 0.0449,
      "step": 3832
    },
    {
      "epoch": 2.528364116094987,
      "grad_norm": 0.8164028525352478,
      "learning_rate": 1.5743183817062447e-05,
      "loss": 0.0305,
      "step": 3833
    },
    {
      "epoch": 2.529023746701847,
      "grad_norm": 0.5936851501464844,
      "learning_rate": 1.5721196130167107e-05,
      "loss": 0.0215,
      "step": 3834
    },
    {
      "epoch": 2.5296833773087073,
      "grad_norm": 3.0739762783050537,
      "learning_rate": 1.5699208443271768e-05,
      "loss": 0.0693,
      "step": 3835
    },
    {
      "epoch": 2.530343007915567,
      "grad_norm": 4.3958282470703125,
      "learning_rate": 1.5677220756376428e-05,
      "loss": 0.0728,
      "step": 3836
    },
    {
      "epoch": 2.5310026385224274,
      "grad_norm": 11.431811332702637,
      "learning_rate": 1.565523306948109e-05,
      "loss": 0.7468,
      "step": 3837
    },
    {
      "epoch": 2.5316622691292876,
      "grad_norm": 1.3259891271591187,
      "learning_rate": 1.5633245382585752e-05,
      "loss": 0.0791,
      "step": 3838
    },
    {
      "epoch": 2.532321899736148,
      "grad_norm": 1.1729984283447266,
      "learning_rate": 1.5611257695690416e-05,
      "loss": 0.0701,
      "step": 3839
    },
    {
      "epoch": 2.532981530343008,
      "grad_norm": 0.7687910795211792,
      "learning_rate": 1.5589270008795076e-05,
      "loss": 0.0539,
      "step": 3840
    },
    {
      "epoch": 2.533641160949868,
      "grad_norm": 1.455480933189392,
      "learning_rate": 1.5567282321899737e-05,
      "loss": 0.0557,
      "step": 3841
    },
    {
      "epoch": 2.534300791556728,
      "grad_norm": 1.7015559673309326,
      "learning_rate": 1.5545294635004397e-05,
      "loss": 0.0597,
      "step": 3842
    },
    {
      "epoch": 2.5349604221635884,
      "grad_norm": 0.899806559085846,
      "learning_rate": 1.552330694810906e-05,
      "loss": 0.052,
      "step": 3843
    },
    {
      "epoch": 2.5356200527704487,
      "grad_norm": 11.078592300415039,
      "learning_rate": 1.550131926121372e-05,
      "loss": 0.4982,
      "step": 3844
    },
    {
      "epoch": 2.536279683377309,
      "grad_norm": 7.264529228210449,
      "learning_rate": 1.547933157431838e-05,
      "loss": 0.0955,
      "step": 3845
    },
    {
      "epoch": 2.5369393139841687,
      "grad_norm": 10.09117603302002,
      "learning_rate": 1.5457343887423042e-05,
      "loss": 1.3086,
      "step": 3846
    },
    {
      "epoch": 2.537598944591029,
      "grad_norm": 0.9937602877616882,
      "learning_rate": 1.5435356200527706e-05,
      "loss": 0.0201,
      "step": 3847
    },
    {
      "epoch": 2.538258575197889,
      "grad_norm": 2.402215003967285,
      "learning_rate": 1.5413368513632366e-05,
      "loss": 0.0696,
      "step": 3848
    },
    {
      "epoch": 2.5389182058047495,
      "grad_norm": 14.129446983337402,
      "learning_rate": 1.539138082673703e-05,
      "loss": 0.2715,
      "step": 3849
    },
    {
      "epoch": 2.5395778364116097,
      "grad_norm": 1.1824995279312134,
      "learning_rate": 1.536939313984169e-05,
      "loss": 0.0783,
      "step": 3850
    },
    {
      "epoch": 2.5402374670184695,
      "grad_norm": 0.3648856580257416,
      "learning_rate": 1.534740545294635e-05,
      "loss": 0.02,
      "step": 3851
    },
    {
      "epoch": 2.54089709762533,
      "grad_norm": 0.46336907148361206,
      "learning_rate": 1.532541776605101e-05,
      "loss": 0.0318,
      "step": 3852
    },
    {
      "epoch": 2.54155672823219,
      "grad_norm": 2.889719009399414,
      "learning_rate": 1.530343007915567e-05,
      "loss": 0.0446,
      "step": 3853
    },
    {
      "epoch": 2.5422163588390503,
      "grad_norm": 0.9582703709602356,
      "learning_rate": 1.5281442392260335e-05,
      "loss": 0.0414,
      "step": 3854
    },
    {
      "epoch": 2.5428759894459105,
      "grad_norm": 8.86095142364502,
      "learning_rate": 1.5259454705364995e-05,
      "loss": 0.1467,
      "step": 3855
    },
    {
      "epoch": 2.5435356200527703,
      "grad_norm": 9.29249095916748,
      "learning_rate": 1.523746701846966e-05,
      "loss": 0.1953,
      "step": 3856
    },
    {
      "epoch": 2.5441952506596306,
      "grad_norm": 22.151281356811523,
      "learning_rate": 1.521547933157432e-05,
      "loss": 0.3931,
      "step": 3857
    },
    {
      "epoch": 2.544854881266491,
      "grad_norm": 0.795466423034668,
      "learning_rate": 1.5193491644678982e-05,
      "loss": 0.0366,
      "step": 3858
    },
    {
      "epoch": 2.5455145118733506,
      "grad_norm": 8.730094909667969,
      "learning_rate": 1.5171503957783642e-05,
      "loss": 0.2601,
      "step": 3859
    },
    {
      "epoch": 2.5461741424802113,
      "grad_norm": 0.4971933960914612,
      "learning_rate": 1.5149516270888302e-05,
      "loss": 0.0456,
      "step": 3860
    },
    {
      "epoch": 2.546833773087071,
      "grad_norm": 0.8344164490699768,
      "learning_rate": 1.5127528583992964e-05,
      "loss": 0.0247,
      "step": 3861
    },
    {
      "epoch": 2.5474934036939314,
      "grad_norm": 8.58495044708252,
      "learning_rate": 1.5105540897097625e-05,
      "loss": 0.3369,
      "step": 3862
    },
    {
      "epoch": 2.5481530343007917,
      "grad_norm": 1.059830665588379,
      "learning_rate": 1.5083553210202287e-05,
      "loss": 0.0247,
      "step": 3863
    },
    {
      "epoch": 2.5488126649076515,
      "grad_norm": 8.485629081726074,
      "learning_rate": 1.5061565523306947e-05,
      "loss": 0.1095,
      "step": 3864
    },
    {
      "epoch": 2.5494722955145117,
      "grad_norm": 21.017629623413086,
      "learning_rate": 1.5039577836411611e-05,
      "loss": 1.1264,
      "step": 3865
    },
    {
      "epoch": 2.550131926121372,
      "grad_norm": 0.43410027027130127,
      "learning_rate": 1.5017590149516273e-05,
      "loss": 0.0155,
      "step": 3866
    },
    {
      "epoch": 2.550791556728232,
      "grad_norm": 1.9046733379364014,
      "learning_rate": 1.4995602462620933e-05,
      "loss": 0.0643,
      "step": 3867
    },
    {
      "epoch": 2.5514511873350925,
      "grad_norm": 0.908599317073822,
      "learning_rate": 1.4973614775725594e-05,
      "loss": 0.0566,
      "step": 3868
    },
    {
      "epoch": 2.5521108179419523,
      "grad_norm": 1.174998164176941,
      "learning_rate": 1.4951627088830256e-05,
      "loss": 0.0355,
      "step": 3869
    },
    {
      "epoch": 2.5527704485488125,
      "grad_norm": 0.6768831014633179,
      "learning_rate": 1.4929639401934916e-05,
      "loss": 0.0303,
      "step": 3870
    },
    {
      "epoch": 2.5534300791556728,
      "grad_norm": 7.554903984069824,
      "learning_rate": 1.4907651715039578e-05,
      "loss": 0.1744,
      "step": 3871
    },
    {
      "epoch": 2.554089709762533,
      "grad_norm": 1.0317261219024658,
      "learning_rate": 1.4885664028144239e-05,
      "loss": 0.0832,
      "step": 3872
    },
    {
      "epoch": 2.5547493403693933,
      "grad_norm": 1.6233985424041748,
      "learning_rate": 1.48636763412489e-05,
      "loss": 0.0676,
      "step": 3873
    },
    {
      "epoch": 2.555408970976253,
      "grad_norm": 19.529979705810547,
      "learning_rate": 1.4841688654353565e-05,
      "loss": 0.8235,
      "step": 3874
    },
    {
      "epoch": 2.5560686015831133,
      "grad_norm": 2.044469118118286,
      "learning_rate": 1.4819700967458225e-05,
      "loss": 0.1082,
      "step": 3875
    },
    {
      "epoch": 2.5567282321899736,
      "grad_norm": 1.1964831352233887,
      "learning_rate": 1.4797713280562885e-05,
      "loss": 0.0549,
      "step": 3876
    },
    {
      "epoch": 2.557387862796834,
      "grad_norm": 0.8030168414115906,
      "learning_rate": 1.4775725593667547e-05,
      "loss": 0.0713,
      "step": 3877
    },
    {
      "epoch": 2.558047493403694,
      "grad_norm": 12.092612266540527,
      "learning_rate": 1.4753737906772208e-05,
      "loss": 1.0325,
      "step": 3878
    },
    {
      "epoch": 2.558707124010554,
      "grad_norm": 0.627350389957428,
      "learning_rate": 1.473175021987687e-05,
      "loss": 0.0409,
      "step": 3879
    },
    {
      "epoch": 2.559366754617414,
      "grad_norm": 4.373517990112305,
      "learning_rate": 1.470976253298153e-05,
      "loss": 0.0731,
      "step": 3880
    },
    {
      "epoch": 2.5600263852242744,
      "grad_norm": 1.132715106010437,
      "learning_rate": 1.4687774846086192e-05,
      "loss": 0.0771,
      "step": 3881
    },
    {
      "epoch": 2.5606860158311346,
      "grad_norm": 0.5658901333808899,
      "learning_rate": 1.4665787159190853e-05,
      "loss": 0.0281,
      "step": 3882
    },
    {
      "epoch": 2.561345646437995,
      "grad_norm": 1.8028056621551514,
      "learning_rate": 1.4643799472295516e-05,
      "loss": 0.0772,
      "step": 3883
    },
    {
      "epoch": 2.5620052770448547,
      "grad_norm": 0.9273175597190857,
      "learning_rate": 1.4621811785400177e-05,
      "loss": 0.0374,
      "step": 3884
    },
    {
      "epoch": 2.562664907651715,
      "grad_norm": 3.945152759552002,
      "learning_rate": 1.4599824098504839e-05,
      "loss": 0.0914,
      "step": 3885
    },
    {
      "epoch": 2.563324538258575,
      "grad_norm": 14.537946701049805,
      "learning_rate": 1.4577836411609499e-05,
      "loss": 0.408,
      "step": 3886
    },
    {
      "epoch": 2.5639841688654355,
      "grad_norm": 0.4603351354598999,
      "learning_rate": 1.4555848724714161e-05,
      "loss": 0.0251,
      "step": 3887
    },
    {
      "epoch": 2.5646437994722957,
      "grad_norm": 11.275094985961914,
      "learning_rate": 1.4533861037818822e-05,
      "loss": 0.7773,
      "step": 3888
    },
    {
      "epoch": 2.5653034300791555,
      "grad_norm": 20.434492111206055,
      "learning_rate": 1.4511873350923482e-05,
      "loss": 0.7507,
      "step": 3889
    },
    {
      "epoch": 2.5659630606860158,
      "grad_norm": 1.2453399896621704,
      "learning_rate": 1.4489885664028144e-05,
      "loss": 0.0477,
      "step": 3890
    },
    {
      "epoch": 2.566622691292876,
      "grad_norm": 1.5764042139053345,
      "learning_rate": 1.4467897977132808e-05,
      "loss": 0.0584,
      "step": 3891
    },
    {
      "epoch": 2.5672823218997363,
      "grad_norm": 1.1579335927963257,
      "learning_rate": 1.4445910290237468e-05,
      "loss": 0.0664,
      "step": 3892
    },
    {
      "epoch": 2.5679419525065965,
      "grad_norm": 10.467266082763672,
      "learning_rate": 1.442392260334213e-05,
      "loss": 0.2326,
      "step": 3893
    },
    {
      "epoch": 2.5686015831134563,
      "grad_norm": 13.314508438110352,
      "learning_rate": 1.440193491644679e-05,
      "loss": 0.4157,
      "step": 3894
    },
    {
      "epoch": 2.5692612137203166,
      "grad_norm": 2.271235704421997,
      "learning_rate": 1.4379947229551453e-05,
      "loss": 0.0424,
      "step": 3895
    },
    {
      "epoch": 2.569920844327177,
      "grad_norm": 7.280887126922607,
      "learning_rate": 1.4357959542656113e-05,
      "loss": 0.143,
      "step": 3896
    },
    {
      "epoch": 2.570580474934037,
      "grad_norm": 1.5325123071670532,
      "learning_rate": 1.4335971855760773e-05,
      "loss": 0.0619,
      "step": 3897
    },
    {
      "epoch": 2.5712401055408973,
      "grad_norm": 8.808189392089844,
      "learning_rate": 1.4313984168865435e-05,
      "loss": 0.6325,
      "step": 3898
    },
    {
      "epoch": 2.571899736147757,
      "grad_norm": 0.5473352670669556,
      "learning_rate": 1.4291996481970096e-05,
      "loss": 0.0349,
      "step": 3899
    },
    {
      "epoch": 2.5725593667546174,
      "grad_norm": 11.077547073364258,
      "learning_rate": 1.427000879507476e-05,
      "loss": 0.1981,
      "step": 3900
    },
    {
      "epoch": 2.5732189973614776,
      "grad_norm": 47.3826904296875,
      "learning_rate": 1.4248021108179422e-05,
      "loss": 1.1776,
      "step": 3901
    },
    {
      "epoch": 2.573878627968338,
      "grad_norm": 0.6086148619651794,
      "learning_rate": 1.4226033421284082e-05,
      "loss": 0.0356,
      "step": 3902
    },
    {
      "epoch": 2.574538258575198,
      "grad_norm": 1.1805998086929321,
      "learning_rate": 1.4204045734388744e-05,
      "loss": 0.054,
      "step": 3903
    },
    {
      "epoch": 2.575197889182058,
      "grad_norm": 18.658828735351562,
      "learning_rate": 1.4182058047493404e-05,
      "loss": 0.3482,
      "step": 3904
    },
    {
      "epoch": 2.575857519788918,
      "grad_norm": 8.956317901611328,
      "learning_rate": 1.4160070360598065e-05,
      "loss": 0.1932,
      "step": 3905
    },
    {
      "epoch": 2.5765171503957784,
      "grad_norm": 0.9997803568840027,
      "learning_rate": 1.4138082673702727e-05,
      "loss": 0.0457,
      "step": 3906
    },
    {
      "epoch": 2.5771767810026383,
      "grad_norm": 4.055206298828125,
      "learning_rate": 1.4116094986807387e-05,
      "loss": 0.1279,
      "step": 3907
    },
    {
      "epoch": 2.577836411609499,
      "grad_norm": 0.5147486925125122,
      "learning_rate": 1.409410729991205e-05,
      "loss": 0.0295,
      "step": 3908
    },
    {
      "epoch": 2.5784960422163588,
      "grad_norm": 3.645068883895874,
      "learning_rate": 1.4072119613016713e-05,
      "loss": 0.0886,
      "step": 3909
    },
    {
      "epoch": 2.579155672823219,
      "grad_norm": 0.9970412254333496,
      "learning_rate": 1.4050131926121373e-05,
      "loss": 0.0485,
      "step": 3910
    },
    {
      "epoch": 2.5798153034300793,
      "grad_norm": 0.7232513427734375,
      "learning_rate": 1.4028144239226035e-05,
      "loss": 0.0307,
      "step": 3911
    },
    {
      "epoch": 2.580474934036939,
      "grad_norm": 1.2599631547927856,
      "learning_rate": 1.4006156552330696e-05,
      "loss": 0.0452,
      "step": 3912
    },
    {
      "epoch": 2.5811345646437993,
      "grad_norm": 11.82790470123291,
      "learning_rate": 1.3984168865435356e-05,
      "loss": 0.8652,
      "step": 3913
    },
    {
      "epoch": 2.5817941952506596,
      "grad_norm": 17.930374145507812,
      "learning_rate": 1.3962181178540018e-05,
      "loss": 0.4541,
      "step": 3914
    },
    {
      "epoch": 2.58245382585752,
      "grad_norm": 0.8837458491325378,
      "learning_rate": 1.3940193491644679e-05,
      "loss": 0.0594,
      "step": 3915
    },
    {
      "epoch": 2.58311345646438,
      "grad_norm": 0.7497588992118835,
      "learning_rate": 1.391820580474934e-05,
      "loss": 0.0235,
      "step": 3916
    },
    {
      "epoch": 2.58377308707124,
      "grad_norm": 0.5477132201194763,
      "learning_rate": 1.3896218117854001e-05,
      "loss": 0.0463,
      "step": 3917
    },
    {
      "epoch": 2.5844327176781,
      "grad_norm": 16.98092269897461,
      "learning_rate": 1.3874230430958665e-05,
      "loss": 0.5215,
      "step": 3918
    },
    {
      "epoch": 2.5850923482849604,
      "grad_norm": 0.7474022507667542,
      "learning_rate": 1.3852242744063327e-05,
      "loss": 0.0241,
      "step": 3919
    },
    {
      "epoch": 2.5857519788918206,
      "grad_norm": 10.270111083984375,
      "learning_rate": 1.3830255057167987e-05,
      "loss": 0.3397,
      "step": 3920
    },
    {
      "epoch": 2.586411609498681,
      "grad_norm": 5.065345764160156,
      "learning_rate": 1.3808267370272648e-05,
      "loss": 0.0766,
      "step": 3921
    },
    {
      "epoch": 2.5870712401055407,
      "grad_norm": 0.6614163517951965,
      "learning_rate": 1.378627968337731e-05,
      "loss": 0.026,
      "step": 3922
    },
    {
      "epoch": 2.587730870712401,
      "grad_norm": 11.70622730255127,
      "learning_rate": 1.376429199648197e-05,
      "loss": 0.3041,
      "step": 3923
    },
    {
      "epoch": 2.588390501319261,
      "grad_norm": 1.765916347503662,
      "learning_rate": 1.3742304309586632e-05,
      "loss": 0.0678,
      "step": 3924
    },
    {
      "epoch": 2.5890501319261214,
      "grad_norm": 9.403667449951172,
      "learning_rate": 1.3720316622691292e-05,
      "loss": 0.5659,
      "step": 3925
    },
    {
      "epoch": 2.5897097625329817,
      "grad_norm": 10.168466567993164,
      "learning_rate": 1.3698328935795955e-05,
      "loss": 1.5938,
      "step": 3926
    },
    {
      "epoch": 2.5903693931398415,
      "grad_norm": 15.890401840209961,
      "learning_rate": 1.3676341248900618e-05,
      "loss": 1.2886,
      "step": 3927
    },
    {
      "epoch": 2.5910290237467017,
      "grad_norm": 22.351375579833984,
      "learning_rate": 1.3654353562005279e-05,
      "loss": 0.4518,
      "step": 3928
    },
    {
      "epoch": 2.591688654353562,
      "grad_norm": 6.498466491699219,
      "learning_rate": 1.3632365875109939e-05,
      "loss": 0.1152,
      "step": 3929
    },
    {
      "epoch": 2.5923482849604222,
      "grad_norm": 0.7590529322624207,
      "learning_rate": 1.3610378188214601e-05,
      "loss": 0.0388,
      "step": 3930
    },
    {
      "epoch": 2.5930079155672825,
      "grad_norm": 16.128984451293945,
      "learning_rate": 1.3588390501319261e-05,
      "loss": 0.6897,
      "step": 3931
    },
    {
      "epoch": 2.5936675461741423,
      "grad_norm": 3.921497344970703,
      "learning_rate": 1.3566402814423924e-05,
      "loss": 0.0805,
      "step": 3932
    },
    {
      "epoch": 2.5943271767810026,
      "grad_norm": 1.0097609758377075,
      "learning_rate": 1.3544415127528584e-05,
      "loss": 0.0532,
      "step": 3933
    },
    {
      "epoch": 2.594986807387863,
      "grad_norm": 0.7636532783508301,
      "learning_rate": 1.3522427440633246e-05,
      "loss": 0.0235,
      "step": 3934
    },
    {
      "epoch": 2.595646437994723,
      "grad_norm": 0.4280858337879181,
      "learning_rate": 1.3500439753737906e-05,
      "loss": 0.0229,
      "step": 3935
    },
    {
      "epoch": 2.5963060686015833,
      "grad_norm": 1.8067805767059326,
      "learning_rate": 1.347845206684257e-05,
      "loss": 0.0586,
      "step": 3936
    },
    {
      "epoch": 2.596965699208443,
      "grad_norm": 13.670090675354004,
      "learning_rate": 1.345646437994723e-05,
      "loss": 0.1134,
      "step": 3937
    },
    {
      "epoch": 2.5976253298153034,
      "grad_norm": 12.964526176452637,
      "learning_rate": 1.3434476693051893e-05,
      "loss": 0.1339,
      "step": 3938
    },
    {
      "epoch": 2.5982849604221636,
      "grad_norm": 8.56367301940918,
      "learning_rate": 1.3412489006156553e-05,
      "loss": 0.1017,
      "step": 3939
    },
    {
      "epoch": 2.598944591029024,
      "grad_norm": 12.181684494018555,
      "learning_rate": 1.3390501319261215e-05,
      "loss": 0.3912,
      "step": 3940
    },
    {
      "epoch": 2.599604221635884,
      "grad_norm": 3.1953444480895996,
      "learning_rate": 1.3368513632365875e-05,
      "loss": 0.0822,
      "step": 3941
    },
    {
      "epoch": 2.600263852242744,
      "grad_norm": 10.84680461883545,
      "learning_rate": 1.3346525945470537e-05,
      "loss": 0.2754,
      "step": 3942
    },
    {
      "epoch": 2.600923482849604,
      "grad_norm": 0.7893548011779785,
      "learning_rate": 1.3324538258575198e-05,
      "loss": 0.0351,
      "step": 3943
    },
    {
      "epoch": 2.6015831134564644,
      "grad_norm": 3.276190996170044,
      "learning_rate": 1.3302550571679858e-05,
      "loss": 0.081,
      "step": 3944
    },
    {
      "epoch": 2.6022427440633247,
      "grad_norm": 0.7188886404037476,
      "learning_rate": 1.3280562884784522e-05,
      "loss": 0.0437,
      "step": 3945
    },
    {
      "epoch": 2.602902374670185,
      "grad_norm": 0.29998141527175903,
      "learning_rate": 1.3258575197889184e-05,
      "loss": 0.0265,
      "step": 3946
    },
    {
      "epoch": 2.6035620052770447,
      "grad_norm": 17.378921508789062,
      "learning_rate": 1.3236587510993844e-05,
      "loss": 1.2052,
      "step": 3947
    },
    {
      "epoch": 2.604221635883905,
      "grad_norm": 0.7251284718513489,
      "learning_rate": 1.3214599824098506e-05,
      "loss": 0.0496,
      "step": 3948
    },
    {
      "epoch": 2.6048812664907652,
      "grad_norm": 0.6185934543609619,
      "learning_rate": 1.3192612137203167e-05,
      "loss": 0.0493,
      "step": 3949
    },
    {
      "epoch": 2.6055408970976255,
      "grad_norm": 1.1776328086853027,
      "learning_rate": 1.3170624450307827e-05,
      "loss": 0.0581,
      "step": 3950
    },
    {
      "epoch": 2.6062005277044857,
      "grad_norm": 9.113363265991211,
      "learning_rate": 1.314863676341249e-05,
      "loss": 0.1816,
      "step": 3951
    },
    {
      "epoch": 2.6068601583113455,
      "grad_norm": 1.5288676023483276,
      "learning_rate": 1.312664907651715e-05,
      "loss": 0.079,
      "step": 3952
    },
    {
      "epoch": 2.607519788918206,
      "grad_norm": 0.49724194407463074,
      "learning_rate": 1.3104661389621812e-05,
      "loss": 0.0347,
      "step": 3953
    },
    {
      "epoch": 2.608179419525066,
      "grad_norm": 1.605236291885376,
      "learning_rate": 1.3082673702726475e-05,
      "loss": 0.1288,
      "step": 3954
    },
    {
      "epoch": 2.608839050131926,
      "grad_norm": 10.103642463684082,
      "learning_rate": 1.3060686015831136e-05,
      "loss": 0.246,
      "step": 3955
    },
    {
      "epoch": 2.6094986807387865,
      "grad_norm": 1.790773630142212,
      "learning_rate": 1.3038698328935798e-05,
      "loss": 0.0893,
      "step": 3956
    },
    {
      "epoch": 2.6101583113456464,
      "grad_norm": 1.8200061321258545,
      "learning_rate": 1.3016710642040458e-05,
      "loss": 0.1195,
      "step": 3957
    },
    {
      "epoch": 2.6108179419525066,
      "grad_norm": 5.108496189117432,
      "learning_rate": 1.2994722955145119e-05,
      "loss": 0.0945,
      "step": 3958
    },
    {
      "epoch": 2.611477572559367,
      "grad_norm": 0.8932541012763977,
      "learning_rate": 1.297273526824978e-05,
      "loss": 0.0371,
      "step": 3959
    },
    {
      "epoch": 2.6121372031662267,
      "grad_norm": 0.9496793150901794,
      "learning_rate": 1.2950747581354441e-05,
      "loss": 0.0556,
      "step": 3960
    },
    {
      "epoch": 2.612796833773087,
      "grad_norm": 0.7872412800788879,
      "learning_rate": 1.2928759894459103e-05,
      "loss": 0.0442,
      "step": 3961
    },
    {
      "epoch": 2.613456464379947,
      "grad_norm": 8.060370445251465,
      "learning_rate": 1.2906772207563763e-05,
      "loss": 0.1281,
      "step": 3962
    },
    {
      "epoch": 2.6141160949868074,
      "grad_norm": 1.2161426544189453,
      "learning_rate": 1.2884784520668427e-05,
      "loss": 0.0651,
      "step": 3963
    },
    {
      "epoch": 2.6147757255936677,
      "grad_norm": 5.935545921325684,
      "learning_rate": 1.286279683377309e-05,
      "loss": 0.1408,
      "step": 3964
    },
    {
      "epoch": 2.6154353562005275,
      "grad_norm": 2.0835883617401123,
      "learning_rate": 1.284080914687775e-05,
      "loss": 0.1108,
      "step": 3965
    },
    {
      "epoch": 2.6160949868073877,
      "grad_norm": 7.1131911277771,
      "learning_rate": 1.281882145998241e-05,
      "loss": 0.4673,
      "step": 3966
    },
    {
      "epoch": 2.616754617414248,
      "grad_norm": 8.148850440979004,
      "learning_rate": 1.2796833773087072e-05,
      "loss": 0.1974,
      "step": 3967
    },
    {
      "epoch": 2.6174142480211082,
      "grad_norm": 4.294432640075684,
      "learning_rate": 1.2774846086191732e-05,
      "loss": 0.0844,
      "step": 3968
    },
    {
      "epoch": 2.6180738786279685,
      "grad_norm": 1.0674004554748535,
      "learning_rate": 1.2752858399296394e-05,
      "loss": 0.0488,
      "step": 3969
    },
    {
      "epoch": 2.6187335092348283,
      "grad_norm": 11.004719734191895,
      "learning_rate": 1.2730870712401055e-05,
      "loss": 0.1492,
      "step": 3970
    },
    {
      "epoch": 2.6193931398416885,
      "grad_norm": 5.863785266876221,
      "learning_rate": 1.2708883025505717e-05,
      "loss": 0.103,
      "step": 3971
    },
    {
      "epoch": 2.620052770448549,
      "grad_norm": 0.9381132125854492,
      "learning_rate": 1.268689533861038e-05,
      "loss": 0.0636,
      "step": 3972
    },
    {
      "epoch": 2.620712401055409,
      "grad_norm": 1.265342116355896,
      "learning_rate": 1.2664907651715041e-05,
      "loss": 0.0535,
      "step": 3973
    },
    {
      "epoch": 2.6213720316622693,
      "grad_norm": 1.1804635524749756,
      "learning_rate": 1.2642919964819701e-05,
      "loss": 0.0526,
      "step": 3974
    },
    {
      "epoch": 2.622031662269129,
      "grad_norm": 10.426886558532715,
      "learning_rate": 1.2620932277924363e-05,
      "loss": 0.5537,
      "step": 3975
    },
    {
      "epoch": 2.6226912928759893,
      "grad_norm": 7.624619007110596,
      "learning_rate": 1.2598944591029024e-05,
      "loss": 0.1837,
      "step": 3976
    },
    {
      "epoch": 2.6233509234828496,
      "grad_norm": 1.0250741243362427,
      "learning_rate": 1.2576956904133686e-05,
      "loss": 0.0536,
      "step": 3977
    },
    {
      "epoch": 2.62401055408971,
      "grad_norm": 0.33879905939102173,
      "learning_rate": 1.2554969217238346e-05,
      "loss": 0.0135,
      "step": 3978
    },
    {
      "epoch": 2.62467018469657,
      "grad_norm": 3.6108763217926025,
      "learning_rate": 1.2532981530343008e-05,
      "loss": 0.0326,
      "step": 3979
    },
    {
      "epoch": 2.62532981530343,
      "grad_norm": 1.8481805324554443,
      "learning_rate": 1.2510993843447669e-05,
      "loss": 0.0498,
      "step": 3980
    },
    {
      "epoch": 2.62598944591029,
      "grad_norm": 11.522388458251953,
      "learning_rate": 1.248900615655233e-05,
      "loss": 0.1678,
      "step": 3981
    },
    {
      "epoch": 2.6266490765171504,
      "grad_norm": 11.860955238342285,
      "learning_rate": 1.2467018469656993e-05,
      "loss": 0.5806,
      "step": 3982
    },
    {
      "epoch": 2.6273087071240107,
      "grad_norm": 0.5083194971084595,
      "learning_rate": 1.2445030782761655e-05,
      "loss": 0.0256,
      "step": 3983
    },
    {
      "epoch": 2.627968337730871,
      "grad_norm": 18.517562866210938,
      "learning_rate": 1.2423043095866315e-05,
      "loss": 0.322,
      "step": 3984
    },
    {
      "epoch": 2.6286279683377307,
      "grad_norm": 0.846799910068512,
      "learning_rate": 1.2401055408970977e-05,
      "loss": 0.041,
      "step": 3985
    },
    {
      "epoch": 2.629287598944591,
      "grad_norm": 2.642606735229492,
      "learning_rate": 1.2379067722075638e-05,
      "loss": 0.067,
      "step": 3986
    },
    {
      "epoch": 2.629947229551451,
      "grad_norm": 0.7551298141479492,
      "learning_rate": 1.23570800351803e-05,
      "loss": 0.0383,
      "step": 3987
    },
    {
      "epoch": 2.6306068601583115,
      "grad_norm": 1.3473749160766602,
      "learning_rate": 1.2335092348284962e-05,
      "loss": 0.0454,
      "step": 3988
    },
    {
      "epoch": 2.6312664907651717,
      "grad_norm": 1.23759925365448,
      "learning_rate": 1.2313104661389622e-05,
      "loss": 0.0415,
      "step": 3989
    },
    {
      "epoch": 2.6319261213720315,
      "grad_norm": 11.559165000915527,
      "learning_rate": 1.2291116974494284e-05,
      "loss": 0.4354,
      "step": 3990
    },
    {
      "epoch": 2.6325857519788918,
      "grad_norm": 1.044439435005188,
      "learning_rate": 1.2269129287598945e-05,
      "loss": 0.0488,
      "step": 3991
    },
    {
      "epoch": 2.633245382585752,
      "grad_norm": 1.1932786703109741,
      "learning_rate": 1.2247141600703607e-05,
      "loss": 0.0557,
      "step": 3992
    },
    {
      "epoch": 2.6339050131926123,
      "grad_norm": 0.8693515062332153,
      "learning_rate": 1.2225153913808269e-05,
      "loss": 0.0529,
      "step": 3993
    },
    {
      "epoch": 2.6345646437994725,
      "grad_norm": 7.328296661376953,
      "learning_rate": 1.2203166226912929e-05,
      "loss": 0.1883,
      "step": 3994
    },
    {
      "epoch": 2.6352242744063323,
      "grad_norm": 3.0342886447906494,
      "learning_rate": 1.2181178540017591e-05,
      "loss": 0.0458,
      "step": 3995
    },
    {
      "epoch": 2.6358839050131926,
      "grad_norm": 4.133182048797607,
      "learning_rate": 1.2159190853122252e-05,
      "loss": 0.0938,
      "step": 3996
    },
    {
      "epoch": 2.636543535620053,
      "grad_norm": 9.76172924041748,
      "learning_rate": 1.2137203166226914e-05,
      "loss": 0.1386,
      "step": 3997
    },
    {
      "epoch": 2.637203166226913,
      "grad_norm": 3.806273937225342,
      "learning_rate": 1.2115215479331576e-05,
      "loss": 0.0793,
      "step": 3998
    },
    {
      "epoch": 2.6378627968337733,
      "grad_norm": 1.1043351888656616,
      "learning_rate": 1.2093227792436236e-05,
      "loss": 0.0422,
      "step": 3999
    },
    {
      "epoch": 2.638522427440633,
      "grad_norm": 9.312101364135742,
      "learning_rate": 1.2071240105540896e-05,
      "loss": 0.372,
      "step": 4000
    },
    {
      "epoch": 2.6391820580474934,
      "grad_norm": 1.4911201000213623,
      "learning_rate": 1.204925241864556e-05,
      "loss": 0.0576,
      "step": 4001
    },
    {
      "epoch": 2.6398416886543536,
      "grad_norm": 3.913938045501709,
      "learning_rate": 1.202726473175022e-05,
      "loss": 0.0949,
      "step": 4002
    },
    {
      "epoch": 2.6405013192612135,
      "grad_norm": 1.627079725265503,
      "learning_rate": 1.2005277044854883e-05,
      "loss": 0.079,
      "step": 4003
    },
    {
      "epoch": 2.641160949868074,
      "grad_norm": 1.0434117317199707,
      "learning_rate": 1.1983289357959543e-05,
      "loss": 0.046,
      "step": 4004
    },
    {
      "epoch": 2.641820580474934,
      "grad_norm": 3.693138599395752,
      "learning_rate": 1.1961301671064203e-05,
      "loss": 0.0548,
      "step": 4005
    },
    {
      "epoch": 2.642480211081794,
      "grad_norm": 1.5258835554122925,
      "learning_rate": 1.1939313984168867e-05,
      "loss": 0.0516,
      "step": 4006
    },
    {
      "epoch": 2.6431398416886545,
      "grad_norm": 5.0171589851379395,
      "learning_rate": 1.1917326297273527e-05,
      "loss": 0.179,
      "step": 4007
    },
    {
      "epoch": 2.6437994722955143,
      "grad_norm": 1.1485018730163574,
      "learning_rate": 1.1895338610378188e-05,
      "loss": 0.0475,
      "step": 4008
    },
    {
      "epoch": 2.6444591029023745,
      "grad_norm": 1.4755668640136719,
      "learning_rate": 1.187335092348285e-05,
      "loss": 0.083,
      "step": 4009
    },
    {
      "epoch": 2.6451187335092348,
      "grad_norm": 1.1495105028152466,
      "learning_rate": 1.1851363236587512e-05,
      "loss": 0.0361,
      "step": 4010
    },
    {
      "epoch": 2.645778364116095,
      "grad_norm": 15.10340404510498,
      "learning_rate": 1.1829375549692174e-05,
      "loss": 0.2653,
      "step": 4011
    },
    {
      "epoch": 2.6464379947229553,
      "grad_norm": 1.3482567071914673,
      "learning_rate": 1.1807387862796834e-05,
      "loss": 0.0571,
      "step": 4012
    },
    {
      "epoch": 2.647097625329815,
      "grad_norm": 2.2611210346221924,
      "learning_rate": 1.1785400175901495e-05,
      "loss": 0.0806,
      "step": 4013
    },
    {
      "epoch": 2.6477572559366753,
      "grad_norm": 7.358067989349365,
      "learning_rate": 1.1763412489006157e-05,
      "loss": 0.1211,
      "step": 4014
    },
    {
      "epoch": 2.6484168865435356,
      "grad_norm": 1.5947935581207275,
      "learning_rate": 1.1741424802110819e-05,
      "loss": 0.0924,
      "step": 4015
    },
    {
      "epoch": 2.649076517150396,
      "grad_norm": 4.695745944976807,
      "learning_rate": 1.171943711521548e-05,
      "loss": 0.0792,
      "step": 4016
    },
    {
      "epoch": 2.649736147757256,
      "grad_norm": 1.013027310371399,
      "learning_rate": 1.1697449428320141e-05,
      "loss": 0.04,
      "step": 4017
    },
    {
      "epoch": 2.650395778364116,
      "grad_norm": 15.418713569641113,
      "learning_rate": 1.1675461741424802e-05,
      "loss": 1.1859,
      "step": 4018
    },
    {
      "epoch": 2.651055408970976,
      "grad_norm": 1.1839146614074707,
      "learning_rate": 1.1653474054529464e-05,
      "loss": 0.0337,
      "step": 4019
    },
    {
      "epoch": 2.6517150395778364,
      "grad_norm": 1.0984046459197998,
      "learning_rate": 1.1631486367634126e-05,
      "loss": 0.0264,
      "step": 4020
    },
    {
      "epoch": 2.6523746701846966,
      "grad_norm": 0.6834794878959656,
      "learning_rate": 1.1609498680738786e-05,
      "loss": 0.0278,
      "step": 4021
    },
    {
      "epoch": 2.653034300791557,
      "grad_norm": 10.068737030029297,
      "learning_rate": 1.1587510993843448e-05,
      "loss": 0.1902,
      "step": 4022
    },
    {
      "epoch": 2.6536939313984167,
      "grad_norm": 0.6368796229362488,
      "learning_rate": 1.1565523306948109e-05,
      "loss": 0.0308,
      "step": 4023
    },
    {
      "epoch": 2.654353562005277,
      "grad_norm": 0.5788251757621765,
      "learning_rate": 1.154353562005277e-05,
      "loss": 0.041,
      "step": 4024
    },
    {
      "epoch": 2.655013192612137,
      "grad_norm": 19.793655395507812,
      "learning_rate": 1.1521547933157433e-05,
      "loss": 0.3138,
      "step": 4025
    },
    {
      "epoch": 2.6556728232189974,
      "grad_norm": 0.6286065578460693,
      "learning_rate": 1.1499560246262093e-05,
      "loss": 0.0314,
      "step": 4026
    },
    {
      "epoch": 2.6563324538258577,
      "grad_norm": 10.739617347717285,
      "learning_rate": 1.1477572559366755e-05,
      "loss": 0.191,
      "step": 4027
    },
    {
      "epoch": 2.6569920844327175,
      "grad_norm": 9.425235748291016,
      "learning_rate": 1.1455584872471417e-05,
      "loss": 0.1097,
      "step": 4028
    },
    {
      "epoch": 2.6576517150395778,
      "grad_norm": 2.1433184146881104,
      "learning_rate": 1.1433597185576078e-05,
      "loss": 0.0797,
      "step": 4029
    },
    {
      "epoch": 2.658311345646438,
      "grad_norm": 1.747363805770874,
      "learning_rate": 1.141160949868074e-05,
      "loss": 0.0644,
      "step": 4030
    },
    {
      "epoch": 2.6589709762532983,
      "grad_norm": 0.4814586937427521,
      "learning_rate": 1.13896218117854e-05,
      "loss": 0.015,
      "step": 4031
    },
    {
      "epoch": 2.6596306068601585,
      "grad_norm": 0.5363450050354004,
      "learning_rate": 1.1367634124890062e-05,
      "loss": 0.0293,
      "step": 4032
    },
    {
      "epoch": 2.6602902374670183,
      "grad_norm": 0.9914566278457642,
      "learning_rate": 1.1345646437994724e-05,
      "loss": 0.0442,
      "step": 4033
    },
    {
      "epoch": 2.6609498680738786,
      "grad_norm": 5.395575523376465,
      "learning_rate": 1.1323658751099385e-05,
      "loss": 0.1037,
      "step": 4034
    },
    {
      "epoch": 2.661609498680739,
      "grad_norm": 0.8817365169525146,
      "learning_rate": 1.1301671064204047e-05,
      "loss": 0.0398,
      "step": 4035
    },
    {
      "epoch": 2.662269129287599,
      "grad_norm": 7.531360626220703,
      "learning_rate": 1.1279683377308707e-05,
      "loss": 0.1323,
      "step": 4036
    },
    {
      "epoch": 2.6629287598944593,
      "grad_norm": 8.112871170043945,
      "learning_rate": 1.1257695690413369e-05,
      "loss": 0.1657,
      "step": 4037
    },
    {
      "epoch": 2.663588390501319,
      "grad_norm": 26.995471954345703,
      "learning_rate": 1.1235708003518031e-05,
      "loss": 0.3348,
      "step": 4038
    },
    {
      "epoch": 2.6642480211081794,
      "grad_norm": 12.750630378723145,
      "learning_rate": 1.1213720316622692e-05,
      "loss": 0.7567,
      "step": 4039
    },
    {
      "epoch": 2.6649076517150396,
      "grad_norm": 13.169004440307617,
      "learning_rate": 1.1191732629727354e-05,
      "loss": 0.7113,
      "step": 4040
    },
    {
      "epoch": 2.6655672823219,
      "grad_norm": 15.445444107055664,
      "learning_rate": 1.1169744942832016e-05,
      "loss": 0.1124,
      "step": 4041
    },
    {
      "epoch": 2.66622691292876,
      "grad_norm": 1.4918808937072754,
      "learning_rate": 1.1147757255936676e-05,
      "loss": 0.0735,
      "step": 4042
    },
    {
      "epoch": 2.66688654353562,
      "grad_norm": 17.18205451965332,
      "learning_rate": 1.1125769569041338e-05,
      "loss": 0.3983,
      "step": 4043
    },
    {
      "epoch": 2.66754617414248,
      "grad_norm": 2.0226809978485107,
      "learning_rate": 1.1103781882145998e-05,
      "loss": 0.1237,
      "step": 4044
    },
    {
      "epoch": 2.6682058047493404,
      "grad_norm": 0.6487613320350647,
      "learning_rate": 1.1081794195250659e-05,
      "loss": 0.038,
      "step": 4045
    },
    {
      "epoch": 2.6688654353562007,
      "grad_norm": 12.979747772216797,
      "learning_rate": 1.1059806508355323e-05,
      "loss": 0.7232,
      "step": 4046
    },
    {
      "epoch": 2.669525065963061,
      "grad_norm": 13.158339500427246,
      "learning_rate": 1.1037818821459983e-05,
      "loss": 0.9009,
      "step": 4047
    },
    {
      "epoch": 2.6701846965699207,
      "grad_norm": 0.8344802260398865,
      "learning_rate": 1.1015831134564645e-05,
      "loss": 0.0471,
      "step": 4048
    },
    {
      "epoch": 2.670844327176781,
      "grad_norm": 2.0094494819641113,
      "learning_rate": 1.0993843447669305e-05,
      "loss": 0.0595,
      "step": 4049
    },
    {
      "epoch": 2.6715039577836412,
      "grad_norm": 0.7442694306373596,
      "learning_rate": 1.0971855760773967e-05,
      "loss": 0.0479,
      "step": 4050
    },
    {
      "epoch": 2.672163588390501,
      "grad_norm": 13.044684410095215,
      "learning_rate": 1.094986807387863e-05,
      "loss": 0.5432,
      "step": 4051
    },
    {
      "epoch": 2.6728232189973617,
      "grad_norm": 9.525715827941895,
      "learning_rate": 1.092788038698329e-05,
      "loss": 0.7223,
      "step": 4052
    },
    {
      "epoch": 2.6734828496042216,
      "grad_norm": 13.19631290435791,
      "learning_rate": 1.090589270008795e-05,
      "loss": 0.2206,
      "step": 4053
    },
    {
      "epoch": 2.674142480211082,
      "grad_norm": 0.8472059965133667,
      "learning_rate": 1.0883905013192612e-05,
      "loss": 0.0512,
      "step": 4054
    },
    {
      "epoch": 2.674802110817942,
      "grad_norm": 10.129034042358398,
      "learning_rate": 1.0861917326297274e-05,
      "loss": 0.2124,
      "step": 4055
    },
    {
      "epoch": 2.675461741424802,
      "grad_norm": 1.5411900281906128,
      "learning_rate": 1.0839929639401936e-05,
      "loss": 0.0852,
      "step": 4056
    },
    {
      "epoch": 2.676121372031662,
      "grad_norm": 1.2360564470291138,
      "learning_rate": 1.0817941952506597e-05,
      "loss": 0.0596,
      "step": 4057
    },
    {
      "epoch": 2.6767810026385224,
      "grad_norm": 1.0768808126449585,
      "learning_rate": 1.0795954265611257e-05,
      "loss": 0.0697,
      "step": 4058
    },
    {
      "epoch": 2.6774406332453826,
      "grad_norm": 0.8108413219451904,
      "learning_rate": 1.0773966578715921e-05,
      "loss": 0.042,
      "step": 4059
    },
    {
      "epoch": 2.678100263852243,
      "grad_norm": 29.20067596435547,
      "learning_rate": 1.0751978891820581e-05,
      "loss": 0.2595,
      "step": 4060
    },
    {
      "epoch": 2.6787598944591027,
      "grad_norm": 0.8653436303138733,
      "learning_rate": 1.0729991204925242e-05,
      "loss": 0.0816,
      "step": 4061
    },
    {
      "epoch": 2.679419525065963,
      "grad_norm": 1.8225748538970947,
      "learning_rate": 1.0708003518029904e-05,
      "loss": 0.0916,
      "step": 4062
    },
    {
      "epoch": 2.680079155672823,
      "grad_norm": 19.47950553894043,
      "learning_rate": 1.0686015831134564e-05,
      "loss": 0.4792,
      "step": 4063
    },
    {
      "epoch": 2.6807387862796834,
      "grad_norm": 1.4320706129074097,
      "learning_rate": 1.0664028144239228e-05,
      "loss": 0.0794,
      "step": 4064
    },
    {
      "epoch": 2.6813984168865437,
      "grad_norm": 0.824198842048645,
      "learning_rate": 1.0642040457343888e-05,
      "loss": 0.055,
      "step": 4065
    },
    {
      "epoch": 2.6820580474934035,
      "grad_norm": 10.225550651550293,
      "learning_rate": 1.0620052770448549e-05,
      "loss": 0.1468,
      "step": 4066
    },
    {
      "epoch": 2.6827176781002637,
      "grad_norm": 3.6270883083343506,
      "learning_rate": 1.059806508355321e-05,
      "loss": 0.0526,
      "step": 4067
    },
    {
      "epoch": 2.683377308707124,
      "grad_norm": 8.69674301147461,
      "learning_rate": 1.0576077396657873e-05,
      "loss": 0.1458,
      "step": 4068
    },
    {
      "epoch": 2.6840369393139842,
      "grad_norm": 1.1418581008911133,
      "learning_rate": 1.0554089709762533e-05,
      "loss": 0.0448,
      "step": 4069
    },
    {
      "epoch": 2.6846965699208445,
      "grad_norm": 1.7542585134506226,
      "learning_rate": 1.0532102022867195e-05,
      "loss": 0.0477,
      "step": 4070
    },
    {
      "epoch": 2.6853562005277043,
      "grad_norm": 1.0421905517578125,
      "learning_rate": 1.0510114335971856e-05,
      "loss": 0.0233,
      "step": 4071
    },
    {
      "epoch": 2.6860158311345645,
      "grad_norm": 3.739622116088867,
      "learning_rate": 1.0488126649076518e-05,
      "loss": 0.0924,
      "step": 4072
    },
    {
      "epoch": 2.686675461741425,
      "grad_norm": 0.3956080675125122,
      "learning_rate": 1.046613896218118e-05,
      "loss": 0.0159,
      "step": 4073
    },
    {
      "epoch": 2.687335092348285,
      "grad_norm": 0.8380484580993652,
      "learning_rate": 1.044415127528584e-05,
      "loss": 0.0417,
      "step": 4074
    },
    {
      "epoch": 2.6879947229551453,
      "grad_norm": 13.9212646484375,
      "learning_rate": 1.0422163588390502e-05,
      "loss": 0.1957,
      "step": 4075
    },
    {
      "epoch": 2.688654353562005,
      "grad_norm": 1.6778299808502197,
      "learning_rate": 1.0400175901495162e-05,
      "loss": 0.0541,
      "step": 4076
    },
    {
      "epoch": 2.6893139841688654,
      "grad_norm": 0.8639379739761353,
      "learning_rate": 1.0378188214599825e-05,
      "loss": 0.051,
      "step": 4077
    },
    {
      "epoch": 2.6899736147757256,
      "grad_norm": 2.0286788940429688,
      "learning_rate": 1.0356200527704487e-05,
      "loss": 0.0776,
      "step": 4078
    },
    {
      "epoch": 2.690633245382586,
      "grad_norm": 15.143228530883789,
      "learning_rate": 1.0334212840809147e-05,
      "loss": 0.667,
      "step": 4079
    },
    {
      "epoch": 2.691292875989446,
      "grad_norm": 1.27558434009552,
      "learning_rate": 1.0312225153913809e-05,
      "loss": 0.0521,
      "step": 4080
    },
    {
      "epoch": 2.691952506596306,
      "grad_norm": 1.8147085905075073,
      "learning_rate": 1.029023746701847e-05,
      "loss": 0.1125,
      "step": 4081
    },
    {
      "epoch": 2.692612137203166,
      "grad_norm": 1.1388334035873413,
      "learning_rate": 1.0268249780123131e-05,
      "loss": 0.0687,
      "step": 4082
    },
    {
      "epoch": 2.6932717678100264,
      "grad_norm": 0.9983629584312439,
      "learning_rate": 1.0246262093227793e-05,
      "loss": 0.0551,
      "step": 4083
    },
    {
      "epoch": 2.6939313984168867,
      "grad_norm": 7.186441421508789,
      "learning_rate": 1.0224274406332454e-05,
      "loss": 0.124,
      "step": 4084
    },
    {
      "epoch": 2.694591029023747,
      "grad_norm": 11.291851043701172,
      "learning_rate": 1.0202286719437116e-05,
      "loss": 0.1513,
      "step": 4085
    },
    {
      "epoch": 2.6952506596306067,
      "grad_norm": 1.9361064434051514,
      "learning_rate": 1.0180299032541778e-05,
      "loss": 0.0875,
      "step": 4086
    },
    {
      "epoch": 2.695910290237467,
      "grad_norm": 30.89701271057129,
      "learning_rate": 1.0158311345646438e-05,
      "loss": 0.4246,
      "step": 4087
    },
    {
      "epoch": 2.6965699208443272,
      "grad_norm": 12.51303768157959,
      "learning_rate": 1.01363236587511e-05,
      "loss": 0.1625,
      "step": 4088
    },
    {
      "epoch": 2.6972295514511875,
      "grad_norm": 2.30126953125,
      "learning_rate": 1.011433597185576e-05,
      "loss": 0.0714,
      "step": 4089
    },
    {
      "epoch": 2.6978891820580477,
      "grad_norm": 1.151546597480774,
      "learning_rate": 1.0092348284960421e-05,
      "loss": 0.0585,
      "step": 4090
    },
    {
      "epoch": 2.6985488126649075,
      "grad_norm": 0.8396580219268799,
      "learning_rate": 1.0070360598065085e-05,
      "loss": 0.0462,
      "step": 4091
    },
    {
      "epoch": 2.699208443271768,
      "grad_norm": 2.473961591720581,
      "learning_rate": 1.0048372911169745e-05,
      "loss": 0.046,
      "step": 4092
    },
    {
      "epoch": 2.699868073878628,
      "grad_norm": 0.7615821957588196,
      "learning_rate": 1.0026385224274407e-05,
      "loss": 0.0292,
      "step": 4093
    },
    {
      "epoch": 2.7005277044854883,
      "grad_norm": 22.013227462768555,
      "learning_rate": 1.0004397537379068e-05,
      "loss": 0.6263,
      "step": 4094
    },
    {
      "epoch": 2.7011873350923485,
      "grad_norm": 7.903624534606934,
      "learning_rate": 9.98240985048373e-06,
      "loss": 0.338,
      "step": 4095
    },
    {
      "epoch": 2.7018469656992083,
      "grad_norm": 0.7522628903388977,
      "learning_rate": 9.960422163588392e-06,
      "loss": 0.0274,
      "step": 4096
    },
    {
      "epoch": 2.7025065963060686,
      "grad_norm": 0.8502640128135681,
      "learning_rate": 9.938434476693052e-06,
      "loss": 0.0492,
      "step": 4097
    },
    {
      "epoch": 2.703166226912929,
      "grad_norm": 4.167928218841553,
      "learning_rate": 9.916446789797713e-06,
      "loss": 0.1101,
      "step": 4098
    },
    {
      "epoch": 2.7038258575197887,
      "grad_norm": 6.99423885345459,
      "learning_rate": 9.894459102902375e-06,
      "loss": 0.1094,
      "step": 4099
    },
    {
      "epoch": 2.7044854881266494,
      "grad_norm": 10.199674606323242,
      "learning_rate": 9.872471416007037e-06,
      "loss": 0.3029,
      "step": 4100
    },
    {
      "epoch": 2.705145118733509,
      "grad_norm": 1.1409573554992676,
      "learning_rate": 9.850483729111699e-06,
      "loss": 0.0558,
      "step": 4101
    },
    {
      "epoch": 2.7058047493403694,
      "grad_norm": 3.2317659854888916,
      "learning_rate": 9.82849604221636e-06,
      "loss": 0.0916,
      "step": 4102
    },
    {
      "epoch": 2.7064643799472297,
      "grad_norm": 9.811902046203613,
      "learning_rate": 9.80650835532102e-06,
      "loss": 0.3824,
      "step": 4103
    },
    {
      "epoch": 2.7071240105540895,
      "grad_norm": 0.6249120831489563,
      "learning_rate": 9.784520668425683e-06,
      "loss": 0.0294,
      "step": 4104
    },
    {
      "epoch": 2.7077836411609497,
      "grad_norm": 25.06687355041504,
      "learning_rate": 9.762532981530344e-06,
      "loss": 0.3065,
      "step": 4105
    },
    {
      "epoch": 2.70844327176781,
      "grad_norm": 13.223275184631348,
      "learning_rate": 9.740545294635004e-06,
      "loss": 0.741,
      "step": 4106
    },
    {
      "epoch": 2.70910290237467,
      "grad_norm": 0.5418490171432495,
      "learning_rate": 9.718557607739666e-06,
      "loss": 0.0255,
      "step": 4107
    },
    {
      "epoch": 2.7097625329815305,
      "grad_norm": 0.6438989043235779,
      "learning_rate": 9.696569920844326e-06,
      "loss": 0.049,
      "step": 4108
    },
    {
      "epoch": 2.7104221635883903,
      "grad_norm": 1.7632627487182617,
      "learning_rate": 9.67458223394899e-06,
      "loss": 0.0514,
      "step": 4109
    },
    {
      "epoch": 2.7110817941952505,
      "grad_norm": 2.2939462661743164,
      "learning_rate": 9.65259454705365e-06,
      "loss": 0.053,
      "step": 4110
    },
    {
      "epoch": 2.711741424802111,
      "grad_norm": 0.9334520697593689,
      "learning_rate": 9.630606860158311e-06,
      "loss": 0.0465,
      "step": 4111
    },
    {
      "epoch": 2.712401055408971,
      "grad_norm": 0.7151888608932495,
      "learning_rate": 9.608619173262973e-06,
      "loss": 0.0473,
      "step": 4112
    },
    {
      "epoch": 2.7130606860158313,
      "grad_norm": 1.9535249471664429,
      "learning_rate": 9.586631486367635e-06,
      "loss": 0.096,
      "step": 4113
    },
    {
      "epoch": 2.713720316622691,
      "grad_norm": 16.588483810424805,
      "learning_rate": 9.564643799472295e-06,
      "loss": 1.4462,
      "step": 4114
    },
    {
      "epoch": 2.7143799472295513,
      "grad_norm": 5.373663902282715,
      "learning_rate": 9.542656112576958e-06,
      "loss": 0.1087,
      "step": 4115
    },
    {
      "epoch": 2.7150395778364116,
      "grad_norm": 1.1910624504089355,
      "learning_rate": 9.520668425681618e-06,
      "loss": 0.052,
      "step": 4116
    },
    {
      "epoch": 2.715699208443272,
      "grad_norm": 4.956547260284424,
      "learning_rate": 9.49868073878628e-06,
      "loss": 0.1328,
      "step": 4117
    },
    {
      "epoch": 2.716358839050132,
      "grad_norm": 1.3996407985687256,
      "learning_rate": 9.476693051890942e-06,
      "loss": 0.0714,
      "step": 4118
    },
    {
      "epoch": 2.717018469656992,
      "grad_norm": 27.87755584716797,
      "learning_rate": 9.454705364995602e-06,
      "loss": 0.6842,
      "step": 4119
    },
    {
      "epoch": 2.717678100263852,
      "grad_norm": 2.670444965362549,
      "learning_rate": 9.432717678100264e-06,
      "loss": 0.0431,
      "step": 4120
    },
    {
      "epoch": 2.7183377308707124,
      "grad_norm": 7.284441947937012,
      "learning_rate": 9.410729991204925e-06,
      "loss": 0.0745,
      "step": 4121
    },
    {
      "epoch": 2.7189973614775726,
      "grad_norm": 1.0089380741119385,
      "learning_rate": 9.388742304309587e-06,
      "loss": 0.0645,
      "step": 4122
    },
    {
      "epoch": 2.719656992084433,
      "grad_norm": 1.1166465282440186,
      "learning_rate": 9.366754617414249e-06,
      "loss": 0.0234,
      "step": 4123
    },
    {
      "epoch": 2.7203166226912927,
      "grad_norm": 35.407745361328125,
      "learning_rate": 9.34476693051891e-06,
      "loss": 0.9241,
      "step": 4124
    },
    {
      "epoch": 2.720976253298153,
      "grad_norm": 17.15703010559082,
      "learning_rate": 9.322779243623571e-06,
      "loss": 0.6376,
      "step": 4125
    },
    {
      "epoch": 2.721635883905013,
      "grad_norm": 0.7766575813293457,
      "learning_rate": 9.300791556728233e-06,
      "loss": 0.0375,
      "step": 4126
    },
    {
      "epoch": 2.7222955145118735,
      "grad_norm": 11.646187782287598,
      "learning_rate": 9.278803869832894e-06,
      "loss": 0.3005,
      "step": 4127
    },
    {
      "epoch": 2.7229551451187337,
      "grad_norm": 0.6846237778663635,
      "learning_rate": 9.256816182937556e-06,
      "loss": 0.0278,
      "step": 4128
    },
    {
      "epoch": 2.7236147757255935,
      "grad_norm": 3.656930446624756,
      "learning_rate": 9.234828496042216e-06,
      "loss": 0.0868,
      "step": 4129
    },
    {
      "epoch": 2.7242744063324538,
      "grad_norm": 1.3356223106384277,
      "learning_rate": 9.212840809146878e-06,
      "loss": 0.0516,
      "step": 4130
    },
    {
      "epoch": 2.724934036939314,
      "grad_norm": 0.9148854613304138,
      "learning_rate": 9.19085312225154e-06,
      "loss": 0.0373,
      "step": 4131
    },
    {
      "epoch": 2.7255936675461743,
      "grad_norm": 1.0104217529296875,
      "learning_rate": 9.1688654353562e-06,
      "loss": 0.0488,
      "step": 4132
    },
    {
      "epoch": 2.7262532981530345,
      "grad_norm": 5.787243366241455,
      "learning_rate": 9.146877748460863e-06,
      "loss": 0.0842,
      "step": 4133
    },
    {
      "epoch": 2.7269129287598943,
      "grad_norm": 1.3986884355545044,
      "learning_rate": 9.124890061565523e-06,
      "loss": 0.0843,
      "step": 4134
    },
    {
      "epoch": 2.7275725593667546,
      "grad_norm": 2.508629560470581,
      "learning_rate": 9.102902374670185e-06,
      "loss": 0.0566,
      "step": 4135
    },
    {
      "epoch": 2.728232189973615,
      "grad_norm": 2.453213691711426,
      "learning_rate": 9.080914687774847e-06,
      "loss": 0.0562,
      "step": 4136
    },
    {
      "epoch": 2.728891820580475,
      "grad_norm": 1.704042911529541,
      "learning_rate": 9.058927000879508e-06,
      "loss": 0.0363,
      "step": 4137
    },
    {
      "epoch": 2.7295514511873353,
      "grad_norm": 19.18508529663086,
      "learning_rate": 9.03693931398417e-06,
      "loss": 0.5204,
      "step": 4138
    },
    {
      "epoch": 2.730211081794195,
      "grad_norm": 18.717357635498047,
      "learning_rate": 9.01495162708883e-06,
      "loss": 0.4237,
      "step": 4139
    },
    {
      "epoch": 2.7308707124010554,
      "grad_norm": 0.6393404006958008,
      "learning_rate": 8.992963940193492e-06,
      "loss": 0.0378,
      "step": 4140
    },
    {
      "epoch": 2.7315303430079156,
      "grad_norm": 6.851226329803467,
      "learning_rate": 8.970976253298154e-06,
      "loss": 0.1493,
      "step": 4141
    },
    {
      "epoch": 2.732189973614776,
      "grad_norm": 1.2108131647109985,
      "learning_rate": 8.948988566402815e-06,
      "loss": 0.0359,
      "step": 4142
    },
    {
      "epoch": 2.732849604221636,
      "grad_norm": 1.9679831266403198,
      "learning_rate": 8.927000879507477e-06,
      "loss": 0.0645,
      "step": 4143
    },
    {
      "epoch": 2.733509234828496,
      "grad_norm": 18.160551071166992,
      "learning_rate": 8.905013192612139e-06,
      "loss": 0.8306,
      "step": 4144
    },
    {
      "epoch": 2.734168865435356,
      "grad_norm": 0.7804422378540039,
      "learning_rate": 8.883025505716799e-06,
      "loss": 0.0221,
      "step": 4145
    },
    {
      "epoch": 2.7348284960422165,
      "grad_norm": 0.8576103448867798,
      "learning_rate": 8.861037818821461e-06,
      "loss": 0.0489,
      "step": 4146
    },
    {
      "epoch": 2.7354881266490763,
      "grad_norm": 0.48518821597099304,
      "learning_rate": 8.839050131926122e-06,
      "loss": 0.0131,
      "step": 4147
    },
    {
      "epoch": 2.736147757255937,
      "grad_norm": 13.211458206176758,
      "learning_rate": 8.817062445030782e-06,
      "loss": 0.2014,
      "step": 4148
    },
    {
      "epoch": 2.7368073878627968,
      "grad_norm": 0.7454769015312195,
      "learning_rate": 8.795074758135446e-06,
      "loss": 0.0283,
      "step": 4149
    },
    {
      "epoch": 2.737467018469657,
      "grad_norm": 0.9983758330345154,
      "learning_rate": 8.773087071240106e-06,
      "loss": 0.0931,
      "step": 4150
    },
    {
      "epoch": 2.7381266490765173,
      "grad_norm": 0.9261561036109924,
      "learning_rate": 8.751099384344766e-06,
      "loss": 0.0362,
      "step": 4151
    },
    {
      "epoch": 2.738786279683377,
      "grad_norm": 16.93756103515625,
      "learning_rate": 8.729111697449428e-06,
      "loss": 0.776,
      "step": 4152
    },
    {
      "epoch": 2.7394459102902373,
      "grad_norm": 0.6692405939102173,
      "learning_rate": 8.70712401055409e-06,
      "loss": 0.0294,
      "step": 4153
    },
    {
      "epoch": 2.7401055408970976,
      "grad_norm": 15.432196617126465,
      "learning_rate": 8.685136323658753e-06,
      "loss": 0.297,
      "step": 4154
    },
    {
      "epoch": 2.740765171503958,
      "grad_norm": 0.5055832266807556,
      "learning_rate": 8.663148636763413e-06,
      "loss": 0.0269,
      "step": 4155
    },
    {
      "epoch": 2.741424802110818,
      "grad_norm": 9.535888671875,
      "learning_rate": 8.641160949868073e-06,
      "loss": 0.4496,
      "step": 4156
    },
    {
      "epoch": 2.742084432717678,
      "grad_norm": 4.239991664886475,
      "learning_rate": 8.619173262972735e-06,
      "loss": 0.1088,
      "step": 4157
    },
    {
      "epoch": 2.742744063324538,
      "grad_norm": 2.2298524379730225,
      "learning_rate": 8.597185576077397e-06,
      "loss": 0.084,
      "step": 4158
    },
    {
      "epoch": 2.7434036939313984,
      "grad_norm": 1.075878381729126,
      "learning_rate": 8.575197889182058e-06,
      "loss": 0.0662,
      "step": 4159
    },
    {
      "epoch": 2.7440633245382586,
      "grad_norm": 1.387770175933838,
      "learning_rate": 8.55321020228672e-06,
      "loss": 0.0771,
      "step": 4160
    },
    {
      "epoch": 2.744722955145119,
      "grad_norm": 3.0725338459014893,
      "learning_rate": 8.53122251539138e-06,
      "loss": 0.0861,
      "step": 4161
    },
    {
      "epoch": 2.7453825857519787,
      "grad_norm": 1.2611223459243774,
      "learning_rate": 8.509234828496044e-06,
      "loss": 0.1043,
      "step": 4162
    },
    {
      "epoch": 2.746042216358839,
      "grad_norm": 1.5529258251190186,
      "learning_rate": 8.487247141600704e-06,
      "loss": 0.1039,
      "step": 4163
    },
    {
      "epoch": 2.746701846965699,
      "grad_norm": 0.9820837378501892,
      "learning_rate": 8.465259454705365e-06,
      "loss": 0.0486,
      "step": 4164
    },
    {
      "epoch": 2.7473614775725594,
      "grad_norm": 0.8793379664421082,
      "learning_rate": 8.443271767810027e-06,
      "loss": 0.0315,
      "step": 4165
    },
    {
      "epoch": 2.7480211081794197,
      "grad_norm": 18.118362426757812,
      "learning_rate": 8.421284080914687e-06,
      "loss": 0.897,
      "step": 4166
    },
    {
      "epoch": 2.7486807387862795,
      "grad_norm": 14.866438865661621,
      "learning_rate": 8.39929639401935e-06,
      "loss": 0.1671,
      "step": 4167
    },
    {
      "epoch": 2.7493403693931397,
      "grad_norm": 9.052447319030762,
      "learning_rate": 8.377308707124011e-06,
      "loss": 0.1784,
      "step": 4168
    },
    {
      "epoch": 2.75,
      "grad_norm": 7.123856544494629,
      "learning_rate": 8.355321020228672e-06,
      "loss": 0.6962,
      "step": 4169
    },
    {
      "epoch": 2.7506596306068603,
      "grad_norm": 0.41376104950904846,
      "learning_rate": 8.333333333333334e-06,
      "loss": 0.0192,
      "step": 4170
    },
    {
      "epoch": 2.7513192612137205,
      "grad_norm": 1.1318237781524658,
      "learning_rate": 8.311345646437996e-06,
      "loss": 0.0499,
      "step": 4171
    },
    {
      "epoch": 2.7519788918205803,
      "grad_norm": 2.7011878490448,
      "learning_rate": 8.289357959542656e-06,
      "loss": 0.0615,
      "step": 4172
    },
    {
      "epoch": 2.7526385224274406,
      "grad_norm": 1.4160782098770142,
      "learning_rate": 8.267370272647318e-06,
      "loss": 0.0319,
      "step": 4173
    },
    {
      "epoch": 2.753298153034301,
      "grad_norm": 5.329255104064941,
      "learning_rate": 8.245382585751979e-06,
      "loss": 0.1001,
      "step": 4174
    },
    {
      "epoch": 2.753957783641161,
      "grad_norm": 1.3954805135726929,
      "learning_rate": 8.22339489885664e-06,
      "loss": 0.0666,
      "step": 4175
    },
    {
      "epoch": 2.7546174142480213,
      "grad_norm": 1.1969655752182007,
      "learning_rate": 8.201407211961303e-06,
      "loss": 0.0717,
      "step": 4176
    },
    {
      "epoch": 2.755277044854881,
      "grad_norm": 1.8773548603057861,
      "learning_rate": 8.179419525065963e-06,
      "loss": 0.0654,
      "step": 4177
    },
    {
      "epoch": 2.7559366754617414,
      "grad_norm": 0.3373773396015167,
      "learning_rate": 8.157431838170625e-06,
      "loss": 0.0179,
      "step": 4178
    },
    {
      "epoch": 2.7565963060686016,
      "grad_norm": 18.24199104309082,
      "learning_rate": 8.135444151275286e-06,
      "loss": 0.5066,
      "step": 4179
    },
    {
      "epoch": 2.757255936675462,
      "grad_norm": 0.6130399703979492,
      "learning_rate": 8.113456464379948e-06,
      "loss": 0.0507,
      "step": 4180
    },
    {
      "epoch": 2.757915567282322,
      "grad_norm": 8.831269264221191,
      "learning_rate": 8.09146877748461e-06,
      "loss": 1.1448,
      "step": 4181
    },
    {
      "epoch": 2.758575197889182,
      "grad_norm": 0.6948719024658203,
      "learning_rate": 8.06948109058927e-06,
      "loss": 0.0397,
      "step": 4182
    },
    {
      "epoch": 2.759234828496042,
      "grad_norm": 9.600865364074707,
      "learning_rate": 8.047493403693932e-06,
      "loss": 0.1991,
      "step": 4183
    },
    {
      "epoch": 2.7598944591029024,
      "grad_norm": 0.973343014717102,
      "learning_rate": 8.025505716798592e-06,
      "loss": 0.0576,
      "step": 4184
    },
    {
      "epoch": 2.7605540897097627,
      "grad_norm": 31.884403228759766,
      "learning_rate": 8.003518029903255e-06,
      "loss": 0.4696,
      "step": 4185
    },
    {
      "epoch": 2.761213720316623,
      "grad_norm": 1.5376886129379272,
      "learning_rate": 7.981530343007917e-06,
      "loss": 0.0777,
      "step": 4186
    },
    {
      "epoch": 2.7618733509234827,
      "grad_norm": 1.2359075546264648,
      "learning_rate": 7.959542656112577e-06,
      "loss": 0.0507,
      "step": 4187
    },
    {
      "epoch": 2.762532981530343,
      "grad_norm": 1.1361565589904785,
      "learning_rate": 7.937554969217239e-06,
      "loss": 0.0316,
      "step": 4188
    },
    {
      "epoch": 2.7631926121372032,
      "grad_norm": 0.5343554019927979,
      "learning_rate": 7.915567282321901e-06,
      "loss": 0.0292,
      "step": 4189
    },
    {
      "epoch": 2.763852242744063,
      "grad_norm": 0.7648807168006897,
      "learning_rate": 7.893579595426561e-06,
      "loss": 0.0378,
      "step": 4190
    },
    {
      "epoch": 2.7645118733509237,
      "grad_norm": 12.810328483581543,
      "learning_rate": 7.871591908531224e-06,
      "loss": 0.2004,
      "step": 4191
    },
    {
      "epoch": 2.7651715039577835,
      "grad_norm": 1.5110180377960205,
      "learning_rate": 7.849604221635884e-06,
      "loss": 0.043,
      "step": 4192
    },
    {
      "epoch": 2.765831134564644,
      "grad_norm": 1.5448368787765503,
      "learning_rate": 7.827616534740544e-06,
      "loss": 0.0698,
      "step": 4193
    },
    {
      "epoch": 2.766490765171504,
      "grad_norm": 5.118042945861816,
      "learning_rate": 7.805628847845208e-06,
      "loss": 0.0939,
      "step": 4194
    },
    {
      "epoch": 2.767150395778364,
      "grad_norm": 0.5079075694084167,
      "learning_rate": 7.783641160949868e-06,
      "loss": 0.0184,
      "step": 4195
    },
    {
      "epoch": 2.767810026385224,
      "grad_norm": 18.04364585876465,
      "learning_rate": 7.76165347405453e-06,
      "loss": 1.3491,
      "step": 4196
    },
    {
      "epoch": 2.7684696569920844,
      "grad_norm": 8.287553787231445,
      "learning_rate": 7.73966578715919e-06,
      "loss": 0.163,
      "step": 4197
    },
    {
      "epoch": 2.7691292875989446,
      "grad_norm": 9.588727951049805,
      "learning_rate": 7.717678100263853e-06,
      "loss": 0.2347,
      "step": 4198
    },
    {
      "epoch": 2.769788918205805,
      "grad_norm": 0.6321183443069458,
      "learning_rate": 7.695690413368515e-06,
      "loss": 0.055,
      "step": 4199
    },
    {
      "epoch": 2.7704485488126647,
      "grad_norm": 0.6545335650444031,
      "learning_rate": 7.673702726473175e-06,
      "loss": 0.04,
      "step": 4200
    },
    {
      "epoch": 2.771108179419525,
      "grad_norm": 12.636637687683105,
      "learning_rate": 7.651715039577836e-06,
      "loss": 1.1681,
      "step": 4201
    },
    {
      "epoch": 2.771767810026385,
      "grad_norm": 6.1829729080200195,
      "learning_rate": 7.629727352682498e-06,
      "loss": 0.2933,
      "step": 4202
    },
    {
      "epoch": 2.7724274406332454,
      "grad_norm": 12.830732345581055,
      "learning_rate": 7.60773966578716e-06,
      "loss": 0.9653,
      "step": 4203
    },
    {
      "epoch": 2.7730870712401057,
      "grad_norm": 6.1088385581970215,
      "learning_rate": 7.585751978891821e-06,
      "loss": 0.0942,
      "step": 4204
    },
    {
      "epoch": 2.7737467018469655,
      "grad_norm": 39.19866943359375,
      "learning_rate": 7.563764291996482e-06,
      "loss": 0.3277,
      "step": 4205
    },
    {
      "epoch": 2.7744063324538257,
      "grad_norm": 1.2886343002319336,
      "learning_rate": 7.5417766051011435e-06,
      "loss": 0.0546,
      "step": 4206
    },
    {
      "epoch": 2.775065963060686,
      "grad_norm": 18.345722198486328,
      "learning_rate": 7.5197889182058055e-06,
      "loss": 0.2091,
      "step": 4207
    },
    {
      "epoch": 2.7757255936675462,
      "grad_norm": 13.91089916229248,
      "learning_rate": 7.497801231310467e-06,
      "loss": 0.7698,
      "step": 4208
    },
    {
      "epoch": 2.7763852242744065,
      "grad_norm": 1.8879103660583496,
      "learning_rate": 7.475813544415128e-06,
      "loss": 0.0848,
      "step": 4209
    },
    {
      "epoch": 2.7770448548812663,
      "grad_norm": 1.9335858821868896,
      "learning_rate": 7.453825857519789e-06,
      "loss": 0.0962,
      "step": 4210
    },
    {
      "epoch": 2.7777044854881265,
      "grad_norm": 1.8372312784194946,
      "learning_rate": 7.43183817062445e-06,
      "loss": 0.1007,
      "step": 4211
    },
    {
      "epoch": 2.778364116094987,
      "grad_norm": 9.177347183227539,
      "learning_rate": 7.4098504837291124e-06,
      "loss": 0.8716,
      "step": 4212
    },
    {
      "epoch": 2.779023746701847,
      "grad_norm": 0.6855614185333252,
      "learning_rate": 7.387862796833774e-06,
      "loss": 0.0359,
      "step": 4213
    },
    {
      "epoch": 2.7796833773087073,
      "grad_norm": 0.7978659868240356,
      "learning_rate": 7.365875109938435e-06,
      "loss": 0.0476,
      "step": 4214
    },
    {
      "epoch": 2.780343007915567,
      "grad_norm": 0.4757736623287201,
      "learning_rate": 7.343887423043096e-06,
      "loss": 0.0288,
      "step": 4215
    },
    {
      "epoch": 2.7810026385224274,
      "grad_norm": 7.189866542816162,
      "learning_rate": 7.321899736147758e-06,
      "loss": 0.1436,
      "step": 4216
    },
    {
      "epoch": 2.7816622691292876,
      "grad_norm": 1.9782599210739136,
      "learning_rate": 7.299912049252419e-06,
      "loss": 0.0974,
      "step": 4217
    },
    {
      "epoch": 2.782321899736148,
      "grad_norm": 0.6699399352073669,
      "learning_rate": 7.277924362357081e-06,
      "loss": 0.0341,
      "step": 4218
    },
    {
      "epoch": 2.782981530343008,
      "grad_norm": 4.800843715667725,
      "learning_rate": 7.255936675461741e-06,
      "loss": 0.061,
      "step": 4219
    },
    {
      "epoch": 2.783641160949868,
      "grad_norm": 0.7398062944412231,
      "learning_rate": 7.233948988566404e-06,
      "loss": 0.0367,
      "step": 4220
    },
    {
      "epoch": 2.784300791556728,
      "grad_norm": 1.2425556182861328,
      "learning_rate": 7.211961301671065e-06,
      "loss": 0.0669,
      "step": 4221
    },
    {
      "epoch": 2.7849604221635884,
      "grad_norm": 3.6291913986206055,
      "learning_rate": 7.189973614775726e-06,
      "loss": 0.1085,
      "step": 4222
    },
    {
      "epoch": 2.7856200527704487,
      "grad_norm": 2.9585609436035156,
      "learning_rate": 7.167985927880387e-06,
      "loss": 0.0726,
      "step": 4223
    },
    {
      "epoch": 2.786279683377309,
      "grad_norm": 1.4445675611495972,
      "learning_rate": 7.145998240985048e-06,
      "loss": 0.0808,
      "step": 4224
    },
    {
      "epoch": 2.7869393139841687,
      "grad_norm": 1.4324007034301758,
      "learning_rate": 7.124010554089711e-06,
      "loss": 0.0577,
      "step": 4225
    },
    {
      "epoch": 2.787598944591029,
      "grad_norm": 0.7353658080101013,
      "learning_rate": 7.102022867194372e-06,
      "loss": 0.0504,
      "step": 4226
    },
    {
      "epoch": 2.788258575197889,
      "grad_norm": 7.328855514526367,
      "learning_rate": 7.080035180299032e-06,
      "loss": 0.1335,
      "step": 4227
    },
    {
      "epoch": 2.7889182058047495,
      "grad_norm": 2.107761859893799,
      "learning_rate": 7.058047493403694e-06,
      "loss": 0.061,
      "step": 4228
    },
    {
      "epoch": 2.7895778364116097,
      "grad_norm": 5.983046531677246,
      "learning_rate": 7.0360598065083565e-06,
      "loss": 0.1461,
      "step": 4229
    },
    {
      "epoch": 2.7902374670184695,
      "grad_norm": 6.702214241027832,
      "learning_rate": 7.014072119613018e-06,
      "loss": 0.2365,
      "step": 4230
    },
    {
      "epoch": 2.79089709762533,
      "grad_norm": 6.934215068817139,
      "learning_rate": 6.992084432717678e-06,
      "loss": 0.1403,
      "step": 4231
    },
    {
      "epoch": 2.79155672823219,
      "grad_norm": 11.324487686157227,
      "learning_rate": 6.970096745822339e-06,
      "loss": 0.439,
      "step": 4232
    },
    {
      "epoch": 2.7922163588390503,
      "grad_norm": 0.40198132395744324,
      "learning_rate": 6.9481090589270005e-06,
      "loss": 0.0225,
      "step": 4233
    },
    {
      "epoch": 2.7928759894459105,
      "grad_norm": 11.503143310546875,
      "learning_rate": 6.9261213720316634e-06,
      "loss": 0.2617,
      "step": 4234
    },
    {
      "epoch": 2.7935356200527703,
      "grad_norm": 0.507171630859375,
      "learning_rate": 6.904133685136324e-06,
      "loss": 0.0349,
      "step": 4235
    },
    {
      "epoch": 2.7941952506596306,
      "grad_norm": 9.243334770202637,
      "learning_rate": 6.882145998240985e-06,
      "loss": 0.574,
      "step": 4236
    },
    {
      "epoch": 2.794854881266491,
      "grad_norm": 10.285351753234863,
      "learning_rate": 6.860158311345646e-06,
      "loss": 0.1609,
      "step": 4237
    },
    {
      "epoch": 2.7955145118733506,
      "grad_norm": 17.90302848815918,
      "learning_rate": 6.838170624450309e-06,
      "loss": 1.2234,
      "step": 4238
    },
    {
      "epoch": 2.7961741424802113,
      "grad_norm": 5.6715617179870605,
      "learning_rate": 6.8161829375549695e-06,
      "loss": 0.0878,
      "step": 4239
    },
    {
      "epoch": 2.796833773087071,
      "grad_norm": 0.601939857006073,
      "learning_rate": 6.794195250659631e-06,
      "loss": 0.0361,
      "step": 4240
    },
    {
      "epoch": 2.7974934036939314,
      "grad_norm": 1.22097647190094,
      "learning_rate": 6.772207563764292e-06,
      "loss": 0.0696,
      "step": 4241
    },
    {
      "epoch": 2.7981530343007917,
      "grad_norm": 6.938438415527344,
      "learning_rate": 6.750219876868953e-06,
      "loss": 0.3485,
      "step": 4242
    },
    {
      "epoch": 2.7988126649076515,
      "grad_norm": 1.549154281616211,
      "learning_rate": 6.728232189973615e-06,
      "loss": 0.067,
      "step": 4243
    },
    {
      "epoch": 2.7994722955145117,
      "grad_norm": 0.7717128992080688,
      "learning_rate": 6.7062445030782765e-06,
      "loss": 0.0341,
      "step": 4244
    },
    {
      "epoch": 2.800131926121372,
      "grad_norm": 1.848994255065918,
      "learning_rate": 6.684256816182938e-06,
      "loss": 0.0741,
      "step": 4245
    },
    {
      "epoch": 2.800791556728232,
      "grad_norm": 0.5000326037406921,
      "learning_rate": 6.662269129287599e-06,
      "loss": 0.04,
      "step": 4246
    },
    {
      "epoch": 2.8014511873350925,
      "grad_norm": 1.802245020866394,
      "learning_rate": 6.640281442392261e-06,
      "loss": 0.0714,
      "step": 4247
    },
    {
      "epoch": 2.8021108179419523,
      "grad_norm": 0.8491655588150024,
      "learning_rate": 6.618293755496922e-06,
      "loss": 0.0629,
      "step": 4248
    },
    {
      "epoch": 2.8027704485488125,
      "grad_norm": 13.966187477111816,
      "learning_rate": 6.596306068601583e-06,
      "loss": 0.9898,
      "step": 4249
    },
    {
      "epoch": 2.8034300791556728,
      "grad_norm": 0.7809112071990967,
      "learning_rate": 6.574318381706245e-06,
      "loss": 0.0243,
      "step": 4250
    },
    {
      "epoch": 2.804089709762533,
      "grad_norm": 0.9470016360282898,
      "learning_rate": 6.552330694810906e-06,
      "loss": 0.0458,
      "step": 4251
    },
    {
      "epoch": 2.8047493403693933,
      "grad_norm": 15.798662185668945,
      "learning_rate": 6.530343007915568e-06,
      "loss": 0.2687,
      "step": 4252
    },
    {
      "epoch": 2.805408970976253,
      "grad_norm": 1.2723928689956665,
      "learning_rate": 6.508355321020229e-06,
      "loss": 0.0563,
      "step": 4253
    },
    {
      "epoch": 2.8060686015831133,
      "grad_norm": 12.608989715576172,
      "learning_rate": 6.48636763412489e-06,
      "loss": 0.1533,
      "step": 4254
    },
    {
      "epoch": 2.8067282321899736,
      "grad_norm": 1.5042527914047241,
      "learning_rate": 6.4643799472295515e-06,
      "loss": 0.0738,
      "step": 4255
    },
    {
      "epoch": 2.807387862796834,
      "grad_norm": 0.7304202914237976,
      "learning_rate": 6.442392260334214e-06,
      "loss": 0.0549,
      "step": 4256
    },
    {
      "epoch": 2.808047493403694,
      "grad_norm": 1.9732162952423096,
      "learning_rate": 6.420404573438875e-06,
      "loss": 0.0414,
      "step": 4257
    },
    {
      "epoch": 2.808707124010554,
      "grad_norm": 0.5747766494750977,
      "learning_rate": 6.398416886543536e-06,
      "loss": 0.0557,
      "step": 4258
    },
    {
      "epoch": 2.809366754617414,
      "grad_norm": 24.72807502746582,
      "learning_rate": 6.376429199648197e-06,
      "loss": 0.3182,
      "step": 4259
    },
    {
      "epoch": 2.8100263852242744,
      "grad_norm": 23.849363327026367,
      "learning_rate": 6.3544415127528585e-06,
      "loss": 0.7399,
      "step": 4260
    },
    {
      "epoch": 2.8106860158311346,
      "grad_norm": 1.1382622718811035,
      "learning_rate": 6.3324538258575205e-06,
      "loss": 0.0671,
      "step": 4261
    },
    {
      "epoch": 2.811345646437995,
      "grad_norm": 0.8121193647384644,
      "learning_rate": 6.310466138962182e-06,
      "loss": 0.0443,
      "step": 4262
    },
    {
      "epoch": 2.8120052770448547,
      "grad_norm": 19.535114288330078,
      "learning_rate": 6.288478452066843e-06,
      "loss": 0.5358,
      "step": 4263
    },
    {
      "epoch": 2.812664907651715,
      "grad_norm": 0.729496419429779,
      "learning_rate": 6.266490765171504e-06,
      "loss": 0.0353,
      "step": 4264
    },
    {
      "epoch": 2.813324538258575,
      "grad_norm": 1.0707958936691284,
      "learning_rate": 6.244503078276165e-06,
      "loss": 0.0534,
      "step": 4265
    },
    {
      "epoch": 2.8139841688654355,
      "grad_norm": 23.45763397216797,
      "learning_rate": 6.2225153913808275e-06,
      "loss": 1.2516,
      "step": 4266
    },
    {
      "epoch": 2.8146437994722957,
      "grad_norm": 0.37371888756752014,
      "learning_rate": 6.200527704485489e-06,
      "loss": 0.0226,
      "step": 4267
    },
    {
      "epoch": 2.8153034300791555,
      "grad_norm": 9.011625289916992,
      "learning_rate": 6.17854001759015e-06,
      "loss": 0.2142,
      "step": 4268
    },
    {
      "epoch": 2.8159630606860158,
      "grad_norm": 6.903364658355713,
      "learning_rate": 6.156552330694811e-06,
      "loss": 0.0864,
      "step": 4269
    },
    {
      "epoch": 2.816622691292876,
      "grad_norm": 2.940230131149292,
      "learning_rate": 6.134564643799472e-06,
      "loss": 0.0772,
      "step": 4270
    },
    {
      "epoch": 2.8172823218997363,
      "grad_norm": 1.296878457069397,
      "learning_rate": 6.112576956904134e-06,
      "loss": 0.0689,
      "step": 4271
    },
    {
      "epoch": 2.8179419525065965,
      "grad_norm": 1.0721052885055542,
      "learning_rate": 6.090589270008796e-06,
      "loss": 0.0485,
      "step": 4272
    },
    {
      "epoch": 2.8186015831134563,
      "grad_norm": 16.3206729888916,
      "learning_rate": 6.068601583113457e-06,
      "loss": 0.451,
      "step": 4273
    },
    {
      "epoch": 2.8192612137203166,
      "grad_norm": 0.7365825772285461,
      "learning_rate": 6.046613896218118e-06,
      "loss": 0.0323,
      "step": 4274
    },
    {
      "epoch": 2.819920844327177,
      "grad_norm": 0.9818959832191467,
      "learning_rate": 6.02462620932278e-06,
      "loss": 0.0436,
      "step": 4275
    },
    {
      "epoch": 2.820580474934037,
      "grad_norm": 7.487669944763184,
      "learning_rate": 6.002638522427441e-06,
      "loss": 0.1273,
      "step": 4276
    },
    {
      "epoch": 2.8212401055408973,
      "grad_norm": 10.250042915344238,
      "learning_rate": 5.980650835532102e-06,
      "loss": 0.2009,
      "step": 4277
    },
    {
      "epoch": 2.821899736147757,
      "grad_norm": 12.407082557678223,
      "learning_rate": 5.958663148636764e-06,
      "loss": 0.6916,
      "step": 4278
    },
    {
      "epoch": 2.8225593667546174,
      "grad_norm": 1.1376173496246338,
      "learning_rate": 5.936675461741425e-06,
      "loss": 0.045,
      "step": 4279
    },
    {
      "epoch": 2.8232189973614776,
      "grad_norm": 2.9845266342163086,
      "learning_rate": 5.914687774846087e-06,
      "loss": 0.1036,
      "step": 4280
    },
    {
      "epoch": 2.823878627968338,
      "grad_norm": 20.80297088623047,
      "learning_rate": 5.892700087950747e-06,
      "loss": 0.8912,
      "step": 4281
    },
    {
      "epoch": 2.824538258575198,
      "grad_norm": 3.9139926433563232,
      "learning_rate": 5.8707124010554095e-06,
      "loss": 0.076,
      "step": 4282
    },
    {
      "epoch": 2.825197889182058,
      "grad_norm": 5.881306171417236,
      "learning_rate": 5.848724714160071e-06,
      "loss": 0.1028,
      "step": 4283
    },
    {
      "epoch": 2.825857519788918,
      "grad_norm": 7.428694725036621,
      "learning_rate": 5.826737027264732e-06,
      "loss": 0.1094,
      "step": 4284
    },
    {
      "epoch": 2.8265171503957784,
      "grad_norm": 2.2563741207122803,
      "learning_rate": 5.804749340369393e-06,
      "loss": 0.1081,
      "step": 4285
    },
    {
      "epoch": 2.8271767810026383,
      "grad_norm": 34.022727966308594,
      "learning_rate": 5.782761653474054e-06,
      "loss": 0.4507,
      "step": 4286
    },
    {
      "epoch": 2.827836411609499,
      "grad_norm": 0.8422161936759949,
      "learning_rate": 5.760773966578716e-06,
      "loss": 0.0488,
      "step": 4287
    },
    {
      "epoch": 2.8284960422163588,
      "grad_norm": 5.370995044708252,
      "learning_rate": 5.738786279683378e-06,
      "loss": 0.2025,
      "step": 4288
    },
    {
      "epoch": 2.829155672823219,
      "grad_norm": 1.6038562059402466,
      "learning_rate": 5.716798592788039e-06,
      "loss": 0.0537,
      "step": 4289
    },
    {
      "epoch": 2.8298153034300793,
      "grad_norm": 0.6234001517295837,
      "learning_rate": 5.6948109058927e-06,
      "loss": 0.0418,
      "step": 4290
    },
    {
      "epoch": 2.830474934036939,
      "grad_norm": 5.577504634857178,
      "learning_rate": 5.672823218997362e-06,
      "loss": 0.0986,
      "step": 4291
    },
    {
      "epoch": 2.8311345646437993,
      "grad_norm": 1.3293966054916382,
      "learning_rate": 5.650835532102023e-06,
      "loss": 0.0903,
      "step": 4292
    },
    {
      "epoch": 2.8317941952506596,
      "grad_norm": 0.5793265700340271,
      "learning_rate": 5.6288478452066845e-06,
      "loss": 0.0273,
      "step": 4293
    },
    {
      "epoch": 2.83245382585752,
      "grad_norm": 5.356605529785156,
      "learning_rate": 5.606860158311346e-06,
      "loss": 0.1002,
      "step": 4294
    },
    {
      "epoch": 2.83311345646438,
      "grad_norm": 7.144900321960449,
      "learning_rate": 5.584872471416008e-06,
      "loss": 0.0864,
      "step": 4295
    },
    {
      "epoch": 2.83377308707124,
      "grad_norm": 24.074737548828125,
      "learning_rate": 5.562884784520669e-06,
      "loss": 0.8035,
      "step": 4296
    },
    {
      "epoch": 2.8344327176781,
      "grad_norm": 1.5775415897369385,
      "learning_rate": 5.540897097625329e-06,
      "loss": 0.0708,
      "step": 4297
    },
    {
      "epoch": 2.8350923482849604,
      "grad_norm": 3.505878448486328,
      "learning_rate": 5.5189094107299915e-06,
      "loss": 0.068,
      "step": 4298
    },
    {
      "epoch": 2.8357519788918206,
      "grad_norm": 2.4148120880126953,
      "learning_rate": 5.496921723834653e-06,
      "loss": 0.0887,
      "step": 4299
    },
    {
      "epoch": 2.836411609498681,
      "grad_norm": 1.4353337287902832,
      "learning_rate": 5.474934036939315e-06,
      "loss": 0.0624,
      "step": 4300
    },
    {
      "epoch": 2.8370712401055407,
      "grad_norm": 2.361323118209839,
      "learning_rate": 5.452946350043975e-06,
      "loss": 0.1171,
      "step": 4301
    },
    {
      "epoch": 2.837730870712401,
      "grad_norm": 14.514204025268555,
      "learning_rate": 5.430958663148637e-06,
      "loss": 0.5961,
      "step": 4302
    },
    {
      "epoch": 2.838390501319261,
      "grad_norm": 1.2950955629348755,
      "learning_rate": 5.408970976253298e-06,
      "loss": 0.083,
      "step": 4303
    },
    {
      "epoch": 2.8390501319261214,
      "grad_norm": 7.632556438446045,
      "learning_rate": 5.3869832893579605e-06,
      "loss": 0.1241,
      "step": 4304
    },
    {
      "epoch": 2.8397097625329817,
      "grad_norm": 15.672579765319824,
      "learning_rate": 5.364995602462621e-06,
      "loss": 0.257,
      "step": 4305
    },
    {
      "epoch": 2.8403693931398415,
      "grad_norm": 15.1185884475708,
      "learning_rate": 5.343007915567282e-06,
      "loss": 0.3883,
      "step": 4306
    },
    {
      "epoch": 2.8410290237467017,
      "grad_norm": 1.7813124656677246,
      "learning_rate": 5.321020228671944e-06,
      "loss": 0.0749,
      "step": 4307
    },
    {
      "epoch": 2.841688654353562,
      "grad_norm": 1.7807536125183105,
      "learning_rate": 5.299032541776605e-06,
      "loss": 0.068,
      "step": 4308
    },
    {
      "epoch": 2.8423482849604222,
      "grad_norm": 6.698299407958984,
      "learning_rate": 5.2770448548812665e-06,
      "loss": 0.2329,
      "step": 4309
    },
    {
      "epoch": 2.8430079155672825,
      "grad_norm": 0.5484076142311096,
      "learning_rate": 5.255057167985928e-06,
      "loss": 0.0221,
      "step": 4310
    },
    {
      "epoch": 2.8436675461741423,
      "grad_norm": 1.2373169660568237,
      "learning_rate": 5.23306948109059e-06,
      "loss": 0.0535,
      "step": 4311
    },
    {
      "epoch": 2.8443271767810026,
      "grad_norm": 15.446581840515137,
      "learning_rate": 5.211081794195251e-06,
      "loss": 1.0351,
      "step": 4312
    },
    {
      "epoch": 2.844986807387863,
      "grad_norm": 1.0552576780319214,
      "learning_rate": 5.189094107299912e-06,
      "loss": 0.0676,
      "step": 4313
    },
    {
      "epoch": 2.845646437994723,
      "grad_norm": 20.36158561706543,
      "learning_rate": 5.1671064204045735e-06,
      "loss": 0.9494,
      "step": 4314
    },
    {
      "epoch": 2.8463060686015833,
      "grad_norm": 6.706544399261475,
      "learning_rate": 5.145118733509235e-06,
      "loss": 0.3231,
      "step": 4315
    },
    {
      "epoch": 2.846965699208443,
      "grad_norm": 11.929997444152832,
      "learning_rate": 5.123131046613897e-06,
      "loss": 0.8271,
      "step": 4316
    },
    {
      "epoch": 2.8476253298153034,
      "grad_norm": 1.126430630683899,
      "learning_rate": 5.101143359718558e-06,
      "loss": 0.0485,
      "step": 4317
    },
    {
      "epoch": 2.8482849604221636,
      "grad_norm": 0.5795262455940247,
      "learning_rate": 5.079155672823219e-06,
      "loss": 0.0319,
      "step": 4318
    },
    {
      "epoch": 2.848944591029024,
      "grad_norm": 14.045674324035645,
      "learning_rate": 5.05716798592788e-06,
      "loss": 0.2581,
      "step": 4319
    },
    {
      "epoch": 2.849604221635884,
      "grad_norm": 1.6494985818862915,
      "learning_rate": 5.0351802990325425e-06,
      "loss": 0.0531,
      "step": 4320
    },
    {
      "epoch": 2.850263852242744,
      "grad_norm": 3.243570566177368,
      "learning_rate": 5.013192612137204e-06,
      "loss": 0.0602,
      "step": 4321
    },
    {
      "epoch": 2.850923482849604,
      "grad_norm": 8.754061698913574,
      "learning_rate": 4.991204925241865e-06,
      "loss": 0.2512,
      "step": 4322
    },
    {
      "epoch": 2.8515831134564644,
      "grad_norm": 1.3742785453796387,
      "learning_rate": 4.969217238346526e-06,
      "loss": 0.0715,
      "step": 4323
    },
    {
      "epoch": 2.8522427440633247,
      "grad_norm": 0.8257945775985718,
      "learning_rate": 4.947229551451187e-06,
      "loss": 0.057,
      "step": 4324
    },
    {
      "epoch": 2.852902374670185,
      "grad_norm": 3.3470635414123535,
      "learning_rate": 4.925241864555849e-06,
      "loss": 0.0747,
      "step": 4325
    },
    {
      "epoch": 2.8535620052770447,
      "grad_norm": 3.0917747020721436,
      "learning_rate": 4.90325417766051e-06,
      "loss": 0.0783,
      "step": 4326
    },
    {
      "epoch": 2.854221635883905,
      "grad_norm": 0.8475444316864014,
      "learning_rate": 4.881266490765172e-06,
      "loss": 0.0509,
      "step": 4327
    },
    {
      "epoch": 2.8548812664907652,
      "grad_norm": 1.049940586090088,
      "learning_rate": 4.859278803869833e-06,
      "loss": 0.0345,
      "step": 4328
    },
    {
      "epoch": 2.8555408970976255,
      "grad_norm": 1.0317037105560303,
      "learning_rate": 4.837291116974495e-06,
      "loss": 0.0767,
      "step": 4329
    },
    {
      "epoch": 2.8562005277044857,
      "grad_norm": 1.4977107048034668,
      "learning_rate": 4.8153034300791555e-06,
      "loss": 0.056,
      "step": 4330
    },
    {
      "epoch": 2.8568601583113455,
      "grad_norm": 16.058361053466797,
      "learning_rate": 4.7933157431838175e-06,
      "loss": 1.2255,
      "step": 4331
    },
    {
      "epoch": 2.857519788918206,
      "grad_norm": 12.696364402770996,
      "learning_rate": 4.771328056288479e-06,
      "loss": 0.5615,
      "step": 4332
    },
    {
      "epoch": 2.858179419525066,
      "grad_norm": 4.138056755065918,
      "learning_rate": 4.74934036939314e-06,
      "loss": 0.1454,
      "step": 4333
    },
    {
      "epoch": 2.858839050131926,
      "grad_norm": 0.7955517768859863,
      "learning_rate": 4.727352682497801e-06,
      "loss": 0.0684,
      "step": 4334
    },
    {
      "epoch": 2.8594986807387865,
      "grad_norm": 9.00228500366211,
      "learning_rate": 4.705364995602462e-06,
      "loss": 0.2425,
      "step": 4335
    },
    {
      "epoch": 2.8601583113456464,
      "grad_norm": 5.544694900512695,
      "learning_rate": 4.6833773087071245e-06,
      "loss": 0.1307,
      "step": 4336
    },
    {
      "epoch": 2.8608179419525066,
      "grad_norm": 20.41557502746582,
      "learning_rate": 4.661389621811786e-06,
      "loss": 0.2998,
      "step": 4337
    },
    {
      "epoch": 2.861477572559367,
      "grad_norm": 34.02547073364258,
      "learning_rate": 4.639401934916447e-06,
      "loss": 0.5583,
      "step": 4338
    },
    {
      "epoch": 2.8621372031662267,
      "grad_norm": 11.418725967407227,
      "learning_rate": 4.617414248021108e-06,
      "loss": 0.1821,
      "step": 4339
    },
    {
      "epoch": 2.862796833773087,
      "grad_norm": 6.358649253845215,
      "learning_rate": 4.59542656112577e-06,
      "loss": 0.1308,
      "step": 4340
    },
    {
      "epoch": 2.863456464379947,
      "grad_norm": 0.7704457640647888,
      "learning_rate": 4.573438874230431e-06,
      "loss": 0.0424,
      "step": 4341
    },
    {
      "epoch": 2.8641160949868074,
      "grad_norm": 1.130914330482483,
      "learning_rate": 4.551451187335093e-06,
      "loss": 0.061,
      "step": 4342
    },
    {
      "epoch": 2.8647757255936677,
      "grad_norm": 0.6677780747413635,
      "learning_rate": 4.529463500439754e-06,
      "loss": 0.0417,
      "step": 4343
    },
    {
      "epoch": 2.8654353562005275,
      "grad_norm": 1.8720197677612305,
      "learning_rate": 4.507475813544415e-06,
      "loss": 0.1061,
      "step": 4344
    },
    {
      "epoch": 2.8660949868073877,
      "grad_norm": 0.9255901575088501,
      "learning_rate": 4.485488126649077e-06,
      "loss": 0.0439,
      "step": 4345
    },
    {
      "epoch": 2.866754617414248,
      "grad_norm": 0.6724576950073242,
      "learning_rate": 4.463500439753738e-06,
      "loss": 0.0337,
      "step": 4346
    },
    {
      "epoch": 2.8674142480211082,
      "grad_norm": 9.783279418945312,
      "learning_rate": 4.4415127528583995e-06,
      "loss": 0.1636,
      "step": 4347
    },
    {
      "epoch": 2.8680738786279685,
      "grad_norm": 1.407001256942749,
      "learning_rate": 4.419525065963061e-06,
      "loss": 0.0792,
      "step": 4348
    },
    {
      "epoch": 2.8687335092348283,
      "grad_norm": 3.2382805347442627,
      "learning_rate": 4.397537379067723e-06,
      "loss": 0.1293,
      "step": 4349
    },
    {
      "epoch": 2.8693931398416885,
      "grad_norm": 0.7036117315292358,
      "learning_rate": 4.375549692172383e-06,
      "loss": 0.0422,
      "step": 4350
    },
    {
      "epoch": 2.870052770448549,
      "grad_norm": 0.41493162512779236,
      "learning_rate": 4.353562005277045e-06,
      "loss": 0.0327,
      "step": 4351
    },
    {
      "epoch": 2.870712401055409,
      "grad_norm": 0.9507851600646973,
      "learning_rate": 4.3315743183817065e-06,
      "loss": 0.0405,
      "step": 4352
    },
    {
      "epoch": 2.8713720316622693,
      "grad_norm": 0.47237464785575867,
      "learning_rate": 4.309586631486368e-06,
      "loss": 0.0401,
      "step": 4353
    },
    {
      "epoch": 2.872031662269129,
      "grad_norm": 20.48341941833496,
      "learning_rate": 4.287598944591029e-06,
      "loss": 0.4699,
      "step": 4354
    },
    {
      "epoch": 2.8726912928759893,
      "grad_norm": 0.42445656657218933,
      "learning_rate": 4.26561125769569e-06,
      "loss": 0.0209,
      "step": 4355
    },
    {
      "epoch": 2.8733509234828496,
      "grad_norm": 0.8017374873161316,
      "learning_rate": 4.243623570800352e-06,
      "loss": 0.0549,
      "step": 4356
    },
    {
      "epoch": 2.87401055408971,
      "grad_norm": 0.6001380085945129,
      "learning_rate": 4.221635883905013e-06,
      "loss": 0.0347,
      "step": 4357
    },
    {
      "epoch": 2.87467018469657,
      "grad_norm": 0.6494858860969543,
      "learning_rate": 4.199648197009675e-06,
      "loss": 0.0355,
      "step": 4358
    },
    {
      "epoch": 2.87532981530343,
      "grad_norm": 2.2578117847442627,
      "learning_rate": 4.177660510114336e-06,
      "loss": 0.0656,
      "step": 4359
    },
    {
      "epoch": 2.87598944591029,
      "grad_norm": 10.423996925354004,
      "learning_rate": 4.155672823218998e-06,
      "loss": 0.2004,
      "step": 4360
    },
    {
      "epoch": 2.8766490765171504,
      "grad_norm": 10.494255065917969,
      "learning_rate": 4.133685136323659e-06,
      "loss": 0.4836,
      "step": 4361
    },
    {
      "epoch": 2.8773087071240107,
      "grad_norm": 3.353480815887451,
      "learning_rate": 4.11169744942832e-06,
      "loss": 0.12,
      "step": 4362
    },
    {
      "epoch": 2.877968337730871,
      "grad_norm": 1.02631676197052,
      "learning_rate": 4.0897097625329815e-06,
      "loss": 0.0477,
      "step": 4363
    },
    {
      "epoch": 2.8786279683377307,
      "grad_norm": 4.185856342315674,
      "learning_rate": 4.067722075637643e-06,
      "loss": 0.0614,
      "step": 4364
    },
    {
      "epoch": 2.879287598944591,
      "grad_norm": 0.4996850788593292,
      "learning_rate": 4.045734388742305e-06,
      "loss": 0.035,
      "step": 4365
    },
    {
      "epoch": 2.879947229551451,
      "grad_norm": 1.0599597692489624,
      "learning_rate": 4.023746701846966e-06,
      "loss": 0.07,
      "step": 4366
    },
    {
      "epoch": 2.8806068601583115,
      "grad_norm": 0.8816585540771484,
      "learning_rate": 4.001759014951627e-06,
      "loss": 0.0439,
      "step": 4367
    },
    {
      "epoch": 2.8812664907651717,
      "grad_norm": 1.2625715732574463,
      "learning_rate": 3.9797713280562885e-06,
      "loss": 0.0409,
      "step": 4368
    },
    {
      "epoch": 2.8819261213720315,
      "grad_norm": 11.94681167602539,
      "learning_rate": 3.9577836411609505e-06,
      "loss": 0.4728,
      "step": 4369
    },
    {
      "epoch": 2.8825857519788918,
      "grad_norm": 1.7781122922897339,
      "learning_rate": 3.935795954265612e-06,
      "loss": 0.0663,
      "step": 4370
    },
    {
      "epoch": 2.883245382585752,
      "grad_norm": 0.5708494782447815,
      "learning_rate": 3.913808267370272e-06,
      "loss": 0.0254,
      "step": 4371
    },
    {
      "epoch": 2.8839050131926123,
      "grad_norm": 7.926267147064209,
      "learning_rate": 3.891820580474934e-06,
      "loss": 0.209,
      "step": 4372
    },
    {
      "epoch": 2.8845646437994725,
      "grad_norm": 0.8472442626953125,
      "learning_rate": 3.869832893579595e-06,
      "loss": 0.0517,
      "step": 4373
    },
    {
      "epoch": 2.8852242744063323,
      "grad_norm": 9.262325286865234,
      "learning_rate": 3.8478452066842575e-06,
      "loss": 0.1097,
      "step": 4374
    },
    {
      "epoch": 2.8858839050131926,
      "grad_norm": 26.8573055267334,
      "learning_rate": 3.825857519788918e-06,
      "loss": 0.5143,
      "step": 4375
    },
    {
      "epoch": 2.886543535620053,
      "grad_norm": 0.6474432349205017,
      "learning_rate": 3.80386983289358e-06,
      "loss": 0.0384,
      "step": 4376
    },
    {
      "epoch": 2.887203166226913,
      "grad_norm": 12.072564125061035,
      "learning_rate": 3.781882145998241e-06,
      "loss": 0.2105,
      "step": 4377
    },
    {
      "epoch": 2.8878627968337733,
      "grad_norm": 1.0884153842926025,
      "learning_rate": 3.7598944591029028e-06,
      "loss": 0.0447,
      "step": 4378
    },
    {
      "epoch": 2.888522427440633,
      "grad_norm": 19.04127311706543,
      "learning_rate": 3.737906772207564e-06,
      "loss": 1.0035,
      "step": 4379
    },
    {
      "epoch": 2.8891820580474934,
      "grad_norm": 11.221268653869629,
      "learning_rate": 3.715919085312225e-06,
      "loss": 0.1565,
      "step": 4380
    },
    {
      "epoch": 2.8898416886543536,
      "grad_norm": 0.7140462398529053,
      "learning_rate": 3.693931398416887e-06,
      "loss": 0.0389,
      "step": 4381
    },
    {
      "epoch": 2.8905013192612135,
      "grad_norm": 4.999077796936035,
      "learning_rate": 3.671943711521548e-06,
      "loss": 0.1283,
      "step": 4382
    },
    {
      "epoch": 2.891160949868074,
      "grad_norm": 0.9727143049240112,
      "learning_rate": 3.6499560246262097e-06,
      "loss": 0.0308,
      "step": 4383
    },
    {
      "epoch": 2.891820580474934,
      "grad_norm": 1.5272263288497925,
      "learning_rate": 3.6279683377308705e-06,
      "loss": 0.0382,
      "step": 4384
    },
    {
      "epoch": 2.892480211081794,
      "grad_norm": 9.030388832092285,
      "learning_rate": 3.6059806508355325e-06,
      "loss": 0.158,
      "step": 4385
    },
    {
      "epoch": 2.8931398416886545,
      "grad_norm": 0.9093332290649414,
      "learning_rate": 3.5839929639401933e-06,
      "loss": 0.0368,
      "step": 4386
    },
    {
      "epoch": 2.8937994722955143,
      "grad_norm": 14.807764053344727,
      "learning_rate": 3.5620052770448554e-06,
      "loss": 0.266,
      "step": 4387
    },
    {
      "epoch": 2.8944591029023745,
      "grad_norm": 0.6556572914123535,
      "learning_rate": 3.540017590149516e-06,
      "loss": 0.0465,
      "step": 4388
    },
    {
      "epoch": 2.8951187335092348,
      "grad_norm": 0.7104672789573669,
      "learning_rate": 3.5180299032541783e-06,
      "loss": 0.0362,
      "step": 4389
    },
    {
      "epoch": 2.895778364116095,
      "grad_norm": 0.5222808122634888,
      "learning_rate": 3.496042216358839e-06,
      "loss": 0.0258,
      "step": 4390
    },
    {
      "epoch": 2.8964379947229553,
      "grad_norm": 0.5741010904312134,
      "learning_rate": 3.4740545294635003e-06,
      "loss": 0.0258,
      "step": 4391
    },
    {
      "epoch": 2.897097625329815,
      "grad_norm": 10.680229187011719,
      "learning_rate": 3.452066842568162e-06,
      "loss": 0.8295,
      "step": 4392
    },
    {
      "epoch": 2.8977572559366753,
      "grad_norm": 0.9300556778907776,
      "learning_rate": 3.430079155672823e-06,
      "loss": 0.0404,
      "step": 4393
    },
    {
      "epoch": 2.8984168865435356,
      "grad_norm": 2.6481680870056152,
      "learning_rate": 3.4080914687774848e-06,
      "loss": 0.1034,
      "step": 4394
    },
    {
      "epoch": 2.899076517150396,
      "grad_norm": 0.9574835896492004,
      "learning_rate": 3.386103781882146e-06,
      "loss": 0.0443,
      "step": 4395
    },
    {
      "epoch": 2.899736147757256,
      "grad_norm": 20.25326919555664,
      "learning_rate": 3.3641160949868076e-06,
      "loss": 0.1668,
      "step": 4396
    },
    {
      "epoch": 2.900395778364116,
      "grad_norm": 1.3395568132400513,
      "learning_rate": 3.342128408091469e-06,
      "loss": 0.0747,
      "step": 4397
    },
    {
      "epoch": 2.901055408970976,
      "grad_norm": 0.991013765335083,
      "learning_rate": 3.3201407211961305e-06,
      "loss": 0.0394,
      "step": 4398
    },
    {
      "epoch": 2.9017150395778364,
      "grad_norm": 1.0895583629608154,
      "learning_rate": 3.2981530343007917e-06,
      "loss": 0.0665,
      "step": 4399
    },
    {
      "epoch": 2.9023746701846966,
      "grad_norm": 17.549875259399414,
      "learning_rate": 3.276165347405453e-06,
      "loss": 0.2181,
      "step": 4400
    },
    {
      "epoch": 2.903034300791557,
      "grad_norm": 3.768018960952759,
      "learning_rate": 3.2541776605101146e-06,
      "loss": 0.0656,
      "step": 4401
    },
    {
      "epoch": 2.9036939313984167,
      "grad_norm": 0.776578962802887,
      "learning_rate": 3.2321899736147758e-06,
      "loss": 0.0552,
      "step": 4402
    },
    {
      "epoch": 2.904353562005277,
      "grad_norm": 1.1088268756866455,
      "learning_rate": 3.2102022867194374e-06,
      "loss": 0.0488,
      "step": 4403
    },
    {
      "epoch": 2.905013192612137,
      "grad_norm": 7.711610317230225,
      "learning_rate": 3.1882145998240986e-06,
      "loss": 0.1558,
      "step": 4404
    },
    {
      "epoch": 2.9056728232189974,
      "grad_norm": 0.9448685646057129,
      "learning_rate": 3.1662269129287603e-06,
      "loss": 0.0479,
      "step": 4405
    },
    {
      "epoch": 2.9063324538258577,
      "grad_norm": 128.7686004638672,
      "learning_rate": 3.1442392260334215e-06,
      "loss": 0.3468,
      "step": 4406
    },
    {
      "epoch": 2.9069920844327175,
      "grad_norm": 28.303632736206055,
      "learning_rate": 3.1222515391380827e-06,
      "loss": 0.9599,
      "step": 4407
    },
    {
      "epoch": 2.9076517150395778,
      "grad_norm": 1.0764766931533813,
      "learning_rate": 3.1002638522427443e-06,
      "loss": 0.0412,
      "step": 4408
    },
    {
      "epoch": 2.908311345646438,
      "grad_norm": 1.7580170631408691,
      "learning_rate": 3.0782761653474056e-06,
      "loss": 0.0739,
      "step": 4409
    },
    {
      "epoch": 2.9089709762532983,
      "grad_norm": 0.917780339717865,
      "learning_rate": 3.056288478452067e-06,
      "loss": 0.025,
      "step": 4410
    },
    {
      "epoch": 2.9096306068601585,
      "grad_norm": 13.890260696411133,
      "learning_rate": 3.0343007915567284e-06,
      "loss": 0.2527,
      "step": 4411
    },
    {
      "epoch": 2.9102902374670183,
      "grad_norm": 0.409993052482605,
      "learning_rate": 3.01231310466139e-06,
      "loss": 0.0271,
      "step": 4412
    },
    {
      "epoch": 2.9109498680738786,
      "grad_norm": 1.3217295408248901,
      "learning_rate": 2.990325417766051e-06,
      "loss": 0.0446,
      "step": 4413
    },
    {
      "epoch": 2.911609498680739,
      "grad_norm": 1.1187196969985962,
      "learning_rate": 2.9683377308707125e-06,
      "loss": 0.0417,
      "step": 4414
    },
    {
      "epoch": 2.912269129287599,
      "grad_norm": 0.9412946701049805,
      "learning_rate": 2.9463500439753737e-06,
      "loss": 0.0403,
      "step": 4415
    },
    {
      "epoch": 2.9129287598944593,
      "grad_norm": 0.6874889731407166,
      "learning_rate": 2.9243623570800353e-06,
      "loss": 0.0515,
      "step": 4416
    },
    {
      "epoch": 2.913588390501319,
      "grad_norm": 18.099048614501953,
      "learning_rate": 2.9023746701846966e-06,
      "loss": 0.9527,
      "step": 4417
    },
    {
      "epoch": 2.9142480211081794,
      "grad_norm": 0.8358800411224365,
      "learning_rate": 2.880386983289358e-06,
      "loss": 0.0288,
      "step": 4418
    },
    {
      "epoch": 2.9149076517150396,
      "grad_norm": 1.3158526420593262,
      "learning_rate": 2.8583992963940194e-06,
      "loss": 0.054,
      "step": 4419
    },
    {
      "epoch": 2.9155672823219,
      "grad_norm": 1.0546647310256958,
      "learning_rate": 2.836411609498681e-06,
      "loss": 0.0507,
      "step": 4420
    },
    {
      "epoch": 2.91622691292876,
      "grad_norm": 0.7397642135620117,
      "learning_rate": 2.8144239226033423e-06,
      "loss": 0.026,
      "step": 4421
    },
    {
      "epoch": 2.91688654353562,
      "grad_norm": 0.6343376040458679,
      "learning_rate": 2.792436235708004e-06,
      "loss": 0.0244,
      "step": 4422
    },
    {
      "epoch": 2.91754617414248,
      "grad_norm": 14.822649002075195,
      "learning_rate": 2.7704485488126647e-06,
      "loss": 0.1902,
      "step": 4423
    },
    {
      "epoch": 2.9182058047493404,
      "grad_norm": 33.42576599121094,
      "learning_rate": 2.7484608619173263e-06,
      "loss": 0.364,
      "step": 4424
    },
    {
      "epoch": 2.9188654353562007,
      "grad_norm": 14.236412048339844,
      "learning_rate": 2.7264731750219876e-06,
      "loss": 0.3181,
      "step": 4425
    },
    {
      "epoch": 2.919525065963061,
      "grad_norm": 0.4345302879810333,
      "learning_rate": 2.704485488126649e-06,
      "loss": 0.0178,
      "step": 4426
    },
    {
      "epoch": 2.9201846965699207,
      "grad_norm": 0.8455691933631897,
      "learning_rate": 2.6824978012313104e-06,
      "loss": 0.0419,
      "step": 4427
    },
    {
      "epoch": 2.920844327176781,
      "grad_norm": 13.342803955078125,
      "learning_rate": 2.660510114335972e-06,
      "loss": 0.4659,
      "step": 4428
    },
    {
      "epoch": 2.9215039577836412,
      "grad_norm": 4.025193214416504,
      "learning_rate": 2.6385224274406333e-06,
      "loss": 0.0578,
      "step": 4429
    },
    {
      "epoch": 2.922163588390501,
      "grad_norm": 14.64498519897461,
      "learning_rate": 2.616534740545295e-06,
      "loss": 0.9614,
      "step": 4430
    },
    {
      "epoch": 2.9228232189973617,
      "grad_norm": 4.6232476234436035,
      "learning_rate": 2.594547053649956e-06,
      "loss": 0.1162,
      "step": 4431
    },
    {
      "epoch": 2.9234828496042216,
      "grad_norm": 13.024150848388672,
      "learning_rate": 2.5725593667546173e-06,
      "loss": 0.3938,
      "step": 4432
    },
    {
      "epoch": 2.924142480211082,
      "grad_norm": 27.69007682800293,
      "learning_rate": 2.550571679859279e-06,
      "loss": 0.2969,
      "step": 4433
    },
    {
      "epoch": 2.924802110817942,
      "grad_norm": 10.320252418518066,
      "learning_rate": 2.52858399296394e-06,
      "loss": 0.1724,
      "step": 4434
    },
    {
      "epoch": 2.925461741424802,
      "grad_norm": 1.211069107055664,
      "learning_rate": 2.506596306068602e-06,
      "loss": 0.0657,
      "step": 4435
    },
    {
      "epoch": 2.926121372031662,
      "grad_norm": 0.8051864504814148,
      "learning_rate": 2.484608619173263e-06,
      "loss": 0.0536,
      "step": 4436
    },
    {
      "epoch": 2.9267810026385224,
      "grad_norm": 0.6843630075454712,
      "learning_rate": 2.4626209322779247e-06,
      "loss": 0.0319,
      "step": 4437
    },
    {
      "epoch": 2.9274406332453826,
      "grad_norm": 8.470593452453613,
      "learning_rate": 2.440633245382586e-06,
      "loss": 0.9762,
      "step": 4438
    },
    {
      "epoch": 2.928100263852243,
      "grad_norm": 22.312654495239258,
      "learning_rate": 2.4186455584872476e-06,
      "loss": 0.6351,
      "step": 4439
    },
    {
      "epoch": 2.9287598944591027,
      "grad_norm": 0.8526325821876526,
      "learning_rate": 2.3966578715919088e-06,
      "loss": 0.0347,
      "step": 4440
    },
    {
      "epoch": 2.929419525065963,
      "grad_norm": 0.7834629416465759,
      "learning_rate": 2.37467018469657e-06,
      "loss": 0.0531,
      "step": 4441
    },
    {
      "epoch": 2.930079155672823,
      "grad_norm": 2.4535179138183594,
      "learning_rate": 2.352682497801231e-06,
      "loss": 0.071,
      "step": 4442
    },
    {
      "epoch": 2.9307387862796834,
      "grad_norm": 16.989416122436523,
      "learning_rate": 2.330694810905893e-06,
      "loss": 0.1881,
      "step": 4443
    },
    {
      "epoch": 2.9313984168865437,
      "grad_norm": 0.9805123805999756,
      "learning_rate": 2.308707124010554e-06,
      "loss": 0.0478,
      "step": 4444
    },
    {
      "epoch": 2.9320580474934035,
      "grad_norm": 6.7498345375061035,
      "learning_rate": 2.2867194371152157e-06,
      "loss": 0.0788,
      "step": 4445
    },
    {
      "epoch": 2.9327176781002637,
      "grad_norm": 9.506508827209473,
      "learning_rate": 2.264731750219877e-06,
      "loss": 0.1264,
      "step": 4446
    },
    {
      "epoch": 2.933377308707124,
      "grad_norm": 9.469369888305664,
      "learning_rate": 2.2427440633245386e-06,
      "loss": 0.1716,
      "step": 4447
    },
    {
      "epoch": 2.9340369393139842,
      "grad_norm": 15.87729263305664,
      "learning_rate": 2.2207563764291998e-06,
      "loss": 0.6225,
      "step": 4448
    },
    {
      "epoch": 2.9346965699208445,
      "grad_norm": 0.5395317077636719,
      "learning_rate": 2.1987686895338614e-06,
      "loss": 0.0326,
      "step": 4449
    },
    {
      "epoch": 2.9353562005277043,
      "grad_norm": 5.314467430114746,
      "learning_rate": 2.1767810026385226e-06,
      "loss": 0.0689,
      "step": 4450
    },
    {
      "epoch": 2.9360158311345645,
      "grad_norm": 7.711124897003174,
      "learning_rate": 2.154793315743184e-06,
      "loss": 0.1855,
      "step": 4451
    },
    {
      "epoch": 2.936675461741425,
      "grad_norm": 1.268164038658142,
      "learning_rate": 2.132805628847845e-06,
      "loss": 0.0445,
      "step": 4452
    },
    {
      "epoch": 2.937335092348285,
      "grad_norm": 13.624227523803711,
      "learning_rate": 2.1108179419525067e-06,
      "loss": 0.5672,
      "step": 4453
    },
    {
      "epoch": 2.9379947229551453,
      "grad_norm": 2.4217612743377686,
      "learning_rate": 2.088830255057168e-06,
      "loss": 0.0567,
      "step": 4454
    },
    {
      "epoch": 2.938654353562005,
      "grad_norm": 0.5845551490783691,
      "learning_rate": 2.0668425681618296e-06,
      "loss": 0.0294,
      "step": 4455
    },
    {
      "epoch": 2.9393139841688654,
      "grad_norm": 2.9926793575286865,
      "learning_rate": 2.0448548812664908e-06,
      "loss": 0.0476,
      "step": 4456
    },
    {
      "epoch": 2.9399736147757256,
      "grad_norm": 0.6425532102584839,
      "learning_rate": 2.0228671943711524e-06,
      "loss": 0.0365,
      "step": 4457
    },
    {
      "epoch": 2.940633245382586,
      "grad_norm": 9.059599876403809,
      "learning_rate": 2.0008795074758136e-06,
      "loss": 0.2249,
      "step": 4458
    },
    {
      "epoch": 2.941292875989446,
      "grad_norm": 1.636047124862671,
      "learning_rate": 1.9788918205804753e-06,
      "loss": 0.0452,
      "step": 4459
    },
    {
      "epoch": 2.941952506596306,
      "grad_norm": 2.3517849445343018,
      "learning_rate": 1.956904133685136e-06,
      "loss": 0.0455,
      "step": 4460
    },
    {
      "epoch": 2.942612137203166,
      "grad_norm": 7.931294918060303,
      "learning_rate": 1.9349164467897977e-06,
      "loss": 0.1913,
      "step": 4461
    },
    {
      "epoch": 2.9432717678100264,
      "grad_norm": 22.38910484313965,
      "learning_rate": 1.912928759894459e-06,
      "loss": 0.3741,
      "step": 4462
    },
    {
      "epoch": 2.9439313984168867,
      "grad_norm": 1.00813627243042,
      "learning_rate": 1.8909410729991206e-06,
      "loss": 0.0557,
      "step": 4463
    },
    {
      "epoch": 2.944591029023747,
      "grad_norm": 4.289270401000977,
      "learning_rate": 1.868953386103782e-06,
      "loss": 0.0523,
      "step": 4464
    },
    {
      "epoch": 2.9452506596306067,
      "grad_norm": 9.374563217163086,
      "learning_rate": 1.8469656992084434e-06,
      "loss": 0.2471,
      "step": 4465
    },
    {
      "epoch": 2.945910290237467,
      "grad_norm": 26.072023391723633,
      "learning_rate": 1.8249780123131048e-06,
      "loss": 0.4494,
      "step": 4466
    },
    {
      "epoch": 2.9465699208443272,
      "grad_norm": 20.230558395385742,
      "learning_rate": 1.8029903254177663e-06,
      "loss": 0.1862,
      "step": 4467
    },
    {
      "epoch": 2.9472295514511875,
      "grad_norm": 0.520427942276001,
      "learning_rate": 1.7810026385224277e-06,
      "loss": 0.0324,
      "step": 4468
    },
    {
      "epoch": 2.9478891820580477,
      "grad_norm": 0.7528843283653259,
      "learning_rate": 1.7590149516270891e-06,
      "loss": 0.0458,
      "step": 4469
    },
    {
      "epoch": 2.9485488126649075,
      "grad_norm": 1.143034815788269,
      "learning_rate": 1.7370272647317501e-06,
      "loss": 0.0766,
      "step": 4470
    },
    {
      "epoch": 2.949208443271768,
      "grad_norm": 16.741703033447266,
      "learning_rate": 1.7150395778364116e-06,
      "loss": 0.726,
      "step": 4471
    },
    {
      "epoch": 2.949868073878628,
      "grad_norm": 4.440384387969971,
      "learning_rate": 1.693051890941073e-06,
      "loss": 0.0872,
      "step": 4472
    },
    {
      "epoch": 2.9505277044854883,
      "grad_norm": 0.8370422720909119,
      "learning_rate": 1.6710642040457344e-06,
      "loss": 0.0554,
      "step": 4473
    },
    {
      "epoch": 2.9511873350923485,
      "grad_norm": 17.192155838012695,
      "learning_rate": 1.6490765171503958e-06,
      "loss": 1.0345,
      "step": 4474
    },
    {
      "epoch": 2.9518469656992083,
      "grad_norm": 0.49297982454299927,
      "learning_rate": 1.6270888302550573e-06,
      "loss": 0.0358,
      "step": 4475
    },
    {
      "epoch": 2.9525065963060686,
      "grad_norm": 0.5588111281394958,
      "learning_rate": 1.6051011433597187e-06,
      "loss": 0.0164,
      "step": 4476
    },
    {
      "epoch": 2.953166226912929,
      "grad_norm": 1.5046002864837646,
      "learning_rate": 1.5831134564643801e-06,
      "loss": 0.0622,
      "step": 4477
    },
    {
      "epoch": 2.9538258575197887,
      "grad_norm": 0.6068868637084961,
      "learning_rate": 1.5611257695690413e-06,
      "loss": 0.0287,
      "step": 4478
    },
    {
      "epoch": 2.9544854881266494,
      "grad_norm": 11.655245780944824,
      "learning_rate": 1.5391380826737028e-06,
      "loss": 0.2135,
      "step": 4479
    },
    {
      "epoch": 2.955145118733509,
      "grad_norm": 18.26773452758789,
      "learning_rate": 1.5171503957783642e-06,
      "loss": 0.429,
      "step": 4480
    },
    {
      "epoch": 2.9558047493403694,
      "grad_norm": 16.55919075012207,
      "learning_rate": 1.4951627088830254e-06,
      "loss": 1.3587,
      "step": 4481
    },
    {
      "epoch": 2.9564643799472297,
      "grad_norm": 0.9661271572113037,
      "learning_rate": 1.4731750219876868e-06,
      "loss": 0.0493,
      "step": 4482
    },
    {
      "epoch": 2.9571240105540895,
      "grad_norm": 5.309443950653076,
      "learning_rate": 1.4511873350923483e-06,
      "loss": 0.0946,
      "step": 4483
    },
    {
      "epoch": 2.9577836411609497,
      "grad_norm": 11.427038192749023,
      "learning_rate": 1.4291996481970097e-06,
      "loss": 0.2333,
      "step": 4484
    },
    {
      "epoch": 2.95844327176781,
      "grad_norm": 20.84124183654785,
      "learning_rate": 1.4072119613016711e-06,
      "loss": 0.6593,
      "step": 4485
    },
    {
      "epoch": 2.95910290237467,
      "grad_norm": 0.43016114830970764,
      "learning_rate": 1.3852242744063324e-06,
      "loss": 0.0176,
      "step": 4486
    },
    {
      "epoch": 2.9597625329815305,
      "grad_norm": 1.1232203245162964,
      "learning_rate": 1.3632365875109938e-06,
      "loss": 0.0531,
      "step": 4487
    },
    {
      "epoch": 2.9604221635883903,
      "grad_norm": 0.940251350402832,
      "learning_rate": 1.3412489006156552e-06,
      "loss": 0.0345,
      "step": 4488
    },
    {
      "epoch": 2.9610817941952505,
      "grad_norm": 11.30337905883789,
      "learning_rate": 1.3192612137203166e-06,
      "loss": 0.2656,
      "step": 4489
    },
    {
      "epoch": 2.961741424802111,
      "grad_norm": 0.394885390996933,
      "learning_rate": 1.297273526824978e-06,
      "loss": 0.0334,
      "step": 4490
    },
    {
      "epoch": 2.962401055408971,
      "grad_norm": 11.112035751342773,
      "learning_rate": 1.2752858399296395e-06,
      "loss": 0.2752,
      "step": 4491
    },
    {
      "epoch": 2.9630606860158313,
      "grad_norm": 0.9238638281822205,
      "learning_rate": 1.253298153034301e-06,
      "loss": 0.034,
      "step": 4492
    },
    {
      "epoch": 2.963720316622691,
      "grad_norm": 4.8715291023254395,
      "learning_rate": 1.2313104661389623e-06,
      "loss": 0.0974,
      "step": 4493
    },
    {
      "epoch": 2.9643799472295513,
      "grad_norm": 3.282294511795044,
      "learning_rate": 1.2093227792436238e-06,
      "loss": 0.0921,
      "step": 4494
    },
    {
      "epoch": 2.9650395778364116,
      "grad_norm": 11.104503631591797,
      "learning_rate": 1.187335092348285e-06,
      "loss": 0.3133,
      "step": 4495
    },
    {
      "epoch": 2.965699208443272,
      "grad_norm": 13.994507789611816,
      "learning_rate": 1.1653474054529464e-06,
      "loss": 0.7317,
      "step": 4496
    },
    {
      "epoch": 2.966358839050132,
      "grad_norm": 1.5292381048202515,
      "learning_rate": 1.1433597185576078e-06,
      "loss": 0.0855,
      "step": 4497
    },
    {
      "epoch": 2.967018469656992,
      "grad_norm": 0.9608989357948303,
      "learning_rate": 1.1213720316622693e-06,
      "loss": 0.0637,
      "step": 4498
    },
    {
      "epoch": 2.967678100263852,
      "grad_norm": 0.475827693939209,
      "learning_rate": 1.0993843447669307e-06,
      "loss": 0.0388,
      "step": 4499
    },
    {
      "epoch": 2.9683377308707124,
      "grad_norm": 0.48367127776145935,
      "learning_rate": 1.077396657871592e-06,
      "loss": 0.0127,
      "step": 4500
    },
    {
      "epoch": 2.9689973614775726,
      "grad_norm": 3.6597542762756348,
      "learning_rate": 1.0554089709762534e-06,
      "loss": 0.0699,
      "step": 4501
    },
    {
      "epoch": 2.969656992084433,
      "grad_norm": 10.805567741394043,
      "learning_rate": 1.0334212840809148e-06,
      "loss": 0.1479,
      "step": 4502
    },
    {
      "epoch": 2.9703166226912927,
      "grad_norm": 0.4485383927822113,
      "learning_rate": 1.0114335971855762e-06,
      "loss": 0.0185,
      "step": 4503
    },
    {
      "epoch": 2.970976253298153,
      "grad_norm": 19.492847442626953,
      "learning_rate": 9.894459102902376e-07,
      "loss": 0.6099,
      "step": 4504
    },
    {
      "epoch": 2.971635883905013,
      "grad_norm": 0.7859775424003601,
      "learning_rate": 9.674582233948989e-07,
      "loss": 0.0276,
      "step": 4505
    },
    {
      "epoch": 2.9722955145118735,
      "grad_norm": 0.9129527807235718,
      "learning_rate": 9.454705364995603e-07,
      "loss": 0.0435,
      "step": 4506
    },
    {
      "epoch": 2.9729551451187337,
      "grad_norm": 9.696532249450684,
      "learning_rate": 9.234828496042217e-07,
      "loss": 0.257,
      "step": 4507
    },
    {
      "epoch": 2.9736147757255935,
      "grad_norm": 33.68986511230469,
      "learning_rate": 9.014951627088831e-07,
      "loss": 0.7199,
      "step": 4508
    },
    {
      "epoch": 2.9742744063324538,
      "grad_norm": 24.785261154174805,
      "learning_rate": 8.795074758135446e-07,
      "loss": 0.5211,
      "step": 4509
    },
    {
      "epoch": 2.974934036939314,
      "grad_norm": 0.703809916973114,
      "learning_rate": 8.575197889182058e-07,
      "loss": 0.0404,
      "step": 4510
    },
    {
      "epoch": 2.9755936675461743,
      "grad_norm": 0.7380404472351074,
      "learning_rate": 8.355321020228672e-07,
      "loss": 0.0334,
      "step": 4511
    },
    {
      "epoch": 2.9762532981530345,
      "grad_norm": 0.22812162339687347,
      "learning_rate": 8.135444151275286e-07,
      "loss": 0.0218,
      "step": 4512
    },
    {
      "epoch": 2.9769129287598943,
      "grad_norm": 11.838595390319824,
      "learning_rate": 7.915567282321901e-07,
      "loss": 0.2309,
      "step": 4513
    },
    {
      "epoch": 2.9775725593667546,
      "grad_norm": 1.0423145294189453,
      "learning_rate": 7.695690413368514e-07,
      "loss": 0.0614,
      "step": 4514
    },
    {
      "epoch": 2.978232189973615,
      "grad_norm": 0.9520595073699951,
      "learning_rate": 7.475813544415127e-07,
      "loss": 0.0732,
      "step": 4515
    },
    {
      "epoch": 2.978891820580475,
      "grad_norm": 27.149429321289062,
      "learning_rate": 7.255936675461741e-07,
      "loss": 0.7922,
      "step": 4516
    },
    {
      "epoch": 2.9795514511873353,
      "grad_norm": 0.6609578132629395,
      "learning_rate": 7.036059806508356e-07,
      "loss": 0.0185,
      "step": 4517
    },
    {
      "epoch": 2.980211081794195,
      "grad_norm": 0.5144947171211243,
      "learning_rate": 6.816182937554969e-07,
      "loss": 0.0287,
      "step": 4518
    },
    {
      "epoch": 2.9808707124010554,
      "grad_norm": 0.5185335278511047,
      "learning_rate": 6.596306068601583e-07,
      "loss": 0.0216,
      "step": 4519
    },
    {
      "epoch": 2.9815303430079156,
      "grad_norm": 1.4793680906295776,
      "learning_rate": 6.376429199648197e-07,
      "loss": 0.058,
      "step": 4520
    },
    {
      "epoch": 2.982189973614776,
      "grad_norm": 0.9208759665489197,
      "learning_rate": 6.156552330694812e-07,
      "loss": 0.0297,
      "step": 4521
    },
    {
      "epoch": 2.982849604221636,
      "grad_norm": 0.8279474377632141,
      "learning_rate": 5.936675461741425e-07,
      "loss": 0.0385,
      "step": 4522
    },
    {
      "epoch": 2.983509234828496,
      "grad_norm": 0.6919320225715637,
      "learning_rate": 5.716798592788039e-07,
      "loss": 0.0374,
      "step": 4523
    },
    {
      "epoch": 2.984168865435356,
      "grad_norm": 13.219635009765625,
      "learning_rate": 5.496921723834654e-07,
      "loss": 0.3146,
      "step": 4524
    },
    {
      "epoch": 2.9848284960422165,
      "grad_norm": 21.522348403930664,
      "learning_rate": 5.277044854881267e-07,
      "loss": 0.4975,
      "step": 4525
    },
    {
      "epoch": 2.9854881266490763,
      "grad_norm": 4.5236687660217285,
      "learning_rate": 5.057167985927881e-07,
      "loss": 0.1092,
      "step": 4526
    },
    {
      "epoch": 2.986147757255937,
      "grad_norm": 12.593965530395508,
      "learning_rate": 4.837291116974494e-07,
      "loss": 1.3383,
      "step": 4527
    },
    {
      "epoch": 2.9868073878627968,
      "grad_norm": 0.5210294723510742,
      "learning_rate": 4.6174142480211085e-07,
      "loss": 0.022,
      "step": 4528
    },
    {
      "epoch": 2.987467018469657,
      "grad_norm": 0.518156111240387,
      "learning_rate": 4.397537379067723e-07,
      "loss": 0.0225,
      "step": 4529
    },
    {
      "epoch": 2.9881266490765173,
      "grad_norm": 0.9249086976051331,
      "learning_rate": 4.177660510114336e-07,
      "loss": 0.029,
      "step": 4530
    },
    {
      "epoch": 2.988786279683377,
      "grad_norm": 18.130998611450195,
      "learning_rate": 3.9577836411609503e-07,
      "loss": 0.6496,
      "step": 4531
    },
    {
      "epoch": 2.9894459102902373,
      "grad_norm": 14.630821228027344,
      "learning_rate": 3.7379067722075636e-07,
      "loss": 0.4998,
      "step": 4532
    },
    {
      "epoch": 2.9901055408970976,
      "grad_norm": 5.854834079742432,
      "learning_rate": 3.518029903254178e-07,
      "loss": 0.1099,
      "step": 4533
    },
    {
      "epoch": 2.990765171503958,
      "grad_norm": 2.604923963546753,
      "learning_rate": 3.2981530343007916e-07,
      "loss": 0.0567,
      "step": 4534
    },
    {
      "epoch": 2.991424802110818,
      "grad_norm": 4.775223731994629,
      "learning_rate": 3.078276165347406e-07,
      "loss": 0.0792,
      "step": 4535
    },
    {
      "epoch": 2.992084432717678,
      "grad_norm": 0.7713251113891602,
      "learning_rate": 2.8583992963940196e-07,
      "loss": 0.0331,
      "step": 4536
    },
    {
      "epoch": 2.992744063324538,
      "grad_norm": 3.935060501098633,
      "learning_rate": 2.6385224274406334e-07,
      "loss": 0.1146,
      "step": 4537
    },
    {
      "epoch": 2.9934036939313984,
      "grad_norm": 1.0313833951950073,
      "learning_rate": 2.418645558487247e-07,
      "loss": 0.0319,
      "step": 4538
    },
    {
      "epoch": 2.9940633245382586,
      "grad_norm": 3.2374305725097656,
      "learning_rate": 2.1987686895338614e-07,
      "loss": 0.0861,
      "step": 4539
    },
    {
      "epoch": 2.994722955145119,
      "grad_norm": 0.7856784462928772,
      "learning_rate": 1.9788918205804752e-07,
      "loss": 0.0468,
      "step": 4540
    },
    {
      "epoch": 2.9953825857519787,
      "grad_norm": 9.76453685760498,
      "learning_rate": 1.759014951627089e-07,
      "loss": 0.0768,
      "step": 4541
    },
    {
      "epoch": 2.996042216358839,
      "grad_norm": 0.35131487250328064,
      "learning_rate": 1.539138082673703e-07,
      "loss": 0.0224,
      "step": 4542
    },
    {
      "epoch": 2.996701846965699,
      "grad_norm": 0.6785789728164673,
      "learning_rate": 1.3192612137203167e-07,
      "loss": 0.0203,
      "step": 4543
    },
    {
      "epoch": 2.9973614775725594,
      "grad_norm": 3.1825485229492188,
      "learning_rate": 1.0993843447669307e-07,
      "loss": 0.0715,
      "step": 4544
    },
    {
      "epoch": 2.9980211081794197,
      "grad_norm": 0.7136189341545105,
      "learning_rate": 8.795074758135445e-08,
      "loss": 0.0312,
      "step": 4545
    },
    {
      "epoch": 2.9986807387862795,
      "grad_norm": 0.6243922114372253,
      "learning_rate": 6.596306068601583e-08,
      "loss": 0.0286,
      "step": 4546
    },
    {
      "epoch": 2.9993403693931397,
      "grad_norm": 2.5028979778289795,
      "learning_rate": 4.397537379067722e-08,
      "loss": 0.0436,
      "step": 4547
    },
    {
      "epoch": 3.0,
      "grad_norm": 13.450060844421387,
      "learning_rate": 2.198768689533861e-08,
      "loss": 0.1716,
      "step": 4548
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8023255813953488,
      "eval_f1": 0.7630853994490359,
      "eval_keras_BCE": 0.6289470195770264,
      "eval_loss": 1.1944702863693237,
      "eval_precision": 0.8239160634974602,
      "eval_recall": 0.5795454545454546,
      "eval_runtime": 1.9822,
      "eval_samples_per_second": 130.156,
      "eval_steps_per_second": 16.648,
      "eval_weighted BCE": 41.242347717285156,
      "step": 4548
    }
  ],
  "logging_steps": 1,
  "max_steps": 4548,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.088858875877192e+17,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
