{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 120,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.025,
      "grad_norm": 5.167374610900879,
      "learning_rate": 0.0002,
      "loss": 0.3338,
      "step": 1
    },
    {
      "epoch": 0.05,
      "grad_norm": 13.821894645690918,
      "learning_rate": 0.00019833333333333335,
      "loss": 0.9728,
      "step": 2
    },
    {
      "epoch": 0.075,
      "grad_norm": 9.279335975646973,
      "learning_rate": 0.00019666666666666666,
      "loss": 0.6583,
      "step": 3
    },
    {
      "epoch": 0.1,
      "grad_norm": 4.771915435791016,
      "learning_rate": 0.000195,
      "loss": 0.3607,
      "step": 4
    },
    {
      "epoch": 0.125,
      "grad_norm": 3.8049278259277344,
      "learning_rate": 0.00019333333333333333,
      "loss": 0.3566,
      "step": 5
    },
    {
      "epoch": 0.15,
      "grad_norm": 6.38751745223999,
      "learning_rate": 0.00019166666666666667,
      "loss": 0.4413,
      "step": 6
    },
    {
      "epoch": 0.175,
      "grad_norm": 5.175629615783691,
      "learning_rate": 0.00019,
      "loss": 0.4299,
      "step": 7
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.3695170879364014,
      "learning_rate": 0.00018833333333333335,
      "loss": 0.3274,
      "step": 8
    },
    {
      "epoch": 0.225,
      "grad_norm": 1.8156388998031616,
      "learning_rate": 0.0001866666666666667,
      "loss": 0.3617,
      "step": 9
    },
    {
      "epoch": 0.25,
      "grad_norm": 2.4865496158599854,
      "learning_rate": 0.00018500000000000002,
      "loss": 0.3293,
      "step": 10
    },
    {
      "epoch": 0.275,
      "grad_norm": 3.4878110885620117,
      "learning_rate": 0.00018333333333333334,
      "loss": 0.342,
      "step": 11
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.4576215744018555,
      "learning_rate": 0.00018166666666666667,
      "loss": 0.2819,
      "step": 12
    },
    {
      "epoch": 0.325,
      "grad_norm": 1.7854337692260742,
      "learning_rate": 0.00018,
      "loss": 0.3449,
      "step": 13
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.004155158996582,
      "learning_rate": 0.00017833333333333335,
      "loss": 0.3275,
      "step": 14
    },
    {
      "epoch": 0.375,
      "grad_norm": 0.8024327158927917,
      "learning_rate": 0.00017666666666666666,
      "loss": 0.2415,
      "step": 15
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.6043896675109863,
      "learning_rate": 0.000175,
      "loss": 0.3108,
      "step": 16
    },
    {
      "epoch": 0.425,
      "grad_norm": 0.6303485631942749,
      "learning_rate": 0.00017333333333333334,
      "loss": 0.2731,
      "step": 17
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.6426074504852295,
      "learning_rate": 0.00017166666666666667,
      "loss": 0.3413,
      "step": 18
    },
    {
      "epoch": 0.475,
      "grad_norm": 1.6177613735198975,
      "learning_rate": 0.00017,
      "loss": 0.3262,
      "step": 19
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.333972454071045,
      "learning_rate": 0.00016833333333333335,
      "loss": 0.284,
      "step": 20
    },
    {
      "epoch": 0.525,
      "grad_norm": 1.0502054691314697,
      "learning_rate": 0.0001666666666666667,
      "loss": 0.3555,
      "step": 21
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.317384958267212,
      "learning_rate": 0.000165,
      "loss": 0.3667,
      "step": 22
    },
    {
      "epoch": 0.575,
      "grad_norm": 1.427955985069275,
      "learning_rate": 0.00016333333333333334,
      "loss": 0.3369,
      "step": 23
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.0400185585021973,
      "learning_rate": 0.00016166666666666668,
      "loss": 0.3102,
      "step": 24
    },
    {
      "epoch": 0.625,
      "grad_norm": 1.408143401145935,
      "learning_rate": 0.00016,
      "loss": 0.2585,
      "step": 25
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.4137141704559326,
      "learning_rate": 0.00015833333333333332,
      "loss": 0.2805,
      "step": 26
    },
    {
      "epoch": 0.675,
      "grad_norm": 1.8067080974578857,
      "learning_rate": 0.00015666666666666666,
      "loss": 0.2791,
      "step": 27
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.5633639097213745,
      "learning_rate": 0.000155,
      "loss": 0.2314,
      "step": 28
    },
    {
      "epoch": 0.725,
      "grad_norm": 1.5969587564468384,
      "learning_rate": 0.00015333333333333334,
      "loss": 0.2536,
      "step": 29
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.2940452098846436,
      "learning_rate": 0.00015166666666666668,
      "loss": 0.3028,
      "step": 30
    },
    {
      "epoch": 0.775,
      "grad_norm": 2.619594097137451,
      "learning_rate": 0.00015000000000000001,
      "loss": 0.3531,
      "step": 31
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.5652761459350586,
      "learning_rate": 0.00014833333333333335,
      "loss": 0.3079,
      "step": 32
    },
    {
      "epoch": 0.825,
      "grad_norm": 0.9705044627189636,
      "learning_rate": 0.00014666666666666666,
      "loss": 0.2183,
      "step": 33
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.8052580952644348,
      "learning_rate": 0.000145,
      "loss": 0.1803,
      "step": 34
    },
    {
      "epoch": 0.875,
      "grad_norm": 1.101906657218933,
      "learning_rate": 0.00014333333333333334,
      "loss": 0.2169,
      "step": 35
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.6966315507888794,
      "learning_rate": 0.00014166666666666668,
      "loss": 0.2279,
      "step": 36
    },
    {
      "epoch": 0.925,
      "grad_norm": 0.7328399419784546,
      "learning_rate": 0.00014,
      "loss": 0.2392,
      "step": 37
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.2317136526107788,
      "learning_rate": 0.00013833333333333333,
      "loss": 0.3629,
      "step": 38
    },
    {
      "epoch": 0.975,
      "grad_norm": 1.5876538753509521,
      "learning_rate": 0.00013666666666666666,
      "loss": 0.3346,
      "step": 39
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.4395935535430908,
      "learning_rate": 0.00013500000000000003,
      "loss": 0.0743,
      "step": 40
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8390804597701149,
      "eval_f1": 0.8280875088214538,
      "eval_keras_BCE": 0.4322870075702667,
      "eval_loss": 0.3839755058288574,
      "eval_precision": 0.8286899098832864,
      "eval_recall": 0.8947368421052632,
      "eval_runtime": 1.1845,
      "eval_samples_per_second": 146.897,
      "eval_steps_per_second": 18.573,
      "eval_weighted BCE (STD)": 0.289185106754303,
      "step": 40
    },
    {
      "epoch": 1.025,
      "grad_norm": 0.8264623284339905,
      "learning_rate": 0.00013333333333333334,
      "loss": 0.2426,
      "step": 41
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.2242884635925293,
      "learning_rate": 0.00013166666666666668,
      "loss": 0.2207,
      "step": 42
    },
    {
      "epoch": 1.075,
      "grad_norm": 1.0010077953338623,
      "learning_rate": 0.00013000000000000002,
      "loss": 0.1812,
      "step": 43
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.887448787689209,
      "learning_rate": 0.00012833333333333335,
      "loss": 0.25,
      "step": 44
    },
    {
      "epoch": 1.125,
      "grad_norm": 1.2023029327392578,
      "learning_rate": 0.00012666666666666666,
      "loss": 0.2104,
      "step": 45
    },
    {
      "epoch": 1.15,
      "grad_norm": 2.4102234840393066,
      "learning_rate": 0.000125,
      "loss": 0.2738,
      "step": 46
    },
    {
      "epoch": 1.175,
      "grad_norm": 1.5174964666366577,
      "learning_rate": 0.00012333333333333334,
      "loss": 0.202,
      "step": 47
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.785957396030426,
      "learning_rate": 0.00012166666666666667,
      "loss": 0.1656,
      "step": 48
    },
    {
      "epoch": 1.225,
      "grad_norm": 1.221472978591919,
      "learning_rate": 0.00012,
      "loss": 0.1715,
      "step": 49
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.7507762908935547,
      "learning_rate": 0.00011833333333333334,
      "loss": 0.1886,
      "step": 50
    },
    {
      "epoch": 1.275,
      "grad_norm": 1.8897897005081177,
      "learning_rate": 0.00011666666666666668,
      "loss": 0.2002,
      "step": 51
    },
    {
      "epoch": 1.3,
      "grad_norm": 1.454951286315918,
      "learning_rate": 0.00011499999999999999,
      "loss": 0.2389,
      "step": 52
    },
    {
      "epoch": 1.325,
      "grad_norm": 2.432628870010376,
      "learning_rate": 0.00011333333333333334,
      "loss": 0.1899,
      "step": 53
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.6863740682601929,
      "learning_rate": 0.00011166666666666668,
      "loss": 0.1757,
      "step": 54
    },
    {
      "epoch": 1.375,
      "grad_norm": 0.8190728425979614,
      "learning_rate": 0.00011000000000000002,
      "loss": 0.1455,
      "step": 55
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.3876230716705322,
      "learning_rate": 0.00010833333333333333,
      "loss": 0.1769,
      "step": 56
    },
    {
      "epoch": 1.425,
      "grad_norm": 1.3890494108200073,
      "learning_rate": 0.00010666666666666667,
      "loss": 0.2449,
      "step": 57
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.957073450088501,
      "learning_rate": 0.000105,
      "loss": 0.2053,
      "step": 58
    },
    {
      "epoch": 1.475,
      "grad_norm": 3.1743180751800537,
      "learning_rate": 0.00010333333333333334,
      "loss": 0.2396,
      "step": 59
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.4365370273590088,
      "learning_rate": 0.00010166666666666667,
      "loss": 0.1466,
      "step": 60
    },
    {
      "epoch": 1.525,
      "grad_norm": 2.5061354637145996,
      "learning_rate": 0.0001,
      "loss": 0.1769,
      "step": 61
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.099416732788086,
      "learning_rate": 9.833333333333333e-05,
      "loss": 0.1809,
      "step": 62
    },
    {
      "epoch": 1.575,
      "grad_norm": 1.006833553314209,
      "learning_rate": 9.666666666666667e-05,
      "loss": 0.2289,
      "step": 63
    },
    {
      "epoch": 1.6,
      "grad_norm": 4.797840595245361,
      "learning_rate": 9.5e-05,
      "loss": 0.2799,
      "step": 64
    },
    {
      "epoch": 1.625,
      "grad_norm": 2.938044786453247,
      "learning_rate": 9.333333333333334e-05,
      "loss": 0.1853,
      "step": 65
    },
    {
      "epoch": 1.65,
      "grad_norm": 1.0519912242889404,
      "learning_rate": 9.166666666666667e-05,
      "loss": 0.1994,
      "step": 66
    },
    {
      "epoch": 1.675,
      "grad_norm": 1.6935325860977173,
      "learning_rate": 9e-05,
      "loss": 0.2623,
      "step": 67
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.7417598962783813,
      "learning_rate": 8.833333333333333e-05,
      "loss": 0.2075,
      "step": 68
    },
    {
      "epoch": 1.725,
      "grad_norm": 1.3694549798965454,
      "learning_rate": 8.666666666666667e-05,
      "loss": 0.2309,
      "step": 69
    },
    {
      "epoch": 1.75,
      "grad_norm": 2.4224493503570557,
      "learning_rate": 8.5e-05,
      "loss": 0.227,
      "step": 70
    },
    {
      "epoch": 1.775,
      "grad_norm": 0.8790111541748047,
      "learning_rate": 8.333333333333334e-05,
      "loss": 0.2104,
      "step": 71
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.9116242527961731,
      "learning_rate": 8.166666666666667e-05,
      "loss": 0.1489,
      "step": 72
    },
    {
      "epoch": 1.825,
      "grad_norm": 2.702502727508545,
      "learning_rate": 8e-05,
      "loss": 0.2057,
      "step": 73
    },
    {
      "epoch": 1.85,
      "grad_norm": 1.6689141988754272,
      "learning_rate": 7.833333333333333e-05,
      "loss": 0.1922,
      "step": 74
    },
    {
      "epoch": 1.875,
      "grad_norm": 1.1888912916183472,
      "learning_rate": 7.666666666666667e-05,
      "loss": 0.2205,
      "step": 75
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.2684011459350586,
      "learning_rate": 7.500000000000001e-05,
      "loss": 0.1998,
      "step": 76
    },
    {
      "epoch": 1.925,
      "grad_norm": 1.501502513885498,
      "learning_rate": 7.333333333333333e-05,
      "loss": 0.1679,
      "step": 77
    },
    {
      "epoch": 1.95,
      "grad_norm": 2.2082748413085938,
      "learning_rate": 7.166666666666667e-05,
      "loss": 0.2494,
      "step": 78
    },
    {
      "epoch": 1.975,
      "grad_norm": 2.512673854827881,
      "learning_rate": 7e-05,
      "loss": 0.1968,
      "step": 79
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.7383657693862915,
      "learning_rate": 6.833333333333333e-05,
      "loss": 0.148,
      "step": 80
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8275862068965517,
      "eval_f1": 0.8169191919191919,
      "eval_keras_BCE": 0.4644618332386017,
      "eval_loss": 0.4169715940952301,
      "eval_precision": 0.8266755938814435,
      "eval_recall": 0.8947368421052632,
      "eval_runtime": 1.1559,
      "eval_samples_per_second": 150.526,
      "eval_steps_per_second": 19.032,
      "eval_weighted BCE (STD)": 0.3107089698314667,
      "step": 80
    },
    {
      "epoch": 2.025,
      "grad_norm": 0.7255959510803223,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.1836,
      "step": 81
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.8614391684532166,
      "learning_rate": 6.500000000000001e-05,
      "loss": 0.1932,
      "step": 82
    },
    {
      "epoch": 2.075,
      "grad_norm": 1.0743318796157837,
      "learning_rate": 6.333333333333333e-05,
      "loss": 0.1444,
      "step": 83
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.6508402228355408,
      "learning_rate": 6.166666666666667e-05,
      "loss": 0.0908,
      "step": 84
    },
    {
      "epoch": 2.125,
      "grad_norm": 0.9254196286201477,
      "learning_rate": 6e-05,
      "loss": 0.1579,
      "step": 85
    },
    {
      "epoch": 2.15,
      "grad_norm": 1.0377875566482544,
      "learning_rate": 5.833333333333334e-05,
      "loss": 0.1592,
      "step": 86
    },
    {
      "epoch": 2.175,
      "grad_norm": 1.0982781648635864,
      "learning_rate": 5.666666666666667e-05,
      "loss": 0.1388,
      "step": 87
    },
    {
      "epoch": 2.2,
      "grad_norm": 1.4583550691604614,
      "learning_rate": 5.500000000000001e-05,
      "loss": 0.1728,
      "step": 88
    },
    {
      "epoch": 2.225,
      "grad_norm": 1.7564135789871216,
      "learning_rate": 5.333333333333333e-05,
      "loss": 0.1449,
      "step": 89
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.8324142694473267,
      "learning_rate": 5.166666666666667e-05,
      "loss": 0.1543,
      "step": 90
    },
    {
      "epoch": 2.275,
      "grad_norm": 1.1917475461959839,
      "learning_rate": 5e-05,
      "loss": 0.1458,
      "step": 91
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.7823706865310669,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 0.0846,
      "step": 92
    },
    {
      "epoch": 2.325,
      "grad_norm": 2.08260440826416,
      "learning_rate": 4.666666666666667e-05,
      "loss": 0.18,
      "step": 93
    },
    {
      "epoch": 2.35,
      "grad_norm": 1.2597599029541016,
      "learning_rate": 4.5e-05,
      "loss": 0.146,
      "step": 94
    },
    {
      "epoch": 2.375,
      "grad_norm": 1.0146152973175049,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 0.1137,
      "step": 95
    },
    {
      "epoch": 2.4,
      "grad_norm": 1.197096347808838,
      "learning_rate": 4.166666666666667e-05,
      "loss": 0.1411,
      "step": 96
    },
    {
      "epoch": 2.425,
      "grad_norm": 1.6770007610321045,
      "learning_rate": 4e-05,
      "loss": 0.1258,
      "step": 97
    },
    {
      "epoch": 2.45,
      "grad_norm": 2.0122439861297607,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 0.1399,
      "step": 98
    },
    {
      "epoch": 2.475,
      "grad_norm": 3.4730260372161865,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 0.1724,
      "step": 99
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.7870945930480957,
      "learning_rate": 3.5e-05,
      "loss": 0.1542,
      "step": 100
    },
    {
      "epoch": 2.525,
      "grad_norm": 1.0851463079452515,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.1716,
      "step": 101
    },
    {
      "epoch": 2.55,
      "grad_norm": 1.6655235290527344,
      "learning_rate": 3.1666666666666666e-05,
      "loss": 0.1061,
      "step": 102
    },
    {
      "epoch": 2.575,
      "grad_norm": 1.2025257349014282,
      "learning_rate": 3e-05,
      "loss": 0.2055,
      "step": 103
    },
    {
      "epoch": 2.6,
      "grad_norm": 1.110576868057251,
      "learning_rate": 2.8333333333333335e-05,
      "loss": 0.166,
      "step": 104
    },
    {
      "epoch": 2.625,
      "grad_norm": 1.182524561882019,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.1477,
      "step": 105
    },
    {
      "epoch": 2.65,
      "grad_norm": 1.2274999618530273,
      "learning_rate": 2.5e-05,
      "loss": 0.1638,
      "step": 106
    },
    {
      "epoch": 2.675,
      "grad_norm": 2.4528861045837402,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 0.1313,
      "step": 107
    },
    {
      "epoch": 2.7,
      "grad_norm": 1.406269907951355,
      "learning_rate": 2.1666666666666667e-05,
      "loss": 0.1479,
      "step": 108
    },
    {
      "epoch": 2.725,
      "grad_norm": 1.624764084815979,
      "learning_rate": 2e-05,
      "loss": 0.1665,
      "step": 109
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.9499014616012573,
      "learning_rate": 1.8333333333333333e-05,
      "loss": 0.1125,
      "step": 110
    },
    {
      "epoch": 2.775,
      "grad_norm": 2.269547700881958,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.1669,
      "step": 111
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.231589436531067,
      "learning_rate": 1.5e-05,
      "loss": 0.1002,
      "step": 112
    },
    {
      "epoch": 2.825,
      "grad_norm": 1.3009968996047974,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.1236,
      "step": 113
    },
    {
      "epoch": 2.85,
      "grad_norm": 1.9398235082626343,
      "learning_rate": 1.1666666666666668e-05,
      "loss": 0.2609,
      "step": 114
    },
    {
      "epoch": 2.875,
      "grad_norm": 2.20076847076416,
      "learning_rate": 1e-05,
      "loss": 0.1288,
      "step": 115
    },
    {
      "epoch": 2.9,
      "grad_norm": 1.542022466659546,
      "learning_rate": 8.333333333333334e-06,
      "loss": 0.1573,
      "step": 116
    },
    {
      "epoch": 2.925,
      "grad_norm": 0.9276154637336731,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.1197,
      "step": 117
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.8680863380432129,
      "learning_rate": 5e-06,
      "loss": 0.1369,
      "step": 118
    },
    {
      "epoch": 2.975,
      "grad_norm": 0.8146469593048096,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.1244,
      "step": 119
    },
    {
      "epoch": 3.0,
      "grad_norm": 3.9019033908843994,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 0.1133,
      "step": 120
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8448275862068966,
      "eval_f1": 0.833705001592864,
      "eval_keras_BCE": 0.5131807923316956,
      "eval_loss": 0.48846444487571716,
      "eval_precision": 0.8444397741696139,
      "eval_recall": 0.8947368421052632,
      "eval_runtime": 1.1688,
      "eval_samples_per_second": 148.877,
      "eval_steps_per_second": 18.824,
      "eval_weighted BCE (STD)": 0.3433002531528473,
      "step": 120
    }
  ],
  "logging_steps": 1,
  "max_steps": 120,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8067821509440000.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
