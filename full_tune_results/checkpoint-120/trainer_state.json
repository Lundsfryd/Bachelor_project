{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 120,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.025,
      "grad_norm": 8.555289268493652,
      "learning_rate": 0.0002,
      "loss": 0.9325,
      "step": 1
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.646759033203125,
      "learning_rate": 0.00019833333333333335,
      "loss": 0.899,
      "step": 2
    },
    {
      "epoch": 0.075,
      "grad_norm": 3.9751241207122803,
      "learning_rate": 0.00019666666666666666,
      "loss": 0.7722,
      "step": 3
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.4402008056640625,
      "learning_rate": 0.000195,
      "loss": 0.7408,
      "step": 4
    },
    {
      "epoch": 0.125,
      "grad_norm": 2.986114263534546,
      "learning_rate": 0.00019333333333333333,
      "loss": 0.7285,
      "step": 5
    },
    {
      "epoch": 0.15,
      "grad_norm": 4.289412021636963,
      "learning_rate": 0.00019166666666666667,
      "loss": 0.6987,
      "step": 6
    },
    {
      "epoch": 0.175,
      "grad_norm": 1.9535458087921143,
      "learning_rate": 0.00019,
      "loss": 0.6904,
      "step": 7
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8147929906845093,
      "learning_rate": 0.00018833333333333335,
      "loss": 0.6355,
      "step": 8
    },
    {
      "epoch": 0.225,
      "grad_norm": 1.7754371166229248,
      "learning_rate": 0.0001866666666666667,
      "loss": 0.6534,
      "step": 9
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.1254924535751343,
      "learning_rate": 0.00018500000000000002,
      "loss": 0.6254,
      "step": 10
    },
    {
      "epoch": 0.275,
      "grad_norm": 2.3379878997802734,
      "learning_rate": 0.00018333333333333334,
      "loss": 0.5944,
      "step": 11
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.5552842617034912,
      "learning_rate": 0.00018166666666666667,
      "loss": 0.5713,
      "step": 12
    },
    {
      "epoch": 0.325,
      "grad_norm": 2.032785654067993,
      "learning_rate": 0.00018,
      "loss": 0.5627,
      "step": 13
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.843167245388031,
      "learning_rate": 0.00017833333333333335,
      "loss": 0.5656,
      "step": 14
    },
    {
      "epoch": 0.375,
      "grad_norm": 0.6792984008789062,
      "learning_rate": 0.00017666666666666666,
      "loss": 0.5172,
      "step": 15
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6494147777557373,
      "learning_rate": 0.000175,
      "loss": 0.5375,
      "step": 16
    },
    {
      "epoch": 0.425,
      "grad_norm": 0.7174789905548096,
      "learning_rate": 0.00017333333333333334,
      "loss": 0.433,
      "step": 17
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.471040964126587,
      "learning_rate": 0.00017166666666666667,
      "loss": 0.5096,
      "step": 18
    },
    {
      "epoch": 0.475,
      "grad_norm": 0.6710855960845947,
      "learning_rate": 0.00017,
      "loss": 0.4314,
      "step": 19
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.303917646408081,
      "learning_rate": 0.00016833333333333335,
      "loss": 0.4266,
      "step": 20
    },
    {
      "epoch": 0.525,
      "grad_norm": 0.7068485021591187,
      "learning_rate": 0.0001666666666666667,
      "loss": 0.4722,
      "step": 21
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7653424143791199,
      "learning_rate": 0.000165,
      "loss": 0.4302,
      "step": 22
    },
    {
      "epoch": 0.575,
      "grad_norm": 1.0652884244918823,
      "learning_rate": 0.00016333333333333334,
      "loss": 0.435,
      "step": 23
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.9494759440422058,
      "learning_rate": 0.00016166666666666668,
      "loss": 0.4692,
      "step": 24
    },
    {
      "epoch": 0.625,
      "grad_norm": 1.087672472000122,
      "learning_rate": 0.00016,
      "loss": 0.3982,
      "step": 25
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.8778414726257324,
      "learning_rate": 0.00015833333333333332,
      "loss": 0.4117,
      "step": 26
    },
    {
      "epoch": 0.675,
      "grad_norm": 3.6973421573638916,
      "learning_rate": 0.00015666666666666666,
      "loss": 0.3941,
      "step": 27
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.715395450592041,
      "learning_rate": 0.000155,
      "loss": 0.3582,
      "step": 28
    },
    {
      "epoch": 0.725,
      "grad_norm": 3.6873514652252197,
      "learning_rate": 0.00015333333333333334,
      "loss": 0.3875,
      "step": 29
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.7523253560066223,
      "learning_rate": 0.00015166666666666668,
      "loss": 0.3538,
      "step": 30
    },
    {
      "epoch": 0.775,
      "grad_norm": 3.5988194942474365,
      "learning_rate": 0.00015000000000000001,
      "loss": 0.4159,
      "step": 31
    },
    {
      "epoch": 0.8,
      "grad_norm": 4.085244178771973,
      "learning_rate": 0.00014833333333333335,
      "loss": 0.3622,
      "step": 32
    },
    {
      "epoch": 0.825,
      "grad_norm": 3.2598345279693604,
      "learning_rate": 0.00014666666666666666,
      "loss": 0.3219,
      "step": 33
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.7797930240631104,
      "learning_rate": 0.000145,
      "loss": 0.3006,
      "step": 34
    },
    {
      "epoch": 0.875,
      "grad_norm": 1.9283726215362549,
      "learning_rate": 0.00014333333333333334,
      "loss": 0.2877,
      "step": 35
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.1261253356933594,
      "learning_rate": 0.00014166666666666668,
      "loss": 0.3617,
      "step": 36
    },
    {
      "epoch": 0.925,
      "grad_norm": 2.7856240272521973,
      "learning_rate": 0.00014,
      "loss": 0.3062,
      "step": 37
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.2625832557678223,
      "learning_rate": 0.00013833333333333333,
      "loss": 0.434,
      "step": 38
    },
    {
      "epoch": 0.975,
      "grad_norm": 1.3485139608383179,
      "learning_rate": 0.00013666666666666666,
      "loss": 0.4173,
      "step": 39
    },
    {
      "epoch": 1.0,
      "grad_norm": 4.133662223815918,
      "learning_rate": 0.00013500000000000003,
      "loss": 0.1961,
      "step": 40
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8505747126436781,
      "eval_f1": 0.8333087693441414,
      "eval_keras_BCE": 0.3786866068840027,
      "eval_loss": 0.42902708053588867,
      "eval_precision": 0.7966009555992877,
      "eval_recall": 0.8070175438596491,
      "eval_runtime": 3.2213,
      "eval_samples_per_second": 54.015,
      "eval_steps_per_second": 6.829,
      "eval_weighted BCE (STD)": 25.332828521728516,
      "step": 40
    },
    {
      "epoch": 1.025,
      "grad_norm": 3.163516044616699,
      "learning_rate": 0.00013333333333333334,
      "loss": 0.3388,
      "step": 41
    },
    {
      "epoch": 1.05,
      "grad_norm": 5.51719331741333,
      "learning_rate": 0.00013166666666666668,
      "loss": 0.395,
      "step": 42
    },
    {
      "epoch": 1.075,
      "grad_norm": 2.70991849899292,
      "learning_rate": 0.00013000000000000002,
      "loss": 0.2769,
      "step": 43
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.413653612136841,
      "learning_rate": 0.00012833333333333335,
      "loss": 0.3216,
      "step": 44
    },
    {
      "epoch": 1.125,
      "grad_norm": 1.0550870895385742,
      "learning_rate": 0.00012666666666666666,
      "loss": 0.2789,
      "step": 45
    },
    {
      "epoch": 1.15,
      "grad_norm": 3.244293212890625,
      "learning_rate": 0.000125,
      "loss": 0.3849,
      "step": 46
    },
    {
      "epoch": 1.175,
      "grad_norm": 2.300867795944214,
      "learning_rate": 0.00012333333333333334,
      "loss": 0.2925,
      "step": 47
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.0451595783233643,
      "learning_rate": 0.00012166666666666667,
      "loss": 0.257,
      "step": 48
    },
    {
      "epoch": 1.225,
      "grad_norm": 1.5193027257919312,
      "learning_rate": 0.00012,
      "loss": 0.2688,
      "step": 49
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.1127325296401978,
      "learning_rate": 0.00011833333333333334,
      "loss": 0.3196,
      "step": 50
    },
    {
      "epoch": 1.275,
      "grad_norm": 1.5790235996246338,
      "learning_rate": 0.00011666666666666668,
      "loss": 0.255,
      "step": 51
    },
    {
      "epoch": 1.3,
      "grad_norm": 2.7702159881591797,
      "learning_rate": 0.00011499999999999999,
      "loss": 0.3145,
      "step": 52
    },
    {
      "epoch": 1.325,
      "grad_norm": 0.8316178917884827,
      "learning_rate": 0.00011333333333333334,
      "loss": 0.2725,
      "step": 53
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.4684979915618896,
      "learning_rate": 0.00011166666666666668,
      "loss": 0.2359,
      "step": 54
    },
    {
      "epoch": 1.375,
      "grad_norm": 0.711292564868927,
      "learning_rate": 0.00011000000000000002,
      "loss": 0.2028,
      "step": 55
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.7026140689849854,
      "learning_rate": 0.00010833333333333333,
      "loss": 0.2629,
      "step": 56
    },
    {
      "epoch": 1.425,
      "grad_norm": 2.4195775985717773,
      "learning_rate": 0.00010666666666666667,
      "loss": 0.2964,
      "step": 57
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.1994937658309937,
      "learning_rate": 0.000105,
      "loss": 0.2205,
      "step": 58
    },
    {
      "epoch": 1.475,
      "grad_norm": 1.5291879177093506,
      "learning_rate": 0.00010333333333333334,
      "loss": 0.2907,
      "step": 59
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.7564292550086975,
      "learning_rate": 0.00010166666666666667,
      "loss": 0.2043,
      "step": 60
    },
    {
      "epoch": 1.525,
      "grad_norm": 3.6690170764923096,
      "learning_rate": 0.0001,
      "loss": 0.2687,
      "step": 61
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.9082616567611694,
      "learning_rate": 9.833333333333333e-05,
      "loss": 0.262,
      "step": 62
    },
    {
      "epoch": 1.575,
      "grad_norm": 2.0391719341278076,
      "learning_rate": 9.666666666666667e-05,
      "loss": 0.2881,
      "step": 63
    },
    {
      "epoch": 1.6,
      "grad_norm": 4.277215003967285,
      "learning_rate": 9.5e-05,
      "loss": 0.3402,
      "step": 64
    },
    {
      "epoch": 1.625,
      "grad_norm": 6.268106460571289,
      "learning_rate": 9.333333333333334e-05,
      "loss": 0.2426,
      "step": 65
    },
    {
      "epoch": 1.65,
      "grad_norm": 2.0538227558135986,
      "learning_rate": 9.166666666666667e-05,
      "loss": 0.305,
      "step": 66
    },
    {
      "epoch": 1.675,
      "grad_norm": 1.7773481607437134,
      "learning_rate": 9e-05,
      "loss": 0.3412,
      "step": 67
    },
    {
      "epoch": 1.7,
      "grad_norm": 1.3816230297088623,
      "learning_rate": 8.833333333333333e-05,
      "loss": 0.2819,
      "step": 68
    },
    {
      "epoch": 1.725,
      "grad_norm": 0.9587317109107971,
      "learning_rate": 8.666666666666667e-05,
      "loss": 0.2743,
      "step": 69
    },
    {
      "epoch": 1.75,
      "grad_norm": 2.9622011184692383,
      "learning_rate": 8.5e-05,
      "loss": 0.2975,
      "step": 70
    },
    {
      "epoch": 1.775,
      "grad_norm": 2.4370882511138916,
      "learning_rate": 8.333333333333334e-05,
      "loss": 0.3058,
      "step": 71
    },
    {
      "epoch": 1.8,
      "grad_norm": 4.056472301483154,
      "learning_rate": 8.166666666666667e-05,
      "loss": 0.2631,
      "step": 72
    },
    {
      "epoch": 1.825,
      "grad_norm": 0.7586740255355835,
      "learning_rate": 8e-05,
      "loss": 0.242,
      "step": 73
    },
    {
      "epoch": 1.85,
      "grad_norm": 1.2061508893966675,
      "learning_rate": 7.833333333333333e-05,
      "loss": 0.2559,
      "step": 74
    },
    {
      "epoch": 1.875,
      "grad_norm": 0.8902865052223206,
      "learning_rate": 7.666666666666667e-05,
      "loss": 0.2962,
      "step": 75
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.7806658744812012,
      "learning_rate": 7.500000000000001e-05,
      "loss": 0.2587,
      "step": 76
    },
    {
      "epoch": 1.925,
      "grad_norm": 0.9445197582244873,
      "learning_rate": 7.333333333333333e-05,
      "loss": 0.2311,
      "step": 77
    },
    {
      "epoch": 1.95,
      "grad_norm": 1.381813645362854,
      "learning_rate": 7.166666666666667e-05,
      "loss": 0.3196,
      "step": 78
    },
    {
      "epoch": 1.975,
      "grad_norm": 0.8865374326705933,
      "learning_rate": 7e-05,
      "loss": 0.2449,
      "step": 79
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.6755664348602295,
      "learning_rate": 6.833333333333333e-05,
      "loss": 0.2606,
      "step": 80
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8045977011494253,
      "eval_f1": 0.7948113207547169,
      "eval_keras_BCE": 0.44638723134994507,
      "eval_loss": 0.34679195284843445,
      "eval_precision": 0.8013182450939391,
      "eval_recall": 0.8947368421052632,
      "eval_runtime": 1.0888,
      "eval_samples_per_second": 159.802,
      "eval_steps_per_second": 20.205,
      "eval_weighted BCE (STD)": 29.861766815185547,
      "step": 80
    },
    {
      "epoch": 2.025,
      "grad_norm": 0.6788092851638794,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.2717,
      "step": 81
    },
    {
      "epoch": 2.05,
      "grad_norm": 1.4382060766220093,
      "learning_rate": 6.500000000000001e-05,
      "loss": 0.3079,
      "step": 82
    },
    {
      "epoch": 2.075,
      "grad_norm": 0.7422330379486084,
      "learning_rate": 6.333333333333333e-05,
      "loss": 0.1967,
      "step": 83
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.9837282299995422,
      "learning_rate": 6.166666666666667e-05,
      "loss": 0.1573,
      "step": 84
    },
    {
      "epoch": 2.125,
      "grad_norm": 1.3331490755081177,
      "learning_rate": 6e-05,
      "loss": 0.2354,
      "step": 85
    },
    {
      "epoch": 2.15,
      "grad_norm": 1.2101143598556519,
      "learning_rate": 5.833333333333334e-05,
      "loss": 0.2135,
      "step": 86
    },
    {
      "epoch": 2.175,
      "grad_norm": 0.9934836030006409,
      "learning_rate": 5.666666666666667e-05,
      "loss": 0.2327,
      "step": 87
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.8461998701095581,
      "learning_rate": 5.500000000000001e-05,
      "loss": 0.2388,
      "step": 88
    },
    {
      "epoch": 2.225,
      "grad_norm": 0.6218279600143433,
      "learning_rate": 5.333333333333333e-05,
      "loss": 0.1801,
      "step": 89
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.9215622544288635,
      "learning_rate": 5.166666666666667e-05,
      "loss": 0.2388,
      "step": 90
    },
    {
      "epoch": 2.275,
      "grad_norm": 1.5607911348342896,
      "learning_rate": 5e-05,
      "loss": 0.1919,
      "step": 91
    },
    {
      "epoch": 2.3,
      "grad_norm": 1.0811854600906372,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 0.1573,
      "step": 92
    },
    {
      "epoch": 2.325,
      "grad_norm": 1.128773808479309,
      "learning_rate": 4.666666666666667e-05,
      "loss": 0.2378,
      "step": 93
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.9116679430007935,
      "learning_rate": 4.5e-05,
      "loss": 0.2447,
      "step": 94
    },
    {
      "epoch": 2.375,
      "grad_norm": 1.2483898401260376,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 0.2119,
      "step": 95
    },
    {
      "epoch": 2.4,
      "grad_norm": 1.0759024620056152,
      "learning_rate": 4.166666666666667e-05,
      "loss": 0.1927,
      "step": 96
    },
    {
      "epoch": 2.425,
      "grad_norm": 1.4006550312042236,
      "learning_rate": 4e-05,
      "loss": 0.19,
      "step": 97
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.7734668850898743,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 0.2319,
      "step": 98
    },
    {
      "epoch": 2.475,
      "grad_norm": 1.6825628280639648,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 0.2123,
      "step": 99
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.4055095911026,
      "learning_rate": 3.5e-05,
      "loss": 0.1725,
      "step": 100
    },
    {
      "epoch": 2.525,
      "grad_norm": 1.6638553142547607,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.2478,
      "step": 101
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.6396988034248352,
      "learning_rate": 3.1666666666666666e-05,
      "loss": 0.1381,
      "step": 102
    },
    {
      "epoch": 2.575,
      "grad_norm": 1.3181387186050415,
      "learning_rate": 3e-05,
      "loss": 0.279,
      "step": 103
    },
    {
      "epoch": 2.6,
      "grad_norm": 1.0519096851348877,
      "learning_rate": 2.8333333333333335e-05,
      "loss": 0.2735,
      "step": 104
    },
    {
      "epoch": 2.625,
      "grad_norm": 1.2093673944473267,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.1904,
      "step": 105
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.9411368370056152,
      "learning_rate": 2.5e-05,
      "loss": 0.2344,
      "step": 106
    },
    {
      "epoch": 2.675,
      "grad_norm": 2.834571599960327,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 0.1893,
      "step": 107
    },
    {
      "epoch": 2.7,
      "grad_norm": 2.015883684158325,
      "learning_rate": 2.1666666666666667e-05,
      "loss": 0.2135,
      "step": 108
    },
    {
      "epoch": 2.725,
      "grad_norm": 1.6683812141418457,
      "learning_rate": 2e-05,
      "loss": 0.2514,
      "step": 109
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.8825273513793945,
      "learning_rate": 1.8333333333333333e-05,
      "loss": 0.1763,
      "step": 110
    },
    {
      "epoch": 2.775,
      "grad_norm": 2.177049398422241,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.2167,
      "step": 111
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.2558518648147583,
      "learning_rate": 1.5e-05,
      "loss": 0.1959,
      "step": 112
    },
    {
      "epoch": 2.825,
      "grad_norm": 0.76796555519104,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.1817,
      "step": 113
    },
    {
      "epoch": 2.85,
      "grad_norm": 1.7294353246688843,
      "learning_rate": 1.1666666666666668e-05,
      "loss": 0.3091,
      "step": 114
    },
    {
      "epoch": 2.875,
      "grad_norm": 1.1894891262054443,
      "learning_rate": 1e-05,
      "loss": 0.1941,
      "step": 115
    },
    {
      "epoch": 2.9,
      "grad_norm": 1.4186699390411377,
      "learning_rate": 8.333333333333334e-06,
      "loss": 0.2017,
      "step": 116
    },
    {
      "epoch": 2.925,
      "grad_norm": 0.9151328206062317,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.1811,
      "step": 117
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.8751468658447266,
      "learning_rate": 5e-06,
      "loss": 0.1957,
      "step": 118
    },
    {
      "epoch": 2.975,
      "grad_norm": 0.8110406398773193,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.1905,
      "step": 119
    },
    {
      "epoch": 3.0,
      "grad_norm": 3.177027940750122,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 0.2159,
      "step": 120
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8103448275862069,
      "eval_f1": 0.8003129890453834,
      "eval_keras_BCE": 0.47690898180007935,
      "eval_loss": 0.3669075071811676,
      "eval_precision": 0.8161882036155694,
      "eval_recall": 0.8947368421052632,
      "eval_runtime": 1.0418,
      "eval_samples_per_second": 167.024,
      "eval_steps_per_second": 21.118,
      "eval_weighted BCE (STD)": 31.903564453125,
      "step": 120
    }
  ],
  "logging_steps": 1,
  "max_steps": 120,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8067821509440000.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
