{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 120,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.025,
      "grad_norm": 12.096012115478516,
      "learning_rate": 0.0001,
      "loss": 1.0774,
      "step": 1
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.5905355215072632,
      "learning_rate": 9.916666666666667e-05,
      "loss": 0.7656,
      "step": 2
    },
    {
      "epoch": 0.075,
      "grad_norm": 10.089310646057129,
      "learning_rate": 9.833333333333333e-05,
      "loss": 0.9553,
      "step": 3
    },
    {
      "epoch": 0.1,
      "grad_norm": 5.424023628234863,
      "learning_rate": 9.75e-05,
      "loss": 0.766,
      "step": 4
    },
    {
      "epoch": 0.125,
      "grad_norm": 3.6228084564208984,
      "learning_rate": 9.666666666666667e-05,
      "loss": 0.7912,
      "step": 5
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.2722028493881226,
      "learning_rate": 9.583333333333334e-05,
      "loss": 0.7001,
      "step": 6
    },
    {
      "epoch": 0.175,
      "grad_norm": 3.0797362327575684,
      "learning_rate": 9.5e-05,
      "loss": 0.7013,
      "step": 7
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.6039180755615234,
      "learning_rate": 9.416666666666667e-05,
      "loss": 0.6875,
      "step": 8
    },
    {
      "epoch": 0.225,
      "grad_norm": 2.7710633277893066,
      "learning_rate": 9.333333333333334e-05,
      "loss": 0.6931,
      "step": 9
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.224374532699585,
      "learning_rate": 9.250000000000001e-05,
      "loss": 0.6597,
      "step": 10
    },
    {
      "epoch": 0.275,
      "grad_norm": 2.217402219772339,
      "learning_rate": 9.166666666666667e-05,
      "loss": 0.6474,
      "step": 11
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.301017165184021,
      "learning_rate": 9.083333333333334e-05,
      "loss": 0.6302,
      "step": 12
    },
    {
      "epoch": 0.325,
      "grad_norm": 2.1399905681610107,
      "learning_rate": 9e-05,
      "loss": 0.6044,
      "step": 13
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.983839988708496,
      "learning_rate": 8.916666666666667e-05,
      "loss": 0.6244,
      "step": 14
    },
    {
      "epoch": 0.375,
      "grad_norm": 1.1320644617080688,
      "learning_rate": 8.833333333333333e-05,
      "loss": 0.5708,
      "step": 15
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.4349346160888672,
      "learning_rate": 8.75e-05,
      "loss": 0.5646,
      "step": 16
    },
    {
      "epoch": 0.425,
      "grad_norm": 0.7351903915405273,
      "learning_rate": 8.666666666666667e-05,
      "loss": 0.5215,
      "step": 17
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.022893190383911,
      "learning_rate": 8.583333333333334e-05,
      "loss": 0.596,
      "step": 18
    },
    {
      "epoch": 0.475,
      "grad_norm": 1.6250693798065186,
      "learning_rate": 8.5e-05,
      "loss": 0.5169,
      "step": 19
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.7655043601989746,
      "learning_rate": 8.416666666666668e-05,
      "loss": 0.5193,
      "step": 20
    },
    {
      "epoch": 0.525,
      "grad_norm": 1.0703309774398804,
      "learning_rate": 8.333333333333334e-05,
      "loss": 0.5387,
      "step": 21
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.242695927619934,
      "learning_rate": 8.25e-05,
      "loss": 0.5327,
      "step": 22
    },
    {
      "epoch": 0.575,
      "grad_norm": 0.7959473133087158,
      "learning_rate": 8.166666666666667e-05,
      "loss": 0.5111,
      "step": 23
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.2915761470794678,
      "learning_rate": 8.083333333333334e-05,
      "loss": 0.5224,
      "step": 24
    },
    {
      "epoch": 0.625,
      "grad_norm": 2.032573699951172,
      "learning_rate": 8e-05,
      "loss": 0.4835,
      "step": 25
    },
    {
      "epoch": 0.65,
      "grad_norm": 3.987213611602783,
      "learning_rate": 7.916666666666666e-05,
      "loss": 0.529,
      "step": 26
    },
    {
      "epoch": 0.675,
      "grad_norm": 0.9473308324813843,
      "learning_rate": 7.833333333333333e-05,
      "loss": 0.4739,
      "step": 27
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.7896548509597778,
      "learning_rate": 7.75e-05,
      "loss": 0.4247,
      "step": 28
    },
    {
      "epoch": 0.725,
      "grad_norm": 2.0958316326141357,
      "learning_rate": 7.666666666666667e-05,
      "loss": 0.404,
      "step": 29
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.735012412071228,
      "learning_rate": 7.583333333333334e-05,
      "loss": 0.455,
      "step": 30
    },
    {
      "epoch": 0.775,
      "grad_norm": 0.9908364415168762,
      "learning_rate": 7.500000000000001e-05,
      "loss": 0.4604,
      "step": 31
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.8264562487602234,
      "learning_rate": 7.416666666666668e-05,
      "loss": 0.4019,
      "step": 32
    },
    {
      "epoch": 0.825,
      "grad_norm": 1.0714343786239624,
      "learning_rate": 7.333333333333333e-05,
      "loss": 0.3261,
      "step": 33
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.8916481137275696,
      "learning_rate": 7.25e-05,
      "loss": 0.3292,
      "step": 34
    },
    {
      "epoch": 0.875,
      "grad_norm": 1.0185400247573853,
      "learning_rate": 7.166666666666667e-05,
      "loss": 0.3125,
      "step": 35
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.7649476528167725,
      "learning_rate": 7.083333333333334e-05,
      "loss": 0.3911,
      "step": 36
    },
    {
      "epoch": 0.925,
      "grad_norm": 0.7022926211357117,
      "learning_rate": 7e-05,
      "loss": 0.3139,
      "step": 37
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.4037690162658691,
      "learning_rate": 6.916666666666666e-05,
      "loss": 0.4673,
      "step": 38
    },
    {
      "epoch": 0.975,
      "grad_norm": 3.4776952266693115,
      "learning_rate": 6.833333333333333e-05,
      "loss": 0.4758,
      "step": 39
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.7816619873046875,
      "learning_rate": 6.750000000000001e-05,
      "loss": 0.1175,
      "step": 40
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8218390804597702,
      "eval_f1": 0.8113656233607274,
      "eval_keras_BCE": 0.47032809257507324,
      "eval_loss": 0.40407872200012207,
      "eval_precision": 0.7968112394467705,
      "eval_recall": 0.8947368421052632,
      "eval_runtime": 3.4212,
      "eval_samples_per_second": 50.86,
      "eval_steps_per_second": 6.431,
      "eval_weighted BCE": 31.463329315185547,
      "step": 40
    },
    {
      "epoch": 1.025,
      "grad_norm": 2.734225034713745,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.393,
      "step": 41
    },
    {
      "epoch": 1.05,
      "grad_norm": 2.412355899810791,
      "learning_rate": 6.583333333333334e-05,
      "loss": 0.3435,
      "step": 42
    },
    {
      "epoch": 1.075,
      "grad_norm": 1.471339464187622,
      "learning_rate": 6.500000000000001e-05,
      "loss": 0.337,
      "step": 43
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.522343635559082,
      "learning_rate": 6.416666666666668e-05,
      "loss": 0.3533,
      "step": 44
    },
    {
      "epoch": 1.125,
      "grad_norm": 3.597278118133545,
      "learning_rate": 6.333333333333333e-05,
      "loss": 0.3165,
      "step": 45
    },
    {
      "epoch": 1.15,
      "grad_norm": 3.221130609512329,
      "learning_rate": 6.25e-05,
      "loss": 0.4236,
      "step": 46
    },
    {
      "epoch": 1.175,
      "grad_norm": 2.1316676139831543,
      "learning_rate": 6.166666666666667e-05,
      "loss": 0.3076,
      "step": 47
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.351717472076416,
      "learning_rate": 6.083333333333333e-05,
      "loss": 0.2896,
      "step": 48
    },
    {
      "epoch": 1.225,
      "grad_norm": 1.706130862236023,
      "learning_rate": 6e-05,
      "loss": 0.2698,
      "step": 49
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.7282733917236328,
      "learning_rate": 5.916666666666667e-05,
      "loss": 0.3747,
      "step": 50
    },
    {
      "epoch": 1.275,
      "grad_norm": 2.1241536140441895,
      "learning_rate": 5.833333333333334e-05,
      "loss": 0.3309,
      "step": 51
    },
    {
      "epoch": 1.3,
      "grad_norm": 2.296192169189453,
      "learning_rate": 5.7499999999999995e-05,
      "loss": 0.3252,
      "step": 52
    },
    {
      "epoch": 1.325,
      "grad_norm": 1.1721686124801636,
      "learning_rate": 5.666666666666667e-05,
      "loss": 0.3465,
      "step": 53
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.7584402561187744,
      "learning_rate": 5.583333333333334e-05,
      "loss": 0.2633,
      "step": 54
    },
    {
      "epoch": 1.375,
      "grad_norm": 0.8912662267684937,
      "learning_rate": 5.500000000000001e-05,
      "loss": 0.2616,
      "step": 55
    },
    {
      "epoch": 1.4,
      "grad_norm": 2.0354976654052734,
      "learning_rate": 5.4166666666666664e-05,
      "loss": 0.2968,
      "step": 56
    },
    {
      "epoch": 1.425,
      "grad_norm": 3.554201602935791,
      "learning_rate": 5.333333333333333e-05,
      "loss": 0.3478,
      "step": 57
    },
    {
      "epoch": 1.45,
      "grad_norm": 1.8190231323242188,
      "learning_rate": 5.25e-05,
      "loss": 0.2557,
      "step": 58
    },
    {
      "epoch": 1.475,
      "grad_norm": 2.2095298767089844,
      "learning_rate": 5.166666666666667e-05,
      "loss": 0.3329,
      "step": 59
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.0002299547195435,
      "learning_rate": 5.0833333333333333e-05,
      "loss": 0.2614,
      "step": 60
    },
    {
      "epoch": 1.525,
      "grad_norm": 4.128238677978516,
      "learning_rate": 5e-05,
      "loss": 0.296,
      "step": 61
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.972168207168579,
      "learning_rate": 4.9166666666666665e-05,
      "loss": 0.2825,
      "step": 62
    },
    {
      "epoch": 1.575,
      "grad_norm": 4.413649082183838,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 0.3592,
      "step": 63
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.8167715072631836,
      "learning_rate": 4.75e-05,
      "loss": 0.3868,
      "step": 64
    },
    {
      "epoch": 1.625,
      "grad_norm": 1.2148783206939697,
      "learning_rate": 4.666666666666667e-05,
      "loss": 0.2682,
      "step": 65
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.8443706035614014,
      "learning_rate": 4.5833333333333334e-05,
      "loss": 0.3206,
      "step": 66
    },
    {
      "epoch": 1.675,
      "grad_norm": 1.1861306428909302,
      "learning_rate": 4.5e-05,
      "loss": 0.3357,
      "step": 67
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.5506887435913086,
      "learning_rate": 4.4166666666666665e-05,
      "loss": 0.3175,
      "step": 68
    },
    {
      "epoch": 1.725,
      "grad_norm": 2.2357656955718994,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 0.3237,
      "step": 69
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.1211439371109009,
      "learning_rate": 4.25e-05,
      "loss": 0.2922,
      "step": 70
    },
    {
      "epoch": 1.775,
      "grad_norm": 0.8794904351234436,
      "learning_rate": 4.166666666666667e-05,
      "loss": 0.3209,
      "step": 71
    },
    {
      "epoch": 1.8,
      "grad_norm": 2.9345502853393555,
      "learning_rate": 4.0833333333333334e-05,
      "loss": 0.294,
      "step": 72
    },
    {
      "epoch": 1.825,
      "grad_norm": 2.3265326023101807,
      "learning_rate": 4e-05,
      "loss": 0.3043,
      "step": 73
    },
    {
      "epoch": 1.85,
      "grad_norm": 1.1085131168365479,
      "learning_rate": 3.9166666666666665e-05,
      "loss": 0.2971,
      "step": 74
    },
    {
      "epoch": 1.875,
      "grad_norm": 1.0922166109085083,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 0.35,
      "step": 75
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.4927600622177124,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 0.2832,
      "step": 76
    },
    {
      "epoch": 1.925,
      "grad_norm": 1.0431300401687622,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 0.2708,
      "step": 77
    },
    {
      "epoch": 1.95,
      "grad_norm": 1.3363473415374756,
      "learning_rate": 3.5833333333333335e-05,
      "loss": 0.3316,
      "step": 78
    },
    {
      "epoch": 1.975,
      "grad_norm": 0.9812036156654358,
      "learning_rate": 3.5e-05,
      "loss": 0.3051,
      "step": 79
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.9880136251449585,
      "learning_rate": 3.4166666666666666e-05,
      "loss": 0.2394,
      "step": 80
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8218390804597702,
      "eval_f1": 0.812415232133542,
      "eval_keras_BCE": 0.4272362291812897,
      "eval_loss": 0.34213322401046753,
      "eval_precision": 0.8285597653265637,
      "eval_recall": 0.9122807017543859,
      "eval_runtime": 1.1422,
      "eval_samples_per_second": 152.339,
      "eval_steps_per_second": 19.261,
      "eval_weighted BCE": 28.58062744140625,
      "step": 80
    },
    {
      "epoch": 2.025,
      "grad_norm": 1.1033538579940796,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.3084,
      "step": 81
    },
    {
      "epoch": 2.05,
      "grad_norm": 1.0890493392944336,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 0.3622,
      "step": 82
    },
    {
      "epoch": 2.075,
      "grad_norm": 1.0908293724060059,
      "learning_rate": 3.1666666666666666e-05,
      "loss": 0.256,
      "step": 83
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.8976914286613464,
      "learning_rate": 3.0833333333333335e-05,
      "loss": 0.2092,
      "step": 84
    },
    {
      "epoch": 2.125,
      "grad_norm": 1.5407066345214844,
      "learning_rate": 3e-05,
      "loss": 0.273,
      "step": 85
    },
    {
      "epoch": 2.15,
      "grad_norm": 1.8820445537567139,
      "learning_rate": 2.916666666666667e-05,
      "loss": 0.2689,
      "step": 86
    },
    {
      "epoch": 2.175,
      "grad_norm": 2.056278705596924,
      "learning_rate": 2.8333333333333335e-05,
      "loss": 0.3089,
      "step": 87
    },
    {
      "epoch": 2.2,
      "grad_norm": 1.2436354160308838,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 0.2967,
      "step": 88
    },
    {
      "epoch": 2.225,
      "grad_norm": 1.9760174751281738,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.2582,
      "step": 89
    },
    {
      "epoch": 2.25,
      "grad_norm": 1.556349754333496,
      "learning_rate": 2.5833333333333336e-05,
      "loss": 0.2931,
      "step": 90
    },
    {
      "epoch": 2.275,
      "grad_norm": 1.7874950170516968,
      "learning_rate": 2.5e-05,
      "loss": 0.2462,
      "step": 91
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.9725401997566223,
      "learning_rate": 2.4166666666666667e-05,
      "loss": 0.1605,
      "step": 92
    },
    {
      "epoch": 2.325,
      "grad_norm": 2.0971970558166504,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 0.2899,
      "step": 93
    },
    {
      "epoch": 2.35,
      "grad_norm": 1.7487739324569702,
      "learning_rate": 2.25e-05,
      "loss": 0.3133,
      "step": 94
    },
    {
      "epoch": 2.375,
      "grad_norm": 1.671911358833313,
      "learning_rate": 2.1666666666666667e-05,
      "loss": 0.2856,
      "step": 95
    },
    {
      "epoch": 2.4,
      "grad_norm": 2.395747661590576,
      "learning_rate": 2.0833333333333336e-05,
      "loss": 0.2743,
      "step": 96
    },
    {
      "epoch": 2.425,
      "grad_norm": 1.3332648277282715,
      "learning_rate": 2e-05,
      "loss": 0.2647,
      "step": 97
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.8503382802009583,
      "learning_rate": 1.9166666666666667e-05,
      "loss": 0.2799,
      "step": 98
    },
    {
      "epoch": 2.475,
      "grad_norm": 2.6497631072998047,
      "learning_rate": 1.8333333333333333e-05,
      "loss": 0.2796,
      "step": 99
    },
    {
      "epoch": 2.5,
      "grad_norm": 2.6188368797302246,
      "learning_rate": 1.75e-05,
      "loss": 0.2304,
      "step": 100
    },
    {
      "epoch": 2.525,
      "grad_norm": 1.670945644378662,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.2529,
      "step": 101
    },
    {
      "epoch": 2.55,
      "grad_norm": 2.0238072872161865,
      "learning_rate": 1.5833333333333333e-05,
      "loss": 0.2103,
      "step": 102
    },
    {
      "epoch": 2.575,
      "grad_norm": 0.8235571980476379,
      "learning_rate": 1.5e-05,
      "loss": 0.2824,
      "step": 103
    },
    {
      "epoch": 2.6,
      "grad_norm": 1.8774515390396118,
      "learning_rate": 1.4166666666666668e-05,
      "loss": 0.346,
      "step": 104
    },
    {
      "epoch": 2.625,
      "grad_norm": 1.052075982093811,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.2329,
      "step": 105
    },
    {
      "epoch": 2.65,
      "grad_norm": 1.2079662084579468,
      "learning_rate": 1.25e-05,
      "loss": 0.2931,
      "step": 106
    },
    {
      "epoch": 2.675,
      "grad_norm": 3.672995090484619,
      "learning_rate": 1.1666666666666668e-05,
      "loss": 0.2281,
      "step": 107
    },
    {
      "epoch": 2.7,
      "grad_norm": 1.2311257123947144,
      "learning_rate": 1.0833333333333334e-05,
      "loss": 0.2671,
      "step": 108
    },
    {
      "epoch": 2.725,
      "grad_norm": 1.0419846773147583,
      "learning_rate": 1e-05,
      "loss": 0.2845,
      "step": 109
    },
    {
      "epoch": 2.75,
      "grad_norm": 1.2636072635650635,
      "learning_rate": 9.166666666666666e-06,
      "loss": 0.2493,
      "step": 110
    },
    {
      "epoch": 2.775,
      "grad_norm": 3.523486375808716,
      "learning_rate": 8.333333333333334e-06,
      "loss": 0.2499,
      "step": 111
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.468117117881775,
      "learning_rate": 7.5e-06,
      "loss": 0.2543,
      "step": 112
    },
    {
      "epoch": 2.825,
      "grad_norm": 2.078110933303833,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.2607,
      "step": 113
    },
    {
      "epoch": 2.85,
      "grad_norm": 1.865801453590393,
      "learning_rate": 5.833333333333334e-06,
      "loss": 0.363,
      "step": 114
    },
    {
      "epoch": 2.875,
      "grad_norm": 2.430530548095703,
      "learning_rate": 5e-06,
      "loss": 0.2442,
      "step": 115
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.8500272035598755,
      "learning_rate": 4.166666666666667e-06,
      "loss": 0.2149,
      "step": 116
    },
    {
      "epoch": 2.925,
      "grad_norm": 0.9981368184089661,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.2043,
      "step": 117
    },
    {
      "epoch": 2.95,
      "grad_norm": 1.2786563634872437,
      "learning_rate": 2.5e-06,
      "loss": 0.2455,
      "step": 118
    },
    {
      "epoch": 2.975,
      "grad_norm": 0.8882056474685669,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 0.2466,
      "step": 119
    },
    {
      "epoch": 3.0,
      "grad_norm": 3.5991506576538086,
      "learning_rate": 8.333333333333333e-07,
      "loss": 0.2725,
      "step": 120
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8160919540229885,
      "eval_f1": 0.806881243063263,
      "eval_keras_BCE": 0.4420470893383026,
      "eval_loss": 0.35464826226234436,
      "eval_precision": 0.8183730455367088,
      "eval_recall": 0.9122807017543859,
      "eval_runtime": 1.1152,
      "eval_samples_per_second": 156.029,
      "eval_steps_per_second": 19.728,
      "eval_weighted BCE": 29.571430206298828,
      "step": 120
    }
  ],
  "logging_steps": 1,
  "max_steps": 120,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8067821509440000.0,
  "train_batch_size": 256,
  "trial_name": null,
  "trial_params": null
}
