{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb3b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c3edda",
   "metadata": {},
   "source": [
    "This script was used to format data into something that Label studio could work with. Essentially this was only used in structuring data for the gold labelled validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eb9900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary to a JSON string and write to file\n",
    "with open('/work/MarkusLundsfrydJensen#1865/Bachelor_project/danish_blame.json', 'w') as file:\n",
    "    file.write(json.dumps(danish_sentences_with_blame, indent=4))\n",
    "\n",
    "#here danish_sentences_with_blame is output of function danish_sentences_with_blame_extraction()\n",
    "\n",
    "\n",
    "#preprocess data for label studio\n",
    "# Load your data\n",
    "with open(\"/work/MarkusLundsfrydJensen#1865/Bachelor_project/danish_blame.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "flattened = []\n",
    "\n",
    "for paragraph, sentences in data.items():\n",
    "    for sentence_nr, text in sentences.items():\n",
    "        flattened.append({\n",
    "            \"paragraph\": paragraph,\n",
    "            \"sentence_nr\": sentence_nr,\n",
    "            \"text\": text\n",
    "        })\n",
    "\n",
    "# Save in a format Label Studio can import\n",
    "with open(\"/work/MarkusLundsfrydJensen#1865/Bachelor_project/labelstudio_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(flattened, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0bb867",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final data is csv file as output of PolDebate model\n",
    "\n",
    "meta_data = final_data[['Unnamed: 0','speaker','party']]\n",
    "\n",
    "\n",
    "meta_data = meta_data.replace({np.nan: None})\n",
    "meta_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83eddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect label studio data with meta data\n",
    "\n",
    "\n",
    "# Load the flattened sentence JSON\n",
    "with open(\"/work/MarkusLundsfrydJensen#1865/Bachelor_project/labelstudio_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    sentences = json.load(f)\n",
    "\n",
    "# Load metadata\n",
    "meta = meta_data\n",
    "\n",
    "# Convert metadata to dict for fast lookup\n",
    "meta_dict = meta.set_index(\"Unnamed: 0\").to_dict(orient=\"index\")\n",
    "\n",
    "# Merge\n",
    "for item in sentences:\n",
    "    paragraph = int(item[\"paragraph\"])\n",
    "    if paragraph in meta_dict:\n",
    "\n",
    "        item.update(meta_dict[paragraph])\n",
    "\n",
    "# Save merged dataset\n",
    "with open(\"/work/MarkusLundsfrydJensen#1865/Bachelor_project/labelstudio_merged.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sentences, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560e2c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a272a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Now append preceding and succeding sentence for each blame\n",
    "import json\n",
    "# Load the flattened sentence JSON\n",
    "with open(\"/work/MarkusLundsfrydJensen#1865/Bachelor_project/labelstudio_merged.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    json_data = json.load(f)\n",
    "#also make government data available\n",
    "\n",
    "regerings_data = pd.read_csv(\"/work/MarkusLundsfrydJensen#1865/Bachelor_project/danish_govs.csv\")\n",
    "\n",
    "final_data[\"date\"] = pd.to_datetime(final_data[\"date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "regerings_data[\"Start Date\"] = pd.to_datetime(regerings_data[\"Start Date\"], format=\"%Y-%m-%d\")\n",
    "regerings_data[\"End Date\"]   = pd.to_datetime(regerings_data[\"End Date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def find_government(date):\n",
    "    match = regerings_data[(regerings_data[\"Start Date\"] <= date) & (regerings_data[\"End Date\"] >= date)]\n",
    "    if not match.empty:\n",
    "\n",
    "        parties = match['Party Letter']\n",
    "        parties = ast.literal_eval(parties.iloc[0])\n",
    "        \n",
    "        return parties\n",
    "    else:\n",
    "        print('empty')\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "import ast\n",
    "\n",
    "for entry in json_data:\n",
    "    paragraph_nr = int(entry['paragraph'])\n",
    "    sentence_nr = int(entry['sentence_nr'])\n",
    "\n",
    "    #initialize information on current paragraph\n",
    "    temp_data = final_data.loc[paragraph_nr]\n",
    "\n",
    "    #get preceding sentence\n",
    "    temp_data_da_text = ast.literal_eval(temp_data['da_segmented_text'])\n",
    "    \n",
    "    pr_sentence_index = sentence_nr-1\n",
    "\n",
    "    if pr_sentence_index < 0:\n",
    "        #do empty string\n",
    "        pr_sent = 'Not available (first sentence in paragraph)'\n",
    "\n",
    "    else:\n",
    "        pr_sent = f'sentence_nr {pr_sentence_index} \\n{temp_data_da_text[pr_sentence_index]}'\n",
    "\n",
    "    # find succesding sentence\n",
    "\n",
    "    suc_sent_index = sentence_nr + 1\n",
    "\n",
    "    try:\n",
    "        suc_sent = f'sentence_nr {suc_sent_index} \\n{temp_data_da_text[suc_sent_index]}'\n",
    "\n",
    "    except:\n",
    "        suc_sent = 'Not available (last sentence in paragraph)'\n",
    "\n",
    "    \n",
    "    #Find out if speaker is member of party in Government\n",
    "    party = entry['party']\n",
    "    date = temp_data['date']\n",
    "    parties_gov = find_government(date)\n",
    "    if party in parties_gov:\n",
    "        in_gov = True\n",
    "    else:\n",
    "        in_gov = False\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    #make into dict\n",
    "\n",
    "    context_dict = {'preceding_sentence': pr_sent, \n",
    "                    'succeeding_sent': suc_sent,\n",
    "                    'current_speaker_in_government': in_gov,\n",
    "                    'parties_in_government': parties_gov,\n",
    "                    'date': str(date)\n",
    "                    }\n",
    "\n",
    "    #update\n",
    "    entry.update(context_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bba1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0d3df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
