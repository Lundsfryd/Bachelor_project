{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29be4141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucloud/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import swifter\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#pip install torch transformers tqdm swifter pandas IProgress \n",
    "# python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3553de5c",
   "metadata": {},
   "source": [
    "This script runs Burnhams DEBATE model for blame detection on the translated text and maps that back to the original Danish utterance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab900d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Here we define a variable that will be passed to our classifier. This will check if a GPU is available, and use the CPU if one is not available.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # if you want to use the GPU on a macbook change 'cuda' to 'mps' and make sure you have the 'accelerate' library installed.\n",
    "# This line prints the device that will be used. Make sure it prints 'cuda' or 'mps' if you are trying to use a GPU.\n",
    "\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66fd56a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "#pipe = pipeline(\"zero-shot-classification\", model=\"mlburnham/Political_DEBATE_base_v1.0\", device = device, batch_size = 32) # To use the base model\n",
    "pipe = pipeline(\"zero-shot-classification\", model='mlburnham/Political_DEBATE_large_v1.0', device = device, batch_size = 128) # To use the large model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b88717bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc = ' it is the fault of the immigrants I think but maybe it is not entirely their fault hello'\n",
    "hypothesis_template = \"Based on this text, the author's attitude towards others is best described as {}.\"\n",
    "test_labels = [\"blame\", \"praise\", \"neutral\"]\n",
    "\n",
    "def evaluate_premise(doc, labels, hypothesis_template):\n",
    "    \n",
    "    result = pipe(doc, labels, hypothesis_template = hypothesis_template, multi_label = True)\n",
    "    result.pop('sequence')\n",
    "\n",
    "    return result\n",
    "\n",
    "result = evaluate_premise(test_doc, test_labels, hypothesis_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df19949c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': ['blame', 'neutral', 'praise'],\n",
       " 'scores': [0.9992548227310181, 0.9989248514175415, 1.2478437838581158e-07]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84c92574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>agenda</th>\n",
       "      <th>speechnumber</th>\n",
       "      <th>speaker</th>\n",
       "      <th>party</th>\n",
       "      <th>party.facts.id</th>\n",
       "      <th>chair</th>\n",
       "      <th>terms</th>\n",
       "      <th>text</th>\n",
       "      <th>parliament</th>\n",
       "      <th>iso3country</th>\n",
       "      <th>da_segmented_text</th>\n",
       "      <th>translated_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-10-07</td>\n",
       "      <td>Dagsorden</td>\n",
       "      <td>1</td>\n",
       "      <td>Gert Petersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>191</td>\n",
       "      <td>Mødet er åbnet. I henhold til grundloven er Fo...</td>\n",
       "      <td>DK-Folketing</td>\n",
       "      <td>DNK</td>\n",
       "      <td>['Mødet er åbnet.', 'I henhold til grundloven ...</td>\n",
       "      <td>['The meeting is open.', 'Under the Constituti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-10-07</td>\n",
       "      <td>Dagsorden</td>\n",
       "      <td>2</td>\n",
       "      <td>Formanden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>182</td>\n",
       "      <td>Jeg vil gerne takke Tinget for den tillid, man...</td>\n",
       "      <td>DK-Folketing</td>\n",
       "      <td>DNK</td>\n",
       "      <td>['Jeg vil gerne takke Tinget for den tillid, m...</td>\n",
       "      <td>['I would like to thank Things for the confide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-10-07</td>\n",
       "      <td>Statsministerens redegørelse i henhold til gru...</td>\n",
       "      <td>3</td>\n",
       "      <td>Poul Nyrup Rasmussen</td>\n",
       "      <td>S</td>\n",
       "      <td>379.0</td>\n",
       "      <td>False</td>\n",
       "      <td>18662</td>\n",
       "      <td>For 25 år siden sagde et flertal i befolkninge...</td>\n",
       "      <td>DK-Folketing</td>\n",
       "      <td>DNK</td>\n",
       "      <td>['For 25 år siden sagde et flertal i befolknin...</td>\n",
       "      <td>['Twenty-five years ago, a majority of the peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-10-09</td>\n",
       "      <td>1) Indstilling fra Udvalget til Valgs Prøvelse.</td>\n",
       "      <td>2</td>\n",
       "      <td>Formanden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>47</td>\n",
       "      <td>Fra Udvalget til Valgs Prøvelse har jeg modtag...</td>\n",
       "      <td>DK-Folketing</td>\n",
       "      <td>DNK</td>\n",
       "      <td>['Fra Udvalget til Valgs', 'Prøvelse', 'har je...</td>\n",
       "      <td>['From the Committee to the Committee of the R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-10-09</td>\n",
       "      <td>2) Forhandling om redegørelse nr. R 1.</td>\n",
       "      <td>3</td>\n",
       "      <td>Torben Lund</td>\n",
       "      <td>S</td>\n",
       "      <td>379.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2865</td>\n",
       "      <td>Vi står over for en meget afgørende folketings...</td>\n",
       "      <td>DK-Folketing</td>\n",
       "      <td>DNK</td>\n",
       "      <td>['Vi står over for en meget afgørende folketin...</td>\n",
       "      <td>['We are faced with a very crucial parliamenta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                             agenda  \\\n",
       "0  1997-10-07                                          Dagsorden   \n",
       "1  1997-10-07                                          Dagsorden   \n",
       "2  1997-10-07  Statsministerens redegørelse i henhold til gru...   \n",
       "3  1997-10-09    1) Indstilling fra Udvalget til Valgs Prøvelse.   \n",
       "4  1997-10-09             2) Forhandling om redegørelse nr. R 1.   \n",
       "\n",
       "   speechnumber               speaker party  party.facts.id  chair  terms  \\\n",
       "0             1         Gert Petersen   NaN             NaN   True    191   \n",
       "1             2             Formanden   NaN             NaN   True    182   \n",
       "2             3  Poul Nyrup Rasmussen     S           379.0  False  18662   \n",
       "3             2             Formanden   NaN             NaN   True     47   \n",
       "4             3           Torben Lund     S           379.0  False   2865   \n",
       "\n",
       "                                                text    parliament  \\\n",
       "0  Mødet er åbnet. I henhold til grundloven er Fo...  DK-Folketing   \n",
       "1  Jeg vil gerne takke Tinget for den tillid, man...  DK-Folketing   \n",
       "2  For 25 år siden sagde et flertal i befolkninge...  DK-Folketing   \n",
       "3  Fra Udvalget til Valgs Prøvelse har jeg modtag...  DK-Folketing   \n",
       "4  Vi står over for en meget afgørende folketings...  DK-Folketing   \n",
       "\n",
       "  iso3country                                  da_segmented_text  \\\n",
       "0         DNK  ['Mødet er åbnet.', 'I henhold til grundloven ...   \n",
       "1         DNK  ['Jeg vil gerne takke Tinget for den tillid, m...   \n",
       "2         DNK  ['For 25 år siden sagde et flertal i befolknin...   \n",
       "3         DNK  ['Fra Udvalget til Valgs', 'Prøvelse', 'har je...   \n",
       "4         DNK  ['Vi står over for en meget afgørende folketin...   \n",
       "\n",
       "                                     translated_text  \n",
       "0  ['The meeting is open.', 'Under the Constituti...  \n",
       "1  ['I would like to thank Things for the confide...  \n",
       "2  ['Twenty-five years ago, a majority of the peo...  \n",
       "3  ['From the Committee to the Committee of the R...  \n",
       "4  ['We are faced with a very crucial parliamenta...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_trans = pd.read_csv(\"/work/MarkusLundsfrydJensen#1865/annotation_data_translated_version_03_10.csv\")\n",
    "\n",
    "df_trans.pop('Unnamed: 0')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c13a0867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36314"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507aa83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_doc = ' it is the fault of the immigrants I think but maybe it is not entirely their fault hello'\n",
    "\n",
    "\n",
    "#result = evaluate_premise(test_doc, test_labels, hypothesis_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d68bb6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef60b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "#tried to make it faster\n",
    "\n",
    "\n",
    "# Pick device automatically\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(f\"Device: {'cuda' if device == 0 else 'cpu'}\")\n",
    "\n",
    "# Use base model for speed (large is much slower)\n",
    "pipe = pipeline(\"zero-shot-classification\", model='mlburnham/Political_DEBATE_large_v1.0', device = device, batch_size = 512)\n",
    "\n",
    "'''def split_paragraph(paragraph: str):\n",
    "    \"\"\"Split paragraph into sentences.\"\"\"\n",
    "    doc = nlp(paragraph)\n",
    "    return [sent.text.strip() for sent in doc.sents]'''\n",
    "\n",
    "# Template + labels\n",
    "hypothesis_template = \"Based on this text, the author's attitude towards others is best described as {}.\"\n",
    "labels = [\"blame\", \"praise\", \"neutral\"]\n",
    "\n",
    "def evaluate_premise(doc):\n",
    "    return pipe(doc, labels, hypothesis_template=hypothesis_template, multi_label=True)\n",
    "\n",
    "def blame_in_batch(sentences, batch_size=512):\n",
    "    results = []\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i+batch_size]\n",
    "        output = evaluate_premise(batch)\n",
    "        if isinstance(output, list):\n",
    "            results.extend(output)\n",
    "        else:\n",
    "            results.append(output)\n",
    "    return results\n",
    "\n",
    "def blame_in_paragraph(para):\n",
    "    #sentences = split_paragraph(para)\n",
    "    sentences = ast.literal_eval(para)\n",
    "    return blame_in_batch(sentences)\n",
    "\n",
    "'''# ✅ Apply in parallel with \n",
    "\n",
    "def detect_blame_in_dataframe(df, text_col=\"translated_text\", batch_size=512):\n",
    "    tqdm.pandas(desc=\"Blame Detection (GPU)\")\n",
    "    df[\"blame_in_text\"] = df[text_col].swifter.apply(blame_in_paragraph)\n",
    "    return df'''\n",
    "\n",
    "def detect_blame_in_dataframe(df, text_col=\"translated_text\", output_column = \"blame_in_text\"):\n",
    "    results = []\n",
    "    for para in tqdm(df[text_col], desc=\"Blame Detection (GPU)\"):\n",
    "        results.append(blame_in_paragraph(para))\n",
    "    df[output_column] = results\n",
    "    return df\n",
    "# Example usage\n",
    "# data_test = detect_blame_in_dataframe(data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e80ca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = df_trans.loc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "026ce45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Blame Detection (GPU):   0%|          | 1/36314 [00:00<1:12:55,  8.30it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Blame Detection (GPU): 100%|██████████| 36314/36314 [1:19:48<00:00,  7.58it/s]  \n"
     ]
    }
   ],
   "source": [
    "#data_test = detect_blame_in_dataframe(data_test)\n",
    "df_trans = detect_blame_in_dataframe(df_trans)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "739df83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean data columns\n",
    "export_data = df_trans\n",
    "export_data['da_segmented_text'] = export_data['da_segmented_text'].apply(ast.literal_eval)\n",
    "export_data['translated_text'] = export_data['translated_text'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e46222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_data.to_csv(\"/work/MarkusLundsfrydJensen#1865/cleaned_annotation_data_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e38746c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test if the cleaning worked\n",
    "\n",
    "type(export_data.loc[0]['da_segmented_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc31fa1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(export_data.loc[0]['translated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "887c458a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MarianMTModel, MarianTokenizer\n\u001b[32m      3\u001b[39m model_name = \u001b[33m'\u001b[39m\u001b[33mHelsinki-NLP/opus-mt-da-en\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      4\u001b[39m tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "model_name = 'Helsinki-NLP/opus-mt-da-en'\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "def translate(text):\n",
    "    translated = model.generate(**tokenizer(text, return_tensors=\"pt\", padding=True))\n",
    "    return tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "\n",
    "print(translate(\"Hej, hvordan har du det?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1b48951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "\n",
    "nlp = spacy.load(\"da_core_news_sm\")\n",
    "\n",
    "def split_paragraph(paragraph: str):\n",
    "    doc = nlp(paragraph)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b1de7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_paragraph(para):\n",
    "\n",
    "    translated_sentences = \"\"\n",
    "\n",
    "    sentences = split_paragraph(para)\n",
    "\n",
    "    for sent in sentences:\n",
    "        #translate sentence\n",
    "        english_sentence = translate(sent)\n",
    "\n",
    "        translated_sentences += english_sentence + \" \"\n",
    "\n",
    "    return translated_sentences\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72a7b390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hey, you. How's it going? You bet I've been through a lot these past few days. I'm super busy, but otherwise I'll be fine. I was down shopping the other day. It was really hard to carry so many things up the apartment again. Hey, you. How you doing? You bet I've been through a lot these past few days. I'm super busy, but otherwise I'll be fine. I was down shopping the other day. It was really hard to carry so many things up the apartment again. Hey, you. How you doing? You bet I've been through a lot these past few days. I'm super busy, but otherwise I'll be fine. I was down shopping the other day. It was really hard to carry so many things up the apartment again. Hey, you. How you doing? You bet I've been through a lot these past few days. I'm super busy, but otherwise I'll be fine. I was down shopping the other day. It was really hard to carry so many things up in the apartment again4 Hey, you. How's it going? You bet I've been through a lot these past few days. I'm super busy, but otherwise I'll be fine. I was down shopping the other day. It was really hard to carry so many things up the apartment again. 7.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph = \"Hej med dig, hvordan går det? Du kan tro, jeg har oplevet meget de seneste par dage. Jeg har super travlt, men ellers går det fint. Jeg var nede og handle den anden dag. Det var virkelig hårdt at bære så mange ting op i lejligheden igen. Hej med dig, hvordan går det? Du kan tro, jeg har oplevet meget de seneste par dage. Jeg har super travlt, men ellers går det fint. Jeg var nede og handle den anden dag. Det var virkelig hårdt at bære så mange ting op i lejligheden igen. Hej med dig, hvordan går det? Du kan tro, jeg har oplevet meget de seneste par dage. Jeg har super travlt, men ellers går det fint. Jeg var nede og handle den anden dag. Det var virkelig hårdt at bære så mange ting op i lejligheden igen. Hej med dig, hvordan går det? Du kan tro, jeg har oplevet meget de seneste par dage. Jeg har super travlt, men ellers går det fint. Jeg var nede og handle den anden dag. Det var virkelig hårdt at bære så mange ting op i lejligheden igen4 Hej med dig, hvordan går det? Du kan tro, jeg har oplevet meget de seneste par dage. Jeg har super travlt, men ellers går det fint. Jeg var nede og handle den anden dag. Det var virkelig hårdt at bære så mange ting op i lejligheden igen. 7.\"\n",
    "\n",
    "output = translate_paragraph(paragraph)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64f68302",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/swifter/swifter.py:311\u001b[39m, in \u001b[36mSeriesAccessor.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, **kwds)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m suppress_stdout_stderr_logging():\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     tmp_df = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    312\u001b[39m     sample_df = sample.apply(func, convert_dtype=convert_dtype, args=args, **kwds)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mtranslate_paragraph\u001b[39m\u001b[34m(para)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtranslate_paragraph\u001b[39m(para):\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     sentences = \u001b[43msplit_paragraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpara\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m     translated_sentences = translate_batch(sentences)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36msplit_paragraph\u001b[39m\u001b[34m(paragraph)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msplit_paragraph\u001b[39m(paragraph: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     doc = \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparagraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [sent.text.strip() \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m doc.sents]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/language.py:1041\u001b[39m, in \u001b[36mLanguage.__call__\u001b[39m\u001b[34m(self, text, disable, component_cfg)\u001b[39m\n\u001b[32m   1027\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Apply the pipeline to some text. The text can span multiple sentences,\u001b[39;00m\n\u001b[32m   1028\u001b[39m \u001b[33;03mand can contain arbitrary whitespace. Alignment into the original string\u001b[39;00m\n\u001b[32m   1029\u001b[39m \u001b[33;03mis preserved.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1039\u001b[39m \u001b[33;03mDOCS: https://spacy.io/api/language#call\u001b[39;00m\n\u001b[32m   1040\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1041\u001b[39m doc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ensure_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m component_cfg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/language.py:1135\u001b[39m, in \u001b[36mLanguage._ensure_doc\u001b[39m\u001b[34m(self, doc_like)\u001b[39m\n\u001b[32m   1134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Doc(\u001b[38;5;28mself\u001b[39m.vocab).from_bytes(doc_like)\n\u001b[32m-> \u001b[39m\u001b[32m1135\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors.E1041.format(\u001b[38;5;28mtype\u001b[39m=\u001b[38;5;28mtype\u001b[39m(doc_like)))\n",
      "\u001b[31mValueError\u001b[39m: [E1041] Expected a string, Doc, or bytes as input, but got: <class 'pandas.core.series.Series'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#df['translated_text'] = df['text'].apply(translate_paragraph)\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mswifter\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mtranslated_text\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mswifter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtranslate_paragraph\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/swifter/swifter.py:320\u001b[39m, in \u001b[36mSeriesAccessor.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, **kwds)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ERRORS_TO_HANDLE:  \u001b[38;5;66;03m# if can't vectorize, estimate time to pandas apply\u001b[39;00m\n\u001b[32m    319\u001b[39m     wrapped = \u001b[38;5;28mself\u001b[39m._wrapped_apply(func, convert_dtype=convert_dtype, args=args, **kwds)\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m     timed = \u001b[43mtimeit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN_REPEATS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m     sample_proc_est = timed / N_REPEATS\n\u001b[32m    322\u001b[39m     est_apply_duration = sample_proc_est / \u001b[38;5;28mself\u001b[39m._SAMPLE_SIZE * \u001b[38;5;28mself\u001b[39m._nrows\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/timeit.py:237\u001b[39m, in \u001b[36mtimeit\u001b[39m\u001b[34m(stmt, setup, timer, number, globals)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtimeit\u001b[39m(stmt=\u001b[33m\"\u001b[39m\u001b[33mpass\u001b[39m\u001b[33m\"\u001b[39m, setup=\u001b[33m\"\u001b[39m\u001b[33mpass\u001b[39m\u001b[33m\"\u001b[39m, timer=default_timer,\n\u001b[32m    235\u001b[39m            number=default_number, \u001b[38;5;28mglobals\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    236\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Convenience function to create Timer object and call timeit method.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTimer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msetup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/timeit.py:180\u001b[39m, in \u001b[36mTimer.timeit\u001b[39m\u001b[34m(self, number)\u001b[39m\n\u001b[32m    178\u001b[39m gc.disable()\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     timing = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<timeit-src>:6\u001b[39m, in \u001b[36minner\u001b[39m\u001b[34m(_it, _timer, _stmt)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/swifter/swifter.py:228\u001b[39m, in \u001b[36mSeriesAccessor._wrapped_apply.<locals>.wrapped\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m():\n\u001b[32m    227\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m suppress_stdout_stderr_logging():\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_SAMPLE_INDEX\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/pandas/core/series.py:4935\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4800\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4801\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4802\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4807\u001b[39m     **kwargs,\n\u001b[32m   4808\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4809\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4810\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4811\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4926\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4927\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4928\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4929\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4930\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4931\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4932\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4933\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4934\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4935\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/pandas/core/apply.py:1422\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1421\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/pandas/core/apply.py:1502\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1501\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1507\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1508\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/pandas/core/base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/pandas/core/algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mtranslate_paragraph\u001b[39m\u001b[34m(para)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtranslate_paragraph\u001b[39m(para):\n\u001b[32m     34\u001b[39m     sentences = split_paragraph(para)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     translated_sentences = \u001b[43mtranslate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(translated_sentences)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mtranslate_batch\u001b[39m\u001b[34m(sentences, batch_size)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available():\n\u001b[32m     27\u001b[39m     tokens = {k: v.to(\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tokens.items()}\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m translated = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m decoded = [tokenizer.decode(t, skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m translated]\n\u001b[32m     30\u001b[39m translations.extend(decoded)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/transformers/generation/utils.py:2551\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2539\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._sample(\n\u001b[32m   2540\u001b[39m         input_ids,\n\u001b[32m   2541\u001b[39m         logits_processor=prepared_logits_processor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2546\u001b[39m         **model_kwargs,\n\u001b[32m   2547\u001b[39m     )\n\u001b[32m   2549\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2550\u001b[39m     \u001b[38;5;66;03m# 11. run beam sample\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2551\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_beam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2552\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2553\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2554\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2555\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2556\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2557\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2558\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2560\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode == GenerationMode.GROUP_BEAM_SEARCH:\n\u001b[32m   2561\u001b[39m     logger.warning_once(\n\u001b[32m   2562\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGroup Beam Search is scheduled to be moved to a `custom_generate` repository in v4.55.0. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2563\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTo prevent loss of backward compatibility, add `trust_remote_code=True` to your `generate` call.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2564\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/transformers/generation/utils.py:3462\u001b[39m, in \u001b[36mGenerationMixin._beam_search\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[39m\n\u001b[32m   3460\u001b[39m         model_kwargs[\u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m._reorder_cache(model_kwargs[\u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m], beam_idx)\n\u001b[32m   3461\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3462\u001b[39m         \u001b[43mmodel_kwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpast_key_values\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreorder_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3464\u001b[39m cur_len = cur_len + \u001b[32m1\u001b[39m\n\u001b[32m   3465\u001b[39m is_early_stop_heuristic_unsatisfied = \u001b[38;5;28mself\u001b[39m._check_early_stop_heuristic(\n\u001b[32m   3466\u001b[39m     is_early_stop_heuristic_unsatisfied=is_early_stop_heuristic_unsatisfied,\n\u001b[32m   3467\u001b[39m     running_beam_scores=running_beam_scores,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3474\u001b[39m     length_penalty=length_penalty,\n\u001b[32m   3475\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/transformers/cache_utils.py:1349\u001b[39m, in \u001b[36mEncoderDecoderCache.reorder_cache\u001b[39m\u001b[34m(self, beam_idx)\u001b[39m\n\u001b[32m   1347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreorder_cache\u001b[39m(\u001b[38;5;28mself\u001b[39m, beam_idx: torch.LongTensor):\n\u001b[32m   1348\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Reorders the cache for beam search, given the selected beam indices.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1349\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attention_cache\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreorder_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1350\u001b[39m     \u001b[38;5;28mself\u001b[39m.cross_attention_cache.reorder_cache(beam_idx)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/transformers/cache_utils.py:884\u001b[39m, in \u001b[36mCache.reorder_cache\u001b[39m\u001b[34m(self, beam_idx)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Reorder the cache for beam search\"\"\"\u001b[39;00m\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.layers)):\n\u001b[32m--> \u001b[39m\u001b[32m884\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreorder_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/transformers/cache_utils.py:78\u001b[39m, in \u001b[36mCacheLayerMixin.reorder_cache\u001b[39m\u001b[34m(self, beam_idx)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Reorders this layer's cache for beam search.\"\"\"\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_seq_length() > \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28mself\u001b[39m.keys = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28mself\u001b[39m.values = \u001b[38;5;28mself\u001b[39m.values.index_select(\u001b[32m0\u001b[39m, beam_idx.to(\u001b[38;5;28mself\u001b[39m.values.device))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#df['translated_text'] = df['text'].apply(translate_paragraph)\n",
    "\n",
    "import swifter\n",
    "\n",
    "df['translated_text'] = df['text'].swifter.apply(translate_paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5584654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "import spacy\n",
    "import swifter\n",
    "\n",
    "# Load models\n",
    "model_name = 'Helsinki-NLP/opus-mt-da-en'\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "model.eval()\n",
    "if torch.cuda.is_available():\n",
    "    model.to('cuda')\n",
    "\n",
    "# SpaCy for sentence splitting (optional)\n",
    "nlp = spacy.load(\"da_core_news_sm\")\n",
    "\n",
    "def split_paragraph(paragraph: str):\n",
    "    doc = nlp.pipe([paragraph], batch_size=1, n_process=1)\n",
    "    return [sent.text.strip() for sent in list(doc)[0].sents]\n",
    "\n",
    "def translate_batch(sentences, batch_size=16):\n",
    "    translations = []\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i+batch_size]\n",
    "        tokens = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        if torch.cuda.is_available():\n",
    "            tokens = {k: v.to('cuda') for k, v in tokens.items()}\n",
    "        translated = model.generate(**tokens)\n",
    "        decoded = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
    "        translations.extend(decoded)\n",
    "    return translations\n",
    "\n",
    "def translate_paragraph(para):\n",
    "    sentences = split_paragraph(para)\n",
    "    translated_sentences = translate_batch(sentences)\n",
    "    return \" \".join(translated_sentences)\n",
    "\n",
    "# Apply to dataframe in parallel\n",
    "#df['translated_text'] = df['text'].swifter.apply(translate_paragraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dc2b5b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/swifter/swifter.py:311\u001b[39m, in \u001b[36mSeriesAccessor.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, **kwds)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m suppress_stdout_stderr_logging():\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     tmp_df = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    312\u001b[39m     sample_df = sample.apply(func, convert_dtype=convert_dtype, args=args, **kwds)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mtranslate_paragraph\u001b[39m\u001b[34m(para)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtranslate_paragraph\u001b[39m(para):\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     sentences = \u001b[43msplit_paragraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpara\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m     translated_sentences = translate_batch(sentences)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36msplit_paragraph\u001b[39m\u001b[34m(paragraph)\u001b[39m\n\u001b[32m     18\u001b[39m doc = nlp.pipe([paragraph], batch_size=\u001b[32m1\u001b[39m, n_process=\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [sent.text.strip() \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m].sents]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/language.py:1622\u001b[39m, in \u001b[36mLanguage.pipe\u001b[39m\u001b[34m(self, texts, as_tuples, batch_size, disable, component_cfg, n_process)\u001b[39m\n\u001b[32m   1621\u001b[39m         docs = pipe(docs)\n\u001b[32m-> \u001b[39m\u001b[32m1622\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1623\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/util.py:1714\u001b[39m, in \u001b[36m_pipe\u001b[39m\u001b[34m(docs, proc, name, default_error_handler, kwargs)\u001b[39m\n\u001b[32m   1713\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[33m\"\u001b[39m\u001b[33mpipe\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1714\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m proc.pipe(docs, **kwargs)\n\u001b[32m   1715\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1716\u001b[39m     \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/pipeline/transition_parser.pyx:245\u001b[39m, in \u001b[36mpipe\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/util.py:1661\u001b[39m, in \u001b[36mminibatch\u001b[39m\u001b[34m(items, size)\u001b[39m\n\u001b[32m   1660\u001b[39m batch_size = \u001b[38;5;28mnext\u001b[39m(size_)\n\u001b[32m-> \u001b[39m\u001b[32m1661\u001b[39m batch = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1662\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/util.py:1714\u001b[39m, in \u001b[36m_pipe\u001b[39m\u001b[34m(docs, proc, name, default_error_handler, kwargs)\u001b[39m\n\u001b[32m   1713\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[33m\"\u001b[39m\u001b[33mpipe\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1714\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m proc.pipe(docs, **kwargs)\n\u001b[32m   1715\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1716\u001b[39m     \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/pipeline/pipe.pyx:48\u001b[39m, in \u001b[36mpipe\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/util.py:1714\u001b[39m, in \u001b[36m_pipe\u001b[39m\u001b[34m(docs, proc, name, default_error_handler, kwargs)\u001b[39m\n\u001b[32m   1713\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[33m\"\u001b[39m\u001b[33mpipe\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1714\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m proc.pipe(docs, **kwargs)\n\u001b[32m   1715\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1716\u001b[39m     \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/pipeline/trainable_pipe.pyx:73\u001b[39m, in \u001b[36mpipe\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/util.py:1661\u001b[39m, in \u001b[36mminibatch\u001b[39m\u001b[34m(items, size)\u001b[39m\n\u001b[32m   1660\u001b[39m batch_size = \u001b[38;5;28mnext\u001b[39m(size_)\n\u001b[32m-> \u001b[39m\u001b[32m1661\u001b[39m batch = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1662\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/util.py:1714\u001b[39m, in \u001b[36m_pipe\u001b[39m\u001b[34m(docs, proc, name, default_error_handler, kwargs)\u001b[39m\n\u001b[32m   1713\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[33m\"\u001b[39m\u001b[33mpipe\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1714\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m proc.pipe(docs, **kwargs)\n\u001b[32m   1715\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1716\u001b[39m     \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/pipeline/transition_parser.pyx:245\u001b[39m, in \u001b[36mpipe\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/util.py:1661\u001b[39m, in \u001b[36mminibatch\u001b[39m\u001b[34m(items, size)\u001b[39m\n\u001b[32m   1660\u001b[39m batch_size = \u001b[38;5;28mnext\u001b[39m(size_)\n\u001b[32m-> \u001b[39m\u001b[32m1661\u001b[39m batch = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1662\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/util.py:1714\u001b[39m, in \u001b[36m_pipe\u001b[39m\u001b[34m(docs, proc, name, default_error_handler, kwargs)\u001b[39m\n\u001b[32m   1713\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[33m\"\u001b[39m\u001b[33mpipe\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1714\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m proc.pipe(docs, **kwargs)\n\u001b[32m   1715\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1716\u001b[39m     \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/pipeline/trainable_pipe.pyx:73\u001b[39m, in \u001b[36mpipe\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/util.py:1661\u001b[39m, in \u001b[36mminibatch\u001b[39m\u001b[34m(items, size)\u001b[39m\n\u001b[32m   1660\u001b[39m batch_size = \u001b[38;5;28mnext\u001b[39m(size_)\n\u001b[32m-> \u001b[39m\u001b[32m1661\u001b[39m batch = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1662\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/util.py:1714\u001b[39m, in \u001b[36m_pipe\u001b[39m\u001b[34m(docs, proc, name, default_error_handler, kwargs)\u001b[39m\n\u001b[32m   1713\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[33m\"\u001b[39m\u001b[33mpipe\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1714\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m proc.pipe(docs, **kwargs)\n\u001b[32m   1715\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1716\u001b[39m     \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/pipeline/trainable_pipe.pyx:73\u001b[39m, in \u001b[36mpipe\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/util.py:1661\u001b[39m, in \u001b[36mminibatch\u001b[39m\u001b[34m(items, size)\u001b[39m\n\u001b[32m   1660\u001b[39m batch_size = \u001b[38;5;28mnext\u001b[39m(size_)\n\u001b[32m-> \u001b[39m\u001b[32m1661\u001b[39m batch = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1662\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/language.py:1619\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1617\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1618\u001b[39m     \u001b[38;5;66;03m# if n_process == 1, no processes are forked.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1619\u001b[39m     docs = (\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ensure_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts)\n\u001b[32m   1620\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m pipe \u001b[38;5;129;01min\u001b[39;00m pipes:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/language.py:1135\u001b[39m, in \u001b[36mLanguage._ensure_doc\u001b[39m\u001b[34m(self, doc_like)\u001b[39m\n\u001b[32m   1134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Doc(\u001b[38;5;28mself\u001b[39m.vocab).from_bytes(doc_like)\n\u001b[32m-> \u001b[39m\u001b[32m1135\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors.E1041.format(\u001b[38;5;28mtype\u001b[39m=\u001b[38;5;28mtype\u001b[39m(doc_like)))\n",
      "\u001b[31mValueError\u001b[39m: [E1041] Expected a string, Doc, or bytes as input, but got: <class 'pandas.core.series.Series'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mtranslated_text\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mswifter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtranslate_paragraph\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/swifter/swifter.py:320\u001b[39m, in \u001b[36mSeriesAccessor.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, **kwds)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ERRORS_TO_HANDLE:  \u001b[38;5;66;03m# if can't vectorize, estimate time to pandas apply\u001b[39;00m\n\u001b[32m    319\u001b[39m     wrapped = \u001b[38;5;28mself\u001b[39m._wrapped_apply(func, convert_dtype=convert_dtype, args=args, **kwds)\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m     timed = \u001b[43mtimeit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN_REPEATS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m     sample_proc_est = timed / N_REPEATS\n\u001b[32m    322\u001b[39m     est_apply_duration = sample_proc_est / \u001b[38;5;28mself\u001b[39m._SAMPLE_SIZE * \u001b[38;5;28mself\u001b[39m._nrows\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/timeit.py:237\u001b[39m, in \u001b[36mtimeit\u001b[39m\u001b[34m(stmt, setup, timer, number, globals)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtimeit\u001b[39m(stmt=\u001b[33m\"\u001b[39m\u001b[33mpass\u001b[39m\u001b[33m\"\u001b[39m, setup=\u001b[33m\"\u001b[39m\u001b[33mpass\u001b[39m\u001b[33m\"\u001b[39m, timer=default_timer,\n\u001b[32m    235\u001b[39m            number=default_number, \u001b[38;5;28mglobals\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    236\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Convenience function to create Timer object and call timeit method.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTimer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msetup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/timeit.py:180\u001b[39m, in \u001b[36mTimer.timeit\u001b[39m\u001b[34m(self, number)\u001b[39m\n\u001b[32m    178\u001b[39m gc.disable()\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     timing = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<timeit-src>:6\u001b[39m, in \u001b[36minner\u001b[39m\u001b[34m(_it, _timer, _stmt)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/swifter/swifter.py:228\u001b[39m, in \u001b[36mSeriesAccessor._wrapped_apply.<locals>.wrapped\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m():\n\u001b[32m    227\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m suppress_stdout_stderr_logging():\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_SAMPLE_INDEX\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/pandas/core/series.py:4935\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4800\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4801\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4802\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4807\u001b[39m     **kwargs,\n\u001b[32m   4808\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4809\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4810\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4811\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4926\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4927\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4928\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4929\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4930\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4931\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4932\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4933\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4934\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4935\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/pandas/core/apply.py:1422\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1421\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/pandas/core/apply.py:1502\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1501\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1507\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1508\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/pandas/core/base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/pandas/core/algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mtranslate_paragraph\u001b[39m\u001b[34m(para)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtranslate_paragraph\u001b[39m(para):\n\u001b[32m     34\u001b[39m     sentences = split_paragraph(para)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     translated_sentences = \u001b[43mtranslate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(translated_sentences)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mtranslate_batch\u001b[39m\u001b[34m(sentences, batch_size)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available():\n\u001b[32m     27\u001b[39m     tokens = {k: v.to(\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tokens.items()}\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m translated = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m decoded = [tokenizer.decode(t, skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m translated]\n\u001b[32m     30\u001b[39m translations.extend(decoded)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/transformers/generation/utils.py:2551\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2539\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._sample(\n\u001b[32m   2540\u001b[39m         input_ids,\n\u001b[32m   2541\u001b[39m         logits_processor=prepared_logits_processor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2546\u001b[39m         **model_kwargs,\n\u001b[32m   2547\u001b[39m     )\n\u001b[32m   2549\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2550\u001b[39m     \u001b[38;5;66;03m# 11. run beam sample\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2551\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_beam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2552\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2553\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2554\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2555\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2556\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2557\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2558\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2560\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode == GenerationMode.GROUP_BEAM_SEARCH:\n\u001b[32m   2561\u001b[39m     logger.warning_once(\n\u001b[32m   2562\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGroup Beam Search is scheduled to be moved to a `custom_generate` repository in v4.55.0. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2563\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTo prevent loss of backward compatibility, add `trust_remote_code=True` to your `generate` call.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2564\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/transformers/generation/utils.py:3462\u001b[39m, in \u001b[36mGenerationMixin._beam_search\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[39m\n\u001b[32m   3460\u001b[39m         model_kwargs[\u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m._reorder_cache(model_kwargs[\u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m], beam_idx)\n\u001b[32m   3461\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3462\u001b[39m         \u001b[43mmodel_kwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpast_key_values\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreorder_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3464\u001b[39m cur_len = cur_len + \u001b[32m1\u001b[39m\n\u001b[32m   3465\u001b[39m is_early_stop_heuristic_unsatisfied = \u001b[38;5;28mself\u001b[39m._check_early_stop_heuristic(\n\u001b[32m   3466\u001b[39m     is_early_stop_heuristic_unsatisfied=is_early_stop_heuristic_unsatisfied,\n\u001b[32m   3467\u001b[39m     running_beam_scores=running_beam_scores,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3474\u001b[39m     length_penalty=length_penalty,\n\u001b[32m   3475\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/transformers/cache_utils.py:1350\u001b[39m, in \u001b[36mEncoderDecoderCache.reorder_cache\u001b[39m\u001b[34m(self, beam_idx)\u001b[39m\n\u001b[32m   1348\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Reorders the cache for beam search, given the selected beam indices.\"\"\"\u001b[39;00m\n\u001b[32m   1349\u001b[39m \u001b[38;5;28mself\u001b[39m.self_attention_cache.reorder_cache(beam_idx)\n\u001b[32m-> \u001b[39m\u001b[32m1350\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcross_attention_cache\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreorder_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/transformers/cache_utils.py:884\u001b[39m, in \u001b[36mCache.reorder_cache\u001b[39m\u001b[34m(self, beam_idx)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Reorder the cache for beam search\"\"\"\u001b[39;00m\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.layers)):\n\u001b[32m--> \u001b[39m\u001b[32m884\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreorder_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/transformers/cache_utils.py:79\u001b[39m, in \u001b[36mCacheLayerMixin.reorder_cache\u001b[39m\u001b[34m(self, beam_idx)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_seq_length() > \u001b[32m0\u001b[39m:\n\u001b[32m     78\u001b[39m     \u001b[38;5;28mself\u001b[39m.keys = \u001b[38;5;28mself\u001b[39m.keys.index_select(\u001b[32m0\u001b[39m, beam_idx.to(\u001b[38;5;28mself\u001b[39m.keys.device))\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     \u001b[38;5;28mself\u001b[39m.values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "df['translated_text'] = df['text'].swifter.apply(translate_paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c18f99dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting da-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/da_core_news_sm-3.8.0/da_core_news_sm-3.8.0-py3-none-any.whl (12.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: da-core-news-sm\n",
      "Successfully installed da-core-news-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('da_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download da_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbffa8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello0\n"
     ]
    }
   ],
   "source": [
    "print('hello0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d29d77a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "import spacy\n",
    "from torch.cuda.amp import autocast\n",
    "import IProgress\n",
    "import ipywidgets\n",
    "\n",
    "# Load model on GPU\n",
    "model_name = \"Helsinki-NLP/opus-mt-da-en\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name).to(\"cuda\").eval()\n",
    "\n",
    "# Load spaCy Danish model\n",
    "nlp = spacy.load(\"da_core_news_sm\", disable=[\"tagger\", \"ner\", \"lemmatizer\"])\n",
    "\n",
    "def split_paragraph(paragraph: str):\n",
    "    \"\"\"Split paragraph into sentences.\"\"\"\n",
    "    doc = nlp(paragraph)\n",
    "    return [sent.text.strip() for sent in doc.sents]\n",
    "\n",
    "def translate_batch(sentences, batch_size=128):\n",
    "    \"\"\"Translate batch of sentences on GPU with mixed precision.\"\"\"\n",
    "    translations = []\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i+batch_size]\n",
    "        tokens = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
    "        with torch.no_grad(), autocast():\n",
    "            translated = model.generate(**tokens, max_length=128)\n",
    "        decoded = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
    "        translations.extend(decoded)\n",
    "    return translations\n",
    "\n",
    "def translate_paragraph(para):\n",
    "    \"\"\"Translate a paragraph sentence by sentence.\"\"\"\n",
    "    sentences = split_paragraph(para)\n",
    "    translated_sentences = translate_batch(sentences)\n",
    "    return sentences, translated_sentences\n",
    "\n",
    "def translate_dataframe_gpu(df, text_col=\"text\", batch_size=128):\n",
    "    \"\"\"Translate DataFrame sequentially with sentence splitting.\"\"\"\n",
    "    texts = df[text_col].tolist()\n",
    "    translated_texts = []\n",
    "    untranslated_text = []\n",
    "\n",
    "    for p in tqdm(texts, desc=\"GPU Translation\"):\n",
    "        untranslated_sentences, translated_sentences = translate_paragraph(p)\n",
    "\n",
    "        translated_texts.append(translated_sentences)\n",
    "        untranslated_text.append(untranslated_sentences)\n",
    "\n",
    "    df['da_segmented_text'] = untranslated_text\n",
    "    df[\"translated_text\"] = translated_texts\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "600b5fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_trans.loc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d890eb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU Translation:   0%|          | 0/36314 [00:00<?, ?it/s]/tmp/ipykernel_30142/3330344898.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), autocast():\n",
      "GPU Translation: 100%|██████████| 36314/36314 [3:09:40<00:00,  3.19it/s]  \n"
     ]
    }
   ],
   "source": [
    "df_trans = translate_dataframe_gpu(df_trans, text_col=\"text\", batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5036f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans.to_csv(\"/work/MarkusLundsfrydJensen#1865/annotation_data_translated_version_03_10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63f3640d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>agenda</th>\n",
       "      <th>speechnumber</th>\n",
       "      <th>speaker</th>\n",
       "      <th>party</th>\n",
       "      <th>party.facts.id</th>\n",
       "      <th>chair</th>\n",
       "      <th>terms</th>\n",
       "      <th>text</th>\n",
       "      <th>parliament</th>\n",
       "      <th>iso3country</th>\n",
       "      <th>da_segmented_text</th>\n",
       "      <th>translated_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-10-07</td>\n",
       "      <td>Dagsorden</td>\n",
       "      <td>1</td>\n",
       "      <td>Gert Petersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>191</td>\n",
       "      <td>Mødet er åbnet. I henhold til grundloven er Fo...</td>\n",
       "      <td>DK-Folketing</td>\n",
       "      <td>DNK</td>\n",
       "      <td>[Mødet er åbnet., I henhold til grundloven er ...</td>\n",
       "      <td>[The meeting is open., Under the Constitution,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-10-07</td>\n",
       "      <td>Dagsorden</td>\n",
       "      <td>2</td>\n",
       "      <td>Formanden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>182</td>\n",
       "      <td>Jeg vil gerne takke Tinget for den tillid, man...</td>\n",
       "      <td>DK-Folketing</td>\n",
       "      <td>DNK</td>\n",
       "      <td>[Jeg vil gerne takke Tinget for den tillid, ma...</td>\n",
       "      <td>[I would like to thank Things for the confiden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-10-07</td>\n",
       "      <td>Statsministerens redegørelse i henhold til gru...</td>\n",
       "      <td>3</td>\n",
       "      <td>Poul Nyrup Rasmussen</td>\n",
       "      <td>S</td>\n",
       "      <td>379.0</td>\n",
       "      <td>False</td>\n",
       "      <td>18662</td>\n",
       "      <td>For 25 år siden sagde et flertal i befolkninge...</td>\n",
       "      <td>DK-Folketing</td>\n",
       "      <td>DNK</td>\n",
       "      <td>[For 25 år siden sagde et flertal i befolkning...</td>\n",
       "      <td>[Twenty-five years ago, a majority of the peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-10-09</td>\n",
       "      <td>1) Indstilling fra Udvalget til Valgs Prøvelse.</td>\n",
       "      <td>2</td>\n",
       "      <td>Formanden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>47</td>\n",
       "      <td>Fra Udvalget til Valgs Prøvelse har jeg modtag...</td>\n",
       "      <td>DK-Folketing</td>\n",
       "      <td>DNK</td>\n",
       "      <td>[Fra Udvalget til Valgs, Prøvelse, har jeg mod...</td>\n",
       "      <td>[From the Committee to the Committee of the Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-10-09</td>\n",
       "      <td>2) Forhandling om redegørelse nr. R 1.</td>\n",
       "      <td>3</td>\n",
       "      <td>Torben Lund</td>\n",
       "      <td>S</td>\n",
       "      <td>379.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2865</td>\n",
       "      <td>Vi står over for en meget afgørende folketings...</td>\n",
       "      <td>DK-Folketing</td>\n",
       "      <td>DNK</td>\n",
       "      <td>[Vi står over for en meget afgørende folketing...</td>\n",
       "      <td>[We are faced with a very crucial parliamentar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1997-10-09</td>\n",
       "      <td>2) Forhandling om redegørelse nr. R 1.</td>\n",
       "      <td>4</td>\n",
       "      <td>Formanden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>211</td>\n",
       "      <td>Der er nu bedt om 17 korte bemærkninger.      ...</td>\n",
       "      <td>DK-Folketing</td>\n",
       "      <td>DNK</td>\n",
       "      <td>[Der er nu bedt om 17 korte bemærkninger., Og ...</td>\n",
       "      <td>[17 brief comments have now been asked., And n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                             agenda  \\\n",
       "0  1997-10-07                                          Dagsorden   \n",
       "1  1997-10-07                                          Dagsorden   \n",
       "2  1997-10-07  Statsministerens redegørelse i henhold til gru...   \n",
       "3  1997-10-09    1) Indstilling fra Udvalget til Valgs Prøvelse.   \n",
       "4  1997-10-09             2) Forhandling om redegørelse nr. R 1.   \n",
       "5  1997-10-09             2) Forhandling om redegørelse nr. R 1.   \n",
       "\n",
       "   speechnumber               speaker party  party.facts.id  chair  terms  \\\n",
       "0             1         Gert Petersen   NaN             NaN   True    191   \n",
       "1             2             Formanden   NaN             NaN   True    182   \n",
       "2             3  Poul Nyrup Rasmussen     S           379.0  False  18662   \n",
       "3             2             Formanden   NaN             NaN   True     47   \n",
       "4             3           Torben Lund     S           379.0  False   2865   \n",
       "5             4             Formanden   NaN             NaN   True    211   \n",
       "\n",
       "                                                text    parliament  \\\n",
       "0  Mødet er åbnet. I henhold til grundloven er Fo...  DK-Folketing   \n",
       "1  Jeg vil gerne takke Tinget for den tillid, man...  DK-Folketing   \n",
       "2  For 25 år siden sagde et flertal i befolkninge...  DK-Folketing   \n",
       "3  Fra Udvalget til Valgs Prøvelse har jeg modtag...  DK-Folketing   \n",
       "4  Vi står over for en meget afgørende folketings...  DK-Folketing   \n",
       "5  Der er nu bedt om 17 korte bemærkninger.      ...  DK-Folketing   \n",
       "\n",
       "  iso3country                                  da_segmented_text  \\\n",
       "0         DNK  [Mødet er åbnet., I henhold til grundloven er ...   \n",
       "1         DNK  [Jeg vil gerne takke Tinget for den tillid, ma...   \n",
       "2         DNK  [For 25 år siden sagde et flertal i befolkning...   \n",
       "3         DNK  [Fra Udvalget til Valgs, Prøvelse, har jeg mod...   \n",
       "4         DNK  [Vi står over for en meget afgørende folketing...   \n",
       "5         DNK  [Der er nu bedt om 17 korte bemærkninger., Og ...   \n",
       "\n",
       "                                     translated_text  \n",
       "0  [The meeting is open., Under the Constitution,...  \n",
       "1  [I would like to thank Things for the confiden...  \n",
       "2  [Twenty-five years ago, a majority of the peop...  \n",
       "3  [From the Committee to the Committee of the Re...  \n",
       "4  [We are faced with a very crucial parliamentar...  \n",
       "5  [17 brief comments have now been asked., And n...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d65ade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(export_data)):\n",
    "    temp_data = export_data.loc[i]\n",
    "    if len(temp_data['da_segmented_text']) != len(temp_data['translated_text']):\n",
    "        print(temp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c60ab842",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans.to_csv(\"/work/MarkusLundsfrydJensen#1865/annotation_data_translated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c1c211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take blame text, split danish text into sentences in the same way as the translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0902a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cd1a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "#data = pd.read_csv(\"/work/MarkusLundsfrydJensen#1865/cleaned_annotation_data_translated_with_blame_heuristics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6a8e3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>agenda</th>\n",
       "      <th>speechnumber</th>\n",
       "      <th>speaker</th>\n",
       "      <th>party</th>\n",
       "      <th>party.facts.id</th>\n",
       "      <th>chair</th>\n",
       "      <th>terms</th>\n",
       "      <th>text</th>\n",
       "      <th>parliament</th>\n",
       "      <th>iso3country</th>\n",
       "      <th>da_segmented_text</th>\n",
       "      <th>translated_text</th>\n",
       "      <th>blame_in_text</th>\n",
       "      <th>second_template_blame_in_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-10-07</td>\n",
       "      <td>Dagsorden</td>\n",
       "      <td>1</td>\n",
       "      <td>Gert Petersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>191</td>\n",
       "      <td>Mødet er åbnet. I henhold til grundloven er Fo...</td>\n",
       "      <td>DK-Folketing</td>\n",
       "      <td>DNK</td>\n",
       "      <td>['Mødet er åbnet.', 'I henhold til grundloven ...</td>\n",
       "      <td>['The meeting is open.', 'Under the Constituti...</td>\n",
       "      <td>[{'sequence': 'The meeting is open.', 'labels'...</td>\n",
       "      <td>[{'sequence': 'The meeting is open.', 'labels'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-10-07</td>\n",
       "      <td>Dagsorden</td>\n",
       "      <td>2</td>\n",
       "      <td>Formanden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>182</td>\n",
       "      <td>Jeg vil gerne takke Tinget for den tillid, man...</td>\n",
       "      <td>DK-Folketing</td>\n",
       "      <td>DNK</td>\n",
       "      <td>['Jeg vil gerne takke Tinget for den tillid, m...</td>\n",
       "      <td>['I would like to thank Things for the confide...</td>\n",
       "      <td>[{'sequence': 'I would like to thank Things fo...</td>\n",
       "      <td>[{'sequence': 'I would like to thank Things fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-10-07</td>\n",
       "      <td>Statsministerens redegørelse i henhold til gru...</td>\n",
       "      <td>3</td>\n",
       "      <td>Poul Nyrup Rasmussen</td>\n",
       "      <td>S</td>\n",
       "      <td>379.0</td>\n",
       "      <td>False</td>\n",
       "      <td>18662</td>\n",
       "      <td>For 25 år siden sagde et flertal i befolkninge...</td>\n",
       "      <td>DK-Folketing</td>\n",
       "      <td>DNK</td>\n",
       "      <td>['For 25 år siden sagde et flertal i befolknin...</td>\n",
       "      <td>['Twenty-five years ago, a majority of the peo...</td>\n",
       "      <td>[{'sequence': 'Twenty-five years ago, a majori...</td>\n",
       "      <td>[{'sequence': 'Twenty-five years ago, a majori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-10-09</td>\n",
       "      <td>1) Indstilling fra Udvalget til Valgs Prøvelse.</td>\n",
       "      <td>2</td>\n",
       "      <td>Formanden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>47</td>\n",
       "      <td>Fra Udvalget til Valgs Prøvelse har jeg modtag...</td>\n",
       "      <td>DK-Folketing</td>\n",
       "      <td>DNK</td>\n",
       "      <td>['Fra Udvalget til Valgs', 'Prøvelse', 'har je...</td>\n",
       "      <td>['From the Committee to the Committee of the R...</td>\n",
       "      <td>[{'sequence': 'From the Committee to the Commi...</td>\n",
       "      <td>[{'sequence': 'From the Committee to the Commi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-10-09</td>\n",
       "      <td>2) Forhandling om redegørelse nr. R 1.</td>\n",
       "      <td>3</td>\n",
       "      <td>Torben Lund</td>\n",
       "      <td>S</td>\n",
       "      <td>379.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2865</td>\n",
       "      <td>Vi står over for en meget afgørende folketings...</td>\n",
       "      <td>DK-Folketing</td>\n",
       "      <td>DNK</td>\n",
       "      <td>['Vi står over for en meget afgørende folketin...</td>\n",
       "      <td>['We are faced with a very crucial parliamenta...</td>\n",
       "      <td>[{'sequence': 'We are faced with a very crucia...</td>\n",
       "      <td>[{'sequence': 'We are faced with a very crucia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                             agenda  \\\n",
       "0  1997-10-07                                          Dagsorden   \n",
       "1  1997-10-07                                          Dagsorden   \n",
       "2  1997-10-07  Statsministerens redegørelse i henhold til gru...   \n",
       "3  1997-10-09    1) Indstilling fra Udvalget til Valgs Prøvelse.   \n",
       "4  1997-10-09             2) Forhandling om redegørelse nr. R 1.   \n",
       "\n",
       "   speechnumber               speaker party  party.facts.id  chair  terms  \\\n",
       "0             1         Gert Petersen   NaN             NaN   True    191   \n",
       "1             2             Formanden   NaN             NaN   True    182   \n",
       "2             3  Poul Nyrup Rasmussen     S           379.0  False  18662   \n",
       "3             2             Formanden   NaN             NaN   True     47   \n",
       "4             3           Torben Lund     S           379.0  False   2865   \n",
       "\n",
       "                                                text    parliament  \\\n",
       "0  Mødet er åbnet. I henhold til grundloven er Fo...  DK-Folketing   \n",
       "1  Jeg vil gerne takke Tinget for den tillid, man...  DK-Folketing   \n",
       "2  For 25 år siden sagde et flertal i befolkninge...  DK-Folketing   \n",
       "3  Fra Udvalget til Valgs Prøvelse har jeg modtag...  DK-Folketing   \n",
       "4  Vi står over for en meget afgørende folketings...  DK-Folketing   \n",
       "\n",
       "  iso3country                                  da_segmented_text  \\\n",
       "0         DNK  ['Mødet er åbnet.', 'I henhold til grundloven ...   \n",
       "1         DNK  ['Jeg vil gerne takke Tinget for den tillid, m...   \n",
       "2         DNK  ['For 25 år siden sagde et flertal i befolknin...   \n",
       "3         DNK  ['Fra Udvalget til Valgs', 'Prøvelse', 'har je...   \n",
       "4         DNK  ['Vi står over for en meget afgørende folketin...   \n",
       "\n",
       "                                     translated_text  \\\n",
       "0  ['The meeting is open.', 'Under the Constituti...   \n",
       "1  ['I would like to thank Things for the confide...   \n",
       "2  ['Twenty-five years ago, a majority of the peo...   \n",
       "3  ['From the Committee to the Committee of the R...   \n",
       "4  ['We are faced with a very crucial parliamenta...   \n",
       "\n",
       "                                       blame_in_text  \\\n",
       "0  [{'sequence': 'The meeting is open.', 'labels'...   \n",
       "1  [{'sequence': 'I would like to thank Things fo...   \n",
       "2  [{'sequence': 'Twenty-five years ago, a majori...   \n",
       "3  [{'sequence': 'From the Committee to the Commi...   \n",
       "4  [{'sequence': 'We are faced with a very crucia...   \n",
       "\n",
       "                       second_template_blame_in_text  \n",
       "0  [{'sequence': 'The meeting is open.', 'labels'...  \n",
       "1  [{'sequence': 'I would like to thank Things fo...  \n",
       "2  [{'sequence': 'Twenty-five years ago, a majori...  \n",
       "3  [{'sequence': 'From the Committee to the Commi...  \n",
       "4  [{'sequence': 'We are faced with a very crucia...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Do second run of blame detection\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_final = pd.read_csv(\"/work/MarkusLundsfrydJensen#1865/annotation_data_second_template_appended.csv\")\n",
    "\n",
    "df_final.pop('Unnamed: 0')\n",
    "\n",
    "\n",
    "df_final.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c66b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Set 1 – Direct attitude framing (closest to original)\n",
    "\"Overall, the author’s stance toward others in this passage is {}.\"\n",
    "\n",
    "🔹 Set 2 – Attribution and evaluation framing\n",
    "\"The overall feeling that the author communicates toward others in this text, is best decribed as {}.\"\n",
    "\n",
    "🔹 Set 3 – Causal / responsibility framing (captures blame nuance more strongly)\n",
    "\"According to this passage, the author’s reaction to others’ conduct can be described as {}.\"\n",
    "→ Good causal framing with explicit reaction attribution.\n",
    "\n",
    "Set 4 – Moral / emotional framing (more affective dimension)\n",
    "\n",
    "\"From the way others are described, the author's expression towards them is best described as {}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85e095a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "#tried to make it faster\n",
    "\n",
    "import ast\n",
    "\n",
    "# Pick device automatically\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(f\"Device: {'cuda' if device == 0 else 'cpu'}\")\n",
    "\n",
    "# Use base model for speed (large is much slower)\n",
    "pipe = pipeline(\"zero-shot-classification\", model='mlburnham/Political_DEBATE_large_v1.0', device = device, batch_size = 256)\n",
    "\n",
    "\n",
    "# Template + labels\n",
    "hypothesis_template = \"From the way others are described, the author's expression towards them is best described as {}.\"\n",
    "labels = [\"blame\", \"praise\", \"neutral\"]\n",
    "\n",
    "def evaluate_premise(doc):\n",
    "    return pipe(doc, labels, hypothesis_template=hypothesis_template, multi_label=True)\n",
    "\n",
    "def blame_in_batch(sentences, batch_size=256):\n",
    "    results = []\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i+batch_size]\n",
    "        output = evaluate_premise(batch)\n",
    "        if isinstance(output, list):\n",
    "            results.extend(output)\n",
    "        else:\n",
    "            results.append(output)\n",
    "    return results\n",
    "\n",
    "def blame_in_paragraph(para):\n",
    "    sentences = ast.literal_eval(para)\n",
    "    return blame_in_batch(sentences)\n",
    "\n",
    "\n",
    "def detect_blame_in_dataframe(df, text_col=\"translated_text\", output_column = \"fifth_template_blame_in_text\"):\n",
    "    results = []\n",
    "    for para in tqdm(df[text_col], desc=\"Blame Detection (GPU)\"):\n",
    "        results.append(blame_in_paragraph(para))\n",
    "    df[output_column] = results\n",
    "    return df\n",
    "# Example usage\n",
    "# data_test = detect_blame_in_dataframe(data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea530e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data = df_final.loc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b987bfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Blame Detection (GPU): 100%|██████████| 36314/36314 [1:20:54<00:00,  7.48it/s]  \n"
     ]
    }
   ],
   "source": [
    "df_final = detect_blame_in_dataframe(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e6d3c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"/work/MarkusLundsfrydJensen#1865/annotation_data_fifth_template_appended.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5edbaa4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf_final\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'df_final' is not defined"
     ]
    }
   ],
   "source": [
    "df_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
