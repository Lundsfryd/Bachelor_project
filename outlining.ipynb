{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "947168e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from outlines import from_transformers, Generator\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d143650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Character(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    skills: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "499e2384",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = from_transformers(\n",
    "    transformers.AutoModelForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"),\n",
    "    transformers.AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94d763e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339] WON'T CONVERT _apply_token_bitmask_inplace_kernel c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\outlines_core\\kernels\\torch.py line 43 \n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339] due to: \n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339] Traceback (most recent call last):\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1272, in __call__\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     result = self._inner_convert(\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 629, in __call__\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     return _compile(\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]            ^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1111, in _compile\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_utils_internal.py\", line 97, in wrapper_function\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     return function(*args, **kwargs)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 793, in compile_inner\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 832, in _compile_inner\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     out_code = transform_code_object(code, transform)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1424, in transform_code_object\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     transformations(instructions, code_options)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 267, in _fn\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     return fn(*args, **kwargs)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 753, in transform\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     tracer.run()\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3497, in run\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     super().run()\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1363, in run\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     while self.step():\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]           ^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1267, in step\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3675, in RETURN_CONST\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     self._return(inst)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3653, in _return\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     all_stack_locals_metadata = self.output.compile_subgraph(\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1422, in compile_subgraph\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1696, in compile_and_call_fx_graph\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     compiled_fn = self.call_user_compiler(gm, self.example_inputs())\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1811, in call_user_compiler\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     return self._call_user_compiler(gm, example_inputs)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1846, in _call_user_compiler\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 150, in __call__\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\__init__.py\", line 2380, in __call__\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 2432, in compile_fx\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 923, in _compile_fx_inner\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     raise InductorError(e, currentframe()).with_traceback(\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 907, in _compile_fx_inner\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1578, in fx_codegen_and_compile\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1456, in codegen_and_compile\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     compiled_module = graph.compile_to_module()\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                       ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 2293, in compile_to_module\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     return self._compile_to_module()\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 2299, in _compile_to_module\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                                                              ^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 2238, in codegen\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     self.scheduler.codegen()\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 4598, in codegen\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     else self._codegen(self.nodes)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 4750, in _codegen\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     self.get_backend(device).codegen_node(node)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\codegen\\cpp.py\", line 5076, in codegen_node\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     cpp_kernel_proxy = self.kernel_proxy_cls(kernel_group)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\codegen\\cpp.py\", line 3816, in __init__\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     self.picked_vec_isa: cpu_vec_isa.VecISA = cpu_vec_isa.pick_vec_isa()\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 432, in pick_vec_isa\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     _valid_vec_isa_list: list[VecISA] = valid_vec_isa_list()\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                                         ^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 419, in valid_vec_isa_list\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     isa_list.extend(\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 422, in <genexpr>\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     if all(flag in _cpu_supported_x86_isa for flag in str(isa).split()) and isa\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                                                                             ^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 147, in __bool__\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     return self.__bool__impl(config.cpp.vec_isa_ok)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 157, in __bool__impl\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     return self.check_build(VecISA._avx_code)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 102, in check_build\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     extra=_get_isa_dry_compile_fingerprint(self._arch_flags),\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 28, in _get_isa_dry_compile_fingerprint\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     compiler_info = get_compiler_version_info(get_cpp_compiler())\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                                               ^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 147, in get_cpp_compiler\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     check_compiler_exist_windows(compiler)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 138, in check_compiler_exist_windows\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     raise RuntimeError(f\"Compiler: {compiler} is not found.\") from exc\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339] torch._inductor.exc.InductorError: RuntimeError: Compiler: cl is not found.\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339] \n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339] \n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339] Traceback (most recent call last):\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1272, in __call__\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     result = self._inner_convert(\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 629, in __call__\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     return _compile(\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]            ^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1111, in _compile\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_utils_internal.py\", line 97, in wrapper_function\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     return function(*args, **kwargs)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 793, in compile_inner\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 832, in _compile_inner\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     out_code = transform_code_object(code, transform)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1424, in transform_code_object\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     transformations(instructions, code_options)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 267, in _fn\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     return fn(*args, **kwargs)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 753, in transform\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     tracer.run()\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3497, in run\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     super().run()\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1363, in run\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     while self.step():\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]           ^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 1267, in step\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3675, in RETURN_CONST\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     self._return(inst)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 3653, in _return\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     all_stack_locals_metadata = self.output.compile_subgraph(\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1422, in compile_subgraph\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1696, in compile_and_call_fx_graph\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     compiled_fn = self.call_user_compiler(gm, self.example_inputs())\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1811, in call_user_compiler\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     return self._call_user_compiler(gm, example_inputs)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1846, in _call_user_compiler\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 150, in __call__\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\__init__.py\", line 2380, in __call__\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 2432, in compile_fx\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 923, in _compile_fx_inner\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     raise InductorError(e, currentframe()).with_traceback(\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 907, in _compile_fx_inner\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1578, in fx_codegen_and_compile\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1456, in codegen_and_compile\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     compiled_module = graph.compile_to_module()\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                       ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 2293, in compile_to_module\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     return self._compile_to_module()\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 2299, in _compile_to_module\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                                                              ^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 2238, in codegen\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     self.scheduler.codegen()\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 4598, in codegen\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     else self._codegen(self.nodes)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 4750, in _codegen\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     self.get_backend(device).codegen_node(node)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\codegen\\cpp.py\", line 5076, in codegen_node\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     cpp_kernel_proxy = self.kernel_proxy_cls(kernel_group)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\codegen\\cpp.py\", line 3816, in __init__\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     self.picked_vec_isa: cpu_vec_isa.VecISA = cpu_vec_isa.pick_vec_isa()\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 432, in pick_vec_isa\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     _valid_vec_isa_list: list[VecISA] = valid_vec_isa_list()\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                                         ^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 419, in valid_vec_isa_list\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     isa_list.extend(\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 422, in <genexpr>\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     if all(flag in _cpu_supported_x86_isa for flag in str(isa).split()) and isa\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                                                                             ^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 147, in __bool__\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     return self.__bool__impl(config.cpp.vec_isa_ok)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 157, in __bool__impl\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     return self.check_build(VecISA._avx_code)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 102, in check_build\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     extra=_get_isa_dry_compile_fingerprint(self._arch_flags),\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\cpu_vec_isa.py\", line 28, in _get_isa_dry_compile_fingerprint\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     compiler_info = get_compiler_version_info(get_cpp_compiler())\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]                                               ^^^^^^^^^^^^^^^^^^\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 147, in get_cpp_compiler\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     check_compiler_exist_windows(compiler)\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]   File \"c:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\torch\\_inductor\\cpp_builder.py\", line 138, in check_compiler_exist_windows\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339]     raise RuntimeError(f\"Compiler: {compiler} is not found.\") from exc\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339] torch._inductor.exc.InductorError: RuntimeError: Compiler: cl is not found.\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339] \n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339] Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "W0930 11:28:37.938000 13276 site-packages\\torch\\_dynamo\\convert_frame.py:1339] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"Jane\", \"age\":20, \"skills\": [\"Cooking\", \"Dancing\", \"Art\"] }\n"
     ]
    }
   ],
   "source": [
    "generator = Generator(model, Character)\n",
    "result = generator(\"Create a character\")\n",
    "\n",
    "# Call it with the output type to generate structured text\n",
    "print(result) # '{\"name\": \"Evelyn\", \"age\": 34, \"skills\": [\"archery\", \"stealth\", \"alchemy\"]}'\n",
    "#print(Character.model_validate_json(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af7d7bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_type = Literal[\"Negative\", \"Positive\", \"Neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "860233f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Semantic:\n",
    "    verb: str\n",
    "    object: str\n",
    "    subject: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af4ac7d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Type Semantic is currently not supported. Please open an issue: https://github.com/dottxt-ai/outlines/issues",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m generator \u001b[38;5;241m=\u001b[39m \u001b[43mGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSemantic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m result \u001b[38;5;241m=\u001b[39m generator(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApply semantic role labelling to this sentence: The immigrants are causing the decline of our economy.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\outlines\\generator.py:392\u001b[0m, in \u001b[0;36mGenerator\u001b[1;34m(model, output_type, backend, processor)\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m SteerableGenerator\u001b[38;5;241m.\u001b[39mfrom_processor(model, processor) \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 392\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSteerableGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    394\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m processor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\outlines\\generator.py:237\u001b[0m, in \u001b[0;36mSteerableGenerator.__init__\u001b[1;34m(self, model, output_type, backend_name)\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogits_processor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     term \u001b[38;5;241m=\u001b[39m \u001b[43mpython_types_to_terms\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(term, CFG):\n\u001b[0;32m    239\u001b[0m         cfg_string \u001b[38;5;241m=\u001b[39m term\u001b[38;5;241m.\u001b[39mdefinition\n",
      "File \u001b[1;32mc:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\outlines\\types\\dsl.py:685\u001b[0m, in \u001b[0;36mpython_types_to_terms\u001b[1;34m(ptype, recursion_depth)\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m JsonSchema(get_schema_from_signature(ptype))\n\u001b[0;32m    684\u001b[0m type_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(ptype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m\"\u001b[39m, ptype)\n\u001b[1;32m--> 685\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    686\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is currently not supported. Please open an issue: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    687\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://github.com/dottxt-ai/outlines/issues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    688\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: Type Semantic is currently not supported. Please open an issue: https://github.com/dottxt-ai/outlines/issues"
     ]
    }
   ],
   "source": [
    "generator = Generator(model, Semantic)\n",
    "result = generator(\"Apply semantic role labelling to this sentence: The immigrants are causing the decline of our economy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d81843",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = from_transformers(\n",
    "    transformers.AutoModelForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"),\n",
    "    transformers.AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d537c0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (2048). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Print the results\\nprint(\"Original sentence:\", result.sentence)\\nprint(\"\\nSemantic Role Labeling:\")\\nfor pred in result.predicates:\\n    print(f\"\\nPredicate: {pred.predicate}\")\\n    for arg in pred.arguments:\\n        print(f\"  {arg.role}: {arg.text}\")\\n\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import outlines\n",
    "from outlines import Generator\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# Define the structured output schema for semantic role labeling\n",
    "class Argument(BaseModel):\n",
    "    role: str = Field(description=\"Semantic role (e.g., ARG0/Agent, ARG1/Patient, ARGM-TMP/Time, ARGM-LOC/Location)\")\n",
    "    text: str = Field(description=\"The text span filling this role\")\n",
    "\n",
    "class Predicate(BaseModel):\n",
    "    predicate: str = Field(description=\"The main predicate/verb\")\n",
    "    agent: str = Field(description=\"ARG0: The entity performing the action (who/what does it)\")\n",
    "    patient: str = Field(description=\"ARG1: The entity affected by the action (who/what is affected)\", default=\"\")\n",
    "    arguments: List[Argument] = Field(description=\"List of semantic arguments for this predicate\")\n",
    "\n",
    "class SemanticRoleLabeling(BaseModel):\n",
    "    sentence: str = Field(description=\"The original sentence\")\n",
    "    predicates: List[Predicate] = Field(description=\"List of predicates with their semantic roles\")\n",
    "\n",
    "# Create a structured generator\n",
    "generator = Generator(model, SemanticRoleLabeling)\n",
    "\n",
    "# Example text for semantic role labeling\n",
    "text = \"John ate an apple in the park yesterday.\"\n",
    "\n",
    "# Create the prompt\n",
    "prompt = f\"\"\"Perform semantic role labeling on the following sentence. Identify all predicates and their semantic arguments.\n",
    "\n",
    "Sentence: {text}\n",
    "\n",
    "Common semantic roles:\n",
    "- ARG0: Agent (who performs the action)\n",
    "- ARG1: Patient/Theme (what is affected by the action)\n",
    "- ARG2: Recipient, Beneficiary, or Instrument\n",
    "- ARGM-TMP: Temporal (when)\n",
    "- ARGM-LOC: Location (where)\n",
    "- ARGM-MNR: Manner (how)\n",
    "- ARGM-PRP: Purpose (why)\n",
    "\n",
    "Analyze the sentence and output the semantic role labeling in the specified JSON format.\"\"\"\n",
    "\n",
    "# Generate structured output\n",
    "result = generator(prompt, max_new_tokens=2048)\n",
    "\n",
    "'''\n",
    "# Print the results\n",
    "print(\"Original sentence:\", result.sentence)\n",
    "print(\"\\nSemantic Role Labeling:\")\n",
    "for pred in result.predicates:\n",
    "    print(f\"\\nPredicate: {pred.predicate}\")\n",
    "    for arg in pred.arguments:\n",
    "        print(f\"  {arg.role}: {arg.text}\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7d636b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the structured output schema for semantic role labeling\n",
    "class Blame(BaseModel):\n",
    "    blame: bool = Field(description=\"Is blame present in the given sentence?\")\n",
    "    blamee: str = Field(description=\"The patient that is being blamed for something (Who / What is affected)\")\n",
    "    arguments: List[str] = Field(description=\"List of arguments that the blamee is being blamed for causing\")\n",
    "    text: str = Field(description=\"Part of the original text that identifies the blame\")\n",
    "\n",
    "#class BlamerBlamee(BaseModel):\n",
    "    #blamer: str = Field(description=\"Blamer: The agent blaming another patient\")\n",
    "    #blamee: str = Field(description=\"Blamee: The patient that is being blamed for something. (Who / What is affected)\")\n",
    "    #arguments: List[Blame] = Field(description=\"List of arguments that the blamee is being blamed for causing\")\n",
    "\n",
    "class Blaming(BaseModel):\n",
    "    sentence: str = Field(description=\"The original sentence\")\n",
    "    arguments: List[Blame] = Field(description=\"List of who or what is being blamed, and for what they are being blamed\")\n",
    "\n",
    "# Create a structured generator\n",
    "generator = Generator(model, Blaming)\n",
    "\n",
    "# Example text for semantic role labeling\n",
    "text = \"The immigrants are not causing the economic recession.\"\n",
    "\n",
    "# Create the prompt\n",
    "prompt = f\"\"\"Perform blame identification only on the following sentence, do not generate alternate sentences. \n",
    "\n",
    "Sentence: {text}\n",
    "\n",
    "Rules:\n",
    "- Start by looking into whether or not blame is present at all in the sentence \n",
    "- then identify who is being blamed, what they are being blamed for, and the arguments the person blaming them are using.\n",
    "- Set blame=true ONLY if someone/something is being blamed for causing a negative outcome\n",
    "- Set blame=false if the sentence explicitly denies blame (uses \"not\", \"never\", \"no\")\n",
    "- The \"text\" field must be EXACTLY the sentence provided above - do not modify it\n",
    "- Do NOT create alternative phrasings or opposite statements\n",
    "- If the sentence says \"X is NOT causing Y\", this means NO blame (blame=false)\n",
    "\n",
    "The relevant semantic roles:\n",
    "- Blamee: The patient receiving the blame (who or what is being blamed for something)\n",
    "- Argument: What is the blamee being blamed for.\n",
    "\n",
    "Analyze the sentence and output your result in the specified JSON format.\"\"\"\n",
    "\n",
    "# Generate structured output\n",
    "result = generator(prompt, max_new_tokens=512)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "887de83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"sentence\": \"The immigrants are not causing the economic recession.\",\"arguments\": [{\"blame\": true,\"blamee\": \"immigrants\",\"arguments\": [], \"text\": \"The immigrants are not causing the economic recession.\"},{\"blame\": false,\"blamee\": \"economy\",\"arguments\": [], \"text\": \"The economy is causing the economic recession.\"},{\"blame\": false,\"blamee\": \"economic recession\",\"arguments\": [], \"text\": \"The economy is not causing the economic recession.\"},{\"blame\": false,\"blamee\": \"immigrants\",\"arguments\": [], \"text\": \"The immigrants are not causing the economic recession.\"},{\"blame\": false,\"blamee\": \"economy\",\"arguments\": [], \"text\": \"The economy is not causing the economic recession.\"},{\"blame\": false,\"blamee\": \"immigrants\",\"arguments\": [], \"text\": \"The immigrants are not causing the economic recession.\"},{\"blame\": false,\"blamee\": \"economy\",\"arguments\": [], \"text\": \"The economy is causing the economic recession.\"},{\"blame\": false,\"blamee\": \"immigrants\",\"arguments\": [], \"text\": \"The immigrants are not causing the economic recession.\"},{\"blame\": false,\"blamee\": \"economy\",\"arguments\": [], \"text\": \"The economy is causing the economic recession.\"},{\"blame\": false,\"blamee\": \"immigrants\",\"arguments\": [], \"text\": \"The immigrants are not causing the economic recession.\"},{\"blame\": false,\"blamee\": \"economy\",\"arguments\": [], \"text\": \"The economy is causing the economic recession.\"},{\"blame\": false,\"blamee\": \"immigrants\",\"arguments\": [], \"text\": \"The immigrants are not causing the economic recession.\"},{\"blame\": false,\"blamee\": \"economy\",\"arguments\": [], \"text\": \"The economy is causing the economic recession.\"},{\"blame\": false,\"blamee\": \"imm\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "581f9789",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Unterminated string starting at: line 1 column 1638 (char 1637)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(data, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\json\\decoder.py:338\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    334\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 338\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    339\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\json\\decoder.py:354\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    351\u001b[0m \n\u001b[0;32m    352\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Unterminated string starting at: line 1 column 1638 (char 1637)"
     ]
    }
   ],
   "source": [
    "data = json.loads(result)\n",
    "print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "21e1648f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for Blaming\npredicates.0.arguments.0.blame_confidence\n  Input should be greater than or equal to 0 [type=greater_than_equal, input_value=-1, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/greater_than_equal\npredicates.1.arguments.0.blame_confidence\n  Input should be greater than or equal to 0 [type=greater_than_equal, input_value=-1, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/greater_than_equal",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result_out \u001b[38;5;241m=\u001b[39m \u001b[43mBlaming\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_validate_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\runet\\miniconda3\\envs\\outlining\\Lib\\site-packages\\pydantic\\main.py:746\u001b[0m, in \u001b[0;36mBaseModel.model_validate_json\u001b[1;34m(cls, json_data, strict, context, by_alias, by_name)\u001b[0m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m by_alias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    741\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[0;32m    742\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAt least one of `by_alias` or `by_name` must be set to True.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    743\u001b[0m         code\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidate-by-alias-and-name-false\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    744\u001b[0m     )\n\u001b[1;32m--> 746\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_name\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValidationError\u001b[0m: 2 validation errors for Blaming\npredicates.0.arguments.0.blame_confidence\n  Input should be greater than or equal to 0 [type=greater_than_equal, input_value=-1, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/greater_than_equal\npredicates.1.arguments.0.blame_confidence\n  Input should be greater than or equal to 0 [type=greater_than_equal, input_value=-1, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/greater_than_equal"
     ]
    }
   ],
   "source": [
    "result_out = Blaming.model_validate_json(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "93056b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"srl_result_blame.json\", \"w\") as f:\n",
    "       json.dump(result_out.model_dump(), f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "217adceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence='John ate an apple in the park yesterday' predicates=[Predicate(predicate='ARGM', arguments=[Argument(role='ARGM_LOC', text='in'), Argument(role='ARGM_MNR', text='at'), Argument(role='ARGM_PRP', text='the'), Argument(role='ARGM_LOC', text='park'), Argument(role='ARGM_MNR', text='in'), Argument(role='ARGM_PRP', text='the'), Argument(role='ARGM_LOC', text='last'), Argument(role='ARGM_MNR', text='night')])]\n"
     ]
    }
   ],
   "source": [
    "print(result_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bb8007a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence='John ate an apple in the park yesterday' predicates=[Predicate(predicate='ARGM', arguments=[Argument(role='ARGM_LOC', text='in'), Argument(role='ARGM_MNR', text='at'), Argument(role='ARGM_PRP', text='the'), Argument(role='ARGM_LOC', text='park'), Argument(role='ARGM_MNR', text='in'), Argument(role='ARGM_PRP', text='the'), Argument(role='ARGM_LOC', text='last'), Argument(role='ARGM_MNR', text='night')])]\n"
     ]
    }
   ],
   "source": [
    "print(result_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74c01d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"\\n\" + \"=\"*50)\\nprint(\"\\nOriginal sentence:\", result2.sentence)\\nprint(\"\\nSemantic Role Labeling:\")\\nfor pred in result2.predicates:\\n    print(f\"\\nPredicate: {pred.predicate}\")\\n    for arg in pred.arguments:\\n        print(f\"  {arg.role}: {arg.text}\")\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example with a more complex sentence\n",
    "text2 = \"Mary gave her friend a book at the library on Monday because she wanted to help.\"\n",
    "\n",
    "prompt2 = f\"\"\"Perform semantic role labeling on the following sentence. Identify all predicates and their semantic arguments.\n",
    "\n",
    "Sentence: {text2}\n",
    "\n",
    "Common semantic roles in order of relevance:\n",
    "- ARG0: Agent (who performs the action)\n",
    "- ARG1: Patient/Theme (what is affected by the action)\n",
    "- ARG2: Recipient, Beneficiary, or Instrument\n",
    "- ARGM-TMP: Temporal (when)\n",
    "- ARGM-LOC: Location (where)\n",
    "- ARGM-MNR: Manner (how)\n",
    "- ARGM-PRP: Purpose (why)\n",
    "\n",
    "Analyze the sentence and output the semantic role labeling in the specified JSON format, focusing on ARG0, ARG1, and ARG2 roles.\"\"\"\n",
    "\n",
    "result2 = generator(prompt2,max_new_tokens=512)\n",
    "\n",
    "'''\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nOriginal sentence:\", result2.sentence)\n",
    "print(\"\\nSemantic Role Labeling:\")\n",
    "for pred in result2.predicates:\n",
    "    print(f\"\\nPredicate: {pred.predicate}\")\n",
    "    for arg in pred.arguments:\n",
    "        print(f\"  {arg.role}: {arg.text}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bce8b1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2_out = SemanticRoleLabeling.model_validate_json(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a11324c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"sentence\": \"Mary gave her friend a book at the library on Monday because she wanted to help.\", \"predicates\": [{\"predicate\": \"gave\", \"arguments\": [{\"role\": \"ARGM_LOC\", \"text\": \"at\"}, {\"role\": \"ARGM_MNR\", \"text\": \"the library\"}, {\"role\": \"ARGM_PRP\", \"text\": \"on\"}, {\"role\": \"ARGM_LOC\", \"text\": \"Monday\"}, {\"role\": \"ARGM_MNR\", \"text\": \"because\"}, {\"role\": \"ARGM_PRP\", \"text\": \"she\"}, {\"role\": \"ARGM_LOC\", \"text\": \"helped\"}]}]}\n"
     ]
    }
   ],
   "source": [
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f05834c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"srl_result_blame.json\", \"w\") as f:\n",
    "       json.dump(result_out.model_dump(), f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dfa1533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"srl_result2.json\", \"w\") as f:\n",
    "       json.dump(result2_out.model_dump(), f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "outlining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
