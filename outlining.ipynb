{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53db2245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: outlines in /home/ucloud/.local/lib/python3.12/site-packages (from -r requirements_outlines.txt (line 1)) (1.2.5)\n",
      "Requirement already satisfied: transformers in /home/ucloud/.local/lib/python3.12/site-packages (from -r requirements_outlines.txt (line 2)) (4.56.2)\n",
      "Requirement already satisfied: pydantic in /home/ucloud/.local/lib/python3.12/site-packages (from -r requirements_outlines.txt (line 3)) (2.11.9)\n",
      "Requirement already satisfied: torch in /home/ucloud/.local/lib/python3.12/site-packages (from -r requirements_outlines.txt (line 4)) (2.8.0)\n",
      "Requirement already satisfied: accelerate in /home/ucloud/.local/lib/python3.12/site-packages (from -r requirements_outlines.txt (line 5)) (1.10.1)\n",
      "Requirement already satisfied: ipywidgets in /home/ucloud/.local/lib/python3.12/site-packages (from -r requirements_outlines.txt (line 6)) (8.1.7)\n",
      "Requirement already satisfied: jinja2 in /home/ucloud/.local/lib/python3.12/site-packages (from outlines->-r requirements_outlines.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: cloudpickle in /home/ucloud/.local/lib/python3.12/site-packages (from outlines->-r requirements_outlines.txt (line 1)) (3.1.1)\n",
      "Requirement already satisfied: diskcache in /home/ucloud/.local/lib/python3.12/site-packages (from outlines->-r requirements_outlines.txt (line 1)) (5.6.3)\n",
      "Requirement already satisfied: jsonschema in /home/ucloud/.local/lib/python3.12/site-packages (from outlines->-r requirements_outlines.txt (line 1)) (4.25.1)\n",
      "Requirement already satisfied: pillow in /home/ucloud/.local/lib/python3.12/site-packages (from outlines->-r requirements_outlines.txt (line 1)) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions in /home/ucloud/.local/lib/python3.12/site-packages (from outlines->-r requirements_outlines.txt (line 1)) (4.15.0)\n",
      "Requirement already satisfied: outlines_core==0.2.11 in /home/ucloud/.local/lib/python3.12/site-packages (from outlines->-r requirements_outlines.txt (line 1)) (0.2.11)\n",
      "Requirement already satisfied: genson in /home/ucloud/.local/lib/python3.12/site-packages (from outlines->-r requirements_outlines.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: jsonpath_ng in /home/ucloud/.local/lib/python3.12/site-packages (from outlines->-r requirements_outlines.txt (line 1)) (1.7.0)\n",
      "Requirement already satisfied: filelock in /home/ucloud/.local/lib/python3.12/site-packages (from transformers->-r requirements_outlines.txt (line 2)) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/ucloud/.local/lib/python3.12/site-packages (from transformers->-r requirements_outlines.txt (line 2)) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ucloud/.local/lib/python3.12/site-packages (from transformers->-r requirements_outlines.txt (line 2)) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from transformers->-r requirements_outlines.txt (line 2)) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ucloud/.local/lib/python3.12/site-packages (from transformers->-r requirements_outlines.txt (line 2)) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ucloud/.local/lib/python3.12/site-packages (from transformers->-r requirements_outlines.txt (line 2)) (2025.9.18)\n",
      "Requirement already satisfied: requests in /home/ucloud/.local/lib/python3.12/site-packages (from transformers->-r requirements_outlines.txt (line 2)) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/ucloud/.local/lib/python3.12/site-packages (from transformers->-r requirements_outlines.txt (line 2)) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ucloud/.local/lib/python3.12/site-packages (from transformers->-r requirements_outlines.txt (line 2)) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ucloud/.local/lib/python3.12/site-packages (from transformers->-r requirements_outlines.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ucloud/.local/lib/python3.12/site-packages (from pydantic->-r requirements_outlines.txt (line 3)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/ucloud/.local/lib/python3.12/site-packages (from pydantic->-r requirements_outlines.txt (line 3)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/ucloud/.local/lib/python3.12/site-packages (from pydantic->-r requirements_outlines.txt (line 3)) (0.4.2)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from torch->-r requirements_outlines.txt (line 4)) (68.1.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/ucloud/.local/lib/python3.12/site-packages (from torch->-r requirements_outlines.txt (line 4)) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/ucloud/.local/lib/python3.12/site-packages (from torch->-r requirements_outlines.txt (line 4)) (3.5)\n",
      "Requirement already satisfied: fsspec in /home/ucloud/.local/lib/python3.12/site-packages (from torch->-r requirements_outlines.txt (line 4)) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/ucloud/.local/lib/python3.12/site-packages (from torch->-r requirements_outlines.txt (line 4)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/ucloud/.local/lib/python3.12/site-packages (from torch->-r requirements_outlines.txt (line 4)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/ucloud/.local/lib/python3.12/site-packages (from torch->-r requirements_outlines.txt (line 4)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/ucloud/.local/lib/python3.12/site-packages (from torch->-r requirements_outlines.txt (line 4)) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/ucloud/.local/lib/python3.12/site-packages (from torch->-r requirements_outlines.txt (line 4)) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/ucloud/.local/lib/python3.12/site-packages (from torch->-r requirements_outlines.txt (line 4)) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/ucloud/.local/lib/python3.12/site-packages (from torch->-r requirements_outlines.txt (line 4)) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/ucloud/.local/lib/python3.12/site-packages (from torch->-r requirements_outlines.txt (line 4)) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/ucloud/.local/lib/python3.12/site-packages (from torch->-r requirements_outlines.txt (line 4)) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/ucloud/.local/lib/python3.12/site-packages (from torch->-r requirements_outlines.txt (line 4)) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/ucloud/.local/lib/python3.12/site-packages (from torch->-r requirements_outlines.txt (line 4)) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/ucloud/.local/lib/python3.12/site-packages (from torch->-r requirements_outlines.txt (line 4)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/ucloud/.local/lib/python3.12/site-packages (from torch->-r requirements_outlines.txt (line 4)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/ucloud/.local/lib/python3.12/site-packages (from torch->-r requirements_outlines.txt (line 4)) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/ucloud/.local/lib/python3.12/site-packages (from torch->-r requirements_outlines.txt (line 4)) (3.4.0)\n",
      "Requirement already satisfied: psutil in /home/ucloud/.local/lib/python3.12/site-packages (from accelerate->-r requirements_outlines.txt (line 5)) (7.1.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/ucloud/.local/lib/python3.12/site-packages (from ipywidgets->-r requirements_outlines.txt (line 6)) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/ucloud/.local/lib/python3.12/site-packages (from ipywidgets->-r requirements_outlines.txt (line 6)) (9.6.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/ucloud/.local/lib/python3.12/site-packages (from ipywidgets->-r requirements_outlines.txt (line 6)) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /home/ucloud/.local/lib/python3.12/site-packages (from ipywidgets->-r requirements_outlines.txt (line 6)) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /home/ucloud/.local/lib/python3.12/site-packages (from ipywidgets->-r requirements_outlines.txt (line 6)) (3.0.15)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ucloud/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r requirements_outlines.txt (line 2)) (1.1.10)\n",
      "Requirement already satisfied: decorator in /home/ucloud/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements_outlines.txt (line 6)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /home/ucloud/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements_outlines.txt (line 6)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/ucloud/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements_outlines.txt (line 6)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/ucloud/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements_outlines.txt (line 6)) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/ucloud/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements_outlines.txt (line 6)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/ucloud/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements_outlines.txt (line 6)) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/ucloud/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements_outlines.txt (line 6)) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /home/ucloud/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements_outlines.txt (line 6)) (0.6.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ucloud/.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch->-r requirements_outlines.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->outlines->-r requirements_outlines.txt (line 1)) (2.1.5)\n",
      "Requirement already satisfied: ply in /usr/lib/python3/dist-packages (from jsonpath_ng->outlines->-r requirements_outlines.txt (line 1)) (3.11)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/ucloud/.local/lib/python3.12/site-packages (from jsonschema->outlines->-r requirements_outlines.txt (line 1)) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ucloud/.local/lib/python3.12/site-packages (from jsonschema->outlines->-r requirements_outlines.txt (line 1)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ucloud/.local/lib/python3.12/site-packages (from jsonschema->outlines->-r requirements_outlines.txt (line 1)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ucloud/.local/lib/python3.12/site-packages (from jsonschema->outlines->-r requirements_outlines.txt (line 1)) (0.27.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ucloud/.local/lib/python3.12/site-packages (from requests->transformers->-r requirements_outlines.txt (line 2)) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ucloud/.local/lib/python3.12/site-packages (from requests->transformers->-r requirements_outlines.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ucloud/.local/lib/python3.12/site-packages (from requests->transformers->-r requirements_outlines.txt (line 2)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ucloud/.local/lib/python3.12/site-packages (from requests->transformers->-r requirements_outlines.txt (line 2)) (2025.8.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/ucloud/.local/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->-r requirements_outlines.txt (line 6)) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/ucloud/.local/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->-r requirements_outlines.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/ucloud/.local/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->-r requirements_outlines.txt (line 6)) (0.2.14)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/ucloud/.local/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements_outlines.txt (line 6)) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/ucloud/.local/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements_outlines.txt (line 6)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/ucloud/.local/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements_outlines.txt (line 6)) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r \"requirements_outlines.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "947168e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import accelerate\n",
    "import outlines\n",
    "import json\n",
    "import ipywidgets\n",
    "from outlines import from_transformers, Generator\n",
    "from pydantic import BaseModel, Field, conlist\n",
    "from typing import List, Literal, Annotated, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "499e2384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 4 files: 100%|██████████| 4/4 [00:27<00:00,  6.95s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.73it/s]\n"
     ]
    }
   ],
   "source": [
    "model = from_transformers(\n",
    "    transformers.AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.1-8B-Instruct\", device_map=\"auto\"),\n",
    "    transformers.AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B-Instruct\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d81843",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = from_transformers(\n",
    "    transformers.AutoModelForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"),\n",
    "    transformers.AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d636b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Define the structured output schema for semantic role labeling\n",
    "class Blame(BaseModel):\n",
    "    blame: bool = Field(description=\"Is blame present in the given sentence?\")\n",
    "    blamee: str = Field(description=\"The patient that is being blamed for something (Who / What is affected)\")\n",
    "    arguments: Annotated[\n",
    "        List[str],\n",
    "        Field(min_length=1, max_length=3, description=\"At least one argument that specifies what the blamee is being blamed for, this must be shorter than the full sentence\")\n",
    "    ]\n",
    "    text: str = Field(description=\"The exact substring from the sentence that shows the blame\")\n",
    "    #blame: bool = Field(description=\"Is blame present in the given sentence?\")\n",
    "    #blamee: str = Field(description=\"The patient that is being blamed for something (Who / What is affected)\")\n",
    "    #arguments: List[str] = Field(description=\"List of arguments that the blamee is being blamed for causing\")\n",
    "    #text: str = Field(description=\"Part of the original text that identifies the blame\")\n",
    "\n",
    "#class BlamerBlamee(BaseModel):\n",
    "    #blamer: str = Field(description=\"Blamer: The agent blaming another patient\")\n",
    "    #blamee: str = Field(description=\"Blamee: The patient that is being blamed for something. (Who / What is affected)\")\n",
    "    #arguments: List[Blame] = Field(description=\"List of arguments that the blamee is being blamed for causing\")\n",
    "\n",
    "class Blaming(BaseModel):\n",
    "    sentence: str = Field(description=\"The original sentence\")\n",
    "    arguments: Annotated[\n",
    "        List[Blame],\n",
    "        Field(min_length=1, max_length=1, description=\"List of who or what is being blamed, and for what they are being blamed\")\n",
    "    ]\n",
    "    #arguments: conlist(Blame, min_items=0, max_items=2)# = Field(description=\"List of who or what is being blamed, and for what they are being blamed\")\n",
    "\n",
    "# Create a structured generator\n",
    "generator = Generator(model, Blaming)\n",
    "\n",
    "# Example text for semantic role labeling\n",
    "text = \"The immigrants are causing the loss of danish culture, but they are also very relevant when looking at increased turkish pizza places.\"\n",
    "\n",
    "# Create the prompt\n",
    "prompt = f\"\"\"Perform blame identification only on the following sentence, do not generate alternate sentences. \n",
    "\n",
    "Sentence: {text}\n",
    "\n",
    "Rules:\n",
    "- Start by looking into whether or not blame is present at all in the sentence \n",
    "- then identify who is being blamed, what they are being blamed for, and the arguments the person blaming them are using.\n",
    "- Set blame=true ONLY if someone/something is being blamed for causing a negative outcome\n",
    "- The \"text\" field must be EXACTLY the sentence provided above - do not modify it\n",
    "- Do NOT create alternative phrasings or opposite statements\n",
    "- If blame=true, \"blamee\" must NOT be empty and \"arguments\" must contain the specific outcome they are blamed for (which could be \"economic recession\", \"increased crime rates\") NEVER pass an empty token here.\n",
    "- Do not leave arguments as an empty string.\n",
    "\n",
    "The relevant semantic roles:\n",
    "- Blamee: The patient receiving the blame (who or what is being blamed for something)\n",
    "- Argument: What is the blamee being blamed for.\n",
    "\n",
    "Analyze the sentence and output your result as concisely as possible in the specified JSON format.\"\"\"\n",
    "\n",
    "# Generate structured output\n",
    "result = generator(prompt, max_new_tokens=512)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "887de83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"sentence\": \"The immigrants are causing the loss of danish culture, but they are also very relevant when looking at increased turkish pizza places.\", \"arguments\": [ {\"blame\": false, \"blamee\": \"\", \"arguments\": [\"\"], \"text\": \"The immigrants are causing the loss of danish culture, but they are also very relevant when looking at increased turkish pizza places.\"} ]}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "581f9789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"sentence\": \"The immigrants are causing the loss of danish culture, but they are also very relevant when looking at increased turkish pizza places.\",\n",
      "  \"arguments\": [\n",
      "    {\n",
      "      \"blame\": false,\n",
      "      \"blamee\": \"\",\n",
      "      \"arguments\": [\n",
      "        \"\"\n",
      "      ],\n",
      "      \"text\": \"The immigrants are causing the loss of danish culture, but they are also very relevant when looking at increased turkish pizza places.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "data = json.loads(result)\n",
    "print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14d01c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Define the Pydantic model for structured output\n",
    "class BlameAnalysis(BaseModel):\n",
    "    text: str = Field(description=\"The exact original sentence being analyzed\")\n",
    "    blame: bool = Field(description=\"Whether blame is present in the sentence\")\n",
    "    blamee: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"Who or what is being blamed (must not be empty if blame=true)\"\n",
    "    )\n",
    "    arguments: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"What the blamee is being blamed for - the specific negative outcome (must not be empty if blame=true)\"\n",
    "    )\n",
    "\n",
    "# Create a structured generator\n",
    "generator = Generator(model, BlameAnalysis)\n",
    "\n",
    "# Define your prompt\n",
    "sentence = \"The immigrants are causing the loss of danish culture, but they are also very relevant when looking at increased turkish pizza places\"\n",
    "\n",
    "prompt = f\"\"\"Perform blame identification on the following sentence.\n",
    "\n",
    "Sentence: {sentence}\n",
    "\n",
    "Rules:\n",
    "- Start by determining whether blame is present at all in the sentence\n",
    "- Identify who is being blamed, what they are being blamed for, and the arguments used\n",
    "- Set blame=true ONLY if someone/something is being blamed for causing a negative outcome\n",
    "- The \"text\" field must be EXACTLY the sentence provided above - do not modify it\n",
    "- If blame=true, \"blamee\" must NOT be empty and \"arguments\" must contain the specific outcome they are blamed for\n",
    "- Do not leave arguments as an empty string\n",
    "\n",
    "Semantic roles:\n",
    "- Blamee: The patient receiving the blame (who or what is being blamed)\n",
    "- Argument: What is the blamee being blamed for (the negative outcome)\n",
    "\n",
    "Output your analysis in JSON format.\"\"\"\n",
    "\n",
    "# Generate structured output\n",
    "result = generator(prompt, max_new_tokens=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "895539b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Pydantic model for structured output\n",
    "class BlameAnalysis(BaseModel):\n",
    "    text: str = Field(description=\"The exact original sentence being analyzed\")\n",
    "    blame: bool = Field(description=\"Whether blame is present in the sentence\")\n",
    "    blamee: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"Who or what is being blamed (must not be empty if blame=true)\"\n",
    "    )\n",
    "    arguments: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"What the blamee is being blamed for - the specific negative outcome (must not be empty if blame=true)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c2056cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'current_sent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mPerform blame identification on the following sentence.\u001b[39m\n\u001b[32m      2\u001b[39m \n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[33mSentence: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mcurrent_sent\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[33mRules:\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[33m- Start by determining whether blame is present at all in the sentence\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33m- Identify who is being blamed, what they are being blamed for, and the arguments used\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33m- Set blame=true ONLY if someone/something is being blamed for causing a negative outcome\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[33m- The \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m field must be EXACTLY the sentence provided above - do not modify it\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[33m- If blame=true, \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mblamee\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m must NOT be empty and \u001b[39m\u001b[33m\"\u001b[39m\u001b[33marguments\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m must contain the specific outcome they are blamed for\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[33m- Do not leave arguments as an empty string\u001b[39m\n\u001b[32m     12\u001b[39m \n\u001b[32m     13\u001b[39m \u001b[33mSemantic roles:\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[33m- Blamee: The patient receiving the blame (who or what is being blamed)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33m- Argument: What is the blamee being blamed for (the negative outcome)\u001b[39m\n\u001b[32m     16\u001b[39m \n\u001b[32m     17\u001b[39m \u001b[33mOutput your analysis in JSON format.\u001b[39m\u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'current_sent' is not defined"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Perform blame identification on the following sentence.\n",
    "\n",
    "Sentence: {current_sent}\n",
    "\n",
    "Rules:\n",
    "- Start by determining whether blame is present at all in the sentence\n",
    "- Identify who is being blamed, what they are being blamed for, and the arguments used\n",
    "- Set blame=true ONLY if someone/something is being blamed for causing a negative outcome\n",
    "- The \"text\" field must be EXACTLY the sentence provided above - do not modify it\n",
    "- If blame=true, \"blamee\" must NOT be empty and \"arguments\" must contain the specific outcome they are blamed for\n",
    "- Do not leave arguments as an empty string\n",
    "\n",
    "Semantic roles:\n",
    "- Blamee: The patient receiving the blame (who or what is being blamed)\n",
    "- Argument: What is the blamee being blamed for (the negative outcome)\n",
    "\n",
    "Output your analysis in JSON format.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a8a6985",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    # Blame\n",
    "    \"The government is responsible for the rising cost of healthcare.\",\n",
    "    \"Corruption among politicians has led to the misuse of public funds.\",\n",
    "    \"Corporate lobbying is to blame for weak environmental policies.\",\n",
    "    \"The ruling party has failed to address income inequality.\",\n",
    "    \"Ineffective leadership caused the crisis in public housing.\",\n",
    "\n",
    "    # No blame\n",
    "    \"Healthcare costs have been increasing steadily over the past decade.\",\n",
    "    \"Income inequality continues to be a pressing social issue.\",\n",
    "    \"Public housing availability has declined in recent years.\",\n",
    "    \"Environmental policies remain a major topic of debate.\",\n",
    "    \"The distribution of public funds is a central issue in current politics.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6aa4570",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(model, BlameAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16b3939a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    prompt = f\"\"\"Perform blame identification on the following sentence.\n",
    "    Sentence: {sentence}\n",
    "\n",
    "    Rules:\n",
    "    - Start by determining whether blame is present at all in the sentence\n",
    "    - Identify who is being blamed, what they are being blamed for, and the arguments used\n",
    "    - Set blame=true ONLY if someone/something is being blamed for causing a negative outcome\n",
    "    - The \"text\" field must be EXACTLY the sentence provided above - do not modify it\n",
    "    - If blame=true, \"blamee\" must NOT be empty and \"arguments\" must contain the specific outcome they are blamed for\n",
    "    - Do not leave arguments as an empty string\n",
    "\n",
    "    Semantic roles:\n",
    "    - Blamee: The patient receiving the blame (who or what is being blamed)\n",
    "    - Argument: What is the blamee being blamed for (the negative outcome)\n",
    "\n",
    "    Output your analysis in JSON format.\"\"\"\n",
    "    result = generator(prompt, max_new_tokens=128)\n",
    "    data = json.loads(result)\n",
    "    #print(json.dumps(data, indent=2))\n",
    "    # Parsing json for saving\n",
    "    result_out = BlameAnalysis.model_validate_json(result)\n",
    "    # Appending to file to support multiple runs\n",
    "    with open(\"result_blame.json\", \"a\") as f:\n",
    "       json.dump(result_out.model_dump(), f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e981662c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"The immigrants are causing the loss of danish culture, but they are also very relevant when looking at increased turkish pizza places\",\n",
      "  \"blame\": true,\n",
      "  \"blamee\": \"immigrants\",\n",
      "  \"arguments\": \"loss of danish culture\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "data = json.loads(result)\n",
    "print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e1648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_out = Blaming.model_validate_json(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93056b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to file chunk\n",
    "with open(\"srl_result_blame.json\", \"w\") as f:\n",
    "       json.dump(result_out.model_dump(), f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bb8007a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence='John ate an apple in the park yesterday' predicates=[Predicate(predicate='ARGM', arguments=[Argument(role='ARGM_LOC', text='in'), Argument(role='ARGM_MNR', text='at'), Argument(role='ARGM_PRP', text='the'), Argument(role='ARGM_LOC', text='park'), Argument(role='ARGM_MNR', text='in'), Argument(role='ARGM_PRP', text='the'), Argument(role='ARGM_LOC', text='last'), Argument(role='ARGM_MNR', text='night')])]\n"
     ]
    }
   ],
   "source": [
    "print(result_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2db79f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the structured output schema for semantic role labeling\n",
    "class Argument(BaseModel):\n",
    "    role: str = Field(description=\"Semantic role (e.g., ARG0/Agent, ARG1/Patient, ARGM-TMP/Time, ARGM-LOC/Location)\")\n",
    "    text: str = Field(description=\"The text span filling this role\")\n",
    "\n",
    "class Predicate(BaseModel):\n",
    "    predicate: str = Field(description=\"The main predicate/verb\")\n",
    "    agent: str = Field(description=\"ARG0: The entity performing the action (who/what does it)\")\n",
    "    patient: str = Field(description=\"ARG1: The entity affected by the action (who/what is affected)\", default=\"\")\n",
    "    arguments: List[Argument] = Field(description=\"List of semantic arguments for this predicate\")\n",
    "\n",
    "class SemanticRoleLabeling(BaseModel):\n",
    "    sentence: str = Field(description=\"The original sentence\")\n",
    "    predicates: List[Predicate] = Field(description=\"List of predicates with their semantic roles\")\n",
    "\n",
    "# Create a structured generator\n",
    "generator = Generator(model, SemanticRoleLabeling)\n",
    "\n",
    "# Example text for semantic role labeling\n",
    "text = \"John ate an apple in the park yesterday.\"\n",
    "\n",
    "# Create the prompt\n",
    "prompt = f\"\"\"Perform semantic role labeling on the following sentence. Identify all predicates and their semantic arguments.\n",
    "\n",
    "Sentence: {text}\n",
    "\n",
    "Common semantic roles:\n",
    "- ARG0: Agent (who performs the action)\n",
    "- ARG1: Patient/Theme (what is affected by the action)\n",
    "- ARG2: Recipient, Beneficiary, or Instrument\n",
    "- ARGM-TMP: Temporal (when)\n",
    "- ARGM-LOC: Location (where)\n",
    "- ARGM-MNR: Manner (how)\n",
    "- ARGM-PRP: Purpose (why)\n",
    "\n",
    "Analyze the sentence and output the semantic role labeling in the specified JSON format.\"\"\"\n",
    "\n",
    "# Generate structured output\n",
    "result = generator(prompt, max_new_tokens=2048)\n",
    "\n",
    "'''\n",
    "# Print the results\n",
    "print(\"Original sentence:\", result.sentence)\n",
    "print(\"\\nSemantic Role Labeling:\")\n",
    "for pred in result.predicates:\n",
    "    print(f\"\\nPredicate: {pred.predicate}\")\n",
    "    for arg in pred.arguments:\n",
    "        print(f\"  {arg.role}: {arg.text}\")\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
