{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 79,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.012658227848101266,
      "grad_norm": 3.2255325317382812,
      "learning_rate": 0.0001,
      "loss": 0.2717,
      "step": 1
    },
    {
      "epoch": 0.02531645569620253,
      "grad_norm": 5.936131000518799,
      "learning_rate": 9.957805907172997e-05,
      "loss": 0.3278,
      "step": 2
    },
    {
      "epoch": 0.0379746835443038,
      "grad_norm": 3.0019633769989014,
      "learning_rate": 9.915611814345992e-05,
      "loss": 0.3092,
      "step": 3
    },
    {
      "epoch": 0.05063291139240506,
      "grad_norm": 2.0255439281463623,
      "learning_rate": 9.873417721518988e-05,
      "loss": 0.2575,
      "step": 4
    },
    {
      "epoch": 0.06329113924050633,
      "grad_norm": 10.445018768310547,
      "learning_rate": 9.831223628691983e-05,
      "loss": 0.5642,
      "step": 5
    },
    {
      "epoch": 0.0759493670886076,
      "grad_norm": 8.164011001586914,
      "learning_rate": 9.78902953586498e-05,
      "loss": 0.4622,
      "step": 6
    },
    {
      "epoch": 0.08860759493670886,
      "grad_norm": 6.724480152130127,
      "learning_rate": 9.746835443037975e-05,
      "loss": 0.4294,
      "step": 7
    },
    {
      "epoch": 0.10126582278481013,
      "grad_norm": 5.121272087097168,
      "learning_rate": 9.704641350210972e-05,
      "loss": 0.3515,
      "step": 8
    },
    {
      "epoch": 0.11392405063291139,
      "grad_norm": 1.1718209981918335,
      "learning_rate": 9.662447257383967e-05,
      "loss": 0.2361,
      "step": 9
    },
    {
      "epoch": 0.12658227848101267,
      "grad_norm": 5.274511814117432,
      "learning_rate": 9.620253164556962e-05,
      "loss": 0.4183,
      "step": 10
    },
    {
      "epoch": 0.13924050632911392,
      "grad_norm": 3.9509999752044678,
      "learning_rate": 9.578059071729957e-05,
      "loss": 0.3357,
      "step": 11
    },
    {
      "epoch": 0.1518987341772152,
      "grad_norm": 3.816878080368042,
      "learning_rate": 9.535864978902954e-05,
      "loss": 0.3208,
      "step": 12
    },
    {
      "epoch": 0.16455696202531644,
      "grad_norm": 1.7339189052581787,
      "learning_rate": 9.493670886075949e-05,
      "loss": 0.3395,
      "step": 13
    },
    {
      "epoch": 0.17721518987341772,
      "grad_norm": 2.8172805309295654,
      "learning_rate": 9.451476793248946e-05,
      "loss": 0.2951,
      "step": 14
    },
    {
      "epoch": 0.189873417721519,
      "grad_norm": 0.8974289298057556,
      "learning_rate": 9.409282700421943e-05,
      "loss": 0.2062,
      "step": 15
    },
    {
      "epoch": 0.20253164556962025,
      "grad_norm": 5.326119899749756,
      "learning_rate": 9.367088607594936e-05,
      "loss": 0.39,
      "step": 16
    },
    {
      "epoch": 0.21518987341772153,
      "grad_norm": 3.894324541091919,
      "learning_rate": 9.324894514767933e-05,
      "loss": 0.2975,
      "step": 17
    },
    {
      "epoch": 0.22784810126582278,
      "grad_norm": 3.9985718727111816,
      "learning_rate": 9.282700421940928e-05,
      "loss": 0.3816,
      "step": 18
    },
    {
      "epoch": 0.24050632911392406,
      "grad_norm": 5.520809173583984,
      "learning_rate": 9.240506329113925e-05,
      "loss": 0.3398,
      "step": 19
    },
    {
      "epoch": 0.25316455696202533,
      "grad_norm": 2.9872121810913086,
      "learning_rate": 9.19831223628692e-05,
      "loss": 0.2654,
      "step": 20
    },
    {
      "epoch": 0.26582278481012656,
      "grad_norm": 1.3459199666976929,
      "learning_rate": 9.156118143459917e-05,
      "loss": 0.1986,
      "step": 21
    },
    {
      "epoch": 0.27848101265822783,
      "grad_norm": 1.5905078649520874,
      "learning_rate": 9.113924050632912e-05,
      "loss": 0.3124,
      "step": 22
    },
    {
      "epoch": 0.2911392405063291,
      "grad_norm": 1.431283712387085,
      "learning_rate": 9.071729957805908e-05,
      "loss": 0.2068,
      "step": 23
    },
    {
      "epoch": 0.3037974683544304,
      "grad_norm": 2.4091384410858154,
      "learning_rate": 9.029535864978903e-05,
      "loss": 0.2782,
      "step": 24
    },
    {
      "epoch": 0.31645569620253167,
      "grad_norm": 0.92051762342453,
      "learning_rate": 8.9873417721519e-05,
      "loss": 0.2652,
      "step": 25
    },
    {
      "epoch": 0.3291139240506329,
      "grad_norm": 1.7090729475021362,
      "learning_rate": 8.945147679324895e-05,
      "loss": 0.2234,
      "step": 26
    },
    {
      "epoch": 0.34177215189873417,
      "grad_norm": 3.464411973953247,
      "learning_rate": 8.902953586497891e-05,
      "loss": 0.3535,
      "step": 27
    },
    {
      "epoch": 0.35443037974683544,
      "grad_norm": 1.1274164915084839,
      "learning_rate": 8.860759493670887e-05,
      "loss": 0.287,
      "step": 28
    },
    {
      "epoch": 0.3670886075949367,
      "grad_norm": 1.1603777408599854,
      "learning_rate": 8.818565400843882e-05,
      "loss": 0.1936,
      "step": 29
    },
    {
      "epoch": 0.379746835443038,
      "grad_norm": 1.2419159412384033,
      "learning_rate": 8.776371308016879e-05,
      "loss": 0.1703,
      "step": 30
    },
    {
      "epoch": 0.3924050632911392,
      "grad_norm": 3.4801580905914307,
      "learning_rate": 8.734177215189874e-05,
      "loss": 0.2766,
      "step": 31
    },
    {
      "epoch": 0.4050632911392405,
      "grad_norm": 4.317643165588379,
      "learning_rate": 8.69198312236287e-05,
      "loss": 0.2797,
      "step": 32
    },
    {
      "epoch": 0.4177215189873418,
      "grad_norm": 1.5091791152954102,
      "learning_rate": 8.649789029535866e-05,
      "loss": 0.2779,
      "step": 33
    },
    {
      "epoch": 0.43037974683544306,
      "grad_norm": 1.4333523511886597,
      "learning_rate": 8.607594936708861e-05,
      "loss": 0.2189,
      "step": 34
    },
    {
      "epoch": 0.4430379746835443,
      "grad_norm": 5.8908185958862305,
      "learning_rate": 8.565400843881856e-05,
      "loss": 0.338,
      "step": 35
    },
    {
      "epoch": 0.45569620253164556,
      "grad_norm": 2.1405158042907715,
      "learning_rate": 8.523206751054853e-05,
      "loss": 0.262,
      "step": 36
    },
    {
      "epoch": 0.46835443037974683,
      "grad_norm": 1.928255319595337,
      "learning_rate": 8.481012658227848e-05,
      "loss": 0.2735,
      "step": 37
    },
    {
      "epoch": 0.4810126582278481,
      "grad_norm": 1.2634241580963135,
      "learning_rate": 8.438818565400845e-05,
      "loss": 0.2499,
      "step": 38
    },
    {
      "epoch": 0.4936708860759494,
      "grad_norm": 1.8778374195098877,
      "learning_rate": 8.39662447257384e-05,
      "loss": 0.2211,
      "step": 39
    },
    {
      "epoch": 0.5063291139240507,
      "grad_norm": 1.2848247289657593,
      "learning_rate": 8.354430379746835e-05,
      "loss": 0.1968,
      "step": 40
    },
    {
      "epoch": 0.5189873417721519,
      "grad_norm": 1.3075088262557983,
      "learning_rate": 8.312236286919831e-05,
      "loss": 0.2742,
      "step": 41
    },
    {
      "epoch": 0.5316455696202531,
      "grad_norm": 3.525006055831909,
      "learning_rate": 8.270042194092827e-05,
      "loss": 0.2763,
      "step": 42
    },
    {
      "epoch": 0.5443037974683544,
      "grad_norm": 3.5085320472717285,
      "learning_rate": 8.227848101265824e-05,
      "loss": 0.328,
      "step": 43
    },
    {
      "epoch": 0.5569620253164557,
      "grad_norm": 4.752373218536377,
      "learning_rate": 8.185654008438819e-05,
      "loss": 0.4671,
      "step": 44
    },
    {
      "epoch": 0.569620253164557,
      "grad_norm": 1.1499031782150269,
      "learning_rate": 8.143459915611815e-05,
      "loss": 0.2383,
      "step": 45
    },
    {
      "epoch": 0.5822784810126582,
      "grad_norm": 2.0514914989471436,
      "learning_rate": 8.10126582278481e-05,
      "loss": 0.3419,
      "step": 46
    },
    {
      "epoch": 0.5949367088607594,
      "grad_norm": 3.4552736282348633,
      "learning_rate": 8.059071729957806e-05,
      "loss": 0.3781,
      "step": 47
    },
    {
      "epoch": 0.6075949367088608,
      "grad_norm": 1.7675797939300537,
      "learning_rate": 8.016877637130802e-05,
      "loss": 0.2787,
      "step": 48
    },
    {
      "epoch": 0.620253164556962,
      "grad_norm": 2.1336567401885986,
      "learning_rate": 7.974683544303798e-05,
      "loss": 0.2536,
      "step": 49
    },
    {
      "epoch": 0.6329113924050633,
      "grad_norm": 2.004063367843628,
      "learning_rate": 7.932489451476794e-05,
      "loss": 0.2438,
      "step": 50
    },
    {
      "epoch": 0.6455696202531646,
      "grad_norm": 2.421466112136841,
      "learning_rate": 7.89029535864979e-05,
      "loss": 0.2024,
      "step": 51
    },
    {
      "epoch": 0.6582278481012658,
      "grad_norm": 3.015326976776123,
      "learning_rate": 7.848101265822784e-05,
      "loss": 0.289,
      "step": 52
    },
    {
      "epoch": 0.6708860759493671,
      "grad_norm": 2.422560930252075,
      "learning_rate": 7.805907172995781e-05,
      "loss": 0.2855,
      "step": 53
    },
    {
      "epoch": 0.6835443037974683,
      "grad_norm": 1.7738765478134155,
      "learning_rate": 7.763713080168776e-05,
      "loss": 0.2479,
      "step": 54
    },
    {
      "epoch": 0.6962025316455697,
      "grad_norm": 1.198279619216919,
      "learning_rate": 7.721518987341773e-05,
      "loss": 0.2962,
      "step": 55
    },
    {
      "epoch": 0.7088607594936709,
      "grad_norm": 1.0668933391571045,
      "learning_rate": 7.679324894514768e-05,
      "loss": 0.1452,
      "step": 56
    },
    {
      "epoch": 0.7215189873417721,
      "grad_norm": 1.779697299003601,
      "learning_rate": 7.637130801687765e-05,
      "loss": 0.2218,
      "step": 57
    },
    {
      "epoch": 0.7341772151898734,
      "grad_norm": 1.5562379360198975,
      "learning_rate": 7.59493670886076e-05,
      "loss": 0.2024,
      "step": 58
    },
    {
      "epoch": 0.7468354430379747,
      "grad_norm": 2.1289143562316895,
      "learning_rate": 7.552742616033755e-05,
      "loss": 0.2946,
      "step": 59
    },
    {
      "epoch": 0.759493670886076,
      "grad_norm": 2.4055440425872803,
      "learning_rate": 7.510548523206752e-05,
      "loss": 0.3721,
      "step": 60
    },
    {
      "epoch": 0.7721518987341772,
      "grad_norm": 3.3397326469421387,
      "learning_rate": 7.468354430379747e-05,
      "loss": 0.3709,
      "step": 61
    },
    {
      "epoch": 0.7848101265822784,
      "grad_norm": 1.6577234268188477,
      "learning_rate": 7.426160337552744e-05,
      "loss": 0.2243,
      "step": 62
    },
    {
      "epoch": 0.7974683544303798,
      "grad_norm": 6.468565464019775,
      "learning_rate": 7.383966244725739e-05,
      "loss": 0.2324,
      "step": 63
    },
    {
      "epoch": 0.810126582278481,
      "grad_norm": 1.2942875623703003,
      "learning_rate": 7.341772151898734e-05,
      "loss": 0.2007,
      "step": 64
    },
    {
      "epoch": 0.8227848101265823,
      "grad_norm": 2.2885570526123047,
      "learning_rate": 7.29957805907173e-05,
      "loss": 0.2435,
      "step": 65
    },
    {
      "epoch": 0.8354430379746836,
      "grad_norm": 1.4624768495559692,
      "learning_rate": 7.257383966244726e-05,
      "loss": 0.1904,
      "step": 66
    },
    {
      "epoch": 0.8481012658227848,
      "grad_norm": 2.2533915042877197,
      "learning_rate": 7.215189873417722e-05,
      "loss": 0.1891,
      "step": 67
    },
    {
      "epoch": 0.8607594936708861,
      "grad_norm": 1.4079869985580444,
      "learning_rate": 7.172995780590718e-05,
      "loss": 0.1711,
      "step": 68
    },
    {
      "epoch": 0.8734177215189873,
      "grad_norm": 2.078516960144043,
      "learning_rate": 7.130801687763713e-05,
      "loss": 0.2406,
      "step": 69
    },
    {
      "epoch": 0.8860759493670886,
      "grad_norm": 2.026370048522949,
      "learning_rate": 7.088607594936709e-05,
      "loss": 0.2281,
      "step": 70
    },
    {
      "epoch": 0.8987341772151899,
      "grad_norm": 3.581109046936035,
      "learning_rate": 7.046413502109705e-05,
      "loss": 0.286,
      "step": 71
    },
    {
      "epoch": 0.9113924050632911,
      "grad_norm": 1.7375619411468506,
      "learning_rate": 7.0042194092827e-05,
      "loss": 0.238,
      "step": 72
    },
    {
      "epoch": 0.9240506329113924,
      "grad_norm": 1.4049296379089355,
      "learning_rate": 6.962025316455697e-05,
      "loss": 0.2592,
      "step": 73
    },
    {
      "epoch": 0.9367088607594937,
      "grad_norm": 1.7302360534667969,
      "learning_rate": 6.919831223628693e-05,
      "loss": 0.1645,
      "step": 74
    },
    {
      "epoch": 0.9493670886075949,
      "grad_norm": 1.417008876800537,
      "learning_rate": 6.877637130801688e-05,
      "loss": 0.2538,
      "step": 75
    },
    {
      "epoch": 0.9620253164556962,
      "grad_norm": 2.027297258377075,
      "learning_rate": 6.835443037974683e-05,
      "loss": 0.263,
      "step": 76
    },
    {
      "epoch": 0.9746835443037974,
      "grad_norm": 3.7345874309539795,
      "learning_rate": 6.79324894514768e-05,
      "loss": 0.3012,
      "step": 77
    },
    {
      "epoch": 0.9873417721518988,
      "grad_norm": 2.245330572128296,
      "learning_rate": 6.751054852320675e-05,
      "loss": 0.3513,
      "step": 78
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.1530632972717285,
      "learning_rate": 6.708860759493672e-05,
      "loss": 0.0814,
      "step": 79
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8604651162790697,
      "eval_f1": 0.8486803519061583,
      "eval_keras_BCE": 0.3869037330150604,
      "eval_loss": 0.4184030294418335,
      "eval_precision": 0.7653061224489796,
      "eval_recall": 0.8522727272727273,
      "eval_runtime": 1.4754,
      "eval_samples_per_second": 174.865,
      "eval_steps_per_second": 22.366,
      "eval_weighted_BCE": 25.37068748474121,
      "step": 79
    }
  ],
  "logging_steps": 1,
  "max_steps": 237,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3512520929280000.0,
  "train_batch_size": 128,
  "trial_name": null,
  "trial_params": null
}
