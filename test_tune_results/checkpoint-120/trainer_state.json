{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 120,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.025,
      "grad_norm": 3.3106822967529297,
      "learning_rate": 0.0001,
      "loss": 0.2828,
      "step": 1
    },
    {
      "epoch": 0.05,
      "grad_norm": 5.557693958282471,
      "learning_rate": 9.916666666666667e-05,
      "loss": 0.3496,
      "step": 2
    },
    {
      "epoch": 0.075,
      "grad_norm": 6.275685787200928,
      "learning_rate": 9.833333333333333e-05,
      "loss": 0.2937,
      "step": 3
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.1007232666015625,
      "learning_rate": 9.75e-05,
      "loss": 0.2127,
      "step": 4
    },
    {
      "epoch": 0.125,
      "grad_norm": 2.8638288974761963,
      "learning_rate": 9.666666666666667e-05,
      "loss": 0.238,
      "step": 5
    },
    {
      "epoch": 0.15,
      "grad_norm": 4.671922206878662,
      "learning_rate": 9.583333333333334e-05,
      "loss": 0.2701,
      "step": 6
    },
    {
      "epoch": 0.175,
      "grad_norm": 4.929488182067871,
      "learning_rate": 9.5e-05,
      "loss": 0.3643,
      "step": 7
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.3187053203582764,
      "learning_rate": 9.416666666666667e-05,
      "loss": 0.2885,
      "step": 8
    },
    {
      "epoch": 0.225,
      "grad_norm": 1.00714111328125,
      "learning_rate": 9.333333333333334e-05,
      "loss": 0.3291,
      "step": 9
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.6390000581741333,
      "learning_rate": 9.250000000000001e-05,
      "loss": 0.1857,
      "step": 10
    },
    {
      "epoch": 0.275,
      "grad_norm": 3.1588025093078613,
      "learning_rate": 9.166666666666667e-05,
      "loss": 0.2641,
      "step": 11
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.1697726249694824,
      "learning_rate": 9.083333333333334e-05,
      "loss": 0.2697,
      "step": 12
    },
    {
      "epoch": 0.325,
      "grad_norm": 1.5488171577453613,
      "learning_rate": 9e-05,
      "loss": 0.3221,
      "step": 13
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.1025944948196411,
      "learning_rate": 8.916666666666667e-05,
      "loss": 0.2365,
      "step": 14
    },
    {
      "epoch": 0.375,
      "grad_norm": 1.4276318550109863,
      "learning_rate": 8.833333333333333e-05,
      "loss": 0.2205,
      "step": 15
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.9977416396141052,
      "learning_rate": 8.75e-05,
      "loss": 0.2397,
      "step": 16
    },
    {
      "epoch": 0.425,
      "grad_norm": 1.1919646263122559,
      "learning_rate": 8.666666666666667e-05,
      "loss": 0.2718,
      "step": 17
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.6869924068450928,
      "learning_rate": 8.583333333333334e-05,
      "loss": 0.2669,
      "step": 18
    },
    {
      "epoch": 0.475,
      "grad_norm": 1.6199865341186523,
      "learning_rate": 8.5e-05,
      "loss": 0.3148,
      "step": 19
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.084200143814087,
      "learning_rate": 8.416666666666668e-05,
      "loss": 0.2156,
      "step": 20
    },
    {
      "epoch": 0.525,
      "grad_norm": 1.1874934434890747,
      "learning_rate": 8.333333333333334e-05,
      "loss": 0.2019,
      "step": 21
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.2516647577285767,
      "learning_rate": 8.25e-05,
      "loss": 0.3354,
      "step": 22
    },
    {
      "epoch": 0.575,
      "grad_norm": 3.741093397140503,
      "learning_rate": 8.166666666666667e-05,
      "loss": 0.247,
      "step": 23
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.417109489440918,
      "learning_rate": 8.083333333333334e-05,
      "loss": 0.202,
      "step": 24
    },
    {
      "epoch": 0.625,
      "grad_norm": 1.0145726203918457,
      "learning_rate": 8e-05,
      "loss": 0.2288,
      "step": 25
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.0482689142227173,
      "learning_rate": 7.916666666666666e-05,
      "loss": 0.2399,
      "step": 26
    },
    {
      "epoch": 0.675,
      "grad_norm": 2.2743942737579346,
      "learning_rate": 7.833333333333333e-05,
      "loss": 0.226,
      "step": 27
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.8802700042724609,
      "learning_rate": 7.75e-05,
      "loss": 0.1787,
      "step": 28
    },
    {
      "epoch": 0.725,
      "grad_norm": 1.3780481815338135,
      "learning_rate": 7.666666666666667e-05,
      "loss": 0.2228,
      "step": 29
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.3813416957855225,
      "learning_rate": 7.583333333333334e-05,
      "loss": 0.2625,
      "step": 30
    },
    {
      "epoch": 0.775,
      "grad_norm": 1.3802765607833862,
      "learning_rate": 7.500000000000001e-05,
      "loss": 0.235,
      "step": 31
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.6873868703842163,
      "learning_rate": 7.416666666666668e-05,
      "loss": 0.2634,
      "step": 32
    },
    {
      "epoch": 0.825,
      "grad_norm": 2.7326314449310303,
      "learning_rate": 7.333333333333333e-05,
      "loss": 0.2151,
      "step": 33
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.366076707839966,
      "learning_rate": 7.25e-05,
      "loss": 0.2304,
      "step": 34
    },
    {
      "epoch": 0.875,
      "grad_norm": 1.3608806133270264,
      "learning_rate": 7.166666666666667e-05,
      "loss": 0.2203,
      "step": 35
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.1076841354370117,
      "learning_rate": 7.083333333333334e-05,
      "loss": 0.2335,
      "step": 36
    },
    {
      "epoch": 0.925,
      "grad_norm": 2.1447510719299316,
      "learning_rate": 7e-05,
      "loss": 0.3243,
      "step": 37
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.9919836521148682,
      "learning_rate": 6.916666666666666e-05,
      "loss": 0.2508,
      "step": 38
    },
    {
      "epoch": 0.975,
      "grad_norm": 1.1844605207443237,
      "learning_rate": 6.833333333333333e-05,
      "loss": 0.2403,
      "step": 39
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.1246761083602905,
      "learning_rate": 6.750000000000001e-05,
      "loss": 0.0289,
      "step": 40
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8488372093023255,
      "eval_f1": 0.8410803127221038,
      "eval_keras_BCE": 0.3949611186981201,
      "eval_loss": 0.3628733456134796,
      "eval_precision": 0.7168141592920354,
      "eval_recall": 0.9204545454545454,
      "eval_runtime": 1.3979,
      "eval_samples_per_second": 184.56,
      "eval_steps_per_second": 23.607,
      "eval_weighted_BCE": 25.899038314819336,
      "step": 40
    },
    {
      "epoch": 1.025,
      "grad_norm": 2.092397689819336,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.2408,
      "step": 41
    },
    {
      "epoch": 1.05,
      "grad_norm": 1.6980018615722656,
      "learning_rate": 6.583333333333334e-05,
      "loss": 0.1896,
      "step": 42
    },
    {
      "epoch": 1.075,
      "grad_norm": 1.6341081857681274,
      "learning_rate": 6.500000000000001e-05,
      "loss": 0.1811,
      "step": 43
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.2877366542816162,
      "learning_rate": 6.416666666666668e-05,
      "loss": 0.191,
      "step": 44
    },
    {
      "epoch": 1.125,
      "grad_norm": 4.4722371101379395,
      "learning_rate": 6.333333333333333e-05,
      "loss": 0.2215,
      "step": 45
    },
    {
      "epoch": 1.15,
      "grad_norm": 3.0863118171691895,
      "learning_rate": 6.25e-05,
      "loss": 0.2541,
      "step": 46
    },
    {
      "epoch": 1.175,
      "grad_norm": 1.1164238452911377,
      "learning_rate": 6.166666666666667e-05,
      "loss": 0.1173,
      "step": 47
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.8928176164627075,
      "learning_rate": 6.083333333333333e-05,
      "loss": 0.145,
      "step": 48
    },
    {
      "epoch": 1.225,
      "grad_norm": 1.45603346824646,
      "learning_rate": 6e-05,
      "loss": 0.2971,
      "step": 49
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.2700088024139404,
      "learning_rate": 5.916666666666667e-05,
      "loss": 0.2474,
      "step": 50
    },
    {
      "epoch": 1.275,
      "grad_norm": 2.7426905632019043,
      "learning_rate": 5.833333333333334e-05,
      "loss": 0.1487,
      "step": 51
    },
    {
      "epoch": 1.3,
      "grad_norm": 4.312984466552734,
      "learning_rate": 5.7499999999999995e-05,
      "loss": 0.2566,
      "step": 52
    },
    {
      "epoch": 1.325,
      "grad_norm": 4.243932247161865,
      "learning_rate": 5.666666666666667e-05,
      "loss": 0.2026,
      "step": 53
    },
    {
      "epoch": 1.35,
      "grad_norm": 1.7143473625183105,
      "learning_rate": 5.583333333333334e-05,
      "loss": 0.1693,
      "step": 54
    },
    {
      "epoch": 1.375,
      "grad_norm": 0.8533796668052673,
      "learning_rate": 5.500000000000001e-05,
      "loss": 0.1003,
      "step": 55
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.775903582572937,
      "learning_rate": 5.4166666666666664e-05,
      "loss": 0.1701,
      "step": 56
    },
    {
      "epoch": 1.425,
      "grad_norm": 2.277599334716797,
      "learning_rate": 5.333333333333333e-05,
      "loss": 0.2233,
      "step": 57
    },
    {
      "epoch": 1.45,
      "grad_norm": 2.277714252471924,
      "learning_rate": 5.25e-05,
      "loss": 0.1406,
      "step": 58
    },
    {
      "epoch": 1.475,
      "grad_norm": 3.2660467624664307,
      "learning_rate": 5.166666666666667e-05,
      "loss": 0.2121,
      "step": 59
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.5725390911102295,
      "learning_rate": 5.0833333333333333e-05,
      "loss": 0.1108,
      "step": 60
    },
    {
      "epoch": 1.525,
      "grad_norm": 1.9415587186813354,
      "learning_rate": 5e-05,
      "loss": 0.1951,
      "step": 61
    },
    {
      "epoch": 1.55,
      "grad_norm": 1.7815648317337036,
      "learning_rate": 4.9166666666666665e-05,
      "loss": 0.1617,
      "step": 62
    },
    {
      "epoch": 1.575,
      "grad_norm": 1.3004217147827148,
      "learning_rate": 4.8333333333333334e-05,
      "loss": 0.115,
      "step": 63
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.026400089263916,
      "learning_rate": 4.75e-05,
      "loss": 0.1591,
      "step": 64
    },
    {
      "epoch": 1.625,
      "grad_norm": 1.5890254974365234,
      "learning_rate": 4.666666666666667e-05,
      "loss": 0.1659,
      "step": 65
    },
    {
      "epoch": 1.65,
      "grad_norm": 2.3358943462371826,
      "learning_rate": 4.5833333333333334e-05,
      "loss": 0.2891,
      "step": 66
    },
    {
      "epoch": 1.675,
      "grad_norm": 1.6208256483078003,
      "learning_rate": 4.5e-05,
      "loss": 0.1845,
      "step": 67
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.8701584339141846,
      "learning_rate": 4.4166666666666665e-05,
      "loss": 0.1248,
      "step": 68
    },
    {
      "epoch": 1.725,
      "grad_norm": 2.60701060295105,
      "learning_rate": 4.3333333333333334e-05,
      "loss": 0.1758,
      "step": 69
    },
    {
      "epoch": 1.75,
      "grad_norm": 3.357503890991211,
      "learning_rate": 4.25e-05,
      "loss": 0.1878,
      "step": 70
    },
    {
      "epoch": 1.775,
      "grad_norm": 1.3283143043518066,
      "learning_rate": 4.166666666666667e-05,
      "loss": 0.1655,
      "step": 71
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.9858325719833374,
      "learning_rate": 4.0833333333333334e-05,
      "loss": 0.1646,
      "step": 72
    },
    {
      "epoch": 1.825,
      "grad_norm": 2.2796919345855713,
      "learning_rate": 4e-05,
      "loss": 0.1017,
      "step": 73
    },
    {
      "epoch": 1.85,
      "grad_norm": 1.6136269569396973,
      "learning_rate": 3.9166666666666665e-05,
      "loss": 0.2248,
      "step": 74
    },
    {
      "epoch": 1.875,
      "grad_norm": 1.847779393196106,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 0.2401,
      "step": 75
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.1012606620788574,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 0.1292,
      "step": 76
    },
    {
      "epoch": 1.925,
      "grad_norm": 1.4806522130966187,
      "learning_rate": 3.6666666666666666e-05,
      "loss": 0.1643,
      "step": 77
    },
    {
      "epoch": 1.95,
      "grad_norm": 1.9715673923492432,
      "learning_rate": 3.5833333333333335e-05,
      "loss": 0.1839,
      "step": 78
    },
    {
      "epoch": 1.975,
      "grad_norm": 1.3334189653396606,
      "learning_rate": 3.5e-05,
      "loss": 0.1021,
      "step": 79
    },
    {
      "epoch": 2.0,
      "grad_norm": 5.037999153137207,
      "learning_rate": 3.4166666666666666e-05,
      "loss": 0.0868,
      "step": 80
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8449612403100775,
      "eval_f1": 0.8378582202111614,
      "eval_keras_BCE": 0.4749823808670044,
      "eval_loss": 0.4233801066875458,
      "eval_precision": 0.7068965517241379,
      "eval_recall": 0.9318181818181818,
      "eval_runtime": 1.4022,
      "eval_samples_per_second": 183.995,
      "eval_steps_per_second": 23.534,
      "eval_weighted_BCE": 31.14632225036621,
      "step": 80
    },
    {
      "epoch": 2.025,
      "grad_norm": 1.608906626701355,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.1241,
      "step": 81
    },
    {
      "epoch": 2.05,
      "grad_norm": 2.5568416118621826,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 0.143,
      "step": 82
    },
    {
      "epoch": 2.075,
      "grad_norm": 1.09221351146698,
      "learning_rate": 3.1666666666666666e-05,
      "loss": 0.1246,
      "step": 83
    },
    {
      "epoch": 2.1,
      "grad_norm": 1.9229758977890015,
      "learning_rate": 3.0833333333333335e-05,
      "loss": 0.189,
      "step": 84
    },
    {
      "epoch": 2.125,
      "grad_norm": 1.1573246717453003,
      "learning_rate": 3e-05,
      "loss": 0.1465,
      "step": 85
    },
    {
      "epoch": 2.15,
      "grad_norm": 2.5371623039245605,
      "learning_rate": 2.916666666666667e-05,
      "loss": 0.197,
      "step": 86
    },
    {
      "epoch": 2.175,
      "grad_norm": 1.5401612520217896,
      "learning_rate": 2.8333333333333335e-05,
      "loss": 0.1472,
      "step": 87
    },
    {
      "epoch": 2.2,
      "grad_norm": 2.43890118598938,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 0.1449,
      "step": 88
    },
    {
      "epoch": 2.225,
      "grad_norm": 1.4530327320098877,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.1231,
      "step": 89
    },
    {
      "epoch": 2.25,
      "grad_norm": 1.5935224294662476,
      "learning_rate": 2.5833333333333336e-05,
      "loss": 0.0651,
      "step": 90
    },
    {
      "epoch": 2.275,
      "grad_norm": 1.1208735704421997,
      "learning_rate": 2.5e-05,
      "loss": 0.0988,
      "step": 91
    },
    {
      "epoch": 2.3,
      "grad_norm": 3.215034246444702,
      "learning_rate": 2.4166666666666667e-05,
      "loss": 0.1269,
      "step": 92
    },
    {
      "epoch": 2.325,
      "grad_norm": 1.4917165040969849,
      "learning_rate": 2.3333333333333336e-05,
      "loss": 0.0893,
      "step": 93
    },
    {
      "epoch": 2.35,
      "grad_norm": 1.808058738708496,
      "learning_rate": 2.25e-05,
      "loss": 0.1326,
      "step": 94
    },
    {
      "epoch": 2.375,
      "grad_norm": 1.6560883522033691,
      "learning_rate": 2.1666666666666667e-05,
      "loss": 0.0987,
      "step": 95
    },
    {
      "epoch": 2.4,
      "grad_norm": 2.9793102741241455,
      "learning_rate": 2.0833333333333336e-05,
      "loss": 0.176,
      "step": 96
    },
    {
      "epoch": 2.425,
      "grad_norm": 2.0836329460144043,
      "learning_rate": 2e-05,
      "loss": 0.2096,
      "step": 97
    },
    {
      "epoch": 2.45,
      "grad_norm": 2.1534383296966553,
      "learning_rate": 1.9166666666666667e-05,
      "loss": 0.1781,
      "step": 98
    },
    {
      "epoch": 2.475,
      "grad_norm": 3.882798671722412,
      "learning_rate": 1.8333333333333333e-05,
      "loss": 0.14,
      "step": 99
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.888293981552124,
      "learning_rate": 1.75e-05,
      "loss": 0.1111,
      "step": 100
    },
    {
      "epoch": 2.525,
      "grad_norm": 1.762364387512207,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.1512,
      "step": 101
    },
    {
      "epoch": 2.55,
      "grad_norm": 1.5200424194335938,
      "learning_rate": 1.5833333333333333e-05,
      "loss": 0.1237,
      "step": 102
    },
    {
      "epoch": 2.575,
      "grad_norm": 1.8271571397781372,
      "learning_rate": 1.5e-05,
      "loss": 0.1942,
      "step": 103
    },
    {
      "epoch": 2.6,
      "grad_norm": 1.5778250694274902,
      "learning_rate": 1.4166666666666668e-05,
      "loss": 0.1565,
      "step": 104
    },
    {
      "epoch": 2.625,
      "grad_norm": 5.880560874938965,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.1143,
      "step": 105
    },
    {
      "epoch": 2.65,
      "grad_norm": 7.649332523345947,
      "learning_rate": 1.25e-05,
      "loss": 0.1447,
      "step": 106
    },
    {
      "epoch": 2.675,
      "grad_norm": 2.4010837078094482,
      "learning_rate": 1.1666666666666668e-05,
      "loss": 0.1874,
      "step": 107
    },
    {
      "epoch": 2.7,
      "grad_norm": 1.5836738348007202,
      "learning_rate": 1.0833333333333334e-05,
      "loss": 0.0725,
      "step": 108
    },
    {
      "epoch": 2.725,
      "grad_norm": 1.335714340209961,
      "learning_rate": 1e-05,
      "loss": 0.0778,
      "step": 109
    },
    {
      "epoch": 2.75,
      "grad_norm": 1.4687600135803223,
      "learning_rate": 9.166666666666666e-06,
      "loss": 0.1361,
      "step": 110
    },
    {
      "epoch": 2.775,
      "grad_norm": 1.9179794788360596,
      "learning_rate": 8.333333333333334e-06,
      "loss": 0.207,
      "step": 111
    },
    {
      "epoch": 2.8,
      "grad_norm": 3.9368484020233154,
      "learning_rate": 7.5e-06,
      "loss": 0.1406,
      "step": 112
    },
    {
      "epoch": 2.825,
      "grad_norm": 2.828841209411621,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.2113,
      "step": 113
    },
    {
      "epoch": 2.85,
      "grad_norm": 1.1937049627304077,
      "learning_rate": 5.833333333333334e-06,
      "loss": 0.1089,
      "step": 114
    },
    {
      "epoch": 2.875,
      "grad_norm": 2.341186046600342,
      "learning_rate": 5e-06,
      "loss": 0.1282,
      "step": 115
    },
    {
      "epoch": 2.9,
      "grad_norm": 1.616553544998169,
      "learning_rate": 4.166666666666667e-06,
      "loss": 0.1081,
      "step": 116
    },
    {
      "epoch": 2.925,
      "grad_norm": 3.4951255321502686,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.1618,
      "step": 117
    },
    {
      "epoch": 2.95,
      "grad_norm": 4.5884809494018555,
      "learning_rate": 2.5e-06,
      "loss": 0.1449,
      "step": 118
    },
    {
      "epoch": 2.975,
      "grad_norm": 3.31260347366333,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 0.0993,
      "step": 119
    },
    {
      "epoch": 3.0,
      "grad_norm": 6.077022552490234,
      "learning_rate": 8.333333333333333e-07,
      "loss": 0.1047,
      "step": 120
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8410852713178295,
      "eval_f1": 0.8316757634104037,
      "eval_keras_BCE": 0.459271639585495,
      "eval_loss": 0.42626556754112244,
      "eval_precision": 0.7155963302752294,
      "eval_recall": 0.8863636363636364,
      "eval_runtime": 1.4018,
      "eval_samples_per_second": 184.049,
      "eval_steps_per_second": 23.541,
      "eval_weighted_BCE": 30.116113662719727,
      "step": 120
    }
  ],
  "logging_steps": 1,
  "max_steps": 120,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5268781393920000.0,
  "train_batch_size": 128,
  "trial_name": null,
  "trial_params": null
}
