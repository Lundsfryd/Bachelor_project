{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87955353",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas spacy swifter\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import swifter\n",
    "import ast\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c0b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -m spacy download da_core_news_sm\n",
    "nlp = spacy.load(\"da_core_news_sm\")\n",
    "\n",
    "def split_paragraph(paragraph: str):\n",
    "    doc = nlp.pipe([paragraph], batch_size=1, n_process=1)\n",
    "    return [sent.text.strip() for sent in list(doc)[0].sents]\n",
    "\n",
    "\n",
    "def danish_sentences_extraction(data, text_column):\n",
    "\n",
    "    sentences = {}\n",
    "\n",
    "    for para in data.index:\n",
    "        text_sentences = data.loc[para][text_column]\n",
    "        \n",
    "        blame_sentence_dict = {}\n",
    "        for indx in range(len(text_sentences)):\n",
    "            blame_sentence = text_sentences[indx]\n",
    "            blame_sentence_dict[indx] = blame_sentence\n",
    "        \n",
    "        \n",
    "        sentences[para] = blame_sentence_dict\n",
    "\n",
    "    return sentences\n",
    "\n",
    "\n",
    "#------------------------------------------#\n",
    "def convert_to_json_and_write(file_name, sentences):\n",
    "    with open(f'/work/MarkusLundsfrydJensen#1865/inferece_data/{file_name}.json', 'w') as file:\n",
    "        file.write(json.dumps(sentences, indent=4))\n",
    "\n",
    "\n",
    "\n",
    "    #preprocess data for label studio\n",
    "    # Load your data\n",
    "    with open(f'/work/MarkusLundsfrydJensen#1865/inferece_data/{file_name}.json', \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    flattened = []\n",
    "\n",
    "    for paragraph, sentences in data.items():\n",
    "        for sentence_nr, text in sentences.items():\n",
    "            flattened.append({\n",
    "                \"paragraph\": paragraph,\n",
    "                \"sentence_nr\": sentence_nr,\n",
    "                \"text\": text\n",
    "            })\n",
    "\n",
    "    # Save in a format Label Studio can import\n",
    "    with open(f'/work/MarkusLundsfrydJensen#1865/inferece_data/{file_name}.json', \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(flattened, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "#final data is csv file as output of PolDebate model\n",
    "\n",
    "def json_append_meta_data(file_name, data):\n",
    "    meta_data = data[['Unnamed: 0','speaker','party']]\n",
    "    meta_data = meta_data.replace({np.nan: None})\n",
    "    #meta_data.head()\n",
    "\n",
    "\n",
    "    #connect label studio data with meta data\n",
    "\n",
    "\n",
    "    # Load the flattened sentence JSON\n",
    "    with open(f\"/work/MarkusLundsfrydJensen#1865/inferece_data/{file_name}.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        sentences = json.load(f)\n",
    "\n",
    "    # Load metadata\n",
    "    meta = meta_data\n",
    "\n",
    "    # Convert metadata to dict for fast lookup\n",
    "    meta_dict = meta.set_index(\"Unnamed: 0\").to_dict(orient=\"index\")\n",
    "\n",
    "    # Merge\n",
    "    for item in sentences:\n",
    "        paragraph = int(item[\"paragraph\"])\n",
    "        if paragraph in meta_dict:\n",
    "\n",
    "            item.update(meta_dict[paragraph])\n",
    "\n",
    "    # Save merged dataset\n",
    "    with open(f'/work/MarkusLundsfrydJensen#1865/inferece_data/{file_name}.json', \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(sentences, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#find parties in government by dataset\n",
    "def find_government(gov_data, date):\n",
    "    match = gov_data[(gov_data[\"Start Date\"] <= date) & (gov_data[\"End Date\"] >= date)]\n",
    "    if not match.empty:\n",
    "\n",
    "        parties = match['Party Letter']\n",
    "        parties = ast.literal_eval(parties.iloc[0])\n",
    "        \n",
    "        return parties\n",
    "    else:\n",
    "        print('empty')\n",
    "        return None\n",
    "\n",
    "\n",
    "#append context and government related data to the json file\n",
    "def json_government_and_context(file_name, data, government_data):\n",
    "\n",
    "    # Load the flattened sentence JSON\n",
    "    with open(f\"/work/MarkusLundsfrydJensen#1865/inferece_data/{file_name}.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    for entry in json_data:\n",
    "        paragraph_nr = int(entry['paragraph'])\n",
    "        sentence_nr = int(entry['sentence_nr'])\n",
    "\n",
    "        #initialize information on current paragraph\n",
    "        temp_data = data.loc[paragraph_nr]\n",
    "\n",
    "        #Find out if speaker is member of party in Government\n",
    "        party = entry['party']\n",
    "        date = temp_data['date']\n",
    "        parties_gov = find_government(government_data, date)\n",
    "        if party in parties_gov:\n",
    "            in_gov = True\n",
    "        else:\n",
    "            in_gov = False\n",
    "        \n",
    "        #make into dict\n",
    "\n",
    "        context_dict = {'current_speaker_in_government': in_gov,\n",
    "                        'parties_in_government': parties_gov,\n",
    "                        'date': str(date)\n",
    "                        }\n",
    "\n",
    "        #update\n",
    "        entry.update(context_dict)\n",
    "\n",
    "    #save data\n",
    "    with open(f\"/work/MarkusLundsfrydJensen#1865/inferece_data/{file_name}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(json_data, f, ensure_ascii=False, indent=2)\n",
    "    return\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "def preprocess_json(input_path, output_path=None):\n",
    "    \"\"\"\n",
    "    Preprocesses a JSON file by filtering out entries based on the 'text' key.\n",
    "    \n",
    "    Criteria for deletion:\n",
    "      - 'text' is missing or empty\n",
    "      - 'text' length is <= 3\n",
    "      - 'text' contains '(' or ')'\n",
    "    \n",
    "    Parameters:\n",
    "        input_path (str): Path to the input JSON file.\n",
    "        output_path (str, optional): If provided, saves the filtered JSON here.\n",
    "    \n",
    "    Returns:\n",
    "        list: The filtered list of JSON entries.\n",
    "    \"\"\"\n",
    "    # Load JSON file\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Filter entries\n",
    "    filtered_data = [\n",
    "        entry for entry in data\n",
    "        if 'text' in entry\n",
    "        and entry['text']\n",
    "        and len(entry['text']) > 3\n",
    "        and '(' not in entry['text']\n",
    "        and ')' not in entry['text']\n",
    "    ]\n",
    "\n",
    "    # Optionally save to a new file\n",
    "    if output_path:\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(filtered_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    return filtered_data\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "127a1457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>agenda</th>\n",
       "      <th>speechnumber</th>\n",
       "      <th>speaker</th>\n",
       "      <th>party</th>\n",
       "      <th>party.facts.id</th>\n",
       "      <th>chair</th>\n",
       "      <th>terms</th>\n",
       "      <th>text</th>\n",
       "      <th>parliament</th>\n",
       "      <th>iso3country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36314</th>\n",
       "      <td>36314</td>\n",
       "      <td>2000-11-01</td>\n",
       "      <td>1) Spørgsmål til ministrene.</td>\n",
       "      <td>2</td>\n",
       "      <td>Henning Grove</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>181</td>\n",
       "      <td>Til at besvare spørgsmål i spørgetimen i dag h...</td>\n",
       "      <td>DK-Folketing</td>\n",
       "      <td>DNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36315</th>\n",
       "      <td>36315</td>\n",
       "      <td>2000-11-01</td>\n",
       "      <td>1) Spørgsmål til ministrene.</td>\n",
       "      <td>3</td>\n",
       "      <td>Frank Dahlgaard</td>\n",
       "      <td>UP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>187</td>\n",
       "      <td>Ministeren er jo ikke bare minister for fødeva...</td>\n",
       "      <td>DK-Folketing</td>\n",
       "      <td>DNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36316</th>\n",
       "      <td>36316</td>\n",
       "      <td>2000-11-01</td>\n",
       "      <td>1) Spørgsmål til ministrene.</td>\n",
       "      <td>4</td>\n",
       "      <td>Henrik Dam Kristensen</td>\n",
       "      <td>S</td>\n",
       "      <td>379.0</td>\n",
       "      <td>False</td>\n",
       "      <td>175</td>\n",
       "      <td>Først vil jeg gerne sige til hr. Frank Dahlgaa...</td>\n",
       "      <td>DK-Folketing</td>\n",
       "      <td>DNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36317</th>\n",
       "      <td>36317</td>\n",
       "      <td>2000-11-01</td>\n",
       "      <td>1) Spørgsmål til ministrene.</td>\n",
       "      <td>5</td>\n",
       "      <td>Frank Dahlgaard</td>\n",
       "      <td>UP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>173</td>\n",
       "      <td>Ja, vi har en stor eksport, men ministeren er ...</td>\n",
       "      <td>DK-Folketing</td>\n",
       "      <td>DNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36318</th>\n",
       "      <td>36318</td>\n",
       "      <td>2000-11-01</td>\n",
       "      <td>1) Spørgsmål til ministrene.</td>\n",
       "      <td>6</td>\n",
       "      <td>Henrik Dam Kristensen</td>\n",
       "      <td>S</td>\n",
       "      <td>379.0</td>\n",
       "      <td>False</td>\n",
       "      <td>138</td>\n",
       "      <td>Hr. Frank Dahlgaard har jo fuldstændig ret i, ...</td>\n",
       "      <td>DK-Folketing</td>\n",
       "      <td>DNK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0       date                        agenda  speechnumber  \\\n",
       "36314       36314 2000-11-01  1) Spørgsmål til ministrene.             2   \n",
       "36315       36315 2000-11-01  1) Spørgsmål til ministrene.             3   \n",
       "36316       36316 2000-11-01  1) Spørgsmål til ministrene.             4   \n",
       "36317       36317 2000-11-01  1) Spørgsmål til ministrene.             5   \n",
       "36318       36318 2000-11-01  1) Spørgsmål til ministrene.             6   \n",
       "\n",
       "                     speaker party  party.facts.id  chair  terms  \\\n",
       "36314          Henning Grove   NaN             NaN   True    181   \n",
       "36315        Frank Dahlgaard    UP             NaN  False    187   \n",
       "36316  Henrik Dam Kristensen     S           379.0  False    175   \n",
       "36317        Frank Dahlgaard    UP             NaN  False    173   \n",
       "36318  Henrik Dam Kristensen     S           379.0  False    138   \n",
       "\n",
       "                                                    text    parliament  \\\n",
       "36314  Til at besvare spørgsmål i spørgetimen i dag h...  DK-Folketing   \n",
       "36315  Ministeren er jo ikke bare minister for fødeva...  DK-Folketing   \n",
       "36316  Først vil jeg gerne sige til hr. Frank Dahlgaa...  DK-Folketing   \n",
       "36317  Ja, vi har en stor eksport, men ministeren er ...  DK-Folketing   \n",
       "36318  Hr. Frank Dahlgaard har jo fuldstændig ret i, ...  DK-Folketing   \n",
       "\n",
       "      iso3country  \n",
       "36314         DNK  \n",
       "36315         DNK  \n",
       "36316         DNK  \n",
       "36317         DNK  \n",
       "36318         DNK  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fist create inference dataset\n",
    "\n",
    "df = pd.read_csv(\"/work/MarkusLundsfrydJensen#1865/Bachelor_project/Corp_Folketing_V2.csv\")\n",
    "\n",
    "# Convert the column to datetime (specify format if necessary)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], errors='coerce', dayfirst=True)\n",
    "\n",
    "# Filter rows after January 1, 2000\n",
    "filtered_df = df[df[\"date\"] > \"2000-01-01\"]\n",
    "\n",
    "#filtered_df.pop(\"Unnamed: 0\")\n",
    "\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f2ea215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a2a45d5dea4a41beb1af3aac5d4f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/293615 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/swifter/swifter.py:311\u001b[39m, in \u001b[36mSeriesAccessor.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, **kwds)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m suppress_stdout_stderr_logging():\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     tmp_df = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    312\u001b[39m     sample_df = sample.apply(func, convert_dtype=convert_dtype, args=args, **kwds)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36msplit_paragraph\u001b[39m\u001b[34m(paragraph)\u001b[39m\n\u001b[32m      5\u001b[39m doc = nlp.pipe([paragraph], batch_size=\u001b[32m1\u001b[39m, n_process=\u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [sent.text.strip() \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m].sents]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/language.py:1622\u001b[39m, in \u001b[36mLanguage.pipe\u001b[39m\u001b[34m(self, texts, as_tuples, batch_size, disable, component_cfg, n_process)\u001b[39m\n\u001b[32m   1621\u001b[39m         docs = pipe(docs)\n\u001b[32m-> \u001b[39m\u001b[32m1622\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1623\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/util.py:1714\u001b[39m, in \u001b[36m_pipe\u001b[39m\u001b[34m(docs, proc, name, default_error_handler, kwargs)\u001b[39m\n\u001b[32m   1713\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[33m\"\u001b[39m\u001b[33mpipe\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1714\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m proc.pipe(docs, **kwargs)\n\u001b[32m   1715\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1716\u001b[39m     \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/pipeline/transition_parser.pyx:245\u001b[39m, in \u001b[36mpipe\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/util.py:1661\u001b[39m, in \u001b[36mminibatch\u001b[39m\u001b[34m(items, size)\u001b[39m\n\u001b[32m   1660\u001b[39m batch_size = \u001b[38;5;28mnext\u001b[39m(size_)\n\u001b[32m-> \u001b[39m\u001b[32m1661\u001b[39m batch = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1662\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/util.py:1714\u001b[39m, in \u001b[36m_pipe\u001b[39m\u001b[34m(docs, proc, name, default_error_handler, kwargs)\u001b[39m\n\u001b[32m   1713\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[33m\"\u001b[39m\u001b[33mpipe\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1714\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m proc.pipe(docs, **kwargs)\n\u001b[32m   1715\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1716\u001b[39m     \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/pipeline/pipe.pyx:48\u001b[39m, in \u001b[36mpipe\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/util.py:1714\u001b[39m, in \u001b[36m_pipe\u001b[39m\u001b[34m(docs, proc, name, default_error_handler, kwargs)\u001b[39m\n\u001b[32m   1713\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[33m\"\u001b[39m\u001b[33mpipe\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1714\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m proc.pipe(docs, **kwargs)\n\u001b[32m   1715\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1716\u001b[39m     \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/pipeline/trainable_pipe.pyx:73\u001b[39m, in \u001b[36mpipe\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/util.py:1661\u001b[39m, in \u001b[36mminibatch\u001b[39m\u001b[34m(items, size)\u001b[39m\n\u001b[32m   1660\u001b[39m batch_size = \u001b[38;5;28mnext\u001b[39m(size_)\n\u001b[32m-> \u001b[39m\u001b[32m1661\u001b[39m batch = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1662\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/util.py:1714\u001b[39m, in \u001b[36m_pipe\u001b[39m\u001b[34m(docs, proc, name, default_error_handler, kwargs)\u001b[39m\n\u001b[32m   1713\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[33m\"\u001b[39m\u001b[33mpipe\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1714\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m proc.pipe(docs, **kwargs)\n\u001b[32m   1715\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1716\u001b[39m     \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/pipeline/transition_parser.pyx:245\u001b[39m, in \u001b[36mpipe\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/util.py:1661\u001b[39m, in \u001b[36mminibatch\u001b[39m\u001b[34m(items, size)\u001b[39m\n\u001b[32m   1660\u001b[39m batch_size = \u001b[38;5;28mnext\u001b[39m(size_)\n\u001b[32m-> \u001b[39m\u001b[32m1661\u001b[39m batch = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1662\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/util.py:1714\u001b[39m, in \u001b[36m_pipe\u001b[39m\u001b[34m(docs, proc, name, default_error_handler, kwargs)\u001b[39m\n\u001b[32m   1713\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[33m\"\u001b[39m\u001b[33mpipe\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1714\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m proc.pipe(docs, **kwargs)\n\u001b[32m   1715\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1716\u001b[39m     \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/pipeline/trainable_pipe.pyx:73\u001b[39m, in \u001b[36mpipe\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/util.py:1661\u001b[39m, in \u001b[36mminibatch\u001b[39m\u001b[34m(items, size)\u001b[39m\n\u001b[32m   1660\u001b[39m batch_size = \u001b[38;5;28mnext\u001b[39m(size_)\n\u001b[32m-> \u001b[39m\u001b[32m1661\u001b[39m batch = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1662\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/util.py:1714\u001b[39m, in \u001b[36m_pipe\u001b[39m\u001b[34m(docs, proc, name, default_error_handler, kwargs)\u001b[39m\n\u001b[32m   1713\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[33m\"\u001b[39m\u001b[33mpipe\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1714\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m proc.pipe(docs, **kwargs)\n\u001b[32m   1715\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1716\u001b[39m     \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/pipeline/trainable_pipe.pyx:73\u001b[39m, in \u001b[36mpipe\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/util.py:1661\u001b[39m, in \u001b[36mminibatch\u001b[39m\u001b[34m(items, size)\u001b[39m\n\u001b[32m   1660\u001b[39m batch_size = \u001b[38;5;28mnext\u001b[39m(size_)\n\u001b[32m-> \u001b[39m\u001b[32m1661\u001b[39m batch = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1662\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/language.py:1619\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1617\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1618\u001b[39m     \u001b[38;5;66;03m# if n_process == 1, no processes are forked.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1619\u001b[39m     docs = (\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ensure_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts)\n\u001b[32m   1620\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m pipe \u001b[38;5;129;01min\u001b[39;00m pipes:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/language.py:1135\u001b[39m, in \u001b[36mLanguage._ensure_doc\u001b[39m\u001b[34m(self, doc_like)\u001b[39m\n\u001b[32m   1134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Doc(\u001b[38;5;28mself\u001b[39m.vocab).from_bytes(doc_like)\n\u001b[32m-> \u001b[39m\u001b[32m1135\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors.E1041.format(\u001b[38;5;28mtype\u001b[39m=\u001b[38;5;28mtype\u001b[39m(doc_like)))\n",
      "\u001b[31mValueError\u001b[39m: [E1041] Expected a string, Doc, or bytes as input, but got: <class 'pandas.core.series.Series'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m filtered_df[\u001b[33m'\u001b[39m\u001b[33msegmented_text\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mfiltered_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mswifter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_paragraph\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/swifter/swifter.py:329\u001b[39m, in \u001b[36mSeriesAccessor.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, **kwds)\u001b[39m\n\u001b[32m    327\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._parallel_apply(func, convert_dtype, *args, **kwds)\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# use pandas\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pandas_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/swifter/swifter.py:235\u001b[39m, in \u001b[36mSeriesAccessor._pandas_apply\u001b[39m\u001b[34m(self, df, func, convert_dtype, *args, **kwds)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._progress_bar:\n\u001b[32m    234\u001b[39m     tqdm.pandas(desc=\u001b[38;5;28mself\u001b[39m._progress_bar_desc \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mPandas Apply\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    237\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df.apply(func, convert_dtype=convert_dtype, args=args, **kwds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/tqdm/std.py:917\u001b[39m, in \u001b[36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[39m\u001b[34m(df, func, *args, **kwargs)\u001b[39m\n\u001b[32m    914\u001b[39m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[32m    915\u001b[39m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    919\u001b[39m     t.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/pandas/core/series.py:4935\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4800\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4801\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4802\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4807\u001b[39m     **kwargs,\n\u001b[32m   4808\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4809\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4810\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4811\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4926\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4927\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4928\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4929\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4930\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4931\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4932\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4933\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4934\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4935\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/pandas/core/apply.py:1422\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1421\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/pandas/core/apply.py:1502\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1501\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1507\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1508\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/pandas/core/base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/pandas/core/algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/tqdm/std.py:912\u001b[39m, in \u001b[36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    906\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    907\u001b[39m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[32m    908\u001b[39m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[32m    909\u001b[39m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[32m    910\u001b[39m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[32m    911\u001b[39m     t.update(n=\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.total \u001b[38;5;129;01mor\u001b[39;00m t.n < t.total \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m912\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36msplit_paragraph\u001b[39m\u001b[34m(paragraph)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msplit_paragraph\u001b[39m(paragraph: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m      5\u001b[39m     doc = nlp.pipe([paragraph], batch_size=\u001b[32m1\u001b[39m, n_process=\u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [sent.text.strip() \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m].sents]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/language.py:1622\u001b[39m, in \u001b[36mLanguage.pipe\u001b[39m\u001b[34m(self, texts, as_tuples, batch_size, disable, component_cfg, n_process)\u001b[39m\n\u001b[32m   1620\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m pipe \u001b[38;5;129;01min\u001b[39;00m pipes:\n\u001b[32m   1621\u001b[39m         docs = pipe(docs)\n\u001b[32m-> \u001b[39m\u001b[32m1622\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1623\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/util.py:1714\u001b[39m, in \u001b[36m_pipe\u001b[39m\u001b[34m(docs, proc, name, default_error_handler, kwargs)\u001b[39m\n\u001b[32m   1704\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_pipe\u001b[39m(\n\u001b[32m   1705\u001b[39m     docs: Iterable[\u001b[33m\"\u001b[39m\u001b[33mDoc\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   1706\u001b[39m     proc: \u001b[33m\"\u001b[39m\u001b[33mPipeCallable\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1711\u001b[39m     kwargs: Mapping[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[32m   1712\u001b[39m ) -> Iterator[\u001b[33m\"\u001b[39m\u001b[33mDoc\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1713\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[33m\"\u001b[39m\u001b[33mpipe\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1714\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m proc.pipe(docs, **kwargs)\n\u001b[32m   1715\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1716\u001b[39m         \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[32m   1717\u001b[39m         kwargs = \u001b[38;5;28mdict\u001b[39m(kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/pipeline/transition_parser.pyx:252\u001b[39m, in \u001b[36mpipe\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/pipeline/transition_parser.pyx:343\u001b[39m, in \u001b[36mspacy.pipeline.transition_parser.Parser.set_annotations\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/pipeline/_parser_internals/ner.pyx:275\u001b[39m, in \u001b[36mspacy.pipeline._parser_internals.ner.BiluoPushDown.set_annotations\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/tokens/doc.pyx:814\u001b[39m, in \u001b[36mspacy.tokens.doc.Doc.set_ents\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/site-packages/spacy/tokens/doc.pyx:127\u001b[39m, in \u001b[36mspacy.tokens.doc.SetEntsDefault.values\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.13/enum.py:807\u001b[39m, in \u001b[36mEnumType.__members__\u001b[39m\u001b[34m(cls)\u001b[39m\n\u001b[32m    802\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    803\u001b[39m \u001b[33;03m    Return the number of members (no aliases)\u001b[39;00m\n\u001b[32m    804\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mcls\u001b[39m._member_names_)\n\u001b[32m--> \u001b[39m\u001b[32m807\u001b[39m \u001b[38;5;129m@bltns\u001b[39m.property\n\u001b[32m    808\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__members__\u001b[39m(\u001b[38;5;28mcls\u001b[39m):\n\u001b[32m    809\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    810\u001b[39m \u001b[33;03m    Returns a mapping of member name->value.\u001b[39;00m\n\u001b[32m    811\u001b[39m \n\u001b[32m    812\u001b[39m \u001b[33;03m    This mapping lists all enum members, including aliases. Note that this\u001b[39;00m\n\u001b[32m    813\u001b[39m \u001b[33;03m    is a read-only view of the internal mapping.\u001b[39;00m\n\u001b[32m    814\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    815\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m MappingProxyType(\u001b[38;5;28mcls\u001b[39m._member_map_)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "filtered_df['segmented_text'] = filtered_df['text'].swifter.apply(split_paragraph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3ce593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract dish sentences and make into json \n",
    "# format using modified function and inspiration from prelim blame detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed878a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m all_sentences = \u001b[43mdanish_sentences_extraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_column\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msegmented_text\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#all_sentences\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mdanish_sentences_extraction\u001b[39m\u001b[34m(data, text_column)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m para \u001b[38;5;129;01min\u001b[39;00m data.index:\n\u001b[32m      9\u001b[39m     text_sentences = data.loc[para][text_column]\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_sentences\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     11\u001b[39m     blame_sentence_dict = {}\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m indx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(text_sentences)):\n",
      "\u001b[31mTypeError\u001b[39m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "all_sentences = danish_sentences_extraction(filtered_df, text_column = 'segmented_text')\n",
    "\n",
    "#all_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a432b549",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "convert_to_json_and_write(file_name = 'inference_data',sentences = all_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023d56a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "json_append_meta_data(file_name = 'inference_data', data = filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b1126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get government data\n",
    "regerings_data = pd.read_csv(\"/work/MarkusLundsfrydJensen#1865/Bachelor_project/danish_govs.csv\")\n",
    "\n",
    "#make date related columns into datetime objects\n",
    "regerings_data[\"Start Date\"] = pd.to_datetime(regerings_data[\"Start Date\"], format=\"%Y-%m-%d\")\n",
    "regerings_data[\"End Date\"]   = pd.to_datetime(regerings_data[\"End Date\"], format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a1287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_government_and_context(file_name = 'inference_data', data = filtered_df, government_data = regerings_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380afae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO some cleanup\n",
    "\n",
    "preprocess_json(input_path = \"hello\", output_path=\"preprocessed_hello\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blame_bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
