{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 38,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 55.78028869628906,
      "learning_rate": 0.0008,
      "loss": 17.4833,
      "step": 1
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 31.6874942779541,
      "learning_rate": 0.0007929824561403509,
      "loss": 9.5889,
      "step": 2
    },
    {
      "epoch": 0.08,
      "grad_norm": Infinity,
      "learning_rate": 0.0007859649122807017,
      "loss": 12.8305,
      "step": 3
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 62.25056076049805,
      "learning_rate": 0.0007789473684210527,
      "loss": 11.8912,
      "step": 4
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 72.38682556152344,
      "learning_rate": 0.0007719298245614035,
      "loss": 12.5137,
      "step": 5
    },
    {
      "epoch": 0.16,
      "grad_norm": 26.00053596496582,
      "learning_rate": 0.0007649122807017545,
      "loss": 10.1511,
      "step": 6
    },
    {
      "epoch": 0.18666666666666668,
      "grad_norm": 6.020503044128418,
      "learning_rate": 0.0007578947368421053,
      "loss": 8.9423,
      "step": 7
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": NaN,
      "learning_rate": 0.0007508771929824562,
      "loss": 8.82,
      "step": 8
    },
    {
      "epoch": 0.24,
      "grad_norm": 14.533181190490723,
      "learning_rate": 0.0007438596491228071,
      "loss": 8.3592,
      "step": 9
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 28.546518325805664,
      "learning_rate": 0.0007368421052631579,
      "loss": 8.5653,
      "step": 10
    },
    {
      "epoch": 0.29333333333333333,
      "grad_norm": 18.31330680847168,
      "learning_rate": 0.0007298245614035088,
      "loss": 9.3543,
      "step": 11
    },
    {
      "epoch": 0.32,
      "grad_norm": 19.0422420501709,
      "learning_rate": 0.0007228070175438597,
      "loss": 8.051,
      "step": 12
    },
    {
      "epoch": 0.3466666666666667,
      "grad_norm": 18.41335678100586,
      "learning_rate": 0.0007157894736842105,
      "loss": 8.3871,
      "step": 13
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 7.2806291580200195,
      "learning_rate": 0.0007087719298245614,
      "loss": 8.64,
      "step": 14
    },
    {
      "epoch": 0.4,
      "grad_norm": NaN,
      "learning_rate": 0.0007017543859649122,
      "loss": 7.6937,
      "step": 15
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": Infinity,
      "learning_rate": 0.0006947368421052632,
      "loss": 8.5563,
      "step": 16
    },
    {
      "epoch": 0.4533333333333333,
      "grad_norm": 13.380133628845215,
      "learning_rate": 0.0006877192982456141,
      "loss": 8.5427,
      "step": 17
    },
    {
      "epoch": 0.48,
      "grad_norm": 9.369707107543945,
      "learning_rate": 0.000680701754385965,
      "loss": 7.7853,
      "step": 18
    },
    {
      "epoch": 0.5066666666666667,
      "grad_norm": 4.855607986450195,
      "learning_rate": 0.0006736842105263158,
      "loss": 7.6599,
      "step": 19
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 18.16205596923828,
      "learning_rate": 0.0006666666666666668,
      "loss": 8.189,
      "step": 20
    },
    {
      "epoch": 0.56,
      "grad_norm": 16.384531021118164,
      "learning_rate": 0.0006596491228070176,
      "loss": 7.8885,
      "step": 21
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 5.370431900024414,
      "learning_rate": 0.0006526315789473684,
      "loss": 7.8535,
      "step": 22
    },
    {
      "epoch": 0.6133333333333333,
      "grad_norm": 11.053662300109863,
      "learning_rate": 0.0006456140350877193,
      "loss": 7.597,
      "step": 23
    },
    {
      "epoch": 0.64,
      "grad_norm": 9.3399076461792,
      "learning_rate": 0.0006385964912280702,
      "loss": 7.4914,
      "step": 24
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 7.10645866394043,
      "learning_rate": 0.0006315789473684211,
      "loss": 7.4043,
      "step": 25
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 26.193994522094727,
      "learning_rate": 0.0006245614035087719,
      "loss": 7.4508,
      "step": 26
    },
    {
      "epoch": 0.72,
      "grad_norm": 12.388811111450195,
      "learning_rate": 0.0006175438596491228,
      "loss": 7.1561,
      "step": 27
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 14.610482215881348,
      "learning_rate": 0.0006105263157894738,
      "loss": 6.9896,
      "step": 28
    },
    {
      "epoch": 0.7733333333333333,
      "grad_norm": 24.24787712097168,
      "learning_rate": 0.0006035087719298246,
      "loss": 7.0931,
      "step": 29
    },
    {
      "epoch": 0.8,
      "grad_norm": 5.944859981536865,
      "learning_rate": 0.0005964912280701755,
      "loss": 6.4756,
      "step": 30
    },
    {
      "epoch": 0.8266666666666667,
      "grad_norm": 18.312475204467773,
      "learning_rate": 0.0005894736842105263,
      "loss": 6.7283,
      "step": 31
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 33.201473236083984,
      "learning_rate": 0.0005824561403508773,
      "loss": 7.7886,
      "step": 32
    },
    {
      "epoch": 0.88,
      "grad_norm": 23.723119735717773,
      "learning_rate": 0.0005754385964912281,
      "loss": 7.0873,
      "step": 33
    },
    {
      "epoch": 0.9066666666666666,
      "grad_norm": 25.75808334350586,
      "learning_rate": 0.0005684210526315789,
      "loss": 7.0654,
      "step": 34
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 5.700085639953613,
      "learning_rate": 0.0005614035087719298,
      "loss": 5.8759,
      "step": 35
    },
    {
      "epoch": 0.96,
      "grad_norm": 37.026771545410156,
      "learning_rate": 0.0005543859649122807,
      "loss": 6.3407,
      "step": 36
    },
    {
      "epoch": 0.9866666666666667,
      "grad_norm": 7.929635524749756,
      "learning_rate": 0.0005473684210526316,
      "loss": 5.418,
      "step": 37
    },
    {
      "epoch": 1.0,
      "grad_norm": 5.222239017486572,
      "learning_rate": 0.0005403508771929825,
      "loss": 2.5202,
      "step": 38
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.7215909090909091,
      "eval_f1": 0.7126769948359153,
      "eval_loss": 0.5952281951904297,
      "eval_runtime": 32.933,
      "eval_samples_per_second": 5.344,
      "eval_steps_per_second": 0.668,
      "step": 38
    }
  ],
  "logging_steps": 1,
  "max_steps": 114,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.972332232704e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
