{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71799c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/MarkusLundsfrydJensen#1865/miniconda3/envs/blame_bert/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#load packages\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a4bcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next step -> implement batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c7aaae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OBS need to be made usable\n",
    "class BlameDetectorDa(object):\n",
    "\n",
    "    def __init__(self, model_path, max_length = 512):\n",
    "\n",
    "        self.model_path = model_path\n",
    "        self.max_length = max_length\n",
    "        #self.batch_size = batch_size\n",
    "\n",
    "        self.model_initialization()\n",
    "\n",
    "        return\n",
    "\n",
    "    def model_initialization(self):\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            self.model_path,\n",
    "            device_map = 'auto'\n",
    "        )\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)\n",
    "        \n",
    "            \n",
    "        # Move to GPU if available\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        print(f\"Model loaded successfully on {self.device}\")\n",
    "\n",
    "        return\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"Make a prediction on a single text input.\"\"\"\n",
    "        # Tokenize input\n",
    "        inputs = self.tokenizer(\n",
    "            self.text,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "       \n",
    "        # Move inputs to device\n",
    "        inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
    "        # Make prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probabilities = torch.softmax(logits, dim=1)\n",
    "            predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "            confidence = probabilities[0][predicted_class].item()\n",
    "        \n",
    "        return predicted_class, confidence, probabilities[0].cpu().numpy()\n",
    "\n",
    "    def run_prediction(self, text):\n",
    "\n",
    "        self.text = text\n",
    "        predicted_class, confidence, probs = self.predict()\n",
    "            \n",
    "        return predicted_class, confidence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1295b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 12:26:32.017384: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-29 12:26:32.084633: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-29 12:26:33.439445: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully on cuda\n"
     ]
    }
   ],
   "source": [
    "BD = BlameDetectorDa(model_path = \"/work/MarkusLundsfrydJensen#1865/test_models_save/Option_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e485a6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7635658914728682\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "json_path = \"/work/MarkusLundsfrydJensen#1865/Bachelor_project/Model_data/validation_set.json\"\n",
    "\n",
    "with open(json_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for entry in data:\n",
    "    text = entry[\"text\"]\n",
    "\n",
    "    entry[\"pred\"], _ = BD.run_prediction(text)\n",
    "\n",
    "    \n",
    "\n",
    "true_labels = 0\n",
    "pred_true = 0\n",
    "false_labels = 0\n",
    "pred_false = 0\n",
    "\n",
    "correct_pred = 0\n",
    "incorrect_pred = 0\n",
    "\n",
    "for entry in data:\n",
    "    if entry[\"label\"] == 1:\n",
    "        true_labels += 1\n",
    "    if entry[\"pred\"] == 1:\n",
    "        pred_true +=1\n",
    "\n",
    "    if entry[\"label\"] == 0:\n",
    "        false_labels += 1\n",
    "    if entry[\"pred\"] == 0:\n",
    "        pred_false +=1\n",
    "\n",
    "    if entry[\"label\"] == entry[\"pred\"]:\n",
    "        correct_pred +=1\n",
    "\n",
    "    if entry[\"label\"] != entry[\"pred\"]:\n",
    "        incorrect_pred +=1\n",
    "\n",
    "\n",
    "print(correct_pred/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa97f962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
